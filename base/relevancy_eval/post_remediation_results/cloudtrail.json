{
    "test_cases_lookup_map": {
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"lambda.amazonaws.com\\\", \\\"EventName\\\": \\\"Create*\\\"}\", \"hyperparameters\": null, \"input\": \"Are there spikes in Lambda function creations that could indicate an overprovisioning or misconfiguration issue?\", \"retrieval_context\": [\" - CloudFormation stack creation events (**EventSource: cloudformation.amazonaws.com**, **EventName: Create\\\\*** ) represent API calls initiating the provisioning of AWS infrastructure and resources via CloudFormation templates. These events in CloudTrail help SREs monitor the start of environment setups and infrastructure deployments as part of Infrastructure as Code workflows.\\n\\n**Purpose:** Track and audit when new CloudFormation stacks or stack components are being created, enabling visibility into changes in infrastructure state and deployment activities.\\n\\n**Alert Thresholds:**  \\n- Trigger an alert if the number of Create* events exceeds a baseline threshold within a short time window (e.g., >10 stack creation attempts in 5 minutes), which may indicate automated deployment loops, misconfigurations, or potential security incidents.  \\n- Alert if Create* events spike unexpectedly outside of scheduled deployment windows or change management periods.\\n\\n**Impact of Values:**  \\n- **High volume:** May signal rapid infrastructure changes that could lead to instability, resource contention, or deployment failures. It could also indicate unauthorized or accidental mass provisioning.  \\n- **Low or zero volume:** Normal during steady-state operations; however, a sudden drop during expected deployment windows might indicate pipeline failures or blocked deployments.\\n\\n**Example Usage:**  \\n- **Dashboard:** Visualize the count of CloudFormation Create* events over time, segmented by stack name or user identity, to correlate deployments with system performance or incidents.  \\n- **Alert Rule:**  \\n  ```  \\n  WHEN count(events where EventSource=\\\"cloudformation.amazonaws.com\\\" AND EventName LIKE \\\"Create%\\\") > 10 within 5 minutes  \\n  THEN trigger alert \\\"High rate of CloudFormation stack creation events detected\\\"  \\n  ```  \\nThis enables proactive detection of abnormal infrastructure provisioning activity and supports rapid investigation and response.\", \" - Redshift cluster creation events in CloudTrail capture all API calls initiating the provisioning of new Redshift clusters (e.g., CreateCluster). These events indicate when new data warehouse resources are being deployed or configured, impacting capacity and cost.  \\n**Purpose:** Enables SREs to monitor and audit cluster provisioning activities for operational control and security compliance.  \\n**Alert Threshold:** Trigger alerts on an unusually high number of cluster creation events within a short time window (e.g., >3 creates in 1 hour), which may indicate automation errors, misconfigurations, or unauthorized resource provisioning.  \\n**Impact:**  \\n- **High values:** May lead to resource sprawl, increased costs, and potential performance degradation due to over-provisioning. Could also signal security risks if unexpected clusters are created.  \\n- **Low or zero values:** Normal in stable environments; no new clusters being created means stable infrastructure.  \\n**Example Alert Rule:**  \\n\\u201cAlert if count of events with EventSource='redshift.amazonaws.com' and EventName starting with 'Create' exceeds 3 within 60 minutes.\\u201d  \\n**Dashboard Use:** Visualize the frequency of Redshift cluster creation events over time to detect spikes or anomalies, correlating with deployment activities or security incidents.\", \" - S3 bucket creation events captured by CloudTrail under **{\\\"EventSource\\\": \\\"s3.amazonaws.com\\\", \\\"EventName\\\": \\\"Create*\\\"}** indicate when new buckets or related resources (e.g., bucket policies, access points) are provisioned. These events help SREs monitor infrastructure changes that affect data storage, security posture, and compliance.\\n\\n**Purpose:**  \\nTrack and audit the creation of S3 buckets and associated configurations to ensure proper governance, prevent unauthorized resource sprawl, and maintain compliance with organizational policies.\\n\\n**Alert Threshold:**  \\nTrigger an alert if the number of S3 bucket creation events exceeds a defined threshold within a short time window (e.g., more than 5 bucket creations within 10 minutes), which may indicate automated provisioning errors, misconfigurations, or potential security incidents such as unauthorized resource creation.\\n\\n**Impact of Values:**  \\n- **High frequency:** May signal abnormal activity, such as a compromised credential or runaway automation scripts creating excessive buckets, leading to increased costs, security risks, or compliance violations.  \\n- **Low or zero frequency:** Normal in stable environments; however, sudden spikes should be investigated promptly.\\n\\n**Example Alert Rule:**  \\n\\u201cAlert when count of events with EventSource = 's3.amazonaws.com' and EventName starting with 'Create' exceeds 5 within 10 minutes.\\u201d\\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of S3 Create* events over time, with thresholds marked to highlight unusual spikes, enabling quick identification of abnormal bucket creation activity.\", \" - This pattern captures all Route 53 resource creation events recorded in CloudTrail, such as the creation of hosted zones, DNS record sets, and health checks. Monitoring these events helps SREs detect configuration changes that could impact DNS resolution and application availability. \\n\\n**Purpose:** Track when new Route 53 resources are created to identify potential unauthorized changes or misconfigurations early.\\n\\n**Alert Threshold:** Trigger an alert if the number of creation events exceeds a baseline threshold (e.g., more than 5 creation events within 10 minutes), which may indicate automated misconfigurations, security breaches, or unintended mass changes.\\n\\n**Impact:**  \\n- **High values:** A spike in creation events could lead to DNS inconsistencies, increased attack surface, or service disruptions if malicious or erroneous resources are introduced.  \\n- **Low or zero values:** Normal operation, assuming no planned infrastructure changes.\\n\\n**Example Alert Rule:**  \\nAlert when `count({\\\"EventSource\\\": \\\"route53.amazonaws.com\\\", \\\"EventName\\\": \\\"Create*\\\"})` > 5 within 10 minutes.\\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of Route 53 creation events over time, enabling quick identification of unusual spikes in resource creation activity.\", \" - Tracks all AWS Lambda function deletion events captured in CloudTrail. Monitoring **{\\\"EventSource\\\": \\\"lambda.amazonaws.com\\\", \\\"EventName\\\": \\\"Delete*\\\"}** helps SREs detect when Lambda functions are removed, which is critical for maintaining application stability, ensuring proper resource cleanup, and preventing accidental or unauthorized deletions.  \\n\\n**Alert Threshold:** Trigger an alert if more than 3 Lambda function deletions occur within a 1-hour window, as this may indicate a misconfiguration, automated script error, or potential security breach.  \\n\\n**Impact:**  \\n- **High values:** A spike in deletions can lead to service disruptions, loss of critical functionality, or security incidents if unauthorized deletions occur. Immediate investigation is required.  \\n- **Low or zero values:** Normal operation; infrequent deletions are expected during routine maintenance or deployments.  \\n\\n**Example Alert Rule:**  \\n`WHEN count(events where EventSource=\\\"lambda.amazonaws.com\\\" AND EventName LIKE \\\"Delete%\\\") > 3 WITHIN 1 hour THEN alert \\\"Unusual number of Lambda deletions detected\\\"`  \\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of Lambda deletion events per hour, annotated with alert thresholds, enabling quick identification of abnormal deletion activity.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": false,
                        "score": 0.17310585727705127,
                        "reason": "The retrieval context does not address Lambda function creation events but instead focuses on other AWS resource creations and Lambda deletions, which is misaligned with the input question about Lambda function creation spikes. While the descriptions are clear and detailed for their respective resources, they lack coverage of Lambda creation monitoring, units, or implications relevant to the question, limiting utility for answering the monitoring question.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Compare the Input (question) and the Retrieval Context (description) to ensure the description clearly addresses the monitoring question.\",\n    \"Evaluate Clarity by checking if the description is concise, uses simple language, and is easy to understand relative to the question asked.\",\n    \"Assess Coverage by verifying the description explains what is measured, the units involved, the monitoring context, and any implications relevant to the input question.\",\n    \"Judge Utility by determining if the description provides sufficient information that enables a user to effectively answer the monitoring question based on the input.\"\n] \n \nRubric:\nNone \n \nScore: 0.17310585727705127"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Compare the Input (question) and the Retrieval Context (description) to ensure the description clearly addresses the monitoring question.",
                            "Evaluate Clarity by checking if the description is concise, uses simple language, and is easy to understand relative to the question asked.",
                            "Assess Coverage by verifying the description explains what is measured, the units involved, the monitoring context, and any implications relevant to the input question.",
                            "Judge Utility by determining if the description provides sufficient information that enables a user to effectively answer the monitoring question based on the input."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"lambda.amazonaws.com\\\", \\\"EventName\\\": \\\"Delete*\\\"}\", \"hyperparameters\": null, \"input\": \"Are there more than three AWS Lambda function deletions occurring within a short period?\", \"retrieval_context\": [\" - API Gateway deletion events captured by CloudTrail indicate when APIs, stages, or related resources are removed. These events are critical for tracking decommissioning activities, ensuring that endpoint removals are intentional and authorized, and preventing accidental service disruptions.  \\n\\n**Purpose:**  \\nMonitor all delete operations initiated via API Gateway (e.g., DeleteRestApi, DeleteStage) to maintain visibility into changes that reduce API surface area or remove critical endpoints.\\n\\n**Alert Threshold:**  \\nTrigger an alert if the number of Delete* events exceeds a predefined baseline within a short time window (e.g., more than 3 deletions within 10 minutes), as this may indicate accidental mass deletions, unauthorized activity, or a misconfigured automation script.\\n\\n**Impact:**  \\n- **High frequency:** Could lead to service outages, broken integrations, or data loss if APIs or stages are removed unexpectedly. Immediate investigation is required.  \\n- **Low or zero frequency:** Normal operation; deletion events are infrequent and typically planned.\\n\\n**Example Usage:**  \\nIn a monitoring dashboard, display a time series graph of Delete* events from apigateway.amazonaws.com. Set an alert rule such as:  \\n`IF count(Delete* events) > 3 within 10 minutes THEN trigger high-severity alert \\\"Potential API Gateway mass deletion detected\\\"`  \\nThis enables rapid response to potentially disruptive changes in the API infrastructure.\", \" - This event pattern captures all CloudTrail events where CloudWatch Logs resources\\u2014such as log groups or log streams\\u2014are deleted (e.g., DeleteLogGroup, DeleteLogStream). Its purpose is to monitor and audit log deletion activities, which can be legitimate cleanup or indicate potential loss of critical log data needed for troubleshooting and compliance.\\n\\n**Alert Threshold:**  \\nTrigger an alert if the number of delete events exceeds a baseline threshold within a defined time window (e.g., more than 3 deletions within 1 hour), or if deletions occur unexpectedly outside of scheduled maintenance windows.\\n\\n**Impact:**  \\n- **High frequency of deletions:** May indicate accidental or malicious removal of logs, risking loss of observability and forensic data. Immediate investigation is recommended.  \\n- **Low or zero deletions:** Normal operation, indicating logs are retained as expected.\\n\\n**Example Alert Rule:**  \\n\\u201cAlert if DeleteLogGroup or DeleteLogStream events from logs.amazonaws.com exceed 3 occurrences in 60 minutes.\\u201d  \\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of Delete* events over time, annotated with alert thresholds and maintenance windows, enabling quick identification of unusual spikes in log deletions.\", \" - This pattern captures ECS deletion events recorded in CloudTrail, specifically any API calls starting with \\\"Delete\\\" from the ECS service (e.g., DeleteCluster, DeleteService, DeleteTaskSet). Its purpose is to monitor when ECS resources are removed, which can signal intentional cleanup or unintended disruptions affecting service availability.\\n\\n**Threshold guidance:**  \\n- Trigger an alert if the number of ECS deletion events exceeds a baseline threshold within a short time window (e.g., more than 3 Delete* events in 5 minutes), as this may indicate accidental mass deletion or a security incident.  \\n- Low or expected deletion rates typically reflect routine maintenance or scaling down of resources and generally have minimal impact.\\n\\n**Impact:**  \\n- High deletion event counts can lead to service downtime, loss of running tasks, or cluster instability, requiring immediate investigation.  \\n- Low or zero deletion events usually indicate stable ECS resource management.\\n\\n**Example alert rule:**  \\n- Alert when `count(events where EventSource=\\\"ecs.amazonaws.com\\\" and EventName starts with \\\"Delete\\\") > 3` within 5 minutes.  \\n- This alert can be visualized on a dashboard showing ECS Delete* event counts over time, helping SREs quickly identify unusual spikes and correlate with service health metrics.\", \" - This pattern captures all Route 53 deletion events recorded in CloudTrail, such as deleting hosted zones, record sets, or health checks. It helps SREs monitor when DNS configurations are removed, which could be part of routine cleanup or signal accidental or malicious disruptions to DNS resolution.\\n\\n**Purpose:**  \\nTrack and alert on Route 53 resource deletions to quickly detect potential service impact caused by DNS changes.\\n\\n**Alert Threshold:**  \\nTrigger an alert if more than 3 deletion events occur within a 10-minute window, as multiple deletions in a short period may indicate an ongoing incident or misconfiguration.\\n\\n**Impact:**  \\n- **High volume:** May cause widespread DNS outages or service disruptions, requiring immediate investigation.  \\n- **Low volume (single event):** Could be routine maintenance but should still be reviewed to confirm legitimacy.\\n\\n**Example Alert Rule:**  \\n\\u201cAlert when count of events matching {EventSource: route53.amazonaws.com, EventName: Delete*} exceeds 3 within 10 minutes.\\u201d\\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of Route 53 deletion events over time, with a threshold line at 3 events per 10 minutes to highlight potential issues.\", \" - Tracks all AWS Lambda function deletion events captured in CloudTrail. Monitoring **{\\\"EventSource\\\": \\\"lambda.amazonaws.com\\\", \\\"EventName\\\": \\\"Delete*\\\"}** helps SREs detect when Lambda functions are removed, which is critical for maintaining application stability, ensuring proper resource cleanup, and preventing accidental or unauthorized deletions.  \\n\\n**Alert Threshold:** Trigger an alert if more than 3 Lambda function deletions occur within a 1-hour window, as this may indicate a misconfiguration, automated script error, or potential security breach.  \\n\\n**Impact:**  \\n- **High values:** A spike in deletions can lead to service disruptions, loss of critical functionality, or security incidents if unauthorized deletions occur. Immediate investigation is required.  \\n- **Low or zero values:** Normal operation; infrequent deletions are expected during routine maintenance or deployments.  \\n\\n**Example Alert Rule:**  \\n`WHEN count(events where EventSource=\\\"lambda.amazonaws.com\\\" AND EventName LIKE \\\"Delete%\\\") > 3 WITHIN 1 hour THEN alert \\\"Unusual number of Lambda deletions detected\\\"`  \\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of Lambda deletion events per hour, annotated with alert thresholds, enabling quick identification of abnormal deletion activity.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": true,
                        "score": 0.9377540661794488,
                        "reason": "The metric description in the Retrieval Context clearly relates to the monitoring question by focusing on AWS Lambda function deletions and specifying an alert threshold of more than 3 deletions within a 1-hour window. It is clear, concise, and directly addresses the question by explaining what is measured (Lambda deletion events), the units (count within 1 hour), and the implications (service disruption, security risks). The inclusion of example alert rules and dashboard widgets enhances utility, providing sufficient information to confidently answer the monitoring question. The only minor shortcoming is the lack of explicit definition of 'short period' beyond the 1-hour window, but this is implied and consistent with the question.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Compare the Input metric description and Retrieval Context to assess if the description clearly relates to and supports the monitoring question.\",\n    \"Evaluate Clarity by checking if the metric description is understandable and concise within the Retrieval Context, ensuring it directly addresses the Input question.\",\n    \"Assess Coverage by verifying whether the description explains what is measured, including units, context, and implications relevant to the Input question and Retrieval Context.\",\n    \"Judge Utility by determining if the metric description and Retrieval Context collectively provide enough information to confidently answer the Input monitoring question.\"\n] \n \nRubric:\nNone \n \nScore: 0.9377540661794488"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Compare the Input metric description and Retrieval Context to assess if the description clearly relates to and supports the monitoring question.",
                            "Evaluate Clarity by checking if the metric description is understandable and concise within the Retrieval Context, ensuring it directly addresses the Input question.",
                            "Assess Coverage by verifying whether the description explains what is measured, including units, context, and implications relevant to the Input question and Retrieval Context.",
                            "Judge Utility by determining if the metric description and Retrieval Context collectively provide enough information to confidently answer the Input monitoring question."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"s3.amazonaws.com\\\", \\\"EventName\\\": \\\"Get*\\\"}\", \"hyperparameters\": null, \"input\": \"Does the number of S3 Get* events exceed its baseline threshold, indicating potential heavy data consumption or abuse?\", \"retrieval_context\": [\" - S3 Get* events in CloudTrail capture all read operations on S3 objects, such as GetObject, GetObjectAcl, and GetObjectVersion. These events indicate when data is accessed or downloaded from your buckets, providing critical visibility into data retrieval patterns and potential unauthorized access.  \\n\\n**Purpose:** Monitor and audit object read activity to detect unusual access spikes, potential data exfiltration, or performance bottlenecks caused by excessive reads.\\n\\n**Alert Threshold:** Trigger an alert if the number of Get* events exceeds a baseline threshold (e.g., a 3x increase over the average hourly rate) or if access occurs from unexpected IP addresses or principals.\\n\\n**Impact:**  \\n- **High values:** May indicate heavy data consumption, possible data leakage, or abuse of resources leading to increased costs and degraded application performance.  \\n- **Low values:** Could suggest reduced usage, potential application issues, or misconfigured permissions blocking legitimate access.\\n\\n**Example Alert Rule:**  \\nAlert when the count of s3.amazonaws.com Get* events in CloudTrail exceeds 5000 within 1 hour, or when access originates from an IP address outside your trusted network range.\\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing hourly counts of Get* events per bucket, combined with a heatmap of source IP addresses, enabling quick identification of unusual access patterns or spikes in data retrieval.\", \" - S3 List operations (EventName starting with \\\"List\\\") in CloudTrail capture requests to enumerate buckets, list objects, or browse directories within S3. These events help track data discovery activities, such as inventory management or security reconnaissance attempts by identifying who is accessing or exploring bucket contents.  \\n\\n**Purpose:**  \\n- Monitor access patterns to detect unusual or excessive listing activity that may indicate unauthorized data exploration or reconnaissance.  \\n- Support auditing and compliance by providing visibility into how and when bucket contents are being queried.\\n\\n**Alert Threshold Guidance:**  \\n- Trigger alerts when the number of List operations exceeds a baseline threshold (e.g., a sudden spike above normal daily averages or a sustained high rate over a short period).  \\n- Thresholds should be customized per environment but a common starting point is alerting on a 3x increase over the average hourly count or more than 100 List requests per minute from a single principal or IP.\\n\\n**Impact of Values:**  \\n- **High values:** May indicate automated scanning, data scraping, or reconnaissance by malicious actors, potentially preceding data exfiltration attempts. Could also reflect legitimate bulk inventory or analytics jobs\\u2014context matters.  \\n- **Low values:** Normal or expected in environments with limited or infrequent bucket browsing; very low values typically pose no risk.\\n\\n**Example Usage:**  \\n- **Dashboard:** Visualize the count of List* events over time, segmented by user or source IP, to identify unusual spikes or patterns.  \\n- **Alert Rule (pseudo-code):**  \\n  ```  \\n  IF count(EventName LIKE \\\"List*\\\") BY user OVER 15 minutes > 3x baseline THEN alert(\\\"Unusual S3 List activity detected for user\\\")  \\n  ```  \\nThis enables proactive detection of suspicious enumeration behavior while minimizing false positives from routine operations.\", \" - S3 bucket creation events captured by CloudTrail under **{\\\"EventSource\\\": \\\"s3.amazonaws.com\\\", \\\"EventName\\\": \\\"Create*\\\"}** indicate when new buckets or related resources (e.g., bucket policies, access points) are provisioned. These events help SREs monitor infrastructure changes that affect data storage, security posture, and compliance.\\n\\n**Purpose:**  \\nTrack and audit the creation of S3 buckets and associated configurations to ensure proper governance, prevent unauthorized resource sprawl, and maintain compliance with organizational policies.\\n\\n**Alert Threshold:**  \\nTrigger an alert if the number of S3 bucket creation events exceeds a defined threshold within a short time window (e.g., more than 5 bucket creations within 10 minutes), which may indicate automated provisioning errors, misconfigurations, or potential security incidents such as unauthorized resource creation.\\n\\n**Impact of Values:**  \\n- **High frequency:** May signal abnormal activity, such as a compromised credential or runaway automation scripts creating excessive buckets, leading to increased costs, security risks, or compliance violations.  \\n- **Low or zero frequency:** Normal in stable environments; however, sudden spikes should be investigated promptly.\\n\\n**Example Alert Rule:**  \\n\\u201cAlert when count of events with EventSource = 's3.amazonaws.com' and EventName starting with 'Create' exceeds 5 within 10 minutes.\\u201d\\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of S3 Create* events over time, with thresholds marked to highlight unusual spikes, enabling quick identification of abnormal bucket creation activity.\", \" - This pattern captures all AWS Security Token Service (STS) \\\"Get\\\" operations, such as `GetSessionToken`, `GetCallerIdentity`, and similar API calls that issue or validate temporary security credentials. In CloudTrail, these events indicate when users or services request short-lived credentials to access AWS resources.\\n\\n**Purpose:**  \\nMonitor STS Get* events to detect unusual or excessive requests for temporary credentials, which can signal automation activity, credential misuse, or potential security incidents like privilege escalation or compromised identities.\\n\\n**Alert Threshold:**  \\nTrigger an alert when the count of STS Get* events exceeds a baseline threshold established from normal activity patterns\\u2014commonly, a sudden spike above 3-5 times the average hourly rate or an absolute count exceeding 100 requests per hour, depending on your environment size and usage.\\n\\n**Impact of Values:**  \\n- **High values:** May indicate automated processes requesting many temporary credentials, potential credential abuse, or an attacker attempting to escalate privileges or move laterally. Prompt investigation is warranted.  \\n- **Low or expected values:** Reflect normal operation with routine credential issuance and validation.\\n\\n**Example Usage:**  \\nIn a monitoring dashboard, plot the count of `sts.amazonaws.com` events with `EventName` matching `Get*` over time. Set an alert rule such as:  \\n`WHEN count(events where EventSource=\\\"sts.amazonaws.com\\\" AND EventName LIKE \\\"Get*\\\") > 100 within 1 hour THEN alert \\\"High STS Get* activity detected\\\"`  \\nThis helps SREs quickly identify abnormal credential request patterns and respond accordingly.\", \" - This pattern detects SNS topic creation events recorded in CloudTrail, specifically any API calls starting with \\\"Create\\\" from the SNS service (e.g., CreateTopic). It helps SREs monitor when new SNS topics are provisioned, which can indicate changes in messaging architecture or potential unauthorized resource creation. An alert threshold could be set on the number of Create* events within a given time window (e.g., more than 5 topic creations in 10 minutes), as a sudden spike may signal automation errors or security issues. Low or expected values typically indicate normal operations, while high values may impact system stability by increasing resource usage or indicate potential misuse. For example, an alert rule could trigger if the count of {\\\"EventSource\\\": \\\"sns.amazonaws.com\\\", \\\"EventName\\\": \\\"Create*\\\"} events exceeds 5 in 10 minutes, and a dashboard widget could display a time series graph of topic creation events to track trends and detect anomalies.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": false,
                        "score": 0.7422628057633487,
                        "reason": "The input question about S3 Get* events is clear and concise, focusing on whether the number exceeds a baseline threshold indicating heavy data consumption or abuse. The retrieval context provides detailed coverage of S3 Get* events, including purpose, alert thresholds, impact, and example alerts, which supports understanding and monitoring the metric. However, the retrieval context also includes unrelated event types (List*, Create*, SNS, STS) that dilute focus and may confuse users seeking direct answers about Get* events. To improve, the context should be more focused solely on S3 Get* events to enhance utility and direct alignment with the monitoring question.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Assess the Input (metric description) for clarity by checking if it is understandable and concise.\",\n    \"Evaluate the Retrieval Context by verifying if the description adequately covers what is measured, including units, context, and possible implications.\",\n    \"Compare the Input and Retrieval Context to determine if the description\u2019s coverage directly supports answering the provided monitoring question, reflecting utility.\",\n    \"Integrate findings from clarity, coverage, and utility to assign a score, and if below 8, suggest specific improvements targeting gaps between the description and the question\u2019s requirements.\"\n] \n \nRubric:\nNone \n \nScore: 0.7422628057633487"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Assess the Input (metric description) for clarity by checking if it is understandable and concise.",
                            "Evaluate the Retrieval Context by verifying if the description adequately covers what is measured, including units, context, and possible implications.",
                            "Compare the Input and Retrieval Context to determine if the description\u2019s coverage directly supports answering the provided monitoring question, reflecting utility.",
                            "Integrate findings from clarity, coverage, and utility to assign a score, and if below 8, suggest specific improvements targeting gaps between the description and the question\u2019s requirements."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"iam.amazonaws.com\\\", \\\"EventName\\\": \\\"Update*\\\"}\", \"hyperparameters\": null, \"input\": \"Does a spike in IAM update events indicate potential malicious activity like privilege escalation attempts?\", \"retrieval_context\": [\" - IAM Detach API events recorded by CloudTrail when IAM entities (users, groups, or roles) have policies detached from them. These events indicate the removal of permissions previously granted via managed or inline policies. Each event includes details such as the identity performing the detachment, the target entity, the detached policy ARN or name, timestamps, and request parameters. Metrics derived from these events typically count the number of detach operations over time (unit: count per minute/hour) sourced directly from CloudTrail logs. An unusual spike or unexpected detach activity\\u2014especially outside normal change windows or by unauthorized principals\\u2014may indicate potential privilege revocation due to security incidents, misconfigurations, or insider threats and should trigger an alert for immediate investigation.\", \" - IAM update events capture all modifications made to IAM resources such as users, roles, groups, policies, and credentials. These events indicate changes to permissions, access controls, and security configurations, which are critical for maintaining the principle of least privilege and preventing unauthorized privilege escalation. In CloudTrail, **{\\\"EventSource\\\": \\\"iam.amazonaws.com\\\", \\\"EventName\\\": \\\"Update*\\\"}** helps track who made changes, what was changed, and when, enabling audit and compliance verification.\\n\\n**Alert Threshold:** Trigger an alert when the number of IAM update events exceeds a baseline threshold within a short time window (e.g., more than 5 update events in 10 minutes), or when specific sensitive updates occur, such as policy changes granting administrative privileges or credential rotations outside of scheduled maintenance.\\n\\n**Impact of Values:**  \\n- **High values:** A spike in update events may indicate automated scripts, bulk permission changes, or potential malicious activity like privilege escalation attempts. Immediate investigation is warranted to confirm legitimacy.  \\n- **Low values:** Normal or zero update events typically indicate stable IAM configurations with no recent permission changes, which is expected in steady-state operations.\\n\\n**Example Usage:**  \\nIn a dashboard, display a time series graph of IAM update events filtered by event name pattern \\\"Update*\\\". Set an alert rule to notify the SRE team if the count of these events exceeds 5 within any rolling 10-minute window, or if any update event modifies policies granting \\\"AdministratorAccess\\\". This enables rapid detection of potentially risky permission changes and supports proactive security posture management.\", \" - This pattern captures AWS Security Token Service (STS) AssumeRole API calls, which occur when an identity assumes a role to obtain temporary security credentials. In CloudTrail, these events indicate role assumption activities such as cross-account access, privilege escalation, or session switching within the same account. Monitoring these events helps detect unusual or unauthorized access patterns.\\n\\n**Purpose:**  \\n- Track when and how often roles are assumed to identify potential security risks or operational anomalies.  \\n- Detect spikes in assume role activity that may indicate compromised credentials or misuse of permissions.\\n\\n**Alert Threshold Guidance:**  \\n- Set alert thresholds based on baseline activity for your environment. For example, trigger an alert if the number of AssumeRole events exceeds the daily average by 3x or if assume role events occur from unexpected source IPs or accounts.  \\n- Low or zero assume role activity may indicate service disruptions or misconfigurations if role assumption is expected regularly.\\n\\n**Impact of Values:**  \\n- **High values:** Could signal automated processes, legitimate scaling activities, or potential security incidents such as credential compromise or privilege escalation attempts.  \\n- **Low values:** May indicate reduced operational activity or potential failures in systems relying on role assumption.\\n\\n**Example Alert Rule:**  \\nTrigger an alert if the count of **{\\\"EventSource\\\": \\\"sts.amazonaws.com\\\", \\\"EventName\\\": \\\"AssumeRole\\\"}** events in a 1-hour window exceeds 100 or deviates by more than 3 standard deviations from the 7-day rolling average.\\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of AssumeRole events per hour, annotated with alerts when thresholds are breached, alongside a table listing top source IPs and assumed roles to aid investigation.\", \" - This pattern captures all update-related events from AWS Secrets Manager, such as modifications to secret values, rotation configurations, and access policy changes, as recorded in CloudTrail. Its purpose is to monitor changes that could affect the confidentiality, integrity, or availability of secrets critical to application security and operations.\\n\\n**Threshold guidance:**  \\n- Trigger an alert if the number of update events exceeds a baseline threshold within a short time window (e.g., more than 5 update events in 10 minutes), as this may indicate unusual or potentially unauthorized activity.  \\n- Conversely, an absence of expected rotation updates over a longer period (e.g., no rotation updates in 30 days) could signal stale secrets and increased security risk.\\n\\n**Impact of values:**  \\n- **High frequency of update events:** May indicate automated rotation, bulk secret changes, or suspicious activity such as credential compromise or insider threat. Immediate investigation is recommended.  \\n- **Low or zero update events:** Could mean secrets are not being rotated as per policy, increasing the risk of secret leakage or misuse.\\n\\n**Example alert rule:**  \\nAlert when `count(secretsmanager.amazonaws.com Update* events) > 5` within 10 minutes, excluding known maintenance windows.  \\n**Example dashboard widget:**  \\nA time-series graph showing the count of Secrets Manager update events over time, annotated with alerts triggered when thresholds are breached, helping SREs quickly identify abnormal secret modification patterns.\", \" - This pattern detects Secrets Manager creation events in CloudTrail, specifically any API calls starting with \\\"Create\\\" (e.g., CreateSecret). It helps SREs monitor when new secrets, secret versions, or related configurations are added, which could indicate deployment changes or potential security risks.  \\n**Alert threshold:** Trigger an alert if the number of create events exceeds a baseline (e.g., more than 5 creates within 10 minutes), as a sudden spike may signal unauthorized secret creation or misconfiguration. Conversely, zero create events over an extended period in an active environment might indicate issues with deployment pipelines or automation failures.  \\n**Impact:**  \\n- High values: Could indicate potential security breaches, unauthorized secret provisioning, or rapid environment changes requiring immediate investigation.  \\n- Low values: May suggest stalled deployments or automation problems, potentially delaying application updates or secret rotations.  \\n**Example usage:**  \\nIn a dashboard, plot the count of Secrets Manager Create* events over time to visualize spikes. An alert rule could be:  \\n`WHEN count(secretsmanager.amazonaws.com Create* events) > 5 within 10 minutes THEN trigger alert \\\"Unusual Secrets Creation Activity\\\"`  \\nThis enables proactive detection of abnormal secret creation activity, helping maintain security and operational stability.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": true,
                        "score": 0.9014063625183691,
                        "reason": "The description directly addresses the question by explaining that IAM update events capture modifications to IAM resources and that spikes may indicate potential malicious activity like privilege escalation attempts. It uses clear, concise language and provides context including alert thresholds, impact of high and low values, and example usage. The description equips users with sufficient information to interpret spikes in IAM update events in relation to security concerns, though it could slightly improve by explicitly defining units of measurement.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Compare the Input (monitoring question) with the Retrieval Context (metric description) to assess if the description directly addresses the question's topic.\",\n    \"Evaluate Clarity by checking if the description uses understandable language and is concise without ambiguity, relevant to the input question.\",\n    \"Assess Coverage by verifying the description explains what is measured, includes units, provides context, and states implications that relate explicitly to the input question.\",\n    \"Determine Utility by judging if the description equips a user with sufficient information to answer the monitoring question effectively, highlighting gaps between description and question if any.\"\n] \n \nRubric:\nNone \n \nScore: 0.9014063625183691"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Compare the Input (monitoring question) with the Retrieval Context (metric description) to assess if the description directly addresses the question's topic.",
                            "Evaluate Clarity by checking if the description uses understandable language and is concise without ambiguity, relevant to the input question.",
                            "Assess Coverage by verifying the description explains what is measured, includes units, provides context, and states implications that relate explicitly to the input question.",
                            "Determine Utility by judging if the description equips a user with sufficient information to answer the monitoring question effectively, highlighting gaps between description and question if any."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"iam.amazonaws.com\\\", \\\"EventName\\\": \\\"Attach*\\\"}\", \"hyperparameters\": null, \"input\": \"Are there spikes in AttachUserPolicyCount that could indicate unauthorized policy attachments?\", \"retrieval_context\": [\" - IAM Detach API events recorded by CloudTrail when IAM entities (users, groups, or roles) have policies detached from them. These events indicate the removal of permissions previously granted via managed or inline policies. Each event includes details such as the identity performing the detachment, the target entity, the detached policy ARN or name, timestamps, and request parameters. Metrics derived from these events typically count the number of detach operations over time (unit: count per minute/hour) sourced directly from CloudTrail logs. An unusual spike or unexpected detach activity\\u2014especially outside normal change windows or by unauthorized principals\\u2014may indicate potential privilege revocation due to security incidents, misconfigurations, or insider threats and should trigger an alert for immediate investigation.\", \" - S3 List operations (EventName starting with \\\"List\\\") in CloudTrail capture requests to enumerate buckets, list objects, or browse directories within S3. These events help track data discovery activities, such as inventory management or security reconnaissance attempts by identifying who is accessing or exploring bucket contents.  \\n\\n**Purpose:**  \\n- Monitor access patterns to detect unusual or excessive listing activity that may indicate unauthorized data exploration or reconnaissance.  \\n- Support auditing and compliance by providing visibility into how and when bucket contents are being queried.\\n\\n**Alert Threshold Guidance:**  \\n- Trigger alerts when the number of List operations exceeds a baseline threshold (e.g., a sudden spike above normal daily averages or a sustained high rate over a short period).  \\n- Thresholds should be customized per environment but a common starting point is alerting on a 3x increase over the average hourly count or more than 100 List requests per minute from a single principal or IP.\\n\\n**Impact of Values:**  \\n- **High values:** May indicate automated scanning, data scraping, or reconnaissance by malicious actors, potentially preceding data exfiltration attempts. Could also reflect legitimate bulk inventory or analytics jobs\\u2014context matters.  \\n- **Low values:** Normal or expected in environments with limited or infrequent bucket browsing; very low values typically pose no risk.\\n\\n**Example Usage:**  \\n- **Dashboard:** Visualize the count of List* events over time, segmented by user or source IP, to identify unusual spikes or patterns.  \\n- **Alert Rule (pseudo-code):**  \\n  ```  \\n  IF count(EventName LIKE \\\"List*\\\") BY user OVER 15 minutes > 3x baseline THEN alert(\\\"Unusual S3 List activity detected for user\\\")  \\n  ```  \\nThis enables proactive detection of suspicious enumeration behavior while minimizing false positives from routine operations.\", \" - S3 bucket creation events captured by CloudTrail under **{\\\"EventSource\\\": \\\"s3.amazonaws.com\\\", \\\"EventName\\\": \\\"Create*\\\"}** indicate when new buckets or related resources (e.g., bucket policies, access points) are provisioned. These events help SREs monitor infrastructure changes that affect data storage, security posture, and compliance.\\n\\n**Purpose:**  \\nTrack and audit the creation of S3 buckets and associated configurations to ensure proper governance, prevent unauthorized resource sprawl, and maintain compliance with organizational policies.\\n\\n**Alert Threshold:**  \\nTrigger an alert if the number of S3 bucket creation events exceeds a defined threshold within a short time window (e.g., more than 5 bucket creations within 10 minutes), which may indicate automated provisioning errors, misconfigurations, or potential security incidents such as unauthorized resource creation.\\n\\n**Impact of Values:**  \\n- **High frequency:** May signal abnormal activity, such as a compromised credential or runaway automation scripts creating excessive buckets, leading to increased costs, security risks, or compliance violations.  \\n- **Low or zero frequency:** Normal in stable environments; however, sudden spikes should be investigated promptly.\\n\\n**Example Alert Rule:**  \\n\\u201cAlert when count of events with EventSource = 's3.amazonaws.com' and EventName starting with 'Create' exceeds 5 within 10 minutes.\\u201d\\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of S3 Create* events over time, with thresholds marked to highlight unusual spikes, enabling quick identification of abnormal bucket creation activity.\", \" - This pattern captures all Amazon EKS \\\"Describe\\\" API operations logged in CloudTrail, which occur when cluster metadata, node group configurations, or add-on details are queried. It helps SREs monitor how often EKS cluster information is accessed, providing visibility into potential reconnaissance or troubleshooting activities. A sudden spike in Describe calls\\u2014such as exceeding 100 requests within 5 minutes\\u2014may indicate unusual or automated querying that could precede configuration changes or security incidents, warranting an alert. Conversely, consistently low or zero Describe activity might suggest lack of monitoring or insufficient operational visibility. For example, an alert rule could trigger when Describe API calls surpass 100 in a 5-minute window, and a dashboard widget might display a time series graph of Describe call counts to track trends and detect anomalies in cluster information access patterns.\", \" - Tracks IAM policy attachment events where policies are linked to users, groups, or roles. Measures the count of attachment actions performed, indicating changes in permission assignments. Monitors access grants and potential privilege escalations to support security oversight of access control modifications.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": false,
                        "score": 0.15621765008857982,
                        "reason": "The Retrieval Context does not directly address the Input question about spikes in AttachUserPolicyCount; it primarily describes detach events and other unrelated metrics. While some attachment events are briefly mentioned, the context lacks a clear, detailed explanation of what AttachUserPolicyCount measures, its units, operational context, or implications. This limits clarity, coverage, and utility for effectively answering the monitoring question.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Compare the Input (question) with the Retrieval Context (metric description) to ensure the description directly addresses the monitoring question.\",\n    \"Assess Clarity by checking if the Retrieval Context is understandable and concise enough for a user to grasp without ambiguity.\",\n    \"Evaluate Coverage by verifying that the Retrieval Context explains what is measured, its units, the operational context, and the implications relevant to the Input question.\",\n    \"Determine Utility by confirming that the Retrieval Context provides sufficient and relevant information to enable a user to answer the Input monitoring question effectively.\"\n] \n \nRubric:\nNone \n \nScore: 0.15621765008857982"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Compare the Input (question) with the Retrieval Context (metric description) to ensure the description directly addresses the monitoring question.",
                            "Assess Clarity by checking if the Retrieval Context is understandable and concise enough for a user to grasp without ambiguity.",
                            "Evaluate Coverage by verifying that the Retrieval Context explains what is measured, its units, the operational context, and the implications relevant to the Input question.",
                            "Determine Utility by confirming that the Retrieval Context provides sufficient and relevant information to enable a user to answer the Input monitoring question effectively."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"s3.amazonaws.com\\\", \\\"EventName\\\": \\\"Put*\\\"}\", \"hyperparameters\": null, \"input\": \"Are there spikes in Put* events indicating a potential issue with data ingestion or modification in S3?\", \"retrieval_context\": [\" - Lambda function \\\"Put*\\\" events in CloudTrail capture changes to function configurations, concurrency settings, event source mappings, and resource provisioning. These events indicate updates or deployments that can affect function behavior and performance. An SRE should monitor the frequency and success of these operations; unusually high rates of \\\"Put*\\\" events may signal automation errors or configuration churn, while absence of expected updates could indicate deployment issues. Alert thresholds might include more than 5 \\\"Put*\\\" events within 5 minutes or failed update attempts exceeding 10% of total \\\"Put*\\\" events. High volumes can lead to inconsistent function states or throttling, impacting availability and latency; low update activity during active development phases may delay critical fixes or optimizations. For example, a dashboard widget can track the count of \\\"Put*\\\" events per hour alongside error rates, and an alert rule could trigger when the number of failed \\\"Put*\\\" events surpasses a set threshold, prompting investigation into deployment or configuration problems.\", \" - S3 bucket creation events captured by CloudTrail under **{\\\"EventSource\\\": \\\"s3.amazonaws.com\\\", \\\"EventName\\\": \\\"Create*\\\"}** indicate when new buckets or related resources (e.g., bucket policies, access points) are provisioned. These events help SREs monitor infrastructure changes that affect data storage, security posture, and compliance.\\n\\n**Purpose:**  \\nTrack and audit the creation of S3 buckets and associated configurations to ensure proper governance, prevent unauthorized resource sprawl, and maintain compliance with organizational policies.\\n\\n**Alert Threshold:**  \\nTrigger an alert if the number of S3 bucket creation events exceeds a defined threshold within a short time window (e.g., more than 5 bucket creations within 10 minutes), which may indicate automated provisioning errors, misconfigurations, or potential security incidents such as unauthorized resource creation.\\n\\n**Impact of Values:**  \\n- **High frequency:** May signal abnormal activity, such as a compromised credential or runaway automation scripts creating excessive buckets, leading to increased costs, security risks, or compliance violations.  \\n- **Low or zero frequency:** Normal in stable environments; however, sudden spikes should be investigated promptly.\\n\\n**Example Alert Rule:**  \\n\\u201cAlert when count of events with EventSource = 's3.amazonaws.com' and EventName starting with 'Create' exceeds 5 within 10 minutes.\\u201d\\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of S3 Create* events over time, with thresholds marked to highlight unusual spikes, enabling quick identification of abnormal bucket creation activity.\", \" - This event captures all S3 operations that begin with \\\"Put,\\\" including object uploads, bucket policy updates, and configuration changes. It measures the occurrence of these actions as discrete event counts. Each event represents a single API call to perform a \\\"Put\\\" operation within an S3 bucket. This data helps track modifications and data ingestion activities in S3.\", \" - This pattern captures CloudWatch Logs Put operations, which occur when log events are written to log streams from applications, systems, or custom sources. In CloudTrail, these events indicate active ingestion of log data into CloudWatch Logs, essential for monitoring application health and troubleshooting.\\n\\n**Purpose:**  \\nMonitor the frequency and volume of log ingestion to detect anomalies such as sudden drops (potentially indicating logging failures or agent issues) or spikes (which may signal increased application activity or potential log flooding).\\n\\n**Alert Threshold Guidance:**  \\n- Trigger an alert if the number of Put operations drops below a baseline threshold for a sustained period (e.g., less than 50% of average daily Put events over 15 minutes), indicating possible logging disruptions.  \\n- Trigger an alert if Put operations spike above a defined upper threshold (e.g., 2x the average rate), which could indicate abnormal application behavior or excessive logging that may impact costs and performance.\\n\\n**Impact:**  \\n- **High values:** May lead to increased CloudWatch Logs ingestion costs and potential performance degradation; could also indicate abnormal application behavior or security events generating excessive logs.  \\n- **Low values:** May result in loss of critical log data, hindering troubleshooting and incident response.\\n\\n**Example Usage:**  \\nIn a monitoring dashboard or alert rule, track the count of CloudTrail events where `EventSource` is `logs.amazonaws.com` and `EventName` matches `Put*` over rolling 5-minute intervals. Set alerts to notify the SRE team if counts fall below or exceed defined thresholds, enabling timely investigation into logging pipeline health.\", \" - This pattern captures all CloudWatch API operations that begin with \\\"Put\\\", such as PutMetricData, PutLogEvents, and PutAlarm, indicating when CloudWatch resources or configurations are created, updated, or modified. In CloudTrail, monitoring these events helps SREs detect changes to monitoring metrics, log ingestion, and alarm settings that could impact observability or alerting behavior.\\n\\n**Threshold guidance:**  \\nAn alert should trigger if the rate of Put* events exceeds a baseline threshold (e.g., a sudden spike beyond normal operational patterns, such as a 3x increase within 5 minutes), which may indicate automated scripts or unauthorized changes modifying monitoring configurations. Conversely, an unusually low rate over an extended period might suggest disruptions in metric or log ingestion.\\n\\n**Impact:**  \\n- High volumes of Put* events can lead to configuration drift, unexpected alert noise, or resource misconfigurations affecting system reliability.  \\n- Low volumes may result in missing critical metrics or logs, reducing visibility into system health.\\n\\n**Example alert rule:**  \\nTrigger an alert when the count of CloudTrail events with EventSource = \\\"cloudwatch.amazonaws.com\\\" and EventName starting with \\\"Put\\\" exceeds 100 events within 5 minutes, signaling potential bulk updates to monitoring configurations that require investigation. This can be visualized in a dashboard showing Put* event counts over time alongside key system metrics to correlate changes with system behavior.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": false,
                        "score": 0.7851779724330186,
                        "reason": "The description clearly addresses spikes in Put* events related to S3, explaining that these events capture object uploads, bucket policy updates, and configuration changes, which relate directly to data ingestion and modification. It is concise and understandable, specifying that each event represents a single API call, thus clarifying what is measured. However, it lacks explicit mention of units (e.g., event counts over time) and threshold guidance or implications, which limits full coverage and utility for answering the monitoring question comprehensively.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Compare the Input's metric description against the Retrieval Context to verify if the description clearly addresses the monitoring question provided.\",\n    \"Evaluate clarity by checking if the metric description is concise, understandable, and free of ambiguity when matched with the context of the retrieval information.\",\n    \"Assess coverage by ensuring the description explains what is being measured, the units involved, relevant context, and potential implications, specifically in relation to the question asked.\",\n    \"Determine utility by judging if the description and the retrieval context together provide sufficient information for a user to accurately answer the monitoring question.\"\n] \n \nRubric:\nNone \n \nScore: 0.7851779724330186"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Compare the Input's metric description against the Retrieval Context to verify if the description clearly addresses the monitoring question provided.",
                            "Evaluate clarity by checking if the metric description is concise, understandable, and free of ambiguity when matched with the context of the retrieval information.",
                            "Assess coverage by ensuring the description explains what is being measured, the units involved, relevant context, and potential implications, specifically in relation to the question asked.",
                            "Determine utility by judging if the description and the retrieval context together provide sufficient information for a user to accurately answer the monitoring question."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"ec2.amazonaws.com\\\", \\\"EventName\\\": \\\"Delete*\\\"}\", \"hyperparameters\": null, \"input\": \"Does the number of EC2 resource deletion events exceed five, indicating a potential infrastructure disruption?\", \"retrieval_context\": [\" - CloudFormation Delete* events in CloudTrail indicate the initiation or completion of stack deletion operations, signaling infrastructure teardown and resource decommissioning activities. These events help SREs monitor environment lifecycle changes and ensure that deletions are intentional and controlled. \\n\\n**Alert Threshold:** Trigger an alert if the number of Delete* events exceeds a predefined baseline (e.g., more than 3 deletions within 1 hour) or occurs unexpectedly outside of scheduled maintenance windows, as this may indicate accidental or malicious infrastructure removal.\\n\\n**Impact of Values:**  \\n- **High frequency:** May lead to unintended service disruptions, data loss, or compliance risks due to rapid or bulk resource deletions. Requires immediate investigation.  \\n- **Low or zero frequency:** Normal in stable environments; indicates no recent stack deletions and stable infrastructure.\\n\\n**Example Usage:**  \\nCreate a dashboard widget tracking the count of CloudFormation Delete* events over time. Set an alert rule to notify the SRE team if Delete* events spike above the threshold within a rolling 1-hour window, enabling prompt response to potential infrastructure teardown incidents.\", \" - This pattern captures AWS CloudTrail events where EC2 instances are terminated (EventName starting with \\\"Terminate\\\"), indicating that instances are being stopped or deleted. It helps SREs monitor infrastructure changes that may affect application availability, cost, or security posture. \\n\\n**Purpose:** Detect unexpected or excessive EC2 instance terminations that could signal operational issues, unauthorized activity, or cost optimization efforts.\\n\\n**Alert Threshold:** Trigger an alert if the number of termination events exceeds a baseline threshold (e.g., more than 5 terminations within 10 minutes), or if terminations occur outside of scheduled maintenance windows.\\n\\n**Impact:**  \\n- **High values:** May indicate potential outages due to accidental or malicious instance termination, or aggressive cost-cutting measures that reduce capacity. Immediate investigation is required to prevent service disruption.  \\n- **Low or zero values:** Normal operation, assuming no planned scaling down or maintenance.\\n\\n**Example Alert Rule:**  \\n\\\"Alert when count of events matching {EventSource: 'ec2.amazonaws.com', EventName: 'TerminateInstances'} exceeds 5 within 10 minutes.\\\"\\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of EC2 TerminateInstances events over time, with annotations for scheduled maintenance windows, enabling quick identification of anomalies or spikes in instance terminations.\", \" - This pattern captures ECS deletion events recorded in CloudTrail, specifically any API calls starting with \\\"Delete\\\" from the ECS service (e.g., DeleteCluster, DeleteService, DeleteTaskSet). Its purpose is to monitor when ECS resources are removed, which can signal intentional cleanup or unintended disruptions affecting service availability.\\n\\n**Threshold guidance:**  \\n- Trigger an alert if the number of ECS deletion events exceeds a baseline threshold within a short time window (e.g., more than 3 Delete* events in 5 minutes), as this may indicate accidental mass deletion or a security incident.  \\n- Low or expected deletion rates typically reflect routine maintenance or scaling down of resources and generally have minimal impact.\\n\\n**Impact:**  \\n- High deletion event counts can lead to service downtime, loss of running tasks, or cluster instability, requiring immediate investigation.  \\n- Low or zero deletion events usually indicate stable ECS resource management.\\n\\n**Example alert rule:**  \\n- Alert when `count(events where EventSource=\\\"ecs.amazonaws.com\\\" and EventName starts with \\\"Delete\\\") > 3` within 5 minutes.  \\n- This alert can be visualized on a dashboard showing ECS Delete* event counts over time, helping SREs quickly identify unusual spikes and correlate with service health metrics.\", \" - This pattern captures all EC2 resource deletion events recorded in CloudTrail, triggered by any API calls starting with \\\"Delete\\\" from the EC2 service (e.g., DeleteSecurityGroup, DeleteNetworkInterface). Its purpose is to monitor and alert on the removal of critical EC2 components, which can impact infrastructure stability and security.\\n\\n**Threshold guidance:**  \\n- Set an alert if the number of deletion events exceeds a baseline threshold within a short time window (e.g., more than 5 deletions in 10 minutes), as this may indicate accidental mass deletions or malicious activity.  \\n- A low or zero count is typical during normal operations, while sudden spikes warrant immediate investigation.\\n\\n**Impact:**  \\n- High deletion event counts can lead to service disruptions, loss of network connectivity, or security vulnerabilities if key resources like security groups or network interfaces are removed unexpectedly.  \\n- Low or no deletion activity generally indicates stable infrastructure management.\\n\\n**Example alert rule:**  \\nTrigger an alert when the count of events matching {\\\"EventSource\\\": \\\"ec2.amazonaws.com\\\", \\\"EventName\\\": \\\"Delete*\\\"} exceeds 5 within 10 minutes.\\n\\n**Example dashboard usage:**  \\nVisualize the count of EC2 deletion events over time to identify unusual spikes, correlating with other operational metrics to assess potential impact on system availability or security posture.\", \" - This pattern captures all deletion events related to Elastic Load Balancers (ELBs) in AWS, as recorded by CloudTrail under the event source \\\"elasticloadbalancing.amazonaws.com\\\" with event names starting with \\\"Delete\\\". Its primary purpose is to monitor when ELBs are removed, which can be part of routine cleanup or indicate unintended service disruptions due to the loss of load balancing resources.\\n\\n**Purpose:**  \\nSREs use this pattern to track ELB deletions to quickly detect and investigate potential impacts on application availability and traffic routing.\\n\\n**Alert Threshold:**  \\nAn alert should be triggered if the number of ELB deletion events exceeds a predefined threshold within a short time window\\u2014for example, more than 1 deletion event within 5 minutes\\u2014since multiple deletions in quick succession may indicate a misconfiguration, automation error, or malicious activity.\\n\\n**Impact of Values:**  \\n- **High values:** Frequent or bulk ELB deletions can cause significant service disruption, leading to downtime or degraded performance due to loss of traffic distribution. Immediate investigation and remediation are required.  \\n- **Low values:** Occasional single deletions may be expected during normal maintenance or scaling operations and typically do not require urgent action but should still be logged for audit purposes.\\n\\n**Example Usage:**  \\nIn a monitoring dashboard or alert rule, you might configure a query to count ELB deletion events over a rolling 5-minute window and trigger an alert if the count exceeds 1. For example:\\n\\n```\\ncount_over_time({EventSource=\\\"elasticloadbalancing.amazonaws.com\\\", EventName=~\\\"Delete.*\\\"}[5m]) > 1\\n```\\n\\nThis alert helps ensure that unexpected or excessive ELB deletions are promptly detected and addressed to maintain service reliability.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": true,
                        "score": 0.9075858183677437,
                        "reason": "The description clearly and concisely explains the EC2 deletion events metric relevant to the question, covering what is measured (EC2 deletion events), the units (number of events), context (CloudTrail API calls starting with 'Delete'), and implications (potential infrastructure disruption). It provides threshold guidance directly addressing the question's threshold of five deletions, explains impact, and includes example alert rules and dashboard usage, offering sufficient information to answer the monitoring question effectively. The only minor shortcoming is the lack of explicit mention of the exact time window in the question, though it is implied in the description.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Compare the Input (monitoring question) with the Retrieval Context (metric description) to check if the description clearly and concisely explains the metric relevant to the question.\",\n    \"Evaluate whether the description covers essential elements: what is measured, units used, context, and potential implications, and assess if these collectively address the input query.\",\n    \"Assess the utility of the description by determining if it provides enough information to directly answer or support answering the monitoring question.\",\n    \"Make a holistic judgment by balancing clarity, coverage, and utility to assign a quality score, ensuring the description aligns well with the input and retrieval context relationship.\"\n] \n \nRubric:\nNone \n \nScore: 0.9075858183677437"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Compare the Input (monitoring question) with the Retrieval Context (metric description) to check if the description clearly and concisely explains the metric relevant to the question.",
                            "Evaluate whether the description covers essential elements: what is measured, units used, context, and potential implications, and assess if these collectively address the input query.",
                            "Assess the utility of the description by determining if it provides enough information to directly answer or support answering the monitoring question.",
                            "Make a holistic judgment by balancing clarity, coverage, and utility to assign a quality score, ensuring the description aligns well with the input and retrieval context relationship."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"ec2.amazonaws.com\\\", \\\"EventName\\\": \\\"Modify*\\\"}\", \"hyperparameters\": null, \"input\": \"Does the number of Modify* events exceed five within a rolling window, indicating unusual or potentially unauthorized changes?\", \"retrieval_context\": [\" - Lambda function \\\"Put*\\\" events in CloudTrail capture changes to function configurations, concurrency settings, event source mappings, and resource provisioning. These events indicate updates or deployments that can affect function behavior and performance. An SRE should monitor the frequency and success of these operations; unusually high rates of \\\"Put*\\\" events may signal automation errors or configuration churn, while absence of expected updates could indicate deployment issues. Alert thresholds might include more than 5 \\\"Put*\\\" events within 5 minutes or failed update attempts exceeding 10% of total \\\"Put*\\\" events. High volumes can lead to inconsistent function states or throttling, impacting availability and latency; low update activity during active development phases may delay critical fixes or optimizations. For example, a dashboard widget can track the count of \\\"Put*\\\" events per hour alongside error rates, and an alert rule could trigger when the number of failed \\\"Put*\\\" events surpasses a set threshold, prompting investigation into deployment or configuration problems.\", \" - This pattern captures all modification events related to EC2 resources in AWS CloudTrail, triggered by any API calls starting with \\\"Modify\\\" (e.g., ModifyInstanceAttribute, ModifyNetworkInterfaceAttribute). Its purpose is to monitor changes to critical EC2 configurations such as instance attributes, security group rules, and network settings, which can directly impact system security, availability, and performance.\\n\\n**Threshold guidance:**  \\n- Alert when the number of Modify* events exceeds a baseline threshold (e.g., more than 5 modifications within 10 minutes), indicating unusual or potentially unauthorized changes.  \\n- A sudden spike in modification events may signal misconfigurations, automation errors, or security incidents like privilege escalation or lateral movement.\\n\\n**Impact of values:**  \\n- **High frequency:** Could indicate active troubleshooting, automated scaling/configuration changes, or suspicious activity requiring immediate investigation.  \\n- **Low or zero frequency:** Normal steady state; no unexpected modifications detected.\\n\\n**Example alert rule:**  \\nTrigger an alert if the count of events matching {\\\"EventSource\\\": \\\"ec2.amazonaws.com\\\", \\\"EventName\\\": \\\"Modify*\\\"} exceeds 5 within a rolling 10-minute window.\\n\\n**Example dashboard widget:**  \\nA time-series graph showing the count of EC2 Modify* events per 5-minute interval, overlaid with a threshold line at 5 events, enabling quick identification of abnormal modification activity.\", \" - This pattern captures all modification events related to Elastic Load Balancing (ELB) resources in AWS, such as changes to load balancer configurations, target groups, and listeners. In CloudTrail, these events indicate when an ELB\\u2019s setup is altered, which can affect traffic routing, availability, and security posture.\\n\\n**Purpose:**  \\nTo monitor and audit any configuration changes to ELB components that could impact application availability or security.\\n\\n**Alert Threshold:**  \\nTrigger an alert if the number of ELB modification events exceeds a defined threshold within a short time window (e.g., more than 3 Modify* events within 10 minutes), as this may indicate unintended or unauthorized changes.\\n\\n**Impact of Values:**  \\n- **High frequency of Modify* events:** Could signal potential misconfigurations, automated deployment issues, or malicious activity altering load balancer behavior, risking downtime or security breaches.  \\n- **Low or no Modify* events:** Typically expected during stable operation; absence of changes suggests configuration stability.\\n\\n**Example Usage:**  \\nIn a monitoring dashboard or alert rule, track the count of **{\\\"EventSource\\\": \\\"elasticloadbalancing.amazonaws.com\\\", \\\"EventName\\\": \\\"Modify*\\\"}** events over rolling 10-minute intervals. Configure alerts to notify the SRE team when this count spikes above the threshold, enabling prompt investigation and rollback if necessary.\", \" - This pattern captures all update-related events from AWS Secrets Manager, such as modifications to secret values, rotation configurations, and access policy changes, as recorded in CloudTrail. Its purpose is to monitor changes that could affect the confidentiality, integrity, or availability of secrets critical to application security and operations.\\n\\n**Threshold guidance:**  \\n- Trigger an alert if the number of update events exceeds a baseline threshold within a short time window (e.g., more than 5 update events in 10 minutes), as this may indicate unusual or potentially unauthorized activity.  \\n- Conversely, an absence of expected rotation updates over a longer period (e.g., no rotation updates in 30 days) could signal stale secrets and increased security risk.\\n\\n**Impact of values:**  \\n- **High frequency of update events:** May indicate automated rotation, bulk secret changes, or suspicious activity such as credential compromise or insider threat. Immediate investigation is recommended.  \\n- **Low or zero update events:** Could mean secrets are not being rotated as per policy, increasing the risk of secret leakage or misuse.\\n\\n**Example alert rule:**  \\nAlert when `count(secretsmanager.amazonaws.com Update* events) > 5` within 10 minutes, excluding known maintenance windows.  \\n**Example dashboard widget:**  \\nA time-series graph showing the count of Secrets Manager update events over time, annotated with alerts triggered when thresholds are breached, helping SREs quickly identify abnormal secret modification patterns.\", \" - This pattern captures all update-related events from AWS Systems Manager (SSM) recorded in CloudTrail, such as modifications to parameters, documents, and maintenance windows. It helps SREs monitor changes to critical SSM resources that could affect system configuration, automation workflows, or maintenance schedules.  \\n\\n**Purpose:** Detect when SSM resources are altered to ensure changes are authorized and to quickly identify unexpected or potentially disruptive updates.\\n\\n**Alert Threshold:** Trigger an alert if the number of update events exceeds a baseline threshold within a short time window (e.g., more than 5 update events in 10 minutes), indicating possible misconfiguration, automation errors, or unauthorized changes.\\n\\n**Impact:**  \\n- **High values:** A spike in update events may signal bulk or automated changes that could introduce instability or security risks if unplanned. Immediate investigation is warranted.  \\n- **Low or zero values:** Normal operation if no updates are expected; however, if updates are regularly scheduled, a sudden drop might indicate monitoring gaps or failures in deployment pipelines.\\n\\n**Example Usage:**  \\nIn a monitoring dashboard, display a time series graph of the count of **{\\\"EventSource\\\": \\\"ssm.amazonaws.com\\\", \\\"EventName\\\": \\\"Update*\\\"}** events over time. Configure an alert rule to notify the SRE team when update events exceed 5 within any rolling 10-minute window, enabling rapid response to unexpected configuration changes.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": true,
                        "score": 0.8974042642708013,
                        "reason": "The retrieval context directly addresses the input question by describing the monitoring of Modify* events related to EC2 resources, including the threshold of more than 5 events within a rolling 10-minute window, which matches the input's focus. The description is clear, detailed, and includes relevant context such as the impact of high frequency events and example alert rules, enabling a user to understand what is measured, the units (event counts within time windows), and the implications of exceeding thresholds. The only minor shortcoming is the lack of explicit mention of the exact rolling window duration in the input question, but the context provides a reasonable example (10 minutes), making it highly useful for answering the monitoring question comprehensively.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Compare the Input (monitoring question) and Retrieval Context (metric description) to ensure the description directly addresses the question's focus and terminology.\",\n    \"Evaluate the clarity of the description in relation to the input to confirm it is understandable, concise, and free from ambiguity.\",\n    \"Assess the coverage of the description by checking if it explains what is measured, includes units, provides relevant context, and outlines implications that relate to the question.\",\n    \"Determine the utility by verifying whether the description sufficiently equips a user to answer the monitoring question accurately and comprehensively.\"\n] \n \nRubric:\nNone \n \nScore: 0.8974042642708013"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Compare the Input (monitoring question) and Retrieval Context (metric description) to ensure the description directly addresses the question's focus and terminology.",
                            "Evaluate the clarity of the description in relation to the input to confirm it is understandable, concise, and free from ambiguity.",
                            "Assess the coverage of the description by checking if it explains what is measured, includes units, provides relevant context, and outlines implications that relate to the question.",
                            "Determine the utility by verifying whether the description sufficiently equips a user to answer the monitoring question accurately and comprehensively."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"ec2.amazonaws.com\\\", \\\"EventName\\\": \\\"Create*\\\"}\", \"hyperparameters\": null, \"input\": \"Are there any Create* events from ec2.amazonaws.com indicating the creation of new EC2 instances?\", \"retrieval_context\": [\" - CloudFormation stack creation events (**EventSource: cloudformation.amazonaws.com**, **EventName: Create\\\\*** ) represent API calls initiating the provisioning of AWS infrastructure and resources via CloudFormation templates. These events in CloudTrail help SREs monitor the start of environment setups and infrastructure deployments as part of Infrastructure as Code workflows.\\n\\n**Purpose:** Track and audit when new CloudFormation stacks or stack components are being created, enabling visibility into changes in infrastructure state and deployment activities.\\n\\n**Alert Thresholds:**  \\n- Trigger an alert if the number of Create* events exceeds a baseline threshold within a short time window (e.g., >10 stack creation attempts in 5 minutes), which may indicate automated deployment loops, misconfigurations, or potential security incidents.  \\n- Alert if Create* events spike unexpectedly outside of scheduled deployment windows or change management periods.\\n\\n**Impact of Values:**  \\n- **High volume:** May signal rapid infrastructure changes that could lead to instability, resource contention, or deployment failures. It could also indicate unauthorized or accidental mass provisioning.  \\n- **Low or zero volume:** Normal during steady-state operations; however, a sudden drop during expected deployment windows might indicate pipeline failures or blocked deployments.\\n\\n**Example Usage:**  \\n- **Dashboard:** Visualize the count of CloudFormation Create* events over time, segmented by stack name or user identity, to correlate deployments with system performance or incidents.  \\n- **Alert Rule:**  \\n  ```  \\n  WHEN count(events where EventSource=\\\"cloudformation.amazonaws.com\\\" AND EventName LIKE \\\"Create%\\\") > 10 within 5 minutes  \\n  THEN trigger alert \\\"High rate of CloudFormation stack creation events detected\\\"  \\n  ```  \\nThis enables proactive detection of abnormal infrastructure provisioning activity and supports rapid investigation and response.\", \" - S3 bucket creation events captured by CloudTrail under **{\\\"EventSource\\\": \\\"s3.amazonaws.com\\\", \\\"EventName\\\": \\\"Create*\\\"}** indicate when new buckets or related resources (e.g., bucket policies, access points) are provisioned. These events help SREs monitor infrastructure changes that affect data storage, security posture, and compliance.\\n\\n**Purpose:**  \\nTrack and audit the creation of S3 buckets and associated configurations to ensure proper governance, prevent unauthorized resource sprawl, and maintain compliance with organizational policies.\\n\\n**Alert Threshold:**  \\nTrigger an alert if the number of S3 bucket creation events exceeds a defined threshold within a short time window (e.g., more than 5 bucket creations within 10 minutes), which may indicate automated provisioning errors, misconfigurations, or potential security incidents such as unauthorized resource creation.\\n\\n**Impact of Values:**  \\n- **High frequency:** May signal abnormal activity, such as a compromised credential or runaway automation scripts creating excessive buckets, leading to increased costs, security risks, or compliance violations.  \\n- **Low or zero frequency:** Normal in stable environments; however, sudden spikes should be investigated promptly.\\n\\n**Example Alert Rule:**  \\n\\u201cAlert when count of events with EventSource = 's3.amazonaws.com' and EventName starting with 'Create' exceeds 5 within 10 minutes.\\u201d\\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of S3 Create* events over time, with thresholds marked to highlight unusual spikes, enabling quick identification of abnormal bucket creation activity.\", \" - This pattern captures all CloudFront distribution creation events recorded in CloudTrail, identified by event names starting with \\\"Create\\\" from the CloudFront service. Its purpose is to monitor when new CloudFront distributions are provisioned, including their initial configuration details. Tracking these events helps SREs detect unexpected or unauthorized distribution creations that could impact content delivery, security, or cost.\\n\\n**Alert Threshold:**  \\nTrigger an alert if the number of CloudFront distribution creation events exceeds a defined threshold within a short time window (e.g., more than 3 creations within 1 hour), as this may indicate automation errors, misconfigurations, or potential security incidents.\\n\\n**Impact of Values:**  \\n- **High values:** A spike in creation events could signal rapid environment changes, possible misconfigurations, or unauthorized activity, potentially leading to increased costs or service disruptions.  \\n- **Low or zero values:** Normal operation typically involves infrequent distribution creations; zero or low values indicate stable infrastructure without unexpected provisioning.\\n\\n**Example Alert Rule:**  \\n\\\"Alert when count of events matching {EventSource: 'cloudfront.amazonaws.com', EventName: 'Create*'} exceeds 3 within 1 hour.\\\"\\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of CloudFront distribution creation events over time, enabling quick identification of unusual spikes or trends in distribution provisioning activity.\", \" - This pattern detects Secrets Manager creation events in CloudTrail, specifically any API calls starting with \\\"Create\\\" (e.g., CreateSecret). It helps SREs monitor when new secrets, secret versions, or related configurations are added, which could indicate deployment changes or potential security risks.  \\n**Alert threshold:** Trigger an alert if the number of create events exceeds a baseline (e.g., more than 5 creates within 10 minutes), as a sudden spike may signal unauthorized secret creation or misconfiguration. Conversely, zero create events over an extended period in an active environment might indicate issues with deployment pipelines or automation failures.  \\n**Impact:**  \\n- High values: Could indicate potential security breaches, unauthorized secret provisioning, or rapid environment changes requiring immediate investigation.  \\n- Low values: May suggest stalled deployments or automation problems, potentially delaying application updates or secret rotations.  \\n**Example usage:**  \\nIn a dashboard, plot the count of Secrets Manager Create* events over time to visualize spikes. An alert rule could be:  \\n`WHEN count(secretsmanager.amazonaws.com Create* events) > 5 within 10 minutes THEN trigger alert \\\"Unusual Secrets Creation Activity\\\"`  \\nThis enables proactive detection of abnormal secret creation activity, helping maintain security and operational stability.\", \" - This pattern matches AWS CloudTrail events where EC2 service actions begin with \\\"Create\\\". It captures API calls that create EC2 resources such as instances, security groups, network interfaces, volumes, and other related components. Each matched event represents a single creation action recorded as an event in CloudTrail logs. This pattern helps monitor and audit the creation of EC2 resources in an AWS account.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": false,
                        "score": 0.7885420086203649,
                        "reason": "The retrieval context includes a specific description of EC2 Create* events, explaining that it captures API calls creating EC2 resources such as instances and related components, which aligns well with the input question about Create* events from ec2.amazonaws.com. The description is clear and provides useful context for monitoring and auditing these events. However, it lacks detailed information on units, alert thresholds, or implications specifically for EC2 Create* events, which limits full coverage and utility compared to other service descriptions in the context.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Compare the Input (monitoring question) and the Retrieval Context (metric description) to ensure the description clearly addresses the question asked.\",\n    \"Evaluate Clarity by checking if the Retrieval Context is understandable and concise, making it easy to relate to the Input.\",\n    \"Assess Coverage by verifying that the Retrieval Context explains what is measured, including units, relevant context, and implications that are pertinent to the Input question.\",\n    \"Determine Utility by judging if the Retrieval Context provides sufficient information for a user to effectively answer the Input question based on the description.\"\n] \n \nRubric:\nNone \n \nScore: 0.7885420086203649"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Compare the Input (monitoring question) and the Retrieval Context (metric description) to ensure the description clearly addresses the question asked.",
                            "Evaluate Clarity by checking if the Retrieval Context is understandable and concise, making it easy to relate to the Input.",
                            "Assess Coverage by verifying that the Retrieval Context explains what is measured, including units, relevant context, and implications that are pertinent to the Input question.",
                            "Determine Utility by judging if the Retrieval Context provides sufficient information for a user to effectively answer the Input question based on the description."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"lambda.amazonaws.com\\\", \\\"EventName\\\": \\\"Put*\\\"}\", \"hyperparameters\": null, \"input\": \"Are there more than 5 Put* events indicating frequent updates to Lambda function configurations?\", \"retrieval_context\": [\" - Lambda function \\\"Put*\\\" events in CloudTrail capture changes to function configurations, concurrency settings, event source mappings, and resource provisioning. These events indicate updates or deployments that can affect function behavior and performance. An SRE should monitor the frequency and success of these operations; unusually high rates of \\\"Put*\\\" events may signal automation errors or configuration churn, while absence of expected updates could indicate deployment issues. Alert thresholds might include more than 5 \\\"Put*\\\" events within 5 minutes or failed update attempts exceeding 10% of total \\\"Put*\\\" events. High volumes can lead to inconsistent function states or throttling, impacting availability and latency; low update activity during active development phases may delay critical fixes or optimizations. For example, a dashboard widget can track the count of \\\"Put*\\\" events per hour alongside error rates, and an alert rule could trigger when the number of failed \\\"Put*\\\" events surpasses a set threshold, prompting investigation into deployment or configuration problems.\", \" - This event captures all S3 operations that begin with \\\"Put,\\\" including object uploads, bucket policy updates, and configuration changes. It measures the occurrence of these actions as discrete event counts. Each event represents a single API call to perform a \\\"Put\\\" operation within an S3 bucket. This data helps track modifications and data ingestion activities in S3.\", \" - This pattern captures all CloudWatch API operations that begin with \\\"Put\\\", such as PutMetricData, PutLogEvents, and PutAlarm, indicating when CloudWatch resources or configurations are created, updated, or modified. In CloudTrail, monitoring these events helps SREs detect changes to monitoring metrics, log ingestion, and alarm settings that could impact observability or alerting behavior.\\n\\n**Threshold guidance:**  \\nAn alert should trigger if the rate of Put* events exceeds a baseline threshold (e.g., a sudden spike beyond normal operational patterns, such as a 3x increase within 5 minutes), which may indicate automated scripts or unauthorized changes modifying monitoring configurations. Conversely, an unusually low rate over an extended period might suggest disruptions in metric or log ingestion.\\n\\n**Impact:**  \\n- High volumes of Put* events can lead to configuration drift, unexpected alert noise, or resource misconfigurations affecting system reliability.  \\n- Low volumes may result in missing critical metrics or logs, reducing visibility into system health.\\n\\n**Example alert rule:**  \\nTrigger an alert when the count of CloudTrail events with EventSource = \\\"cloudwatch.amazonaws.com\\\" and EventName starting with \\\"Put\\\" exceeds 100 events within 5 minutes, signaling potential bulk updates to monitoring configurations that require investigation. This can be visualized in a dashboard showing Put* event counts over time alongside key system metrics to correlate changes with system behavior.\", \" - This pattern matches DynamoDB events where items are added or replaced in tables. It captures all write operations starting with \\\"Put,\\\" including single item puts, conditional puts, and batch put requests. The measurement is event occurrence count, indicating how many put operations were performed. Each event corresponds to one put action recorded by DynamoDB.\", \" - Tracks all update operations on AWS Lambda functions initiated by the Lambda service, including code deployments, configuration changes, environment variable updates, memory size adjustments, timeout settings, and version management. Each event represents a discrete update action performed on a Lambda function. The metric counts the number of such update events, measured as a simple event count.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": false,
                        "score": 0.6229767770819247,
                        "reason": "The Input is clear and concise in asking about the frequency of Put* events related to Lambda function updates, aligning well with the Retrieval Context's focus on Lambda Put* events. However, it lacks coverage of key details such as the units of measurement (e.g., events per time interval), specific thresholds (like more than 5 events within 5 minutes), and the implications of high or low event rates on system behavior. This limits its utility for fully answering the Retrieval Context's monitoring and alerting guidance. Including measurement units, threshold examples, and potential impacts would improve completeness and usefulness.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Evaluate clarity by checking if the Input (metric description) is concise and easy to understand in relation to the Retrieval Context (monitoring question).\",\n    \"Assess coverage by verifying that the Input explains what is measured, the units used, relevant context, and potential implications necessary to answer the Retrieval Context.\",\n    \"Determine utility by confirming that the Input provides sufficient and relevant information to effectively answer the Retrieval Context question.\",\n    \"If any aspect scores below 8, identify specific gaps linking the Input's deficiencies to the Retrieval Context and suggest concrete improvements.\"\n] \n \nRubric:\nNone \n \nScore: 0.6229767770819247"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Evaluate clarity by checking if the Input (metric description) is concise and easy to understand in relation to the Retrieval Context (monitoring question).",
                            "Assess coverage by verifying that the Input explains what is measured, the units used, relevant context, and potential implications necessary to answer the Retrieval Context.",
                            "Determine utility by confirming that the Input provides sufficient and relevant information to effectively answer the Retrieval Context question.",
                            "If any aspect scores below 8, identify specific gaps linking the Input's deficiencies to the Retrieval Context and suggest concrete improvements."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"s3.amazonaws.com\\\", \\\"EventName\\\": \\\"Create*\\\"}\", \"hyperparameters\": null, \"input\": \"Does the number of S3 bucket creation events exceed five within a short time window, indicating potential automated provisioning errors or security incidents?\", \"retrieval_context\": [\" - S3 bucket creation events captured by CloudTrail under **{\\\"EventSource\\\": \\\"s3.amazonaws.com\\\", \\\"EventName\\\": \\\"Create*\\\"}** indicate when new buckets or related resources (e.g., bucket policies, access points) are provisioned. These events help SREs monitor infrastructure changes that affect data storage, security posture, and compliance.\\n\\n**Purpose:**  \\nTrack and audit the creation of S3 buckets and associated configurations to ensure proper governance, prevent unauthorized resource sprawl, and maintain compliance with organizational policies.\\n\\n**Alert Threshold:**  \\nTrigger an alert if the number of S3 bucket creation events exceeds a defined threshold within a short time window (e.g., more than 5 bucket creations within 10 minutes), which may indicate automated provisioning errors, misconfigurations, or potential security incidents such as unauthorized resource creation.\\n\\n**Impact of Values:**  \\n- **High frequency:** May signal abnormal activity, such as a compromised credential or runaway automation scripts creating excessive buckets, leading to increased costs, security risks, or compliance violations.  \\n- **Low or zero frequency:** Normal in stable environments; however, sudden spikes should be investigated promptly.\\n\\n**Example Alert Rule:**  \\n\\u201cAlert when count of events with EventSource = 's3.amazonaws.com' and EventName starting with 'Create' exceeds 5 within 10 minutes.\\u201d\\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of S3 Create* events over time, with thresholds marked to highlight unusual spikes, enabling quick identification of abnormal bucket creation activity.\", \" - This pattern captures all AWS Systems Manager (SSM) resource creation events logged in CloudTrail, such as the creation of parameters, documents, and maintenance windows. It helps SREs monitor the provisioning of new SSM assets, which can indicate configuration changes or automation deployments.\\n\\n**Purpose:**  \\nTo detect when new SSM resources are created, enabling timely awareness of infrastructure changes that may affect system behavior or security posture.\\n\\n**Alert Threshold Guidance:**  \\nSet an alert threshold based on your environment\\u2019s baseline creation activity. For example, trigger an alert if more than 5 creation events occur within 10 minutes, which may indicate unexpected or unauthorized provisioning.\\n\\n**Impact of Values:**  \\n- **High values:** A spike in creation events could signal automated deployments, configuration drift, or potential security incidents such as unauthorized resource creation.  \\n- **Low or zero values:** Normal in stable environments; however, a sudden drop might indicate issues with deployment pipelines or monitoring gaps.\\n\\n**Example Alert Rule:**  \\nTrigger an alert when the count of events matching `{\\\"EventSource\\\": \\\"ssm.amazonaws.com\\\", \\\"EventName\\\": \\\"Create*\\\"}` exceeds 5 within a 10-minute window.\\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of SSM creation events over time, with thresholds marked to highlight unusual spikes, helping SREs quickly identify and investigate abnormal provisioning activity.\", \" - This pattern detects CloudTrail events where CloudWatch resources are created, such as alarms, dashboards, and log groups. Its purpose is to monitor the provisioning of new CloudWatch components, which can indicate changes in monitoring coverage or potential configuration drift. An alert should be triggered when the number of creation events exceeds a defined threshold within a short time window (e.g., more than 5 Create* events in 10 minutes), as a sudden spike may signal automated deployments, misconfigurations, or unauthorized activity. Conversely, a prolonged absence of creation events might suggest stagnation in monitoring updates or missed deployments. For example, in a monitoring dashboard, you can visualize the count of CloudWatch Create* events over time and set an alert rule to notify the SRE team if the event count surpasses the threshold, enabling timely investigation and response to unexpected changes in monitoring infrastructure.\", \" - This pattern detects SNS topic creation events recorded in CloudTrail, specifically any API calls starting with \\\"Create\\\" from the SNS service (e.g., CreateTopic). It helps SREs monitor when new SNS topics are provisioned, which can indicate changes in messaging architecture or potential unauthorized resource creation. An alert threshold could be set on the number of Create* events within a given time window (e.g., more than 5 topic creations in 10 minutes), as a sudden spike may signal automation errors or security issues. Low or expected values typically indicate normal operations, while high values may impact system stability by increasing resource usage or indicate potential misuse. For example, an alert rule could trigger if the count of {\\\"EventSource\\\": \\\"sns.amazonaws.com\\\", \\\"EventName\\\": \\\"Create*\\\"} events exceeds 5 in 10 minutes, and a dashboard widget could display a time series graph of topic creation events to track trends and detect anomalies.\", \" - This pattern detects Secrets Manager creation events in CloudTrail, specifically any API calls starting with \\\"Create\\\" (e.g., CreateSecret). It helps SREs monitor when new secrets, secret versions, or related configurations are added, which could indicate deployment changes or potential security risks.  \\n**Alert threshold:** Trigger an alert if the number of create events exceeds a baseline (e.g., more than 5 creates within 10 minutes), as a sudden spike may signal unauthorized secret creation or misconfiguration. Conversely, zero create events over an extended period in an active environment might indicate issues with deployment pipelines or automation failures.  \\n**Impact:**  \\n- High values: Could indicate potential security breaches, unauthorized secret provisioning, or rapid environment changes requiring immediate investigation.  \\n- Low values: May suggest stalled deployments or automation problems, potentially delaying application updates or secret rotations.  \\n**Example usage:**  \\nIn a dashboard, plot the count of Secrets Manager Create* events over time to visualize spikes. An alert rule could be:  \\n`WHEN count(secretsmanager.amazonaws.com Create* events) > 5 within 10 minutes THEN trigger alert \\\"Unusual Secrets Creation Activity\\\"`  \\nThis enables proactive detection of abnormal secret creation activity, helping maintain security and operational stability.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": true,
                        "score": 0.9029312233295256,
                        "reason": "The retrieval context clearly matches the monitoring question by describing S3 bucket creation events, including event sources, alert thresholds (exceeding 5 within 10 minutes), and implications such as automated provisioning errors or security incidents. The description is concise, well-structured, and provides sufficient detail on what is measured, units (event counts within time windows), context, and impact, enabling confident answers to the question. Minor improvement could be made by explicitly restating the exact threshold and time window from the question in a more direct manner.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Compare the Input (monitoring question) with the Retrieval Context (metric description) to assess if the description clearly matches and addresses the question's intent.\",\n    \"Evaluate Clarity by checking if the description is concise and easily understandable in relation to the question being asked.\",\n    \"Assess Coverage by verifying that the description includes details on what is measured, units, context, and implications to fully inform the question.\",\n    \"Determine Utility by judging if the description provides enough relevant information to confidently answer the monitoring question; if not, suggest specific improvements.\"\n] \n \nRubric:\nNone \n \nScore: 0.9029312233295256"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Compare the Input (monitoring question) with the Retrieval Context (metric description) to assess if the description clearly matches and addresses the question's intent.",
                            "Evaluate Clarity by checking if the description is concise and easily understandable in relation to the question being asked.",
                            "Assess Coverage by verifying that the description includes details on what is measured, units, context, and implications to fully inform the question.",
                            "Determine Utility by judging if the description provides enough relevant information to confidently answer the monitoring question; if not, suggest specific improvements."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"s3.amazonaws.com\\\", \\\"EventName\\\": \\\"Delete*\\\"}\", \"hyperparameters\": null, \"input\": \"Are there any delete operations in S3 buckets that could indicate unintended data removal or a potential security issue?\", \"retrieval_context\": [\" - S3 bucket creation events captured by CloudTrail under **{\\\"EventSource\\\": \\\"s3.amazonaws.com\\\", \\\"EventName\\\": \\\"Create*\\\"}** indicate when new buckets or related resources (e.g., bucket policies, access points) are provisioned. These events help SREs monitor infrastructure changes that affect data storage, security posture, and compliance.\\n\\n**Purpose:**  \\nTrack and audit the creation of S3 buckets and associated configurations to ensure proper governance, prevent unauthorized resource sprawl, and maintain compliance with organizational policies.\\n\\n**Alert Threshold:**  \\nTrigger an alert if the number of S3 bucket creation events exceeds a defined threshold within a short time window (e.g., more than 5 bucket creations within 10 minutes), which may indicate automated provisioning errors, misconfigurations, or potential security incidents such as unauthorized resource creation.\\n\\n**Impact of Values:**  \\n- **High frequency:** May signal abnormal activity, such as a compromised credential or runaway automation scripts creating excessive buckets, leading to increased costs, security risks, or compliance violations.  \\n- **Low or zero frequency:** Normal in stable environments; however, sudden spikes should be investigated promptly.\\n\\n**Example Alert Rule:**  \\n\\u201cAlert when count of events with EventSource = 's3.amazonaws.com' and EventName starting with 'Create' exceeds 5 within 10 minutes.\\u201d\\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of S3 Create* events over time, with thresholds marked to highlight unusual spikes, enabling quick identification of abnormal bucket creation activity.\", \" - This pattern captures DynamoDB deletion events. It identifies when DynamoDB tables are removed, which can indicate cleanup operations or potential data loss incidents.\", \" - This pattern captures Secrets Manager deletion events. It identifies when secrets are removed, which can indicate cleanup operations or potential credential loss incidents.\", \" - This pattern captures all EC2 resource deletion events recorded in CloudTrail, triggered by any API calls starting with \\\"Delete\\\" from the EC2 service (e.g., DeleteSecurityGroup, DeleteNetworkInterface). Its purpose is to monitor and alert on the removal of critical EC2 components, which can impact infrastructure stability and security.\\n\\n**Threshold guidance:**  \\n- Set an alert if the number of deletion events exceeds a baseline threshold within a short time window (e.g., more than 5 deletions in 10 minutes), as this may indicate accidental mass deletions or malicious activity.  \\n- A low or zero count is typical during normal operations, while sudden spikes warrant immediate investigation.\\n\\n**Impact:**  \\n- High deletion event counts can lead to service disruptions, loss of network connectivity, or security vulnerabilities if key resources like security groups or network interfaces are removed unexpectedly.  \\n- Low or no deletion activity generally indicates stable infrastructure management.\\n\\n**Example alert rule:**  \\nTrigger an alert when the count of events matching {\\\"EventSource\\\": \\\"ec2.amazonaws.com\\\", \\\"EventName\\\": \\\"Delete*\\\"} exceeds 5 within 10 minutes.\\n\\n**Example dashboard usage:**  \\nVisualize the count of EC2 deletion events over time to identify unusual spikes, correlating with other operational metrics to assess potential impact on system availability or security posture.\", \" - Tracks all AWS Lambda function deletion events captured in CloudTrail. Monitoring **{\\\"EventSource\\\": \\\"lambda.amazonaws.com\\\", \\\"EventName\\\": \\\"Delete*\\\"}** helps SREs detect when Lambda functions are removed, which is critical for maintaining application stability, ensuring proper resource cleanup, and preventing accidental or unauthorized deletions.  \\n\\n**Alert Threshold:** Trigger an alert if more than 3 Lambda function deletions occur within a 1-hour window, as this may indicate a misconfiguration, automated script error, or potential security breach.  \\n\\n**Impact:**  \\n- **High values:** A spike in deletions can lead to service disruptions, loss of critical functionality, or security incidents if unauthorized deletions occur. Immediate investigation is required.  \\n- **Low or zero values:** Normal operation; infrequent deletions are expected during routine maintenance or deployments.  \\n\\n**Example Alert Rule:**  \\n`WHEN count(events where EventSource=\\\"lambda.amazonaws.com\\\" AND EventName LIKE \\\"Delete%\\\") > 3 WITHIN 1 hour THEN alert \\\"Unusual number of Lambda deletions detected\\\"`  \\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of Lambda deletion events per hour, annotated with alert thresholds, enabling quick identification of abnormal deletion activity.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": false,
                        "score": 0.19626731157347208,
                        "reason": "The Retrieval Context does not address delete operations in S3 buckets, focusing instead on Lambda deletions, S3 bucket creations, Secrets Manager deletions, DynamoDB deletions, and EC2 deletions. It lacks clear and concise information about S3 delete events, their measurement, units, or implications, thus failing to provide coverage or utility for the monitoring question about unintended or security-related S3 bucket deletions.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Compare the Input (monitoring question) with the Retrieval Context (metric description) to assess if the description is clear and concise enough to be easily understood in relation to the question.\",\n    \"Evaluate Coverage by checking if the Retrieval Context adequately explains what is measured, including units, relevant context, and implications, specifically to address the monitoring question in the Input.\",\n    \"Assess Utility by determining if the Retrieval Context provides sufficient information to directly and effectively help answer the Input question.\",\n    \"If any aspect scores below 8, identify specific gaps where the Retrieval Context fails to align with the Input and suggest improvements to enhance clarity, coverage, or utility accordingly.\"\n] \n \nRubric:\nNone \n \nScore: 0.19626731157347208"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Compare the Input (monitoring question) with the Retrieval Context (metric description) to assess if the description is clear and concise enough to be easily understood in relation to the question.",
                            "Evaluate Coverage by checking if the Retrieval Context adequately explains what is measured, including units, relevant context, and implications, specifically to address the monitoring question in the Input.",
                            "Assess Utility by determining if the Retrieval Context provides sufficient information to directly and effectively help answer the Input question.",
                            "If any aspect scores below 8, identify specific gaps where the Retrieval Context fails to align with the Input and suggest improvements to enhance clarity, coverage, or utility accordingly."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"ec2.amazonaws.com\\\", \\\"EventName\\\": \\\"Run*\\\"}\", \"hyperparameters\": null, \"input\": \"Are there spikes in the number of instances launched via EC2, indicating a potential scaling issue?\", \"retrieval_context\": [\" - **{\\\"EventName\\\": \\\"Start*\\\"}** events in CloudTrail indicate the initiation of resource start operations across various AWS services, such as starting EC2 instances, RDS databases, or other managed resources. These events help SREs track when resources transition from a stopped or inactive state to an active state, which is critical for service availability, cost management, and operational recovery.\\n\\n**Purpose:**  \\nTo monitor and audit the activation of cloud resources, ensuring that start operations align with expected usage patterns and do not indicate unauthorized or unexpected activity.\\n\\n**Alert Thresholds:**  \\n- Trigger an alert if the number of **Start*** events exceeds a predefined threshold within a short time window (e.g., more than 10 start operations within 5 minutes), which may indicate an automated scaling event, a potential misconfiguration, or a security incident.  \\n- Conversely, alert if expected start operations do not occur during scheduled maintenance windows, indicating possible failures in recovery or deployment processes.\\n\\n**Impact of Values:**  \\n- **High volume of Start* events:** Could lead to increased costs due to resource activation, potential service disruptions if resources are started unexpectedly, or indicate automated scaling or recovery actions.  \\n- **Low or zero Start* events during expected periods:** May signal failed recovery attempts, stalled deployments, or issues in operational workflows, potentially impacting service availability.\\n\\n**Example Usage:**  \\nIn a CloudWatch dashboard, plot the count of **Start*** events over time to visualize spikes or drops. An alert rule can be configured as:  \\n```\\nIF count(Start* events) > 10 within 5 minutes THEN trigger alert \\\"Unusual spike in resource start operations\\\"\\n```\\nThis enables proactive investigation into unexpected resource activations or failures to start critical services.\", \" - Redshift cluster creation events in CloudTrail capture all API calls initiating the provisioning of new Redshift clusters (e.g., CreateCluster). These events indicate when new data warehouse resources are being deployed or configured, impacting capacity and cost.  \\n**Purpose:** Enables SREs to monitor and audit cluster provisioning activities for operational control and security compliance.  \\n**Alert Threshold:** Trigger alerts on an unusually high number of cluster creation events within a short time window (e.g., >3 creates in 1 hour), which may indicate automation errors, misconfigurations, or unauthorized resource provisioning.  \\n**Impact:**  \\n- **High values:** May lead to resource sprawl, increased costs, and potential performance degradation due to over-provisioning. Could also signal security risks if unexpected clusters are created.  \\n- **Low or zero values:** Normal in stable environments; no new clusters being created means stable infrastructure.  \\n**Example Alert Rule:**  \\n\\u201cAlert if count of events with EventSource='redshift.amazonaws.com' and EventName starting with 'Create' exceeds 3 within 60 minutes.\\u201d  \\n**Dashboard Use:** Visualize the frequency of Redshift cluster creation events over time to detect spikes or anomalies, correlating with deployment activities or security incidents.\", \" - S3 bucket creation events captured by CloudTrail under **{\\\"EventSource\\\": \\\"s3.amazonaws.com\\\", \\\"EventName\\\": \\\"Create*\\\"}** indicate when new buckets or related resources (e.g., bucket policies, access points) are provisioned. These events help SREs monitor infrastructure changes that affect data storage, security posture, and compliance.\\n\\n**Purpose:**  \\nTrack and audit the creation of S3 buckets and associated configurations to ensure proper governance, prevent unauthorized resource sprawl, and maintain compliance with organizational policies.\\n\\n**Alert Threshold:**  \\nTrigger an alert if the number of S3 bucket creation events exceeds a defined threshold within a short time window (e.g., more than 5 bucket creations within 10 minutes), which may indicate automated provisioning errors, misconfigurations, or potential security incidents such as unauthorized resource creation.\\n\\n**Impact of Values:**  \\n- **High frequency:** May signal abnormal activity, such as a compromised credential or runaway automation scripts creating excessive buckets, leading to increased costs, security risks, or compliance violations.  \\n- **Low or zero frequency:** Normal in stable environments; however, sudden spikes should be investigated promptly.\\n\\n**Example Alert Rule:**  \\n\\u201cAlert when count of events with EventSource = 's3.amazonaws.com' and EventName starting with 'Create' exceeds 5 within 10 minutes.\\u201d\\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of S3 Create* events over time, with thresholds marked to highlight unusual spikes, enabling quick identification of abnormal bucket creation activity.\", \" - This pattern captures Elastic Load Balancing (ELB) target deregistration events from CloudTrail, indicating when backend targets (such as EC2 instances or IP addresses) are removed from a load balancer. These events typically occur during scaling operations, deployments, or maintenance activities that affect service availability.\\n\\n**Purpose:**  \\nMonitoring deregistration events helps SREs track changes in load balancer target groups, ensuring that scaling or maintenance actions do not inadvertently reduce capacity or cause service disruptions.\\n\\n**Alert Threshold Guidance:**  \\n- Trigger an alert if the number of deregistration events exceeds a defined threshold within a short time window (e.g., more than 5 deregistrations within 5 minutes), which may indicate unexpected or excessive target removals.  \\n- Conversely, a prolonged absence of deregistration events during expected scaling periods might signal issues with autoscaling or deployment processes.\\n\\n**Impact of Values:**  \\n- **High deregistration rate:** Could lead to reduced backend capacity, increased latency, or service outages if targets are removed too quickly or unexpectedly. Immediate investigation is warranted.  \\n- **Low or no deregistration events:** May indicate stable operations or, if scaling is expected, potential failures in scaling mechanisms.\\n\\n**Example Alert Rule:**  \\n```\\nWHEN count of events WHERE EventSource = \\\"elasticloadbalancing.amazonaws.com\\\" AND EventName LIKE \\\"Deregister%\\\"  \\nIN last 5 minutes > 5  \\nTHEN trigger alert \\\"High ELB Target Deregistration Rate\\\"\\n```\\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of deregistration events per minute, overlaid with thresholds, to visualize spikes or drops in deregistration activity aligned with deployment or scaling events.\", \" - This pattern captures all CloudFront distribution creation events recorded in CloudTrail, identified by event names starting with \\\"Create\\\" from the CloudFront service. Its purpose is to monitor when new CloudFront distributions are provisioned, including their initial configuration details. Tracking these events helps SREs detect unexpected or unauthorized distribution creations that could impact content delivery, security, or cost.\\n\\n**Alert Threshold:**  \\nTrigger an alert if the number of CloudFront distribution creation events exceeds a defined threshold within a short time window (e.g., more than 3 creations within 1 hour), as this may indicate automation errors, misconfigurations, or potential security incidents.\\n\\n**Impact of Values:**  \\n- **High values:** A spike in creation events could signal rapid environment changes, possible misconfigurations, or unauthorized activity, potentially leading to increased costs or service disruptions.  \\n- **Low or zero values:** Normal operation typically involves infrequent distribution creations; zero or low values indicate stable infrastructure without unexpected provisioning.\\n\\n**Example Alert Rule:**  \\n\\\"Alert when count of events matching {EventSource: 'cloudfront.amazonaws.com', EventName: 'Create*'} exceeds 3 within 1 hour.\\\"\\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of CloudFront distribution creation events over time, enabling quick identification of unusual spikes or trends in distribution provisioning activity.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": true,
                        "score": 0.8393174852012912,
                        "reason": "The retrieval context clearly addresses the question by explaining that 'Start*' events in CloudTrail include EC2 instance launches and how monitoring spikes in these events can indicate scaling issues. The description is detailed, providing alert thresholds, impact of high event volumes, and example alert rules, which directly inform the question about spikes in EC2 instance launches. However, it does not explicitly isolate EC2 instances from other resource starts, which slightly reduces clarity and specificity for the exact inquiry.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Compare the Input (monitoring question) and the Retrieval Context (metric description) to ensure the description clearly addresses the specific inquiry posed by the question.\",\n    \"Evaluate the clarity of the description to determine if it is concise and easy to understand within the context of the question.\",\n    \"Check the coverage in the description by verifying if it explains what is measured, includes units, provides context, and discusses the implications relevant to the question.\",\n    \"Assess the utility by confirming whether the description contains sufficient information to directly inform or answer the given question effectively.\"\n] \n \nRubric:\nNone \n \nScore: 0.8393174852012912"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Compare the Input (monitoring question) and the Retrieval Context (metric description) to ensure the description clearly addresses the specific inquiry posed by the question.",
                            "Evaluate the clarity of the description to determine if it is concise and easy to understand within the context of the question.",
                            "Check the coverage in the description by verifying if it explains what is measured, includes units, provides context, and discusses the implications relevant to the question.",
                            "Assess the utility by confirming whether the description contains sufficient information to directly inform or answer the given question effectively."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"ec2.amazonaws.com\\\", \\\"EventName\\\": \\\"Terminate*\\\"}\", \"hyperparameters\": null, \"input\": \"Are there more than five EC2 instance termination events occurring within a short period, indicating potential outages or unauthorized activity?\", \"retrieval_context\": [\" - This pattern captures AWS CloudTrail events where EC2 instances are terminated (EventName starting with \\\"Terminate\\\"), indicating that instances are being stopped or deleted. It helps SREs monitor infrastructure changes that may affect application availability, cost, or security posture. \\n\\n**Purpose:** Detect unexpected or excessive EC2 instance terminations that could signal operational issues, unauthorized activity, or cost optimization efforts.\\n\\n**Alert Threshold:** Trigger an alert if the number of termination events exceeds a baseline threshold (e.g., more than 5 terminations within 10 minutes), or if terminations occur outside of scheduled maintenance windows.\\n\\n**Impact:**  \\n- **High values:** May indicate potential outages due to accidental or malicious instance termination, or aggressive cost-cutting measures that reduce capacity. Immediate investigation is required to prevent service disruption.  \\n- **Low or zero values:** Normal operation, assuming no planned scaling down or maintenance.\\n\\n**Example Alert Rule:**  \\n\\\"Alert when count of events matching {EventSource: 'ec2.amazonaws.com', EventName: 'TerminateInstances'} exceeds 5 within 10 minutes.\\\"\\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of EC2 TerminateInstances events over time, with annotations for scheduled maintenance windows, enabling quick identification of anomalies or spikes in instance terminations.\", \" - This pattern captures ECS deletion events recorded in CloudTrail, specifically any API calls starting with \\\"Delete\\\" from the ECS service (e.g., DeleteCluster, DeleteService, DeleteTaskSet). Its purpose is to monitor when ECS resources are removed, which can signal intentional cleanup or unintended disruptions affecting service availability.\\n\\n**Threshold guidance:**  \\n- Trigger an alert if the number of ECS deletion events exceeds a baseline threshold within a short time window (e.g., more than 3 Delete* events in 5 minutes), as this may indicate accidental mass deletion or a security incident.  \\n- Low or expected deletion rates typically reflect routine maintenance or scaling down of resources and generally have minimal impact.\\n\\n**Impact:**  \\n- High deletion event counts can lead to service downtime, loss of running tasks, or cluster instability, requiring immediate investigation.  \\n- Low or zero deletion events usually indicate stable ECS resource management.\\n\\n**Example alert rule:**  \\n- Alert when `count(events where EventSource=\\\"ecs.amazonaws.com\\\" and EventName starts with \\\"Delete\\\") > 3` within 5 minutes.  \\n- This alert can be visualized on a dashboard showing ECS Delete* event counts over time, helping SREs quickly identify unusual spikes and correlate with service health metrics.\", \" - This pattern captures Elastic Load Balancing (ELB) target deregistration events from CloudTrail, indicating when backend targets (such as EC2 instances or IP addresses) are removed from a load balancer. These events typically occur during scaling operations, deployments, or maintenance activities that affect service availability.\\n\\n**Purpose:**  \\nMonitoring deregistration events helps SREs track changes in load balancer target groups, ensuring that scaling or maintenance actions do not inadvertently reduce capacity or cause service disruptions.\\n\\n**Alert Threshold Guidance:**  \\n- Trigger an alert if the number of deregistration events exceeds a defined threshold within a short time window (e.g., more than 5 deregistrations within 5 minutes), which may indicate unexpected or excessive target removals.  \\n- Conversely, a prolonged absence of deregistration events during expected scaling periods might signal issues with autoscaling or deployment processes.\\n\\n**Impact of Values:**  \\n- **High deregistration rate:** Could lead to reduced backend capacity, increased latency, or service outages if targets are removed too quickly or unexpectedly. Immediate investigation is warranted.  \\n- **Low or no deregistration events:** May indicate stable operations or, if scaling is expected, potential failures in scaling mechanisms.\\n\\n**Example Alert Rule:**  \\n```\\nWHEN count of events WHERE EventSource = \\\"elasticloadbalancing.amazonaws.com\\\" AND EventName LIKE \\\"Deregister%\\\"  \\nIN last 5 minutes > 5  \\nTHEN trigger alert \\\"High ELB Target Deregistration Rate\\\"\\n```\\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of deregistration events per minute, overlaid with thresholds, to visualize spikes or drops in deregistration activity aligned with deployment or scaling events.\", \" - This pattern captures all EC2 resource deletion events recorded in CloudTrail, triggered by any API calls starting with \\\"Delete\\\" from the EC2 service (e.g., DeleteSecurityGroup, DeleteNetworkInterface). Its purpose is to monitor and alert on the removal of critical EC2 components, which can impact infrastructure stability and security.\\n\\n**Threshold guidance:**  \\n- Set an alert if the number of deletion events exceeds a baseline threshold within a short time window (e.g., more than 5 deletions in 10 minutes), as this may indicate accidental mass deletions or malicious activity.  \\n- A low or zero count is typical during normal operations, while sudden spikes warrant immediate investigation.\\n\\n**Impact:**  \\n- High deletion event counts can lead to service disruptions, loss of network connectivity, or security vulnerabilities if key resources like security groups or network interfaces are removed unexpectedly.  \\n- Low or no deletion activity generally indicates stable infrastructure management.\\n\\n**Example alert rule:**  \\nTrigger an alert when the count of events matching {\\\"EventSource\\\": \\\"ec2.amazonaws.com\\\", \\\"EventName\\\": \\\"Delete*\\\"} exceeds 5 within 10 minutes.\\n\\n**Example dashboard usage:**  \\nVisualize the count of EC2 deletion events over time to identify unusual spikes, correlating with other operational metrics to assess potential impact on system availability or security posture.\", \" - This pattern captures all modification events related to EC2 resources in AWS CloudTrail, triggered by any API calls starting with \\\"Modify\\\" (e.g., ModifyInstanceAttribute, ModifyNetworkInterfaceAttribute). Its purpose is to monitor changes to critical EC2 configurations such as instance attributes, security group rules, and network settings, which can directly impact system security, availability, and performance.\\n\\n**Threshold guidance:**  \\n- Alert when the number of Modify* events exceeds a baseline threshold (e.g., more than 5 modifications within 10 minutes), indicating unusual or potentially unauthorized changes.  \\n- A sudden spike in modification events may signal misconfigurations, automation errors, or security incidents like privilege escalation or lateral movement.\\n\\n**Impact of values:**  \\n- **High frequency:** Could indicate active troubleshooting, automated scaling/configuration changes, or suspicious activity requiring immediate investigation.  \\n- **Low or zero frequency:** Normal steady state; no unexpected modifications detected.\\n\\n**Example alert rule:**  \\nTrigger an alert if the count of events matching {\\\"EventSource\\\": \\\"ec2.amazonaws.com\\\", \\\"EventName\\\": \\\"Modify*\\\"} exceeds 5 within a rolling 10-minute window.\\n\\n**Example dashboard widget:**  \\nA time-series graph showing the count of EC2 Modify* events per 5-minute interval, overlaid with a threshold line at 5 events, enabling quick identification of abnormal modification activity.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": true,
                        "score": 0.907585817479811,
                        "reason": "The description clearly addresses the monitoring question by focusing on EC2 instance termination events and their significance, matching the retrieval context's emphasis on detecting more than five terminations within a short period. It is clear, concise, and unambiguous, explaining what is measured (termination events), specifying units (e.g., more than 5 terminations within 10 minutes), and providing relevant context including potential impacts such as outages or unauthorized activity. The description enables effective answering of the monitoring question, though it could slightly improve by explicitly mentioning the exact time window (e.g., 10 minutes) in the input for full alignment.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Compare the Input (metric description) and the Retrieval Context to ensure the description clearly addresses the monitoring question provided.\",\n    \"Evaluate Clarity by checking if the description is understandable, concise, and free of ambiguity when considered alongside the retrieval context.\",\n    \"Assess Coverage by verifying that the description explains what is measured, specifies units, provides relevant context, and discusses potential implications with respect to the retrieval context.\",\n    \"Judge Utility by determining if the description enables a user to effectively answer the monitoring question given both the Input and Retrieval Context; if not, identify what details are missing.\"\n] \n \nRubric:\nNone \n \nScore: 0.907585817479811"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Compare the Input (metric description) and the Retrieval Context to ensure the description clearly addresses the monitoring question provided.",
                            "Evaluate Clarity by checking if the description is understandable, concise, and free of ambiguity when considered alongside the retrieval context.",
                            "Assess Coverage by verifying that the description explains what is measured, specifies units, provides relevant context, and discusses potential implications with respect to the retrieval context.",
                            "Judge Utility by determining if the description enables a user to effectively answer the monitoring question given both the Input and Retrieval Context; if not, identify what details are missing."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"lambda.amazonaws.com\\\", \\\"EventName\\\": \\\"Invoke*\\\"}\", \"hyperparameters\": null, \"input\": \"Are there spikes in InvokeCount that could indicate a Lambda function is experiencing high traffic or errors?\", \"retrieval_context\": [\" - Lambda function \\\"Put*\\\" events in CloudTrail capture changes to function configurations, concurrency settings, event source mappings, and resource provisioning. These events indicate updates or deployments that can affect function behavior and performance. An SRE should monitor the frequency and success of these operations; unusually high rates of \\\"Put*\\\" events may signal automation errors or configuration churn, while absence of expected updates could indicate deployment issues. Alert thresholds might include more than 5 \\\"Put*\\\" events within 5 minutes or failed update attempts exceeding 10% of total \\\"Put*\\\" events. High volumes can lead to inconsistent function states or throttling, impacting availability and latency; low update activity during active development phases may delay critical fixes or optimizations. For example, a dashboard widget can track the count of \\\"Put*\\\" events per hour alongside error rates, and an alert rule could trigger when the number of failed \\\"Put*\\\" events surpasses a set threshold, prompting investigation into deployment or configuration problems.\", \" - S3 bucket creation events captured by CloudTrail under **{\\\"EventSource\\\": \\\"s3.amazonaws.com\\\", \\\"EventName\\\": \\\"Create*\\\"}** indicate when new buckets or related resources (e.g., bucket policies, access points) are provisioned. These events help SREs monitor infrastructure changes that affect data storage, security posture, and compliance.\\n\\n**Purpose:**  \\nTrack and audit the creation of S3 buckets and associated configurations to ensure proper governance, prevent unauthorized resource sprawl, and maintain compliance with organizational policies.\\n\\n**Alert Threshold:**  \\nTrigger an alert if the number of S3 bucket creation events exceeds a defined threshold within a short time window (e.g., more than 5 bucket creations within 10 minutes), which may indicate automated provisioning errors, misconfigurations, or potential security incidents such as unauthorized resource creation.\\n\\n**Impact of Values:**  \\n- **High frequency:** May signal abnormal activity, such as a compromised credential or runaway automation scripts creating excessive buckets, leading to increased costs, security risks, or compliance violations.  \\n- **Low or zero frequency:** Normal in stable environments; however, sudden spikes should be investigated promptly.\\n\\n**Example Alert Rule:**  \\n\\u201cAlert when count of events with EventSource = 's3.amazonaws.com' and EventName starting with 'Create' exceeds 5 within 10 minutes.\\u201d\\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of S3 Create* events over time, with thresholds marked to highlight unusual spikes, enabling quick identification of abnormal bucket creation activity.\", \" - This pattern captures all Route 53 resource creation events recorded in CloudTrail, such as the creation of hosted zones, DNS record sets, and health checks. Monitoring these events helps SREs detect configuration changes that could impact DNS resolution and application availability. \\n\\n**Purpose:** Track when new Route 53 resources are created to identify potential unauthorized changes or misconfigurations early.\\n\\n**Alert Threshold:** Trigger an alert if the number of creation events exceeds a baseline threshold (e.g., more than 5 creation events within 10 minutes), which may indicate automated misconfigurations, security breaches, or unintended mass changes.\\n\\n**Impact:**  \\n- **High values:** A spike in creation events could lead to DNS inconsistencies, increased attack surface, or service disruptions if malicious or erroneous resources are introduced.  \\n- **Low or zero values:** Normal operation, assuming no planned infrastructure changes.\\n\\n**Example Alert Rule:**  \\nAlert when `count({\\\"EventSource\\\": \\\"route53.amazonaws.com\\\", \\\"EventName\\\": \\\"Create*\\\"})` > 5 within 10 minutes.\\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of Route 53 creation events over time, enabling quick identification of unusual spikes in resource creation activity.\", \" - Tracks all AWS Lambda function deletion events captured in CloudTrail. Monitoring **{\\\"EventSource\\\": \\\"lambda.amazonaws.com\\\", \\\"EventName\\\": \\\"Delete*\\\"}** helps SREs detect when Lambda functions are removed, which is critical for maintaining application stability, ensuring proper resource cleanup, and preventing accidental or unauthorized deletions.  \\n\\n**Alert Threshold:** Trigger an alert if more than 3 Lambda function deletions occur within a 1-hour window, as this may indicate a misconfiguration, automated script error, or potential security breach.  \\n\\n**Impact:**  \\n- **High values:** A spike in deletions can lead to service disruptions, loss of critical functionality, or security incidents if unauthorized deletions occur. Immediate investigation is required.  \\n- **Low or zero values:** Normal operation; infrequent deletions are expected during routine maintenance or deployments.  \\n\\n**Example Alert Rule:**  \\n`WHEN count(events where EventSource=\\\"lambda.amazonaws.com\\\" AND EventName LIKE \\\"Delete%\\\") > 3 WITHIN 1 hour THEN alert \\\"Unusual number of Lambda deletions detected\\\"`  \\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of Lambda deletion events per hour, annotated with alert thresholds, enabling quick identification of abnormal deletion activity.\", \" - Tracks each invocation of AWS Lambda functions, recording the number of times a function is executed. Measures invocation count as discrete events triggered by function calls. Provides data essential for monitoring application performance, error rates, cold starts, and usage patterns. Enables optimization of application health and cost management.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": false,
                        "score": 0.1977022628166471,
                        "reason": "The Input question asks specifically about spikes in InvokeCount related to Lambda function traffic or errors, but the Retrieval Context primarily describes Lambda deletion events, Put* events, and other unrelated AWS event types. Only one brief segment mentions invocation counts without detailing units, context, or implications, resulting in insufficient coverage and limited utility for answering the question. The Retrieval Context lacks clear, concise, and directly relevant information about InvokeCount spikes, their measurement, or impact, causing a mismatch that hinders practical use.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Evaluate how clearly the Input (monitoring question) and Retrieval Context (metric description) are stated and whether the description uses straightforward, concise language that aligns with the question.\",\n    \"Assess whether the Retrieval Context sufficiently covers all relevant aspects\u2014what is measured, units, environmental or system context, and potential implications\u2014in a way that directly relates to and supports understanding the Input question.\",\n    \"Determine the utility of the Retrieval Context by checking if it provides the necessary information to effectively answer the Input question, ensuring no critical gaps exist between the description and the inquiry.\",\n    \"Compare Input and Retrieval Context holistically to identify any mismatches or missing links, indicating whether the description can serve the user's practical needs in addressing the question, and recommend improvements if the coverage or clarity is insufficient.\"\n] \n \nRubric:\nNone \n \nScore: 0.1977022628166471"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Evaluate how clearly the Input (monitoring question) and Retrieval Context (metric description) are stated and whether the description uses straightforward, concise language that aligns with the question.",
                            "Assess whether the Retrieval Context sufficiently covers all relevant aspects\u2014what is measured, units, environmental or system context, and potential implications\u2014in a way that directly relates to and supports understanding the Input question.",
                            "Determine the utility of the Retrieval Context by checking if it provides the necessary information to effectively answer the Input question, ensuring no critical gaps exist between the description and the inquiry.",
                            "Compare Input and Retrieval Context holistically to identify any mismatches or missing links, indicating whether the description can serve the user's practical needs in addressing the question, and recommend improvements if the coverage or clarity is insufficient."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"iam.amazonaws.com\\\", \\\"EventName\\\": \\\"Detach*\\\"}\", \"hyperparameters\": null, \"input\": \"Are there any IAM Detach API events indicating removal of permissions from sensitive entities?\", \"retrieval_context\": [\" - API Gateway deletion events captured by CloudTrail indicate when APIs, stages, or related resources are removed. These events are critical for tracking decommissioning activities, ensuring that endpoint removals are intentional and authorized, and preventing accidental service disruptions.  \\n\\n**Purpose:**  \\nMonitor all delete operations initiated via API Gateway (e.g., DeleteRestApi, DeleteStage) to maintain visibility into changes that reduce API surface area or remove critical endpoints.\\n\\n**Alert Threshold:**  \\nTrigger an alert if the number of Delete* events exceeds a predefined baseline within a short time window (e.g., more than 3 deletions within 10 minutes), as this may indicate accidental mass deletions, unauthorized activity, or a misconfigured automation script.\\n\\n**Impact:**  \\n- **High frequency:** Could lead to service outages, broken integrations, or data loss if APIs or stages are removed unexpectedly. Immediate investigation is required.  \\n- **Low or zero frequency:** Normal operation; deletion events are infrequent and typically planned.\\n\\n**Example Usage:**  \\nIn a monitoring dashboard, display a time series graph of Delete* events from apigateway.amazonaws.com. Set an alert rule such as:  \\n`IF count(Delete* events) > 3 within 10 minutes THEN trigger high-severity alert \\\"Potential API Gateway mass deletion detected\\\"`  \\nThis enables rapid response to potentially disruptive changes in the API infrastructure.\", \" - IAM Detach API events recorded by CloudTrail when IAM entities (users, groups, or roles) have policies detached from them. These events indicate the removal of permissions previously granted via managed or inline policies. Each event includes details such as the identity performing the detachment, the target entity, the detached policy ARN or name, timestamps, and request parameters. Metrics derived from these events typically count the number of detach operations over time (unit: count per minute/hour) sourced directly from CloudTrail logs. An unusual spike or unexpected detach activity\\u2014especially outside normal change windows or by unauthorized principals\\u2014may indicate potential privilege revocation due to security incidents, misconfigurations, or insider threats and should trigger an alert for immediate investigation.\", \" - IAM deletion events (e.g., DeleteUser, DeleteRole) recorded by CloudTrail indicate removal of IAM identities or permissions. These events are critical for detecting unauthorized or accidental deletions that can disrupt access or signal a security breach. An alert threshold should be set to trigger on any unexpected deletion event or a sudden spike above normal baseline activity (e.g., more than 1 deletion event within 5 minutes), as even a single deletion can have significant impact. High volumes may indicate automated attacks or misconfigurations causing mass access removal, while low or zero values typically indicate normal operation.  \\nExample alert rule: trigger when count of iam.amazonaws.com Delete* events > 1 in 5 minutes.  \\nExample dashboard widget: a time series graph showing Delete* event counts over time, annotated with alert thresholds to quickly identify unusual deletion activity.\", \" - IAM update events capture all modifications made to IAM resources such as users, roles, groups, policies, and credentials. These events indicate changes to permissions, access controls, and security configurations, which are critical for maintaining the principle of least privilege and preventing unauthorized privilege escalation. In CloudTrail, **{\\\"EventSource\\\": \\\"iam.amazonaws.com\\\", \\\"EventName\\\": \\\"Update*\\\"}** helps track who made changes, what was changed, and when, enabling audit and compliance verification.\\n\\n**Alert Threshold:** Trigger an alert when the number of IAM update events exceeds a baseline threshold within a short time window (e.g., more than 5 update events in 10 minutes), or when specific sensitive updates occur, such as policy changes granting administrative privileges or credential rotations outside of scheduled maintenance.\\n\\n**Impact of Values:**  \\n- **High values:** A spike in update events may indicate automated scripts, bulk permission changes, or potential malicious activity like privilege escalation attempts. Immediate investigation is warranted to confirm legitimacy.  \\n- **Low values:** Normal or zero update events typically indicate stable IAM configurations with no recent permission changes, which is expected in steady-state operations.\\n\\n**Example Usage:**  \\nIn a dashboard, display a time series graph of IAM update events filtered by event name pattern \\\"Update*\\\". Set an alert rule to notify the SRE team if the count of these events exceeds 5 within any rolling 10-minute window, or if any update event modifies policies granting \\\"AdministratorAccess\\\". This enables rapid detection of potentially risky permission changes and supports proactive security posture management.\", \" - This pattern captures Secrets Manager deletion events. It identifies when secrets are removed, which can indicate cleanup operations or potential credential loss incidents.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": true,
                        "score": 0.8705106261383276,
                        "reason": "The input question is clear and concise, directly asking about IAM Detach API events indicating permission removals from sensitive entities. The retrieval context thoroughly covers what is measured (IAM Detach API events), units (count per minute/hour), relevant details (identity, target entity, policy info, timestamps), and implications (potential privilege revocation, security incidents). The description provides sufficient information to answer the question effectively. The only minor shortcoming is the input could explicitly mention the unit of measurement or alert thresholds to fully align with the detailed context.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Evaluate the clarity of the Input by checking if the metric description is straightforward, concise, and free of ambiguous language.\",\n    \"Assess the Coverage by verifying whether the description includes what is being measured, its units, relevant context, and the implications of the metric in relation to the Retrieval Context (the monitoring question).\",\n    \"Examine the Utility by determining if the description provides sufficient information from the Input to effectively answer the Retrieval Context question.\",\n    \"If the description scores below 8, identify specific missing elements or unclear aspects that, when improved, would enhance the alignment and usefulness between Input and Retrieval Context.\"\n] \n \nRubric:\nNone \n \nScore: 0.8705106261383276"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Evaluate the clarity of the Input by checking if the metric description is straightforward, concise, and free of ambiguous language.",
                            "Assess the Coverage by verifying whether the description includes what is being measured, its units, relevant context, and the implications of the metric in relation to the Retrieval Context (the monitoring question).",
                            "Examine the Utility by determining if the description provides sufficient information from the Input to effectively answer the Retrieval Context question.",
                            "If the description scores below 8, identify specific missing elements or unclear aspects that, when improved, would enhance the alignment and usefulness between Input and Retrieval Context."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"s3.amazonaws.com\\\", \\\"EventName\\\": \\\"List*\\\"}\", \"hyperparameters\": null, \"input\": \"Does the number of S3 List operations exceed a 3x increase over the average hourly count, indicating potential unauthorized data exploration or reconnaissance?\", \"retrieval_context\": [\" - Resource listing operations (events with names starting with \\\"List\\\") in CloudTrail capture API calls that enumerate or retrieve metadata about cloud resources across services (e.g., ListBuckets, ListInstances). These events help SREs monitor inventory changes, detect unusual enumeration activity, and maintain infrastructure visibility. \\n\\n**Purpose:** Track and audit resource discovery actions to identify potential reconnaissance or automation behaviors.\\n\\n**Alert Threshold:** Trigger alerts when the rate of List* events exceeds a baseline by 3x within a 5-minute window, indicating possible automated scanning or misconfigured scripts.\\n\\n**Impact:**  \\n- **High values:** May signal excessive resource enumeration, potentially due to unauthorized scanning, automation loops, or misconfigured monitoring tools, increasing API costs and risk exposure.  \\n- **Low values:** Could indicate loss of visibility or failures in inventory processes, risking outdated infrastructure awareness.\\n\\n**Example Alert Rule:**  \\n`IF count(List*) > 300 events in 5 minutes THEN alert \\\"High resource enumeration activity detected\\\"`  \\n\\n**Dashboard Use:** Visualize List* event counts over time alongside other API calls to correlate spikes with deployments or incidents, aiding in capacity planning and anomaly detection.\", \" - S3 Get* events in CloudTrail capture all read operations on S3 objects, such as GetObject, GetObjectAcl, and GetObjectVersion. These events indicate when data is accessed or downloaded from your buckets, providing critical visibility into data retrieval patterns and potential unauthorized access.  \\n\\n**Purpose:** Monitor and audit object read activity to detect unusual access spikes, potential data exfiltration, or performance bottlenecks caused by excessive reads.\\n\\n**Alert Threshold:** Trigger an alert if the number of Get* events exceeds a baseline threshold (e.g., a 3x increase over the average hourly rate) or if access occurs from unexpected IP addresses or principals.\\n\\n**Impact:**  \\n- **High values:** May indicate heavy data consumption, possible data leakage, or abuse of resources leading to increased costs and degraded application performance.  \\n- **Low values:** Could suggest reduced usage, potential application issues, or misconfigured permissions blocking legitimate access.\\n\\n**Example Alert Rule:**  \\nAlert when the count of s3.amazonaws.com Get* events in CloudTrail exceeds 5000 within 1 hour, or when access originates from an IP address outside your trusted network range.\\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing hourly counts of Get* events per bucket, combined with a heatmap of source IP addresses, enabling quick identification of unusual access patterns or spikes in data retrieval.\", \" - S3 List operations (EventName starting with \\\"List\\\") in CloudTrail capture requests to enumerate buckets, list objects, or browse directories within S3. These events help track data discovery activities, such as inventory management or security reconnaissance attempts by identifying who is accessing or exploring bucket contents.  \\n\\n**Purpose:**  \\n- Monitor access patterns to detect unusual or excessive listing activity that may indicate unauthorized data exploration or reconnaissance.  \\n- Support auditing and compliance by providing visibility into how and when bucket contents are being queried.\\n\\n**Alert Threshold Guidance:**  \\n- Trigger alerts when the number of List operations exceeds a baseline threshold (e.g., a sudden spike above normal daily averages or a sustained high rate over a short period).  \\n- Thresholds should be customized per environment but a common starting point is alerting on a 3x increase over the average hourly count or more than 100 List requests per minute from a single principal or IP.\\n\\n**Impact of Values:**  \\n- **High values:** May indicate automated scanning, data scraping, or reconnaissance by malicious actors, potentially preceding data exfiltration attempts. Could also reflect legitimate bulk inventory or analytics jobs\\u2014context matters.  \\n- **Low values:** Normal or expected in environments with limited or infrequent bucket browsing; very low values typically pose no risk.\\n\\n**Example Usage:**  \\n- **Dashboard:** Visualize the count of List* events over time, segmented by user or source IP, to identify unusual spikes or patterns.  \\n- **Alert Rule (pseudo-code):**  \\n  ```  \\n  IF count(EventName LIKE \\\"List*\\\") BY user OVER 15 minutes > 3x baseline THEN alert(\\\"Unusual S3 List activity detected for user\\\")  \\n  ```  \\nThis enables proactive detection of suspicious enumeration behavior while minimizing false positives from routine operations.\", \" - This pattern captures AWS KMS Decrypt API calls recorded in CloudTrail, indicating when encrypted data is accessed and decrypted using KMS keys. It helps SREs monitor data access events for security auditing and anomaly detection. A sudden spike in Decrypt events may signal unusual or unauthorized data access, while consistently low or expected volumes suggest normal operation. As a threshold, alerting on a sustained increase exceeding 3 standard deviations above the historical average or a sudden burst of Decrypt calls within a short time window (e.g., 5 minutes) is recommended. For example, an alert rule could trigger when the count of Decrypt events exceeds 100 in 5 minutes, indicating potential data exfiltration or misuse. In dashboards, tracking the rate of Decrypt events over time alongside user identities and key IDs can help quickly identify suspicious patterns or compromised credentials.\", \" - This pattern captures CloudWatch API operations that list resources, such as metrics, log groups, and alarms, as recorded in CloudTrail under EventSource \\\"cloudwatch.amazonaws.com\\\" with EventNames starting with \\\"List\\\". It helps SREs monitor enumeration activity on CloudWatch resources, which can indicate normal operational queries or potential reconnaissance by unauthorized users.\\n\\n**Purpose:**  \\nTo track and analyze the frequency of CloudWatch resource listing actions, enabling detection of unusual spikes that may signal automated scanning, misconfigurations, or security incidents.\\n\\n**Threshold Guidance:**  \\nSet alert thresholds based on baseline activity for your environment. For example, trigger an alert if the number of List* events exceeds 3 standard deviations above the daily average or if more than 100 list operations occur within a 5-minute window, indicating abnormal enumeration.\\n\\n**Impact of Values:**  \\n- **High values:** May indicate excessive or automated querying of CloudWatch resources, potentially revealing reconnaissance attempts or inefficient scripts causing performance overhead.  \\n- **Low values:** Typically normal, but a sudden drop could suggest issues with monitoring tools or API access problems.\\n\\n**Example Alert Rule:**  \\nTrigger an alert when the count of CloudWatch List* events in CloudTrail exceeds 100 within 5 minutes, signaling potential unauthorized or excessive enumeration activity.\\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of CloudWatch List* events per 5-minute interval, overlaid with the alert threshold line, to visualize normal versus anomalous listing activity.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": true,
                        "score": 0.9060086653329865,
                        "reason": "The Retrieval Context directly addresses the Input question by clearly explaining what S3 List operations are, their purpose, and how to monitor for a 3x increase over the average hourly count. It provides detailed alert threshold guidance, impact of high values, and example alert rules, enabling confident detection of potential unauthorized data exploration. The description is clear, concise, and sufficiently covers measurement, units, context, and implications, making it highly useful for answering the question. Minor deduction is due to slight complexity in formatting that could affect immediate readability.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Compare the Input (monitoring question) with the Retrieval Context (metric description) to ensure the description clearly addresses the question asked.\",\n    \"Evaluate the clarity of the Retrieval Context by checking if it is understandable, concise, and free of ambiguity in relation to the wording and scope of the Input.\",\n    \"Assess coverage by verifying if the Retrieval Context sufficiently explains what is measured, the units, the relevant context, and implications that directly support answering the Input question.\",\n    \"Determine the utility by confirming if the description provides actionable or insightful information that enables a user to confidently answer the Input question based on the Retrieval Context.\"\n] \n \nRubric:\nNone \n \nScore: 0.9060086653329865"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Compare the Input (monitoring question) with the Retrieval Context (metric description) to ensure the description clearly addresses the question asked.",
                            "Evaluate the clarity of the Retrieval Context by checking if it is understandable, concise, and free of ambiguity in relation to the wording and scope of the Input.",
                            "Assess coverage by verifying if the Retrieval Context sufficiently explains what is measured, the units, the relevant context, and implications that directly support answering the Input question.",
                            "Determine the utility by confirming if the description provides actionable or insightful information that enables a user to confidently answer the Input question based on the Retrieval Context."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"iam.amazonaws.com\\\", \\\"EventName\\\": \\\"Delete*\\\"}\", \"hyperparameters\": null, \"input\": \"Are there any IAM deletion events recorded by CloudTrail that exceed the normal baseline activity?\", \"retrieval_context\": [\" - CloudFormation Delete* events in CloudTrail indicate the initiation or completion of stack deletion operations, signaling infrastructure teardown and resource decommissioning activities. These events help SREs monitor environment lifecycle changes and ensure that deletions are intentional and controlled. \\n\\n**Alert Threshold:** Trigger an alert if the number of Delete* events exceeds a predefined baseline (e.g., more than 3 deletions within 1 hour) or occurs unexpectedly outside of scheduled maintenance windows, as this may indicate accidental or malicious infrastructure removal.\\n\\n**Impact of Values:**  \\n- **High frequency:** May lead to unintended service disruptions, data loss, or compliance risks due to rapid or bulk resource deletions. Requires immediate investigation.  \\n- **Low or zero frequency:** Normal in stable environments; indicates no recent stack deletions and stable infrastructure.\\n\\n**Example Usage:**  \\nCreate a dashboard widget tracking the count of CloudFormation Delete* events over time. Set an alert rule to notify the SRE team if Delete* events spike above the threshold within a rolling 1-hour window, enabling prompt response to potential infrastructure teardown incidents.\", \" - IAM deletion events (e.g., DeleteUser, DeleteRole) recorded by CloudTrail indicate removal of IAM identities or permissions. These events are critical for detecting unauthorized or accidental deletions that can disrupt access or signal a security breach. An alert threshold should be set to trigger on any unexpected deletion event or a sudden spike above normal baseline activity (e.g., more than 1 deletion event within 5 minutes), as even a single deletion can have significant impact. High volumes may indicate automated attacks or misconfigurations causing mass access removal, while low or zero values typically indicate normal operation.  \\nExample alert rule: trigger when count of iam.amazonaws.com Delete* events > 1 in 5 minutes.  \\nExample dashboard widget: a time series graph showing Delete* event counts over time, annotated with alert thresholds to quickly identify unusual deletion activity.\", \" - This event pattern captures all CloudTrail events where CloudWatch Logs resources\\u2014such as log groups or log streams\\u2014are deleted (e.g., DeleteLogGroup, DeleteLogStream). Its purpose is to monitor and audit log deletion activities, which can be legitimate cleanup or indicate potential loss of critical log data needed for troubleshooting and compliance.\\n\\n**Alert Threshold:**  \\nTrigger an alert if the number of delete events exceeds a baseline threshold within a defined time window (e.g., more than 3 deletions within 1 hour), or if deletions occur unexpectedly outside of scheduled maintenance windows.\\n\\n**Impact:**  \\n- **High frequency of deletions:** May indicate accidental or malicious removal of logs, risking loss of observability and forensic data. Immediate investigation is recommended.  \\n- **Low or zero deletions:** Normal operation, indicating logs are retained as expected.\\n\\n**Example Alert Rule:**  \\n\\u201cAlert if DeleteLogGroup or DeleteLogStream events from logs.amazonaws.com exceed 3 occurrences in 60 minutes.\\u201d  \\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of Delete* events over time, annotated with alert thresholds and maintenance windows, enabling quick identification of unusual spikes in log deletions.\", \" - This pattern captures ECS deletion events recorded in CloudTrail, specifically any API calls starting with \\\"Delete\\\" from the ECS service (e.g., DeleteCluster, DeleteService, DeleteTaskSet). Its purpose is to monitor when ECS resources are removed, which can signal intentional cleanup or unintended disruptions affecting service availability.\\n\\n**Threshold guidance:**  \\n- Trigger an alert if the number of ECS deletion events exceeds a baseline threshold within a short time window (e.g., more than 3 Delete* events in 5 minutes), as this may indicate accidental mass deletion or a security incident.  \\n- Low or expected deletion rates typically reflect routine maintenance or scaling down of resources and generally have minimal impact.\\n\\n**Impact:**  \\n- High deletion event counts can lead to service downtime, loss of running tasks, or cluster instability, requiring immediate investigation.  \\n- Low or zero deletion events usually indicate stable ECS resource management.\\n\\n**Example alert rule:**  \\n- Alert when `count(events where EventSource=\\\"ecs.amazonaws.com\\\" and EventName starts with \\\"Delete\\\") > 3` within 5 minutes.  \\n- This alert can be visualized on a dashboard showing ECS Delete* event counts over time, helping SREs quickly identify unusual spikes and correlate with service health metrics.\", \" - This pattern captures all EC2 resource deletion events recorded in CloudTrail, triggered by any API calls starting with \\\"Delete\\\" from the EC2 service (e.g., DeleteSecurityGroup, DeleteNetworkInterface). Its purpose is to monitor and alert on the removal of critical EC2 components, which can impact infrastructure stability and security.\\n\\n**Threshold guidance:**  \\n- Set an alert if the number of deletion events exceeds a baseline threshold within a short time window (e.g., more than 5 deletions in 10 minutes), as this may indicate accidental mass deletions or malicious activity.  \\n- A low or zero count is typical during normal operations, while sudden spikes warrant immediate investigation.\\n\\n**Impact:**  \\n- High deletion event counts can lead to service disruptions, loss of network connectivity, or security vulnerabilities if key resources like security groups or network interfaces are removed unexpectedly.  \\n- Low or no deletion activity generally indicates stable infrastructure management.\\n\\n**Example alert rule:**  \\nTrigger an alert when the count of events matching {\\\"EventSource\\\": \\\"ec2.amazonaws.com\\\", \\\"EventName\\\": \\\"Delete*\\\"} exceeds 5 within 10 minutes.\\n\\n**Example dashboard usage:**  \\nVisualize the count of EC2 deletion events over time to identify unusual spikes, correlating with other operational metrics to assess potential impact on system availability or security posture.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": true,
                        "score": 0.9,
                        "reason": "The description clearly addresses the monitoring question by explaining IAM deletion events recorded by CloudTrail, including specific event examples (DeleteUser, DeleteRole) and their significance. It provides detailed coverage of what is measured, alert thresholds (e.g., more than 1 deletion event within 5 minutes), and contextual implications such as security risks and operational impact. The utility is high, offering example alert rules and dashboard visualization guidance to confidently detect deviations from baseline activity. A minor improvement could be explicitly stating the units of measurement (event counts per time window) upfront for enhanced clarity.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Compare the input (monitoring question) with the retrieval context (metric description) to assess clarity: Ensure the description directly addresses the question in a clear and concise manner.\",\n    \"Evaluate coverage by checking if the description explains what is measured, including units and contextual implications relevant to the question.\",\n    \"Assess utility by determining if the description provides sufficient information to confidently answer the monitoring question.\",\n    \"If any aspect scores below 8, identify specific gaps in the description relative to the question and suggest targeted improvements to enhance clarity, coverage, or utility.\"\n] \n \nRubric:\nNone \n \nScore: 0.9"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Compare the input (monitoring question) with the retrieval context (metric description) to assess clarity: Ensure the description directly addresses the question in a clear and concise manner.",
                            "Evaluate coverage by checking if the description explains what is measured, including units and contextual implications relevant to the question.",
                            "Assess utility by determining if the description provides sufficient information to confidently answer the monitoring question.",
                            "If any aspect scores below 8, identify specific gaps in the description relative to the question and suggest targeted improvements to enhance clarity, coverage, or utility."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"iam.amazonaws.com\\\", \\\"EventName\\\": \\\"Create*\\\"}\", \"hyperparameters\": null, \"input\": \"Are there any CreateUser events that indicate unauthorized user creation?\", \"retrieval_context\": [\" - CloudFormation stack creation events (**EventSource: cloudformation.amazonaws.com**, **EventName: Create\\\\*** ) represent API calls initiating the provisioning of AWS infrastructure and resources via CloudFormation templates. These events in CloudTrail help SREs monitor the start of environment setups and infrastructure deployments as part of Infrastructure as Code workflows.\\n\\n**Purpose:** Track and audit when new CloudFormation stacks or stack components are being created, enabling visibility into changes in infrastructure state and deployment activities.\\n\\n**Alert Thresholds:**  \\n- Trigger an alert if the number of Create* events exceeds a baseline threshold within a short time window (e.g., >10 stack creation attempts in 5 minutes), which may indicate automated deployment loops, misconfigurations, or potential security incidents.  \\n- Alert if Create* events spike unexpectedly outside of scheduled deployment windows or change management periods.\\n\\n**Impact of Values:**  \\n- **High volume:** May signal rapid infrastructure changes that could lead to instability, resource contention, or deployment failures. It could also indicate unauthorized or accidental mass provisioning.  \\n- **Low or zero volume:** Normal during steady-state operations; however, a sudden drop during expected deployment windows might indicate pipeline failures or blocked deployments.\\n\\n**Example Usage:**  \\n- **Dashboard:** Visualize the count of CloudFormation Create* events over time, segmented by stack name or user identity, to correlate deployments with system performance or incidents.  \\n- **Alert Rule:**  \\n  ```  \\n  WHEN count(events where EventSource=\\\"cloudformation.amazonaws.com\\\" AND EventName LIKE \\\"Create%\\\") > 10 within 5 minutes  \\n  THEN trigger alert \\\"High rate of CloudFormation stack creation events detected\\\"  \\n  ```  \\nThis enables proactive detection of abnormal infrastructure provisioning activity and supports rapid investigation and response.\", \" - This pattern captures all CloudFront distribution creation events recorded in CloudTrail, identified by event names starting with \\\"Create\\\" from the CloudFront service. Its purpose is to monitor when new CloudFront distributions are provisioned, including their initial configuration details. Tracking these events helps SREs detect unexpected or unauthorized distribution creations that could impact content delivery, security, or cost.\\n\\n**Alert Threshold:**  \\nTrigger an alert if the number of CloudFront distribution creation events exceeds a defined threshold within a short time window (e.g., more than 3 creations within 1 hour), as this may indicate automation errors, misconfigurations, or potential security incidents.\\n\\n**Impact of Values:**  \\n- **High values:** A spike in creation events could signal rapid environment changes, possible misconfigurations, or unauthorized activity, potentially leading to increased costs or service disruptions.  \\n- **Low or zero values:** Normal operation typically involves infrequent distribution creations; zero or low values indicate stable infrastructure without unexpected provisioning.\\n\\n**Example Alert Rule:**  \\n\\\"Alert when count of events matching {EventSource: 'cloudfront.amazonaws.com', EventName: 'Create*'} exceeds 3 within 1 hour.\\\"\\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of CloudFront distribution creation events over time, enabling quick identification of unusual spikes or trends in distribution provisioning activity.\", \" - This pattern detects SNS topic creation events recorded in CloudTrail, specifically any API calls starting with \\\"Create\\\" from the SNS service (e.g., CreateTopic). It helps SREs monitor when new SNS topics are provisioned, which can indicate changes in messaging architecture or potential unauthorized resource creation. An alert threshold could be set on the number of Create* events within a given time window (e.g., more than 5 topic creations in 10 minutes), as a sudden spike may signal automation errors or security issues. Low or expected values typically indicate normal operations, while high values may impact system stability by increasing resource usage or indicate potential misuse. For example, an alert rule could trigger if the count of {\\\"EventSource\\\": \\\"sns.amazonaws.com\\\", \\\"EventName\\\": \\\"Create*\\\"} events exceeds 5 in 10 minutes, and a dashboard widget could display a time series graph of topic creation events to track trends and detect anomalies.\", \" - This pattern detects Secrets Manager creation events in CloudTrail, specifically any API calls starting with \\\"Create\\\" (e.g., CreateSecret). It helps SREs monitor when new secrets, secret versions, or related configurations are added, which could indicate deployment changes or potential security risks.  \\n**Alert threshold:** Trigger an alert if the number of create events exceeds a baseline (e.g., more than 5 creates within 10 minutes), as a sudden spike may signal unauthorized secret creation or misconfiguration. Conversely, zero create events over an extended period in an active environment might indicate issues with deployment pipelines or automation failures.  \\n**Impact:**  \\n- High values: Could indicate potential security breaches, unauthorized secret provisioning, or rapid environment changes requiring immediate investigation.  \\n- Low values: May suggest stalled deployments or automation problems, potentially delaying application updates or secret rotations.  \\n**Example usage:**  \\nIn a dashboard, plot the count of Secrets Manager Create* events over time to visualize spikes. An alert rule could be:  \\n`WHEN count(secretsmanager.amazonaws.com Create* events) > 5 within 10 minutes THEN trigger alert \\\"Unusual Secrets Creation Activity\\\"`  \\nThis enables proactive detection of abnormal secret creation activity, helping maintain security and operational stability.\", \" - Tracks all creation events initiated via AWS IAM, including users, roles, policies, and groups. Each event records the creation of a new identity or access control entity within the AWS account. This measurement is event-based, counting each individual creation action. Monitoring these events is essential for detecting unauthorized access setup and ensuring compliance with security policies.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": false,
                        "score": 0.5923095176394504,
                        "reason": "The input question is clear and concise, asking specifically about unauthorized CreateUser events. However, the retrieval context does not explicitly mention CreateUser events or user creation specifically; it focuses broadly on creation events for various AWS services like IAM identities, Secrets Manager, CloudFront, CloudFormation, and SNS. While the first context snippet mentions creation of users, roles, policies, and groups, it lacks detail on how to identify unauthorized user creation or specific alerting guidance for CreateUser events. This limits the utility of the context in fully answering the question. To improve, the context should explicitly address CreateUser events, their detection, and indicators of unauthorized creation to better align with the monitoring question.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Evaluate the Input for clarity by checking if the monitoring question is clearly stated and concise without ambiguity.\",\n    \"Assess the Retrieval Context (metric description) for coverage by verifying if it explains what is measured, including units, relevant context, and potential implications.\",\n    \"Compare the Input and Retrieval Context to determine utility by ensuring the description provides enough information to effectively answer the monitoring question.\",\n    \"Assign a score from 1 to 10 based on how well the description balances clarity, coverage, and utility relative to the question; if below 8, provide a specific suggestion to improve alignment or completeness.\"\n] \n \nRubric:\nNone \n \nScore: 0.5923095176394504"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Evaluate the Input for clarity by checking if the monitoring question is clearly stated and concise without ambiguity.",
                            "Assess the Retrieval Context (metric description) for coverage by verifying if it explains what is measured, including units, relevant context, and potential implications.",
                            "Compare the Input and Retrieval Context to determine utility by ensuring the description provides enough information to effectively answer the monitoring question.",
                            "Assign a score from 1 to 10 based on how well the description balances clarity, coverage, and utility relative to the question; if below 8, provide a specific suggestion to improve alignment or completeness."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"lambda.amazonaws.com\\\", \\\"EventName\\\": \\\"Update*\\\"}\", \"hyperparameters\": null, \"input\": \"Are there spikes in UpdateEvents that correlate with recent drops in HealthyHostCount?\", \"retrieval_context\": [\" - Detective security investigation events capture detailed activity logs related to threat analysis, security incident investigations, and behavioral analytics within AWS Detective. These events help SREs monitor and correlate security forensics and threat intelligence to identify suspicious or anomalous behavior in the environment.\\n\\n**Purpose in CloudTrail:**  \\nEvents from `detective.amazonaws.com` provide visibility into investigative actions and findings performed by AWS Detective, enabling tracking of security-related activities and potential threat escalations.\\n\\n**Alert Threshold Guidance:**  \\n- Trigger alerts when the volume of Detective investigation events spikes significantly above baseline (e.g., a 3x increase in investigative queries or findings within a short time window), indicating potential active threat hunting or incident response.  \\n- Alert on unusual event types or repeated failed investigation attempts that may suggest misuse or compromised credentials.\\n\\n**Impact of Values:**  \\n- **High event volume:** May indicate active security incidents, ongoing investigations, or potential security breaches requiring immediate attention.  \\n- **Low or no events:** Could suggest normal operation or lack of active investigations; however, a sudden drop after a period of activity might also warrant review.\\n\\n**Example Alert Rule:**  \\n```\\nWHEN count(detective.amazonaws.com EventName=*) OVER 15 minutes > 3 * baseline_average THEN alert \\\"Unusual Detective investigation activity detected\\\"\\n```\\n\\n**Example Dashboard Widget:**  \\n- A time-series graph showing the count of Detective events per minute, annotated with alerts on spikes.  \\n- A table listing top EventNames and their frequencies to identify unusual investigative patterns.\", \" - This pattern captures SNS unsubscription events recorded in CloudTrail, indicating when endpoints or subscribers are removed from SNS topics. For an SRE, monitoring these events helps track changes in notification delivery and detect potential disruptions or configuration changes.\\n\\n**Purpose:**  \\n- Identify when subscribers unsubscribe from SNS topics, which may reflect endpoint decommissioning, application changes, or user-initiated opt-outs.  \\n- Detect unusual spikes that could indicate mass unsubscriptions due to misconfigurations, security incidents, or service issues.\\n\\n**Alert Threshold:**  \\n- Trigger an alert if the number of Unsubscribe events exceeds a baseline threshold (e.g., more than 5 unsubscriptions within 5 minutes) or shows a sudden increase compared to historical averages. Thresholds should be tuned based on normal subscription churn rates.\\n\\n**Impact:**  \\n- **High values:** May signal widespread endpoint removals causing notification delivery failures, potential service degradation, or security concerns (e.g., unauthorized unsubscriptions). Immediate investigation is warranted.  \\n- **Low or zero values:** Typically expected during stable operations; a sudden drop to zero after a period of regular unsubscriptions might indicate logging issues or CloudTrail misconfigurations.\\n\\n**Example Usage:**  \\n- **Dashboard:** Display a time series graph of Unsubscribe event counts per minute to visualize trends and detect anomalies.  \\n- **Alert Rule (pseudo-code):**  \\n  ```\\n  WHEN count(Events where EventSource=\\\"sns.amazonaws.com\\\" AND EventName LIKE \\\"Unsubscribe%\\\") \\n  OVER last 5 minutes > 5 \\n  THEN trigger alert \\\"High SNS Unsubscription Rate\\\"\\n  ```\", \" - This pattern captures all Route 53 \\\"Get\\\" API operations logged in CloudTrail, such as retrieving hosted zone details, record sets, and health check statuses. It helps SREs monitor read access to DNS configurations and health data, which can indicate normal operational queries or potential reconnaissance activity. A sudden spike in these \\\"Get\\\" requests\\u2014exceeding a baseline threshold (e.g., 3 standard deviations above the average hourly rate)\\u2014may signal unusual interest in DNS infrastructure, warranting investigation. Conversely, a significant drop could indicate issues with monitoring or automation systems relying on these queries. For example, an alert rule could trigger when the count of **{\\\"EventSource\\\": \\\"route53.amazonaws.com\\\", \\\"EventName\\\": \\\"Get*\\\"}** events exceeds 100 requests per hour, and a dashboard widget might display a time series graph of these events to track trends and detect anomalies in DNS query activity.\", \" - This pattern captures all Route 53 resource creation events recorded in CloudTrail, such as the creation of hosted zones, DNS record sets, and health checks. Monitoring these events helps SREs detect configuration changes that could impact DNS resolution and application availability. \\n\\n**Purpose:** Track when new Route 53 resources are created to identify potential unauthorized changes or misconfigurations early.\\n\\n**Alert Threshold:** Trigger an alert if the number of creation events exceeds a baseline threshold (e.g., more than 5 creation events within 10 minutes), which may indicate automated misconfigurations, security breaches, or unintended mass changes.\\n\\n**Impact:**  \\n- **High values:** A spike in creation events could lead to DNS inconsistencies, increased attack surface, or service disruptions if malicious or erroneous resources are introduced.  \\n- **Low or zero values:** Normal operation, assuming no planned infrastructure changes.\\n\\n**Example Alert Rule:**  \\nAlert when `count({\\\"EventSource\\\": \\\"route53.amazonaws.com\\\", \\\"EventName\\\": \\\"Create*\\\"})` > 5 within 10 minutes.\\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of Route 53 creation events over time, enabling quick identification of unusual spikes in resource creation activity.\", \" - This pattern captures all update-related events from Amazon EKS recorded in CloudTrail, such as cluster version upgrades, managed node group modifications, and add-on updates. Its purpose is to monitor changes that can affect cluster stability, security, or performance. An SRE should set alert thresholds based on the frequency and timing of these update events\\u2014for example, triggering an alert if more than 3 update events occur within a 1-hour window, which may indicate unexpected or automated changes that require investigation. High volumes of update events in a short period could signal potential configuration drift, deployment issues, or unauthorized modifications, increasing risk to cluster availability and security. Conversely, low or no update events over extended periods may suggest stagnation in maintenance or missed critical updates. An example alert rule could be: \\u201cAlert if count of events matching {EventSource: 'eks.amazonaws.com', EventName: 'Update*'} exceeds 3 within 60 minutes.\\u201d In a dashboard, this pattern can be visualized as a time series graph showing update event counts per hour, helping SREs quickly identify unusual spikes or trends in cluster modifications.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": false,
                        "score": 0.6872140788819441,
                        "reason": "The input question is clear and relevant, asking about spikes in UpdateEvents correlating with drops in HealthyHostCount. The retrieval context includes a detailed description of update-related events from Amazon EKS, covering what is measured, alert thresholds, impact, and example usage, which aligns well with the 'UpdateEvents' part of the question. However, the context does not address HealthyHostCount or its relationship to UpdateEvents, limiting its utility in fully answering the monitoring question. To improve, the retrieval context should explicitly include metrics or patterns related to HealthyHostCount and how it correlates with UpdateEvents.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Assess the Input for clarity and relevance in terms of the monitoring question, ensuring it is concise and directly linked to what needs to be measured.\",\n    \"Evaluate the Retrieval Context description for coverage, checking if it details what is measured, the units, the context, and implications.\",\n    \"Compare the Input and Retrieval Context to determine if the description enables answering the monitoring question effectively (utility).\",\n    \"Score the description based on how clearly and comprehensively the retrieval context supports the metric question, and suggest specific improvements if the score is below 8.\"\n] \n \nRubric:\nNone \n \nScore: 0.6872140788819441"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Assess the Input for clarity and relevance in terms of the monitoring question, ensuring it is concise and directly linked to what needs to be measured.",
                            "Evaluate the Retrieval Context description for coverage, checking if it details what is measured, the units, the context, and implications.",
                            "Compare the Input and Retrieval Context to determine if the description enables answering the monitoring question effectively (utility).",
                            "Score the description based on how clearly and comprehensively the retrieval context supports the metric question, and suggest specific improvements if the score is below 8."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"rds.amazonaws.com\\\", \\\"EventName\\\": \\\"Create*\\\"}\", \"hyperparameters\": null, \"input\": \"Are there more than three Create* events from rds.amazonaws.com indicating potential unexpected scaling or automation issues?\", \"retrieval_context\": [\" - CloudFormation stack creation events (**EventSource: cloudformation.amazonaws.com**, **EventName: Create\\\\*** ) represent API calls initiating the provisioning of AWS infrastructure and resources via CloudFormation templates. These events in CloudTrail help SREs monitor the start of environment setups and infrastructure deployments as part of Infrastructure as Code workflows.\\n\\n**Purpose:** Track and audit when new CloudFormation stacks or stack components are being created, enabling visibility into changes in infrastructure state and deployment activities.\\n\\n**Alert Thresholds:**  \\n- Trigger an alert if the number of Create* events exceeds a baseline threshold within a short time window (e.g., >10 stack creation attempts in 5 minutes), which may indicate automated deployment loops, misconfigurations, or potential security incidents.  \\n- Alert if Create* events spike unexpectedly outside of scheduled deployment windows or change management periods.\\n\\n**Impact of Values:**  \\n- **High volume:** May signal rapid infrastructure changes that could lead to instability, resource contention, or deployment failures. It could also indicate unauthorized or accidental mass provisioning.  \\n- **Low or zero volume:** Normal during steady-state operations; however, a sudden drop during expected deployment windows might indicate pipeline failures or blocked deployments.\\n\\n**Example Usage:**  \\n- **Dashboard:** Visualize the count of CloudFormation Create* events over time, segmented by stack name or user identity, to correlate deployments with system performance or incidents.  \\n- **Alert Rule:**  \\n  ```  \\n  WHEN count(events where EventSource=\\\"cloudformation.amazonaws.com\\\" AND EventName LIKE \\\"Create%\\\") > 10 within 5 minutes  \\n  THEN trigger alert \\\"High rate of CloudFormation stack creation events detected\\\"  \\n  ```  \\nThis enables proactive detection of abnormal infrastructure provisioning activity and supports rapid investigation and response.\", \" - Redshift cluster creation events in CloudTrail capture all API calls initiating the provisioning of new Redshift clusters (e.g., CreateCluster). These events indicate when new data warehouse resources are being deployed or configured, impacting capacity and cost.  \\n**Purpose:** Enables SREs to monitor and audit cluster provisioning activities for operational control and security compliance.  \\n**Alert Threshold:** Trigger alerts on an unusually high number of cluster creation events within a short time window (e.g., >3 creates in 1 hour), which may indicate automation errors, misconfigurations, or unauthorized resource provisioning.  \\n**Impact:**  \\n- **High values:** May lead to resource sprawl, increased costs, and potential performance degradation due to over-provisioning. Could also signal security risks if unexpected clusters are created.  \\n- **Low or zero values:** Normal in stable environments; no new clusters being created means stable infrastructure.  \\n**Example Alert Rule:**  \\n\\u201cAlert if count of events with EventSource='redshift.amazonaws.com' and EventName starting with 'Create' exceeds 3 within 60 minutes.\\u201d  \\n**Dashboard Use:** Visualize the frequency of Redshift cluster creation events over time to detect spikes or anomalies, correlating with deployment activities or security incidents.\", \" - S3 bucket creation events captured by CloudTrail under **{\\\"EventSource\\\": \\\"s3.amazonaws.com\\\", \\\"EventName\\\": \\\"Create*\\\"}** indicate when new buckets or related resources (e.g., bucket policies, access points) are provisioned. These events help SREs monitor infrastructure changes that affect data storage, security posture, and compliance.\\n\\n**Purpose:**  \\nTrack and audit the creation of S3 buckets and associated configurations to ensure proper governance, prevent unauthorized resource sprawl, and maintain compliance with organizational policies.\\n\\n**Alert Threshold:**  \\nTrigger an alert if the number of S3 bucket creation events exceeds a defined threshold within a short time window (e.g., more than 5 bucket creations within 10 minutes), which may indicate automated provisioning errors, misconfigurations, or potential security incidents such as unauthorized resource creation.\\n\\n**Impact of Values:**  \\n- **High frequency:** May signal abnormal activity, such as a compromised credential or runaway automation scripts creating excessive buckets, leading to increased costs, security risks, or compliance violations.  \\n- **Low or zero frequency:** Normal in stable environments; however, sudden spikes should be investigated promptly.\\n\\n**Example Alert Rule:**  \\n\\u201cAlert when count of events with EventSource = 's3.amazonaws.com' and EventName starting with 'Create' exceeds 5 within 10 minutes.\\u201d\\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of S3 Create* events over time, with thresholds marked to highlight unusual spikes, enabling quick identification of abnormal bucket creation activity.\", \" - This pattern captures all CloudFront distribution creation events recorded in CloudTrail, identified by event names starting with \\\"Create\\\" from the CloudFront service. Its purpose is to monitor when new CloudFront distributions are provisioned, including their initial configuration details. Tracking these events helps SREs detect unexpected or unauthorized distribution creations that could impact content delivery, security, or cost.\\n\\n**Alert Threshold:**  \\nTrigger an alert if the number of CloudFront distribution creation events exceeds a defined threshold within a short time window (e.g., more than 3 creations within 1 hour), as this may indicate automation errors, misconfigurations, or potential security incidents.\\n\\n**Impact of Values:**  \\n- **High values:** A spike in creation events could signal rapid environment changes, possible misconfigurations, or unauthorized activity, potentially leading to increased costs or service disruptions.  \\n- **Low or zero values:** Normal operation typically involves infrequent distribution creations; zero or low values indicate stable infrastructure without unexpected provisioning.\\n\\n**Example Alert Rule:**  \\n\\\"Alert when count of events matching {EventSource: 'cloudfront.amazonaws.com', EventName: 'Create*'} exceeds 3 within 1 hour.\\\"\\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of CloudFront distribution creation events over time, enabling quick identification of unusual spikes or trends in distribution provisioning activity.\", \" - This pattern detects all Amazon RDS database creation events captured in CloudTrail, identified by any event name starting with \\\"Create\\\" from the \\\"rds.amazonaws.com\\\" source. It enables SREs to monitor when new RDS instances or related resources are provisioned, providing visibility into changes that may impact database capacity, cost, or security posture. A typical alert threshold could be set to trigger if more than 3 RDS creation events occur within a 1-hour window, indicating potential unexpected scaling or automation issues. High volumes of creation events may signal rapid infrastructure changes or misconfigurations, increasing operational risk and cost, while low or zero events generally indicate stable database provisioning activity. For example, an alert rule could be configured as:  \\n`WHEN count of events matching {\\\"EventSource\\\": \\\"rds.amazonaws.com\\\", \\\"EventName\\\": \\\"Create*\\\"} > 3 IN 1 hour THEN trigger alert`  \\nThis can be visualized in a dashboard showing the count of RDS creation events over time, helping teams quickly identify unusual spikes in database provisioning activity.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": true,
                        "score": 0.9,
                        "reason": "The retrieval context directly addresses the input question by describing RDS Create* events, including what is measured (creation events from rds.amazonaws.com), the units (count within 1 hour), context (monitoring provisioning and potential automation issues), and implications (indicating scaling or misconfiguration risks). The description is clear, concise, and provides an example alert rule and dashboard use, enabling confident monitoring and response. The only minor shortcoming is the lack of explicit mention of 'more than three' phrasing, though the threshold >3 is clearly stated.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Compare the input question with the retrieval context (description) to assess if the description provides a clear and concise explanation directly related to the question.\",\n    \"Evaluate the coverage of the description by verifying that it includes what is measured, units, context, and implications relevant to the input question.\",\n    \"Assess the overall clarity of the description by checking if it can be easily understood by someone with knowledge of cloud telemetry given the specific question asked.\",\n    \"Determine the utility by deciding if the description enables a user to confidently answer the input monitoring question based on the retrieval context provided.\"\n] \n \nRubric:\nNone \n \nScore: 0.9"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Compare the input question with the retrieval context (description) to assess if the description provides a clear and concise explanation directly related to the question.",
                            "Evaluate the coverage of the description by verifying that it includes what is measured, units, context, and implications relevant to the input question.",
                            "Assess the overall clarity of the description by checking if it can be easily understood by someone with knowledge of cloud telemetry given the specific question asked.",
                            "Determine the utility by deciding if the description enables a user to confidently answer the input monitoring question based on the retrieval context provided."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"rds.amazonaws.com\\\", \\\"EventName\\\": \\\"Delete*\\\"}\", \"hyperparameters\": null, \"input\": \"Does this single RDS deletion event align with scheduled maintenance or is it unexpected?\", \"retrieval_context\": [\" - CloudFormation Delete* events in CloudTrail indicate the initiation or completion of stack deletion operations, signaling infrastructure teardown and resource decommissioning activities. These events help SREs monitor environment lifecycle changes and ensure that deletions are intentional and controlled. \\n\\n**Alert Threshold:** Trigger an alert if the number of Delete* events exceeds a predefined baseline (e.g., more than 3 deletions within 1 hour) or occurs unexpectedly outside of scheduled maintenance windows, as this may indicate accidental or malicious infrastructure removal.\\n\\n**Impact of Values:**  \\n- **High frequency:** May lead to unintended service disruptions, data loss, or compliance risks due to rapid or bulk resource deletions. Requires immediate investigation.  \\n- **Low or zero frequency:** Normal in stable environments; indicates no recent stack deletions and stable infrastructure.\\n\\n**Example Usage:**  \\nCreate a dashboard widget tracking the count of CloudFormation Delete* events over time. Set an alert rule to notify the SRE team if Delete* events spike above the threshold within a rolling 1-hour window, enabling prompt response to potential infrastructure teardown incidents.\", \" - This event pattern captures all CloudTrail events where CloudWatch Logs resources\\u2014such as log groups or log streams\\u2014are deleted (e.g., DeleteLogGroup, DeleteLogStream). Its purpose is to monitor and audit log deletion activities, which can be legitimate cleanup or indicate potential loss of critical log data needed for troubleshooting and compliance.\\n\\n**Alert Threshold:**  \\nTrigger an alert if the number of delete events exceeds a baseline threshold within a defined time window (e.g., more than 3 deletions within 1 hour), or if deletions occur unexpectedly outside of scheduled maintenance windows.\\n\\n**Impact:**  \\n- **High frequency of deletions:** May indicate accidental or malicious removal of logs, risking loss of observability and forensic data. Immediate investigation is recommended.  \\n- **Low or zero deletions:** Normal operation, indicating logs are retained as expected.\\n\\n**Example Alert Rule:**  \\n\\u201cAlert if DeleteLogGroup or DeleteLogStream events from logs.amazonaws.com exceed 3 occurrences in 60 minutes.\\u201d  \\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of Delete* events over time, annotated with alert thresholds and maintenance windows, enabling quick identification of unusual spikes in log deletions.\", \" - This pattern captures AWS CloudTrail events where Amazon RDS instances are stopped (EventSource: \\\"rds.amazonaws.com\\\", EventName starting with \\\"Stop\\\"). It helps SREs monitor when RDS databases are intentionally or unintentionally stopped, which can impact application availability and indicate maintenance or cost-saving actions.\\n\\n**Purpose:**  \\n- Detect RDS stop operations to quickly identify potential service disruptions or planned maintenance.  \\n- Provide visibility into operational changes affecting database availability.\\n\\n**Alert Threshold Guidance:**  \\n- Trigger an alert if the number of RDS stop events exceeds a defined threshold within a short time window (e.g., more than 1 stop event per hour per critical environment), as multiple stops may indicate automation issues or unexpected failures.  \\n- For low-frequency environments, even a single unexpected stop event should trigger an alert.\\n\\n**Impact of Values:**  \\n- **High frequency of stop events:** May indicate instability, automation misconfiguration, or repeated manual interventions, potentially causing downtime or degraded service.  \\n- **Low or zero stop events:** Normal operation, assuming no planned maintenance is ongoing.\\n\\n**Example Alert Rule:**  \\n- Alert when count of events matching {\\\"EventSource\\\": \\\"rds.amazonaws.com\\\", \\\"EventName\\\": \\\"Stop*\\\"} exceeds 1 within 60 minutes for production accounts.  \\n- Dashboard widget can display a time series graph of RDS stop events over the past 24 hours, segmented by environment or instance ID, to correlate stops with incidents or maintenance windows.\", \" - This pattern captures ECS deletion events recorded in CloudTrail, specifically any API calls starting with \\\"Delete\\\" from the ECS service (e.g., DeleteCluster, DeleteService, DeleteTaskSet). Its purpose is to monitor when ECS resources are removed, which can signal intentional cleanup or unintended disruptions affecting service availability.\\n\\n**Threshold guidance:**  \\n- Trigger an alert if the number of ECS deletion events exceeds a baseline threshold within a short time window (e.g., more than 3 Delete* events in 5 minutes), as this may indicate accidental mass deletion or a security incident.  \\n- Low or expected deletion rates typically reflect routine maintenance or scaling down of resources and generally have minimal impact.\\n\\n**Impact:**  \\n- High deletion event counts can lead to service downtime, loss of running tasks, or cluster instability, requiring immediate investigation.  \\n- Low or zero deletion events usually indicate stable ECS resource management.\\n\\n**Example alert rule:**  \\n- Alert when `count(events where EventSource=\\\"ecs.amazonaws.com\\\" and EventName starts with \\\"Delete\\\") > 3` within 5 minutes.  \\n- This alert can be visualized on a dashboard showing ECS Delete* event counts over time, helping SREs quickly identify unusual spikes and correlate with service health metrics.\", \" - This pattern captures all AWS CloudTrail events where RDS resources are deleted (e.g., DeleteDBInstance, DeleteDBSnapshot). Its purpose is to monitor and alert on potentially destructive actions affecting RDS databases, which could indicate intentional cleanup, accidental deletions, or malicious activity. \\n\\n**Threshold guidance:**  \\n- Trigger an alert if more than 1 deletion event occurs within a short time window (e.g., 5 minutes), as multiple deletions in quick succession are unusual and may signal a problem.  \\n- A single deletion event should also prompt review, especially if unexpected or outside maintenance windows.\\n\\n**Impact:**  \\n- **High values:** Multiple deletions in a short period can lead to significant data loss or service disruption, requiring immediate investigation and possible recovery actions.  \\n- **Low values:** Occasional single deletions may be normal during maintenance but still warrant confirmation to avoid unnoticed data loss.\\n\\n**Example usage:**  \\nIn a monitoring dashboard, display a time series count of RDS deletion events filtered by this pattern. Configure an alert rule to notify the SRE team if the count exceeds 1 event within any 5-minute interval, enabling rapid response to potential incidents.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": true,
                        "score": 0.8348811804138666,
                        "reason": "The Retrieval Context clearly addresses the monitoring of RDS deletion events, explaining what is measured (RDS deletion events), the alert thresholds (alerts on more than 1 deletion in a short window and review of single deletions), and the implications (potential data loss or maintenance). It is understandable and concise, providing relevant guidance on distinguishing expected maintenance from unexpected deletions. However, it does not explicitly define scheduled maintenance windows or how to confirm alignment with them, which slightly limits its utility in fully answering whether a single deletion event is expected or unexpected.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Compare the Input (monitoring question) against the Retrieval Context (metric description) to ensure the description clearly addresses the specific information requested in the question.\",\n    \"Evaluate the clarity of the Retrieval Context by checking if it is understandable and concise without ambiguous or excessive details relative to the Input.\",\n    \"Assess the coverage of the Retrieval Context by verifying it explains what is measured, units, context, and implications relevant to the Input.\",\n    \"Determine the utility by judging whether the Retrieval Context provides sufficient and relevant information to effectively answer the Input\u2019s monitoring question.\"\n] \n \nRubric:\nNone \n \nScore: 0.8348811804138666"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Compare the Input (monitoring question) against the Retrieval Context (metric description) to ensure the description clearly addresses the specific information requested in the question.",
                            "Evaluate the clarity of the Retrieval Context by checking if it is understandable and concise without ambiguous or excessive details relative to the Input.",
                            "Assess the coverage of the Retrieval Context by verifying it explains what is measured, units, context, and implications relevant to the Input.",
                            "Determine the utility by judging whether the Retrieval Context provides sufficient and relevant information to effectively answer the Input\u2019s monitoring question."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"rds.amazonaws.com\\\", \\\"EventName\\\": \\\"Modify*\\\"}\", \"hyperparameters\": null, \"input\": \"Are there spikes in Modify* events indicating potential RDS resource misconfigurations or scaling issues?\", \"retrieval_context\": [\" - **{\\\"EventName\\\": \\\"Start*\\\"}** events in CloudTrail indicate the initiation of resource start operations across various AWS services, such as starting EC2 instances, RDS databases, or other managed resources. These events help SREs track when resources transition from a stopped or inactive state to an active state, which is critical for service availability, cost management, and operational recovery.\\n\\n**Purpose:**  \\nTo monitor and audit the activation of cloud resources, ensuring that start operations align with expected usage patterns and do not indicate unauthorized or unexpected activity.\\n\\n**Alert Thresholds:**  \\n- Trigger an alert if the number of **Start*** events exceeds a predefined threshold within a short time window (e.g., more than 10 start operations within 5 minutes), which may indicate an automated scaling event, a potential misconfiguration, or a security incident.  \\n- Conversely, alert if expected start operations do not occur during scheduled maintenance windows, indicating possible failures in recovery or deployment processes.\\n\\n**Impact of Values:**  \\n- **High volume of Start* events:** Could lead to increased costs due to resource activation, potential service disruptions if resources are started unexpectedly, or indicate automated scaling or recovery actions.  \\n- **Low or zero Start* events during expected periods:** May signal failed recovery attempts, stalled deployments, or issues in operational workflows, potentially impacting service availability.\\n\\n**Example Usage:**  \\nIn a CloudWatch dashboard, plot the count of **Start*** events over time to visualize spikes or drops. An alert rule can be configured as:  \\n```\\nIF count(Start* events) > 10 within 5 minutes THEN trigger alert \\\"Unusual spike in resource start operations\\\"\\n```\\nThis enables proactive investigation into unexpected resource activations or failures to start critical services.\", \" - Redshift cluster creation events in CloudTrail capture all API calls initiating the provisioning of new Redshift clusters (e.g., CreateCluster). These events indicate when new data warehouse resources are being deployed or configured, impacting capacity and cost.  \\n**Purpose:** Enables SREs to monitor and audit cluster provisioning activities for operational control and security compliance.  \\n**Alert Threshold:** Trigger alerts on an unusually high number of cluster creation events within a short time window (e.g., >3 creates in 1 hour), which may indicate automation errors, misconfigurations, or unauthorized resource provisioning.  \\n**Impact:**  \\n- **High values:** May lead to resource sprawl, increased costs, and potential performance degradation due to over-provisioning. Could also signal security risks if unexpected clusters are created.  \\n- **Low or zero values:** Normal in stable environments; no new clusters being created means stable infrastructure.  \\n**Example Alert Rule:**  \\n\\u201cAlert if count of events with EventSource='redshift.amazonaws.com' and EventName starting with 'Create' exceeds 3 within 60 minutes.\\u201d  \\n**Dashboard Use:** Visualize the frequency of Redshift cluster creation events over time to detect spikes or anomalies, correlating with deployment activities or security incidents.\", \" - This pattern captures CloudTrail events where ElastiCache clusters are modified, including scaling operations (e.g., changing node count or instance types), parameter group updates, and configuration changes. It helps SREs monitor critical changes that can impact cache performance, availability, or cost.\\n\\n**Purpose:**  \\nDetect when ElastiCache resources are altered to ensure changes are intentional, authorized, and do not degrade system stability.\\n\\n**Alert Threshold:**  \\nTrigger an alert on any **Modify\\\\*** event to catch all configuration changes. For noisy environments, consider alerting only on modifications that increase or decrease node count by more than 1, or changes to parameter groups affecting performance-critical settings.\\n\\n**Impact of Values:**  \\n- **High frequency of Modify events:** May indicate repeated scaling or configuration changes, potentially causing instability or unexpected behavior.  \\n- **Low or zero Modify events:** Suggests stable cache configuration, but lack of changes during scaling needs may indicate missed updates.\\n\\n**Example Alert Rule:**  \\nAlert when an event with `EventSource = \\\"elasticache.amazonaws.com\\\"` and `EventName` matching `Modify*` occurs, optionally filtering for changes in node count or parameter group names. This can be visualized in a dashboard showing a timeline of modification events alongside cluster performance metrics to correlate changes with impact.\", \" - This pattern captures all modification events related to Elastic Load Balancing (ELB) resources in AWS, such as changes to load balancer configurations, target groups, and listeners. In CloudTrail, these events indicate when an ELB\\u2019s setup is altered, which can affect traffic routing, availability, and security posture.\\n\\n**Purpose:**  \\nTo monitor and audit any configuration changes to ELB components that could impact application availability or security.\\n\\n**Alert Threshold:**  \\nTrigger an alert if the number of ELB modification events exceeds a defined threshold within a short time window (e.g., more than 3 Modify* events within 10 minutes), as this may indicate unintended or unauthorized changes.\\n\\n**Impact of Values:**  \\n- **High frequency of Modify* events:** Could signal potential misconfigurations, automated deployment issues, or malicious activity altering load balancer behavior, risking downtime or security breaches.  \\n- **Low or no Modify* events:** Typically expected during stable operation; absence of changes suggests configuration stability.\\n\\n**Example Usage:**  \\nIn a monitoring dashboard or alert rule, track the count of **{\\\"EventSource\\\": \\\"elasticloadbalancing.amazonaws.com\\\", \\\"EventName\\\": \\\"Modify*\\\"}** events over rolling 10-minute intervals. Configure alerts to notify the SRE team when this count spikes above the threshold, enabling prompt investigation and rollback if necessary.\", \" - This pattern matches AWS RDS events where the event name begins with \\\"Modify,\\\" indicating changes to RDS resources. It captures actions such as instance configuration updates, parameter group modifications, and scaling adjustments. Each event represents a discrete modification operation recorded as an individual API call. The measurement unit is the count of these modification events occurring within the monitored timeframe.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": false,
                        "score": 0.7939603544620288,
                        "reason": "The description clearly explains that Modify* events correspond to AWS RDS resource changes, including configuration updates and scaling adjustments, measured as counts of discrete API calls. It aligns well with the retrieval context by covering what is measured, units, and implications such as potential misconfigurations or scaling issues. However, it could improve by explicitly mentioning alert thresholds or example usage to better support the monitoring question about spikes indicating issues.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Compare the input metric description against the retrieval context to assess if the description is clear and concise in explaining the metric.\",\n    \"Evaluate whether the description covers what is measured, the units involved, relevant context, and the implications, using the retrieval context as a reference for completeness.\",\n    \"Assess if the description's level of detail and focus effectively supports answering the specific monitoring question presented in the input.\",\n    \"Determine alignment between the input and retrieval context by checking if the description utilizes information from the retrieval context to fully address the monitoring question, suggesting improvements if coverage or clarity is lacking.\"\n] \n \nRubric:\nNone \n \nScore: 0.7939603544620288"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Compare the input metric description against the retrieval context to assess if the description is clear and concise in explaining the metric.",
                            "Evaluate whether the description covers what is measured, the units involved, relevant context, and the implications, using the retrieval context as a reference for completeness.",
                            "Assess if the description's level of detail and focus effectively supports answering the specific monitoring question presented in the input.",
                            "Determine alignment between the input and retrieval context by checking if the description utilizes information from the retrieval context to fully address the monitoring question, suggesting improvements if coverage or clarity is lacking."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"dynamodb.amazonaws.com\\\", \\\"EventName\\\": \\\"Get*\\\"}\", \"hyperparameters\": null, \"input\": \"Are there spikes in Get* API calls, indicating an unusual volume of data being fetched from DynamoDB?\", \"retrieval_context\": [\" - S3 Get* events in CloudTrail capture all read operations on S3 objects, such as GetObject, GetObjectAcl, and GetObjectVersion. These events indicate when data is accessed or downloaded from your buckets, providing critical visibility into data retrieval patterns and potential unauthorized access.  \\n\\n**Purpose:** Monitor and audit object read activity to detect unusual access spikes, potential data exfiltration, or performance bottlenecks caused by excessive reads.\\n\\n**Alert Threshold:** Trigger an alert if the number of Get* events exceeds a baseline threshold (e.g., a 3x increase over the average hourly rate) or if access occurs from unexpected IP addresses or principals.\\n\\n**Impact:**  \\n- **High values:** May indicate heavy data consumption, possible data leakage, or abuse of resources leading to increased costs and degraded application performance.  \\n- **Low values:** Could suggest reduced usage, potential application issues, or misconfigured permissions blocking legitimate access.\\n\\n**Example Alert Rule:**  \\nAlert when the count of s3.amazonaws.com Get* events in CloudTrail exceeds 5000 within 1 hour, or when access originates from an IP address outside your trusted network range.\\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing hourly counts of Get* events per bucket, combined with a heatmap of source IP addresses, enabling quick identification of unusual access patterns or spikes in data retrieval.\", \" - This pattern captures CloudWatch Logs retrieval operations (any API call starting with \\\"Get\\\") recorded in CloudTrail, such as GetLogEvents and GetQueryResults. Its purpose is to monitor access to log data, helping SREs detect unusual or excessive log reads that may indicate troubleshooting activity, data exfiltration, or unauthorized access.\\n\\n**Threshold guidance:**  \\n- Trigger an alert if the number of Get* events exceeds a baseline by 3x within a 5-minute window, or if there is a sudden spike compared to historical averages.  \\n- Low or normal values typically indicate routine log access during debugging or monitoring.\\n\\n**Impact:**  \\n- High values may signal active investigation, potential security incidents, or misuse of log data.  \\n- Low values generally reflect normal operations with minimal log retrieval.\\n\\n**Example alert rule:**  \\n\\u201cAlert when logs.amazonaws.com Get* events exceed 100 calls in 5 minutes.\\u201d  \\n\\n**Example dashboard usage:**  \\nVisualize the count of Get* events over time to identify spikes in log access, correlating with incident response or suspicious activity. This helps ensure log data is accessed appropriately and supports timely detection of anomalies.\", \" - This pattern captures all Amazon EKS \\\"Describe\\\" API operations logged in CloudTrail, which occur when cluster metadata, node group configurations, or add-on details are queried. It helps SREs monitor how often EKS cluster information is accessed, providing visibility into potential reconnaissance or troubleshooting activities. A sudden spike in Describe calls\\u2014such as exceeding 100 requests within 5 minutes\\u2014may indicate unusual or automated querying that could precede configuration changes or security incidents, warranting an alert. Conversely, consistently low or zero Describe activity might suggest lack of monitoring or insufficient operational visibility. For example, an alert rule could trigger when Describe API calls surpass 100 in a 5-minute window, and a dashboard widget might display a time series graph of Describe call counts to track trends and detect anomalies in cluster information access patterns.\", \" - This pattern captures all Route 53 \\\"Get\\\" API operations logged in CloudTrail, such as retrieving hosted zone details, record sets, and health check statuses. It helps SREs monitor read access to DNS configurations and health data, which can indicate normal operational queries or potential reconnaissance activity. A sudden spike in these \\\"Get\\\" requests\\u2014exceeding a baseline threshold (e.g., 3 standard deviations above the average hourly rate)\\u2014may signal unusual interest in DNS infrastructure, warranting investigation. Conversely, a significant drop could indicate issues with monitoring or automation systems relying on these queries. For example, an alert rule could trigger when the count of **{\\\"EventSource\\\": \\\"route53.amazonaws.com\\\", \\\"EventName\\\": \\\"Get*\\\"}** events exceeds 100 requests per hour, and a dashboard widget might display a time series graph of these events to track trends and detect anomalies in DNS query activity.\", \" - This pattern matches all DynamoDB API calls that begin with \\\"Get,\\\" such as GetItem and GetRecords. It measures the occurrence of read operations where data is retrieved from DynamoDB tables. Each matched event represents a single request to fetch data. This helps monitor and audit data access activity in DynamoDB.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": false,
                        "score": 0.5717360978150331,
                        "reason": "The retrieval context includes a relevant description of DynamoDB Get* API calls, explaining what is measured (read operations like GetItem and GetRecords) and their purpose (monitoring data access). However, it lacks details on units, thresholds, or implications such as alerting criteria or impact of spikes, which limits clarity and utility in directly answering the question about unusual volume spikes.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Compare the Input (question) and Retrieval Context (description) to ensure the description addresses the specific monitoring question clearly and directly.\",\n    \"Evaluate the description's clarity by checking if it is concise and easily understandable in relation to the question asked.\",\n    \"Assess the coverage of the description by verifying it explains what is measured, including units, context, and implications, relevant to the input question.\",\n    \"Determine the utility by confirming that the description provides enough information to effectively answer the monitoring question.\"\n] \n \nRubric:\nNone \n \nScore: 0.5717360978150331"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Compare the Input (question) and Retrieval Context (description) to ensure the description addresses the specific monitoring question clearly and directly.",
                            "Evaluate the description's clarity by checking if it is concise and easily understandable in relation to the question asked.",
                            "Assess the coverage of the description by verifying it explains what is measured, including units, context, and implications, relevant to the input question.",
                            "Determine the utility by confirming that the description provides enough information to effectively answer the monitoring question."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"sns.amazonaws.com\\\", \\\"EventName\\\": \\\"Delete*\\\"}\", \"hyperparameters\": null, \"input\": \"Are Delete* events triggering through the SNS service exceeding ten, indicating potential disruption to notification workflows?\", \"retrieval_context\": [\" - This pattern captures SNS unsubscription events recorded in CloudTrail, indicating when endpoints or subscribers are removed from SNS topics. For an SRE, monitoring these events helps track changes in notification delivery and detect potential disruptions or configuration changes.\\n\\n**Purpose:**  \\n- Identify when subscribers unsubscribe from SNS topics, which may reflect endpoint decommissioning, application changes, or user-initiated opt-outs.  \\n- Detect unusual spikes that could indicate mass unsubscriptions due to misconfigurations, security incidents, or service issues.\\n\\n**Alert Threshold:**  \\n- Trigger an alert if the number of Unsubscribe events exceeds a baseline threshold (e.g., more than 5 unsubscriptions within 5 minutes) or shows a sudden increase compared to historical averages. Thresholds should be tuned based on normal subscription churn rates.\\n\\n**Impact:**  \\n- **High values:** May signal widespread endpoint removals causing notification delivery failures, potential service degradation, or security concerns (e.g., unauthorized unsubscriptions). Immediate investigation is warranted.  \\n- **Low or zero values:** Typically expected during stable operations; a sudden drop to zero after a period of regular unsubscriptions might indicate logging issues or CloudTrail misconfigurations.\\n\\n**Example Usage:**  \\n- **Dashboard:** Display a time series graph of Unsubscribe event counts per minute to visualize trends and detect anomalies.  \\n- **Alert Rule (pseudo-code):**  \\n  ```\\n  WHEN count(Events where EventSource=\\\"sns.amazonaws.com\\\" AND EventName LIKE \\\"Unsubscribe%\\\") \\n  OVER last 5 minutes > 5 \\n  THEN trigger alert \\\"High SNS Unsubscription Rate\\\"\\n  ```\", \" - This pattern captures all EC2 resource deletion events recorded in CloudTrail, triggered by any API calls starting with \\\"Delete\\\" from the EC2 service (e.g., DeleteSecurityGroup, DeleteNetworkInterface). Its purpose is to monitor and alert on the removal of critical EC2 components, which can impact infrastructure stability and security.\\n\\n**Threshold guidance:**  \\n- Set an alert if the number of deletion events exceeds a baseline threshold within a short time window (e.g., more than 5 deletions in 10 minutes), as this may indicate accidental mass deletions or malicious activity.  \\n- A low or zero count is typical during normal operations, while sudden spikes warrant immediate investigation.\\n\\n**Impact:**  \\n- High deletion event counts can lead to service disruptions, loss of network connectivity, or security vulnerabilities if key resources like security groups or network interfaces are removed unexpectedly.  \\n- Low or no deletion activity generally indicates stable infrastructure management.\\n\\n**Example alert rule:**  \\nTrigger an alert when the count of events matching {\\\"EventSource\\\": \\\"ec2.amazonaws.com\\\", \\\"EventName\\\": \\\"Delete*\\\"} exceeds 5 within 10 minutes.\\n\\n**Example dashboard usage:**  \\nVisualize the count of EC2 deletion events over time to identify unusual spikes, correlating with other operational metrics to assess potential impact on system availability or security posture.\", \" - This pattern captures all deletion events related to Elastic Load Balancers (ELBs) in AWS, as recorded by CloudTrail under the event source \\\"elasticloadbalancing.amazonaws.com\\\" with event names starting with \\\"Delete\\\". Its primary purpose is to monitor when ELBs are removed, which can be part of routine cleanup or indicate unintended service disruptions due to the loss of load balancing resources.\\n\\n**Purpose:**  \\nSREs use this pattern to track ELB deletions to quickly detect and investigate potential impacts on application availability and traffic routing.\\n\\n**Alert Threshold:**  \\nAn alert should be triggered if the number of ELB deletion events exceeds a predefined threshold within a short time window\\u2014for example, more than 1 deletion event within 5 minutes\\u2014since multiple deletions in quick succession may indicate a misconfiguration, automation error, or malicious activity.\\n\\n**Impact of Values:**  \\n- **High values:** Frequent or bulk ELB deletions can cause significant service disruption, leading to downtime or degraded performance due to loss of traffic distribution. Immediate investigation and remediation are required.  \\n- **Low values:** Occasional single deletions may be expected during normal maintenance or scaling operations and typically do not require urgent action but should still be logged for audit purposes.\\n\\n**Example Usage:**  \\nIn a monitoring dashboard or alert rule, you might configure a query to count ELB deletion events over a rolling 5-minute window and trigger an alert if the count exceeds 1. For example:\\n\\n```\\ncount_over_time({EventSource=\\\"elasticloadbalancing.amazonaws.com\\\", EventName=~\\\"Delete.*\\\"}[5m]) > 1\\n```\\n\\nThis alert helps ensure that unexpected or excessive ELB deletions are promptly detected and addressed to maintain service reliability.\", \" - This pattern detects API calls made through the SNS service that begin with \\\"Delete,\\\" such as deleting SNS topics or subscriptions. It measures the occurrence of deletion events triggered via the AWS SNS API. Each matched event represents a single deletion action recorded in AWS CloudTrail logs. This helps monitor resource removals that may impact notification workflows.\", \" - This pattern detects SNS topic creation events recorded in CloudTrail, specifically any API calls starting with \\\"Create\\\" from the SNS service (e.g., CreateTopic). It helps SREs monitor when new SNS topics are provisioned, which can indicate changes in messaging architecture or potential unauthorized resource creation. An alert threshold could be set on the number of Create* events within a given time window (e.g., more than 5 topic creations in 10 minutes), as a sudden spike may signal automation errors or security issues. Low or expected values typically indicate normal operations, while high values may impact system stability by increasing resource usage or indicate potential misuse. For example, an alert rule could trigger if the count of {\\\"EventSource\\\": \\\"sns.amazonaws.com\\\", \\\"EventName\\\": \\\"Create*\\\"} events exceeds 5 in 10 minutes, and a dashboard widget could display a time series graph of topic creation events to track trends and detect anomalies.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": false,
                        "score": 0.5541794642687068,
                        "reason": "The retrieval context includes a relevant pattern describing SNS Delete* events, specifying what is measured (deletion events via SNS API) and their impact on notification workflows, which aligns with the input question. However, it lacks explicit threshold guidance or examples related to exceeding ten Delete* events, limiting clarity and utility for confidently assessing potential disruption. The language is generally clear but could be more concise and directly address the threshold and implications asked in the input.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Compare the Input (monitoring question) with the Retrieval Context (metric description) to assess if the description clearly addresses the question.\",\n    \"Evaluate Clarity by checking if the description uses concise and understandable language relevant to the question asked in the Input.\",\n    \"Assess Coverage by verifying the presence of what is measured, units, relevant context, and potential implications in the Retrieval Context, ensuring they relate directly to the Input query.\",\n    \"Determine Utility by judging if the description provides sufficient information to confidently answer the Input question, highlighting how well the description supports the query.\"\n] \n \nRubric:\nNone \n \nScore: 0.5541794642687068"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Compare the Input (monitoring question) with the Retrieval Context (metric description) to assess if the description clearly addresses the question.",
                            "Evaluate Clarity by checking if the description uses concise and understandable language relevant to the question asked in the Input.",
                            "Assess Coverage by verifying the presence of what is measured, units, relevant context, and potential implications in the Retrieval Context, ensuring they relate directly to the Input query.",
                            "Determine Utility by judging if the description provides sufficient information to confidently answer the Input question, highlighting how well the description supports the query."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"sns.amazonaws.com\\\", \\\"EventName\\\": \\\"Subscribe*\\\"}\", \"hyperparameters\": null, \"input\": \"Are there spikes in Subscribe* API calls indicating potential abuse of SNS topic subscriptions?\", \"retrieval_context\": [\" - S3 bucket creation events captured by CloudTrail under **{\\\"EventSource\\\": \\\"s3.amazonaws.com\\\", \\\"EventName\\\": \\\"Create*\\\"}** indicate when new buckets or related resources (e.g., bucket policies, access points) are provisioned. These events help SREs monitor infrastructure changes that affect data storage, security posture, and compliance.\\n\\n**Purpose:**  \\nTrack and audit the creation of S3 buckets and associated configurations to ensure proper governance, prevent unauthorized resource sprawl, and maintain compliance with organizational policies.\\n\\n**Alert Threshold:**  \\nTrigger an alert if the number of S3 bucket creation events exceeds a defined threshold within a short time window (e.g., more than 5 bucket creations within 10 minutes), which may indicate automated provisioning errors, misconfigurations, or potential security incidents such as unauthorized resource creation.\\n\\n**Impact of Values:**  \\n- **High frequency:** May signal abnormal activity, such as a compromised credential or runaway automation scripts creating excessive buckets, leading to increased costs, security risks, or compliance violations.  \\n- **Low or zero frequency:** Normal in stable environments; however, sudden spikes should be investigated promptly.\\n\\n**Example Alert Rule:**  \\n\\u201cAlert when count of events with EventSource = 's3.amazonaws.com' and EventName starting with 'Create' exceeds 5 within 10 minutes.\\u201d\\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of S3 Create* events over time, with thresholds marked to highlight unusual spikes, enabling quick identification of abnormal bucket creation activity.\", \" - This pattern captures SNS unsubscription events recorded in CloudTrail, indicating when endpoints or subscribers are removed from SNS topics. For an SRE, monitoring these events helps track changes in notification delivery and detect potential disruptions or configuration changes.\\n\\n**Purpose:**  \\n- Identify when subscribers unsubscribe from SNS topics, which may reflect endpoint decommissioning, application changes, or user-initiated opt-outs.  \\n- Detect unusual spikes that could indicate mass unsubscriptions due to misconfigurations, security incidents, or service issues.\\n\\n**Alert Threshold:**  \\n- Trigger an alert if the number of Unsubscribe events exceeds a baseline threshold (e.g., more than 5 unsubscriptions within 5 minutes) or shows a sudden increase compared to historical averages. Thresholds should be tuned based on normal subscription churn rates.\\n\\n**Impact:**  \\n- **High values:** May signal widespread endpoint removals causing notification delivery failures, potential service degradation, or security concerns (e.g., unauthorized unsubscriptions). Immediate investigation is warranted.  \\n- **Low or zero values:** Typically expected during stable operations; a sudden drop to zero after a period of regular unsubscriptions might indicate logging issues or CloudTrail misconfigurations.\\n\\n**Example Usage:**  \\n- **Dashboard:** Display a time series graph of Unsubscribe event counts per minute to visualize trends and detect anomalies.  \\n- **Alert Rule (pseudo-code):**  \\n  ```\\n  WHEN count(Events where EventSource=\\\"sns.amazonaws.com\\\" AND EventName LIKE \\\"Unsubscribe%\\\") \\n  OVER last 5 minutes > 5 \\n  THEN trigger alert \\\"High SNS Unsubscription Rate\\\"\\n  ```\", \" - This pattern captures all SNS Publish API calls recorded in CloudTrail, indicating when messages are sent to SNS topics. For an SRE, this helps monitor the volume and frequency of notifications within your applications and infrastructure. \\n\\n**Purpose:**  \\n- Track message publishing activity to detect unusual spikes or drops that may indicate application issues, misconfigurations, or potential abuse.  \\n- Correlate with downstream system behavior to troubleshoot notification delivery problems or failures.\\n\\n**Threshold guidance:**  \\n- Set alert thresholds based on baseline publish rates (e.g., average publishes per minute/hour).  \\n- Trigger alerts if publish events exceed a high threshold (e.g., 2-3x normal volume), which may indicate a runaway process or spam.  \\n- Trigger alerts if publish events drop below a low threshold (e.g., near zero for a sustained period), which may indicate a failure in upstream systems or broken notification flows.\\n\\n**Impact of values:**  \\n- **High publish rates:** Could lead to increased costs, throttling, or downstream system overload. May signal application errors or security incidents.  \\n- **Low publish rates:** May cause delayed or missing notifications, impacting user experience or operational awareness.\\n\\n**Example usage:**  \\n- Dashboard widget showing SNS Publish event count per minute with baseline and threshold lines.  \\n- Alert rule: \\u201cAlert if SNS Publish events exceed 500 per 5 minutes or drop below 10 per 5 minutes for more than 10 minutes.\\u201d  \\n- Use CloudWatch Logs Insights or a SIEM query filtering on `EventSource = \\\"sns.amazonaws.com\\\"` and `EventName` starting with `Publish` to visualize trends and anomalies.\", \" - This pattern detects API calls related to creating or confirming SNS topic subscriptions. It captures events where a subscription request is made or confirmed, including details about the subscription endpoint and protocol. The measurement is event-based, counting each subscription action as a single event. This helps monitor and audit SNS subscription activities in real time.\", \" - This pattern detects SNS topic creation events recorded in CloudTrail, specifically any API calls starting with \\\"Create\\\" from the SNS service (e.g., CreateTopic). It helps SREs monitor when new SNS topics are provisioned, which can indicate changes in messaging architecture or potential unauthorized resource creation. An alert threshold could be set on the number of Create* events within a given time window (e.g., more than 5 topic creations in 10 minutes), as a sudden spike may signal automation errors or security issues. Low or expected values typically indicate normal operations, while high values may impact system stability by increasing resource usage or indicate potential misuse. For example, an alert rule could trigger if the count of {\\\"EventSource\\\": \\\"sns.amazonaws.com\\\", \\\"EventName\\\": \\\"Create*\\\"} events exceeds 5 in 10 minutes, and a dashboard widget could display a time series graph of topic creation events to track trends and detect anomalies.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": false,
                        "score": 0.22227001388253087,
                        "reason": "The description does not address the monitoring question about spikes in Subscribe* API calls; instead, the retrieval context focuses on Unsubscribe events and other SNS event types unrelated to Subscribe calls. It lacks clarity and coverage regarding what is measured, units, or implications for Subscribe API spikes, providing insufficient utility to answer the question. To improve, the description should explicitly define Subscribe* API call events, their significance, thresholds for spikes, and impact on potential abuse detection.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Compare the Input (metric description) with the Retrieval Context (monitoring question) to ensure clarity: verify that the description is understandable and concise in relation to the question asked.\",\n    \"Evaluate Coverage by checking if the description sufficiently explains what is measured, including units, context, and implications relevant to the monitoring question.\",\n    \"Assess Utility by determining whether the description provides enough information to directly help a user answer the monitoring question.\",\n    \"If any of the above aspects score below 8, identify missing or unclear elements in the description relative to the retrieval context and suggest specific improvements.\"\n] \n \nRubric:\nNone \n \nScore: 0.22227001388253087"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Compare the Input (metric description) with the Retrieval Context (monitoring question) to ensure clarity: verify that the description is understandable and concise in relation to the question asked.",
                            "Evaluate Coverage by checking if the description sufficiently explains what is measured, including units, context, and implications relevant to the monitoring question.",
                            "Assess Utility by determining whether the description provides enough information to directly help a user answer the monitoring question.",
                            "If any of the above aspects score below 8, identify missing or unclear elements in the description relative to the retrieval context and suggest specific improvements."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"sqs.amazonaws.com\\\", \\\"EventName\\\": \\\"Delete*\\\"}\", \"hyperparameters\": null, \"input\": \"Are there any Delete* API calls to SQS queues being made in large numbers?\", \"retrieval_context\": [\" - API Gateway deletion events captured by CloudTrail indicate when APIs, stages, or related resources are removed. These events are critical for tracking decommissioning activities, ensuring that endpoint removals are intentional and authorized, and preventing accidental service disruptions.  \\n\\n**Purpose:**  \\nMonitor all delete operations initiated via API Gateway (e.g., DeleteRestApi, DeleteStage) to maintain visibility into changes that reduce API surface area or remove critical endpoints.\\n\\n**Alert Threshold:**  \\nTrigger an alert if the number of Delete* events exceeds a predefined baseline within a short time window (e.g., more than 3 deletions within 10 minutes), as this may indicate accidental mass deletions, unauthorized activity, or a misconfigured automation script.\\n\\n**Impact:**  \\n- **High frequency:** Could lead to service outages, broken integrations, or data loss if APIs or stages are removed unexpectedly. Immediate investigation is required.  \\n- **Low or zero frequency:** Normal operation; deletion events are infrequent and typically planned.\\n\\n**Example Usage:**  \\nIn a monitoring dashboard, display a time series graph of Delete* events from apigateway.amazonaws.com. Set an alert rule such as:  \\n`IF count(Delete* events) > 3 within 10 minutes THEN trigger high-severity alert \\\"Potential API Gateway mass deletion detected\\\"`  \\nThis enables rapid response to potentially disruptive changes in the API infrastructure.\", \" - This pattern captures ECS deletion events recorded in CloudTrail, specifically any API calls starting with \\\"Delete\\\" from the ECS service (e.g., DeleteCluster, DeleteService, DeleteTaskSet). Its purpose is to monitor when ECS resources are removed, which can signal intentional cleanup or unintended disruptions affecting service availability.\\n\\n**Threshold guidance:**  \\n- Trigger an alert if the number of ECS deletion events exceeds a baseline threshold within a short time window (e.g., more than 3 Delete* events in 5 minutes), as this may indicate accidental mass deletion or a security incident.  \\n- Low or expected deletion rates typically reflect routine maintenance or scaling down of resources and generally have minimal impact.\\n\\n**Impact:**  \\n- High deletion event counts can lead to service downtime, loss of running tasks, or cluster instability, requiring immediate investigation.  \\n- Low or zero deletion events usually indicate stable ECS resource management.\\n\\n**Example alert rule:**  \\n- Alert when `count(events where EventSource=\\\"ecs.amazonaws.com\\\" and EventName starts with \\\"Delete\\\") > 3` within 5 minutes.  \\n- This alert can be visualized on a dashboard showing ECS Delete* event counts over time, helping SREs quickly identify unusual spikes and correlate with service health metrics.\", \" - This pattern captures all EC2 resource deletion events recorded in CloudTrail, triggered by any API calls starting with \\\"Delete\\\" from the EC2 service (e.g., DeleteSecurityGroup, DeleteNetworkInterface). Its purpose is to monitor and alert on the removal of critical EC2 components, which can impact infrastructure stability and security.\\n\\n**Threshold guidance:**  \\n- Set an alert if the number of deletion events exceeds a baseline threshold within a short time window (e.g., more than 5 deletions in 10 minutes), as this may indicate accidental mass deletions or malicious activity.  \\n- A low or zero count is typical during normal operations, while sudden spikes warrant immediate investigation.\\n\\n**Impact:**  \\n- High deletion event counts can lead to service disruptions, loss of network connectivity, or security vulnerabilities if key resources like security groups or network interfaces are removed unexpectedly.  \\n- Low or no deletion activity generally indicates stable infrastructure management.\\n\\n**Example alert rule:**  \\nTrigger an alert when the count of events matching {\\\"EventSource\\\": \\\"ec2.amazonaws.com\\\", \\\"EventName\\\": \\\"Delete*\\\"} exceeds 5 within 10 minutes.\\n\\n**Example dashboard usage:**  \\nVisualize the count of EC2 deletion events over time to identify unusual spikes, correlating with other operational metrics to assess potential impact on system availability or security posture.\", \" - This pattern detects API calls to delete Amazon SQS queues. It captures all events where the event source is \\\"sqs.amazonaws.com\\\" and the event name starts with \\\"Delete,\\\" such as DeleteQueue. The measurement is event occurrence count, indicating how many delete operations were initiated. Monitoring these events helps track queue removals that may affect message processing or system cleanup.\", \" - Tracks all AWS Lambda function deletion events captured in CloudTrail. Monitoring **{\\\"EventSource\\\": \\\"lambda.amazonaws.com\\\", \\\"EventName\\\": \\\"Delete*\\\"}** helps SREs detect when Lambda functions are removed, which is critical for maintaining application stability, ensuring proper resource cleanup, and preventing accidental or unauthorized deletions.  \\n\\n**Alert Threshold:** Trigger an alert if more than 3 Lambda function deletions occur within a 1-hour window, as this may indicate a misconfiguration, automated script error, or potential security breach.  \\n\\n**Impact:**  \\n- **High values:** A spike in deletions can lead to service disruptions, loss of critical functionality, or security incidents if unauthorized deletions occur. Immediate investigation is required.  \\n- **Low or zero values:** Normal operation; infrequent deletions are expected during routine maintenance or deployments.  \\n\\n**Example Alert Rule:**  \\n`WHEN count(events where EventSource=\\\"lambda.amazonaws.com\\\" AND EventName LIKE \\\"Delete%\\\") > 3 WITHIN 1 hour THEN alert \\\"Unusual number of Lambda deletions detected\\\"`  \\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of Lambda deletion events per hour, annotated with alert thresholds, enabling quick identification of abnormal deletion activity.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": false,
                        "score": 0.6722380539016887,
                        "reason": "The description clearly defines the metric as counting Delete* API calls to SQS queues and explains its purpose in tracking queue removals that may impact message processing or cleanup. However, it lacks specific alert thresholds, impact details, and example usage that would better align with the monitoring question's need to detect large numbers of deletions. Including these aspects would improve clarity, coverage, and utility for effective monitoring.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Compare the Input (metric description) with the Retrieval Context (monitoring question) to assess if the description clearly and concisely explains what is measured and why, ensuring it directly supports understanding the question.\",\n    \"Evaluate if the description covers all necessary aspects: the metric definition, units, context of use, and implications, in relation to the specific needs posed by the monitoring question.\",\n    \"Determine the utility of the description by judging whether it provides sufficient information for a user to answer the monitoring question effectively, linking description details back to question requirements.\",\n    \"If any aspect (clarity, coverage, or utility) is weak relative to the monitoring question, identify specific improvements to make the description more informative and relevant.\"\n] \n \nRubric:\nNone \n \nScore: 0.6722380539016887"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Compare the Input (metric description) with the Retrieval Context (monitoring question) to assess if the description clearly and concisely explains what is measured and why, ensuring it directly supports understanding the question.",
                            "Evaluate if the description covers all necessary aspects: the metric definition, units, context of use, and implications, in relation to the specific needs posed by the monitoring question.",
                            "Determine the utility of the description by judging whether it provides sufficient information for a user to answer the monitoring question effectively, linking description details back to question requirements.",
                            "If any aspect (clarity, coverage, or utility) is weak relative to the monitoring question, identify specific improvements to make the description more informative and relevant."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"dynamodb.amazonaws.com\\\", \\\"EventName\\\": \\\"Put*\\\"}\", \"hyperparameters\": null, \"input\": \"Are the Put* events in DynamoDB exceeding their normal rate, potentially causing performance issues?\", \"retrieval_context\": [\" - Lambda function \\\"Put*\\\" events in CloudTrail capture changes to function configurations, concurrency settings, event source mappings, and resource provisioning. These events indicate updates or deployments that can affect function behavior and performance. An SRE should monitor the frequency and success of these operations; unusually high rates of \\\"Put*\\\" events may signal automation errors or configuration churn, while absence of expected updates could indicate deployment issues. Alert thresholds might include more than 5 \\\"Put*\\\" events within 5 minutes or failed update attempts exceeding 10% of total \\\"Put*\\\" events. High volumes can lead to inconsistent function states or throttling, impacting availability and latency; low update activity during active development phases may delay critical fixes or optimizations. For example, a dashboard widget can track the count of \\\"Put*\\\" events per hour alongside error rates, and an alert rule could trigger when the number of failed \\\"Put*\\\" events surpasses a set threshold, prompting investigation into deployment or configuration problems.\", \" - This pattern captures CloudWatch Logs Put operations, which occur when log events are written to log streams from applications, systems, or custom sources. In CloudTrail, these events indicate active ingestion of log data into CloudWatch Logs, essential for monitoring application health and troubleshooting.\\n\\n**Purpose:**  \\nMonitor the frequency and volume of log ingestion to detect anomalies such as sudden drops (potentially indicating logging failures or agent issues) or spikes (which may signal increased application activity or potential log flooding).\\n\\n**Alert Threshold Guidance:**  \\n- Trigger an alert if the number of Put operations drops below a baseline threshold for a sustained period (e.g., less than 50% of average daily Put events over 15 minutes), indicating possible logging disruptions.  \\n- Trigger an alert if Put operations spike above a defined upper threshold (e.g., 2x the average rate), which could indicate abnormal application behavior or excessive logging that may impact costs and performance.\\n\\n**Impact:**  \\n- **High values:** May lead to increased CloudWatch Logs ingestion costs and potential performance degradation; could also indicate abnormal application behavior or security events generating excessive logs.  \\n- **Low values:** May result in loss of critical log data, hindering troubleshooting and incident response.\\n\\n**Example Usage:**  \\nIn a monitoring dashboard or alert rule, track the count of CloudTrail events where `EventSource` is `logs.amazonaws.com` and `EventName` matches `Put*` over rolling 5-minute intervals. Set alerts to notify the SRE team if counts fall below or exceed defined thresholds, enabling timely investigation into logging pipeline health.\", \" - This pattern captures all CloudWatch API operations that begin with \\\"Put\\\", such as PutMetricData, PutLogEvents, and PutAlarm, indicating when CloudWatch resources or configurations are created, updated, or modified. In CloudTrail, monitoring these events helps SREs detect changes to monitoring metrics, log ingestion, and alarm settings that could impact observability or alerting behavior.\\n\\n**Threshold guidance:**  \\nAn alert should trigger if the rate of Put* events exceeds a baseline threshold (e.g., a sudden spike beyond normal operational patterns, such as a 3x increase within 5 minutes), which may indicate automated scripts or unauthorized changes modifying monitoring configurations. Conversely, an unusually low rate over an extended period might suggest disruptions in metric or log ingestion.\\n\\n**Impact:**  \\n- High volumes of Put* events can lead to configuration drift, unexpected alert noise, or resource misconfigurations affecting system reliability.  \\n- Low volumes may result in missing critical metrics or logs, reducing visibility into system health.\\n\\n**Example alert rule:**  \\nTrigger an alert when the count of CloudTrail events with EventSource = \\\"cloudwatch.amazonaws.com\\\" and EventName starting with \\\"Put\\\" exceeds 100 events within 5 minutes, signaling potential bulk updates to monitoring configurations that require investigation. This can be visualized in a dashboard showing Put* event counts over time alongside key system metrics to correlate changes with system behavior.\", \" - This pattern captures all DynamoDB update events recorded in CloudTrail, specifically those where the event name starts with \\\"Update\\\" (e.g., UpdateTable, UpdateGlobalTable). It helps SREs monitor changes to DynamoDB table configurations such as capacity adjustments (read/write throughput), index modifications, and other table settings.\\n\\n**Purpose:**  \\nBy tracking these update events, SREs can detect configuration changes that may impact application performance, availability, or cost. Unexpected or frequent updates could indicate misconfigurations, automation errors, or unauthorized changes.\\n\\n**Alert Thresholds:**  \\n- Trigger an alert if more than 5 update events occur within a 10-minute window, which may suggest excessive or unintended configuration changes.  \\n- Trigger an alert if update events occur outside of scheduled maintenance windows or change management periods.\\n\\n**Impact of Values:**  \\n- **High frequency of updates:** May lead to instability, performance degradation, or increased costs due to rapid scaling or misconfigured indexes.  \\n- **Low or no updates:** Generally indicates stable table configurations, but lack of expected updates during deployments could signal deployment failures.\\n\\n**Example Usage:**  \\n- **Dashboard:** Display a time series graph showing the count of DynamoDB Update* events over time, annotated with deployment windows.  \\n- **Alert Rule:**  \\n  ```\\n  WHEN count(events where EventSource=\\\"dynamodb.amazonaws.com\\\" AND EventName LIKE \\\"Update%\\\") > 5 \\n  WITHIN 10 minutes \\n  AND current_time NOT IN maintenance_window \\n  THEN trigger alert \\\"Excessive DynamoDB table updates detected\\\"\\n  ```\", \" - This pattern matches DynamoDB events where items are added or replaced in tables. It captures all write operations starting with \\\"Put,\\\" including single item puts, conditional puts, and batch put requests. The measurement is event occurrence count, indicating how many put operations were performed. Each event corresponds to one put action recorded by DynamoDB.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": false,
                        "score": 0.4301738109773011,
                        "reason": "The Retrieval Context includes multiple 'Put*' event patterns but only one brief mention of DynamoDB Put events, which lacks detail on normal rates, thresholds, or performance impact. It does not clearly address whether DynamoDB Put* events are exceeding normal rates or causing performance issues, missing key coverage elements like units, context, and implications. The description is somewhat technical and fragmented, reducing clarity and utility for confidently answering the input question.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Compare the Input (monitoring question) with the Retrieval Context (metric description) to ensure the description directly addresses the question's intent and scope.\",\n    \"Evaluate the clarity of the Retrieval Context by assessing if it is concise, jargon-free, and easily understandable in relation to the specific needs implied by the Input.\",\n    \"Assess the coverage of the Retrieval Context by verifying if it details what is measured, units, context, and implications relevant to the Input question.\",\n    \"Judge the utility of the Retrieval Context by determining whether the description provides sufficient information to confidently answer the Input question, and suggest improvements if the score is below 8.\"\n] \n \nRubric:\nNone \n \nScore: 0.4301738109773011"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Compare the Input (monitoring question) with the Retrieval Context (metric description) to ensure the description directly addresses the question's intent and scope.",
                            "Evaluate the clarity of the Retrieval Context by assessing if it is concise, jargon-free, and easily understandable in relation to the specific needs implied by the Input.",
                            "Assess the coverage of the Retrieval Context by verifying if it details what is measured, units, context, and implications relevant to the Input question.",
                            "Judge the utility of the Retrieval Context by determining whether the description provides sufficient information to confidently answer the Input question, and suggest improvements if the score is below 8."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"sns.amazonaws.com\\\", \\\"EventName\\\": \\\"Publish*\\\"}\", \"hyperparameters\": null, \"input\": \"Do SNS Publish events exceed a high threshold, indicating potential application errors or security incidents?\", \"retrieval_context\": [\" - Lambda function \\\"Put*\\\" events in CloudTrail capture changes to function configurations, concurrency settings, event source mappings, and resource provisioning. These events indicate updates or deployments that can affect function behavior and performance. An SRE should monitor the frequency and success of these operations; unusually high rates of \\\"Put*\\\" events may signal automation errors or configuration churn, while absence of expected updates could indicate deployment issues. Alert thresholds might include more than 5 \\\"Put*\\\" events within 5 minutes or failed update attempts exceeding 10% of total \\\"Put*\\\" events. High volumes can lead to inconsistent function states or throttling, impacting availability and latency; low update activity during active development phases may delay critical fixes or optimizations. For example, a dashboard widget can track the count of \\\"Put*\\\" events per hour alongside error rates, and an alert rule could trigger when the number of failed \\\"Put*\\\" events surpasses a set threshold, prompting investigation into deployment or configuration problems.\", \" - S3 bucket creation events captured by CloudTrail under **{\\\"EventSource\\\": \\\"s3.amazonaws.com\\\", \\\"EventName\\\": \\\"Create*\\\"}** indicate when new buckets or related resources (e.g., bucket policies, access points) are provisioned. These events help SREs monitor infrastructure changes that affect data storage, security posture, and compliance.\\n\\n**Purpose:**  \\nTrack and audit the creation of S3 buckets and associated configurations to ensure proper governance, prevent unauthorized resource sprawl, and maintain compliance with organizational policies.\\n\\n**Alert Threshold:**  \\nTrigger an alert if the number of S3 bucket creation events exceeds a defined threshold within a short time window (e.g., more than 5 bucket creations within 10 minutes), which may indicate automated provisioning errors, misconfigurations, or potential security incidents such as unauthorized resource creation.\\n\\n**Impact of Values:**  \\n- **High frequency:** May signal abnormal activity, such as a compromised credential or runaway automation scripts creating excessive buckets, leading to increased costs, security risks, or compliance violations.  \\n- **Low or zero frequency:** Normal in stable environments; however, sudden spikes should be investigated promptly.\\n\\n**Example Alert Rule:**  \\n\\u201cAlert when count of events with EventSource = 's3.amazonaws.com' and EventName starting with 'Create' exceeds 5 within 10 minutes.\\u201d\\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of S3 Create* events over time, with thresholds marked to highlight unusual spikes, enabling quick identification of abnormal bucket creation activity.\", \" - This pattern captures SNS unsubscription events recorded in CloudTrail, indicating when endpoints or subscribers are removed from SNS topics. For an SRE, monitoring these events helps track changes in notification delivery and detect potential disruptions or configuration changes.\\n\\n**Purpose:**  \\n- Identify when subscribers unsubscribe from SNS topics, which may reflect endpoint decommissioning, application changes, or user-initiated opt-outs.  \\n- Detect unusual spikes that could indicate mass unsubscriptions due to misconfigurations, security incidents, or service issues.\\n\\n**Alert Threshold:**  \\n- Trigger an alert if the number of Unsubscribe events exceeds a baseline threshold (e.g., more than 5 unsubscriptions within 5 minutes) or shows a sudden increase compared to historical averages. Thresholds should be tuned based on normal subscription churn rates.\\n\\n**Impact:**  \\n- **High values:** May signal widespread endpoint removals causing notification delivery failures, potential service degradation, or security concerns (e.g., unauthorized unsubscriptions). Immediate investigation is warranted.  \\n- **Low or zero values:** Typically expected during stable operations; a sudden drop to zero after a period of regular unsubscriptions might indicate logging issues or CloudTrail misconfigurations.\\n\\n**Example Usage:**  \\n- **Dashboard:** Display a time series graph of Unsubscribe event counts per minute to visualize trends and detect anomalies.  \\n- **Alert Rule (pseudo-code):**  \\n  ```\\n  WHEN count(Events where EventSource=\\\"sns.amazonaws.com\\\" AND EventName LIKE \\\"Unsubscribe%\\\") \\n  OVER last 5 minutes > 5 \\n  THEN trigger alert \\\"High SNS Unsubscription Rate\\\"\\n  ```\", \" - This pattern captures all SNS Publish API calls recorded in CloudTrail, indicating when messages are sent to SNS topics. For an SRE, this helps monitor the volume and frequency of notifications within your applications and infrastructure. \\n\\n**Purpose:**  \\n- Track message publishing activity to detect unusual spikes or drops that may indicate application issues, misconfigurations, or potential abuse.  \\n- Correlate with downstream system behavior to troubleshoot notification delivery problems or failures.\\n\\n**Threshold guidance:**  \\n- Set alert thresholds based on baseline publish rates (e.g., average publishes per minute/hour).  \\n- Trigger alerts if publish events exceed a high threshold (e.g., 2-3x normal volume), which may indicate a runaway process or spam.  \\n- Trigger alerts if publish events drop below a low threshold (e.g., near zero for a sustained period), which may indicate a failure in upstream systems or broken notification flows.\\n\\n**Impact of values:**  \\n- **High publish rates:** Could lead to increased costs, throttling, or downstream system overload. May signal application errors or security incidents.  \\n- **Low publish rates:** May cause delayed or missing notifications, impacting user experience or operational awareness.\\n\\n**Example usage:**  \\n- Dashboard widget showing SNS Publish event count per minute with baseline and threshold lines.  \\n- Alert rule: \\u201cAlert if SNS Publish events exceed 500 per 5 minutes or drop below 10 per 5 minutes for more than 10 minutes.\\u201d  \\n- Use CloudWatch Logs Insights or a SIEM query filtering on `EventSource = \\\"sns.amazonaws.com\\\"` and `EventName` starting with `Publish` to visualize trends and anomalies.\", \" - This pattern detects SNS topic creation events recorded in CloudTrail, specifically any API calls starting with \\\"Create\\\" from the SNS service (e.g., CreateTopic). It helps SREs monitor when new SNS topics are provisioned, which can indicate changes in messaging architecture or potential unauthorized resource creation. An alert threshold could be set on the number of Create* events within a given time window (e.g., more than 5 topic creations in 10 minutes), as a sudden spike may signal automation errors or security issues. Low or expected values typically indicate normal operations, while high values may impact system stability by increasing resource usage or indicate potential misuse. For example, an alert rule could trigger if the count of {\\\"EventSource\\\": \\\"sns.amazonaws.com\\\", \\\"EventName\\\": \\\"Create*\\\"} events exceeds 5 in 10 minutes, and a dashboard widget could display a time series graph of topic creation events to track trends and detect anomalies.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": true,
                        "score": 0.9047425875533716,
                        "reason": "The description in the retrieval context directly addresses the input question by explaining SNS Publish events, their monitoring purpose, threshold guidance for high values, and the implications of exceeding thresholds, including potential application errors or security incidents. It is clear, detailed, and provides operational context, measurement units (e.g., events per minute), and example alert rules, enabling effective user understanding and response. The only minor shortcoming is the lack of explicit mention of exact threshold values in the input question's phrasing, but the context sufficiently covers this with examples.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Compare the Input (monitoring question) and Retrieval Context (metric description) to ensure the description clearly addresses the question's intent and scope.\",\n    \"Evaluate Clarity by verifying if the description is understandable and concise in explaining the metric referenced in the Input.\",\n    \"Assess Coverage by checking if the description provides complete information about what is measured, measurement units, operational context, and implications relevant to the Input.\",\n    \"Judge Utility by determining if the description enables a user to effectively answer the Input question based on the information in the Retrieval Context.\"\n] \n \nRubric:\nNone \n \nScore: 0.9047425875533716"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Compare the Input (monitoring question) and Retrieval Context (metric description) to ensure the description clearly addresses the question's intent and scope.",
                            "Evaluate Clarity by verifying if the description is understandable and concise in explaining the metric referenced in the Input.",
                            "Assess Coverage by checking if the description provides complete information about what is measured, measurement units, operational context, and implications relevant to the Input.",
                            "Judge Utility by determining if the description enables a user to effectively answer the Input question based on the information in the Retrieval Context."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"dynamodb.amazonaws.com\\\", \\\"EventName\\\": \\\"Query*\\\"}\", \"hyperparameters\": null, \"input\": \"Are there spikes in DynamoDB Query* events that could indicate a performance issue or resource bottleneck?\", \"retrieval_context\": [\" - **{\\\"EventName\\\": \\\"Start*\\\"}** events in CloudTrail indicate the initiation of resource start operations across various AWS services, such as starting EC2 instances, RDS databases, or other managed resources. These events help SREs track when resources transition from a stopped or inactive state to an active state, which is critical for service availability, cost management, and operational recovery.\\n\\n**Purpose:**  \\nTo monitor and audit the activation of cloud resources, ensuring that start operations align with expected usage patterns and do not indicate unauthorized or unexpected activity.\\n\\n**Alert Thresholds:**  \\n- Trigger an alert if the number of **Start*** events exceeds a predefined threshold within a short time window (e.g., more than 10 start operations within 5 minutes), which may indicate an automated scaling event, a potential misconfiguration, or a security incident.  \\n- Conversely, alert if expected start operations do not occur during scheduled maintenance windows, indicating possible failures in recovery or deployment processes.\\n\\n**Impact of Values:**  \\n- **High volume of Start* events:** Could lead to increased costs due to resource activation, potential service disruptions if resources are started unexpectedly, or indicate automated scaling or recovery actions.  \\n- **Low or zero Start* events during expected periods:** May signal failed recovery attempts, stalled deployments, or issues in operational workflows, potentially impacting service availability.\\n\\n**Example Usage:**  \\nIn a CloudWatch dashboard, plot the count of **Start*** events over time to visualize spikes or drops. An alert rule can be configured as:  \\n```\\nIF count(Start* events) > 10 within 5 minutes THEN trigger alert \\\"Unusual spike in resource start operations\\\"\\n```\\nThis enables proactive investigation into unexpected resource activations or failures to start critical services.\", \" - Redshift cluster creation events in CloudTrail capture all API calls initiating the provisioning of new Redshift clusters (e.g., CreateCluster). These events indicate when new data warehouse resources are being deployed or configured, impacting capacity and cost.  \\n**Purpose:** Enables SREs to monitor and audit cluster provisioning activities for operational control and security compliance.  \\n**Alert Threshold:** Trigger alerts on an unusually high number of cluster creation events within a short time window (e.g., >3 creates in 1 hour), which may indicate automation errors, misconfigurations, or unauthorized resource provisioning.  \\n**Impact:**  \\n- **High values:** May lead to resource sprawl, increased costs, and potential performance degradation due to over-provisioning. Could also signal security risks if unexpected clusters are created.  \\n- **Low or zero values:** Normal in stable environments; no new clusters being created means stable infrastructure.  \\n**Example Alert Rule:**  \\n\\u201cAlert if count of events with EventSource='redshift.amazonaws.com' and EventName starting with 'Create' exceeds 3 within 60 minutes.\\u201d  \\n**Dashboard Use:** Visualize the frequency of Redshift cluster creation events over time to detect spikes or anomalies, correlating with deployment activities or security incidents.\", \" - S3 bucket creation events captured by CloudTrail under **{\\\"EventSource\\\": \\\"s3.amazonaws.com\\\", \\\"EventName\\\": \\\"Create*\\\"}** indicate when new buckets or related resources (e.g., bucket policies, access points) are provisioned. These events help SREs monitor infrastructure changes that affect data storage, security posture, and compliance.\\n\\n**Purpose:**  \\nTrack and audit the creation of S3 buckets and associated configurations to ensure proper governance, prevent unauthorized resource sprawl, and maintain compliance with organizational policies.\\n\\n**Alert Threshold:**  \\nTrigger an alert if the number of S3 bucket creation events exceeds a defined threshold within a short time window (e.g., more than 5 bucket creations within 10 minutes), which may indicate automated provisioning errors, misconfigurations, or potential security incidents such as unauthorized resource creation.\\n\\n**Impact of Values:**  \\n- **High frequency:** May signal abnormal activity, such as a compromised credential or runaway automation scripts creating excessive buckets, leading to increased costs, security risks, or compliance violations.  \\n- **Low or zero frequency:** Normal in stable environments; however, sudden spikes should be investigated promptly.\\n\\n**Example Alert Rule:**  \\n\\u201cAlert when count of events with EventSource = 's3.amazonaws.com' and EventName starting with 'Create' exceeds 5 within 10 minutes.\\u201d\\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of S3 Create* events over time, with thresholds marked to highlight unusual spikes, enabling quick identification of abnormal bucket creation activity.\", \" - This pattern captures CloudWatch Logs retrieval operations (any API call starting with \\\"Get\\\") recorded in CloudTrail, such as GetLogEvents and GetQueryResults. Its purpose is to monitor access to log data, helping SREs detect unusual or excessive log reads that may indicate troubleshooting activity, data exfiltration, or unauthorized access.\\n\\n**Threshold guidance:**  \\n- Trigger an alert if the number of Get* events exceeds a baseline by 3x within a 5-minute window, or if there is a sudden spike compared to historical averages.  \\n- Low or normal values typically indicate routine log access during debugging or monitoring.\\n\\n**Impact:**  \\n- High values may signal active investigation, potential security incidents, or misuse of log data.  \\n- Low values generally reflect normal operations with minimal log retrieval.\\n\\n**Example alert rule:**  \\n\\u201cAlert when logs.amazonaws.com Get* events exceed 100 calls in 5 minutes.\\u201d  \\n\\n**Example dashboard usage:**  \\nVisualize the count of Get* events over time to identify spikes in log access, correlating with incident response or suspicious activity. This helps ensure log data is accessed appropriately and supports timely detection of anomalies.\", \" - This pattern captures all DynamoDB update events recorded in CloudTrail, specifically those where the event name starts with \\\"Update\\\" (e.g., UpdateTable, UpdateGlobalTable). It helps SREs monitor changes to DynamoDB table configurations such as capacity adjustments (read/write throughput), index modifications, and other table settings.\\n\\n**Purpose:**  \\nBy tracking these update events, SREs can detect configuration changes that may impact application performance, availability, or cost. Unexpected or frequent updates could indicate misconfigurations, automation errors, or unauthorized changes.\\n\\n**Alert Thresholds:**  \\n- Trigger an alert if more than 5 update events occur within a 10-minute window, which may suggest excessive or unintended configuration changes.  \\n- Trigger an alert if update events occur outside of scheduled maintenance windows or change management periods.\\n\\n**Impact of Values:**  \\n- **High frequency of updates:** May lead to instability, performance degradation, or increased costs due to rapid scaling or misconfigured indexes.  \\n- **Low or no updates:** Generally indicates stable table configurations, but lack of expected updates during deployments could signal deployment failures.\\n\\n**Example Usage:**  \\n- **Dashboard:** Display a time series graph showing the count of DynamoDB Update* events over time, annotated with deployment windows.  \\n- **Alert Rule:**  \\n  ```\\n  WHEN count(events where EventSource=\\\"dynamodb.amazonaws.com\\\" AND EventName LIKE \\\"Update%\\\") > 5 \\n  WITHIN 10 minutes \\n  AND current_time NOT IN maintenance_window \\n  THEN trigger alert \\\"Excessive DynamoDB table updates detected\\\"\\n  ```\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": false,
                        "score": 0.3191037302951283,
                        "reason": "The Input question asks about spikes in DynamoDB Query* events indicating performance issues, but the Retrieval Context primarily describes DynamoDB Update* events and unrelated AWS service events, causing a mismatch. The Input and Retrieval Context lack alignment, reducing clarity and utility. Additionally, the Retrieval Context does not cover metrics or units related to Query events or their performance implications, limiting coverage and the ability to answer the monitoring question effectively.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Assess the clarity of the Input and Retrieval Context jointly by confirming if both are understandable and concise, with no ambiguous terminology.\",\n    \"Evaluate coverage by verifying that the Input and Retrieval Context collectively explain what is measured, include units where applicable, provide relevant context, and discuss possible implications.\",\n    \"Determine utility by checking if the description and the question together enable the user to answer the monitoring question effectively, ensuring alignment between Input and Retrieval Context.\",\n    \"If any of the above criteria score below 8, identify specific gaps in clarity, coverage, or utility, and suggest targeted improvements to either the Input or the Retrieval Context to enhance overall quality.\"\n] \n \nRubric:\nNone \n \nScore: 0.3191037302951283"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Assess the clarity of the Input and Retrieval Context jointly by confirming if both are understandable and concise, with no ambiguous terminology.",
                            "Evaluate coverage by verifying that the Input and Retrieval Context collectively explain what is measured, include units where applicable, provide relevant context, and discuss possible implications.",
                            "Determine utility by checking if the description and the question together enable the user to answer the monitoring question effectively, ensuring alignment between Input and Retrieval Context.",
                            "If any of the above criteria score below 8, identify specific gaps in clarity, coverage, or utility, and suggest targeted improvements to either the Input or the Retrieval Context to enhance overall quality."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"sqs.amazonaws.com\\\", \\\"EventName\\\": \\\"Receive*\\\"}\", \"hyperparameters\": null, \"input\": \"Does a sudden spike in ReceiveMessage events from SQS indicate increased load or potential message flooding?\", \"retrieval_context\": [\" - S3 bucket creation events captured by CloudTrail under **{\\\"EventSource\\\": \\\"s3.amazonaws.com\\\", \\\"EventName\\\": \\\"Create*\\\"}** indicate when new buckets or related resources (e.g., bucket policies, access points) are provisioned. These events help SREs monitor infrastructure changes that affect data storage, security posture, and compliance.\\n\\n**Purpose:**  \\nTrack and audit the creation of S3 buckets and associated configurations to ensure proper governance, prevent unauthorized resource sprawl, and maintain compliance with organizational policies.\\n\\n**Alert Threshold:**  \\nTrigger an alert if the number of S3 bucket creation events exceeds a defined threshold within a short time window (e.g., more than 5 bucket creations within 10 minutes), which may indicate automated provisioning errors, misconfigurations, or potential security incidents such as unauthorized resource creation.\\n\\n**Impact of Values:**  \\n- **High frequency:** May signal abnormal activity, such as a compromised credential or runaway automation scripts creating excessive buckets, leading to increased costs, security risks, or compliance violations.  \\n- **Low or zero frequency:** Normal in stable environments; however, sudden spikes should be investigated promptly.\\n\\n**Example Alert Rule:**  \\n\\u201cAlert when count of events with EventSource = 's3.amazonaws.com' and EventName starting with 'Create' exceeds 5 within 10 minutes.\\u201d\\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of S3 Create* events over time, with thresholds marked to highlight unusual spikes, enabling quick identification of abnormal bucket creation activity.\", \" - This pattern captures CloudFront cache invalidation events recorded in CloudTrail, which occur when cached content is explicitly removed or refreshed to ensure users receive the latest versions of assets. For an SRE, monitoring these events helps track content deployment activities and detect potential operational issues such as excessive invalidations that may indicate misconfigurations or abuse.\\n\\n**Purpose:**  \\n- Identify when CloudFront distributions are updated via cache invalidations.  \\n- Correlate invalidation frequency with deployment cycles or troubleshooting efforts.\\n\\n**Alert Threshold Guidance:**  \\n- Trigger an alert if the number of invalidation requests exceeds a defined threshold within a short time window (e.g., more than 10 invalidations in 5 minutes), as this may signal abnormal activity or inefficient cache management.  \\n- Conversely, unusually low invalidation activity during expected deployment periods might indicate deployment failures or monitoring gaps.\\n\\n**Impact:**  \\n- **High invalidation rates:** Can increase latency and cost, as CloudFront must fetch fresh content from origin servers more frequently, potentially degrading user experience.  \\n- **Low invalidation rates:** May cause users to receive stale content, impacting application correctness and user satisfaction.\\n\\n**Example Usage:**  \\n- **Dashboard:** Display a time-series graph of invalidation event counts per minute to visualize spikes or drops in cache refresh activity.  \\n- **Alert Rule (pseudo-code):**  \\n  ```  \\n  WHEN count(EventName LIKE \\\"Invalidate*\\\") FROM cloudtrail  \\n  OVER last 5 minutes > 10  \\n  THEN alert \\\"High CloudFront invalidation rate detected\\\"  \\n  ```\", \" - This pattern captures CloudTrail events where messages are received from Amazon SQS queues (EventSource: \\\"sqs.amazonaws.com\\\", EventName starting with \\\"Receive\\\"), indicating when consumers poll and retrieve messages for processing. Monitoring these events helps SREs track message consumption rates, detect potential processing delays, and ensure downstream systems are actively handling queued workloads. \\n\\n**Alert Threshold Guidance:**  \\n- Set alerts for unusually low receive event counts over a defined period (e.g., fewer than 10 receives in 5 minutes), which may indicate consumer failures or processing bottlenecks.  \\n- Conversely, a sudden spike in receive events (e.g., a 2x increase compared to baseline) could signal increased load or potential message flooding that might overwhelm downstream services.\\n\\n**Impact:**  \\n- **Low receive event counts** can lead to message backlog growth, increased latency, and potential service degradation.  \\n- **High receive event counts** may reflect healthy throughput or, if excessive, could cause resource exhaustion or indicate abnormal traffic patterns.\\n\\n**Example Alert Rule:**  \\nTrigger an alert if the count of ReceiveMessage events from SQS falls below 10 in a rolling 5-minute window, signaling possible consumer inactivity.  \\n```  \\nWHEN count(events where EventSource=\\\"sqs.amazonaws.com\\\" AND EventName LIKE \\\"Receive%\\\") < 10 OVER last 5 minutes  \\nTHEN alert \\\"SQS message consumption is below expected levels\\\"  \\n```  \\n\\nThis enables proactive detection of issues in message processing pipelines and helps maintain system reliability.\", \" - This pattern captures all Amazon SQS message send events recorded in CloudTrail, identifying when messages are sent to SQS queues by applications or services. It helps SREs monitor the volume and frequency of messages entering the queue, which is critical for understanding application throughput and detecting anomalies in message flow.\\n\\n**Threshold guidance:**  \\n- Set alert thresholds based on baseline message send rates for your application. For example, trigger an alert if the number of Send* events drops below 50% of the normal rate over a 5-minute window, indicating potential upstream issues or message loss.  \\n- Conversely, alert if the send rate spikes above 150% of the baseline, which may signal unexpected load, misbehaving producers, or potential flooding that could overwhelm downstream consumers.\\n\\n**Impact of values:**  \\n- **High send event volume:** May indicate increased application activity or a surge in workload; sustained spikes can lead to queue congestion, increased processing latency, or throttling.  \\n- **Low send event volume:** Could suggest upstream failures, application downtime, or message generation issues, potentially causing downstream starvation and impacting system responsiveness.\\n\\n**Example usage:**  \\nIn a monitoring dashboard, plot the count of **{\\\"EventSource\\\": \\\"sqs.amazonaws.com\\\", \\\"EventName\\\": \\\"Send*\\\"}** events per minute to visualize message inflow trends. Configure an alert rule to notify the SRE team if the send event count deviates by more than \\u00b150% from the established baseline over a rolling 5-minute period, enabling rapid detection and response to abnormal message flow patterns.\", \" - This pattern detects AWS CloudTrail events where new Amazon SQS queues are created (EventSource: \\\"sqs.amazonaws.com\\\", EventName starting with \\\"Create\\\"). It helps SREs monitor the provisioning of new queues, including their initial configurations such as visibility timeout and message retention settings. Alert thresholds should be set based on the expected rate of queue creation in your environment\\u2014for example, triggering an alert if more than 5 queues are created within a 10-minute window, which may indicate unexpected automation or potential security issues. A sudden spike in queue creation can impact resource limits and increase costs, while consistently low or zero creation events may suggest underutilization or stalled deployments. Example alert rule:  \\n`WHEN count() OF events WHERE EventSource=\\\"sqs.amazonaws.com\\\" AND EventName LIKE \\\"Create*\\\" OVER last 10 minutes > 5 THEN trigger alert`  \\nThis can be visualized in a dashboard as a time series graph showing the count of SQS queue creation events over time, enabling quick detection of anomalies in queue provisioning activity.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": true,
                        "score": 0.9,
                        "reason": "The retrieval context directly addresses the input question by explaining that a sudden spike in ReceiveMessage events from SQS can indicate increased load or potential message flooding. It clearly describes what is measured (CloudTrail ReceiveMessage events), includes relevant context such as alert thresholds and impacts, and discusses implications for system health. The description is concise and understandable, providing sufficient information to confidently interpret spikes in ReceiveMessage events. The only minor shortcoming is the lack of explicit units for the event counts, though the time windows (e.g., 5 minutes) are specified.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Compare the Input (monitoring question) to the Retrieval Context (metric description) to assess if the description directly addresses the question.\",\n    \"Evaluate the clarity of the description by checking if it is easily understandable and concise in relation to the specific monitoring question.\",\n    \"Assess the coverage by verifying if the description explains what is measured, includes units, provides relevant context, and discusses implications pertinent to the input question.\",\n    \"Determine the utility by judging whether the description provides sufficient information to confidently answer the input question; if not, identify gaps between the input needs and retrieval context.\"\n] \n \nRubric:\nNone \n \nScore: 0.9"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Compare the Input (monitoring question) to the Retrieval Context (metric description) to assess if the description directly addresses the question.",
                            "Evaluate the clarity of the description by checking if it is easily understandable and concise in relation to the specific monitoring question.",
                            "Assess the coverage by verifying if the description explains what is measured, includes units, provides relevant context, and discusses implications pertinent to the input question.",
                            "Determine the utility by judging whether the description provides sufficient information to confidently answer the input question; if not, identify gaps between the input needs and retrieval context."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"dynamodb.amazonaws.com\\\", \\\"EventName\\\": \\\"Update*\\\"}\", \"hyperparameters\": null, \"input\": \"Do the update events in CloudTrail exceed five, indicating potential misconfigurations or automation errors?\", \"retrieval_context\": [\" - CloudFormation stack update events (**EventSource**: \\\"cloudformation.amazonaws.com\\\", **EventName**: \\\"Update*\\\") capture all modifications to AWS CloudFormation stacks, including infrastructure changes, resource additions/removals, and configuration updates. These events are critical for tracking infrastructure evolution and ensuring change management compliance.\\n\\n**Purpose:**  \\nThey provide visibility into when and how infrastructure is altered via CloudFormation, enabling SREs to audit changes, detect unauthorized or unexpected updates, and correlate incidents with recent deployments.\\n\\n**Alert Threshold Guidance:**  \\n- Trigger alerts on unusually high frequencies of update events within a short time window (e.g., >5 updates in 10 minutes), which may indicate automation loops, deployment failures, or misconfigurations.  \\n- Alert on failed or rollback update events to quickly identify deployment issues impacting system stability.\\n\\n**Impact of Values:**  \\n- **High volume of updates:** May signal instability, rapid iterative deployments, or potential automation errors, increasing risk of outages or configuration drift.  \\n- **Low or zero updates:** Normal during stable periods but prolonged absence of updates might indicate stalled deployments or lack of infrastructure changes.\\n\\n**Example Usage:**  \\n- **Dashboard:** Display a time-series graph of CloudFormation Update* events per hour, highlighting failed updates in red.  \\n- **Alert Rule:** Trigger an alert if the count of UpdateStack events exceeds 5 within 10 minutes or if any update event has a status of FAILED or ROLLBACK_COMPLETE, enabling rapid response to deployment issues.\", \" - IAM update events capture all modifications made to IAM resources such as users, roles, groups, policies, and credentials. These events indicate changes to permissions, access controls, and security configurations, which are critical for maintaining the principle of least privilege and preventing unauthorized privilege escalation. In CloudTrail, **{\\\"EventSource\\\": \\\"iam.amazonaws.com\\\", \\\"EventName\\\": \\\"Update*\\\"}** helps track who made changes, what was changed, and when, enabling audit and compliance verification.\\n\\n**Alert Threshold:** Trigger an alert when the number of IAM update events exceeds a baseline threshold within a short time window (e.g., more than 5 update events in 10 minutes), or when specific sensitive updates occur, such as policy changes granting administrative privileges or credential rotations outside of scheduled maintenance.\\n\\n**Impact of Values:**  \\n- **High values:** A spike in update events may indicate automated scripts, bulk permission changes, or potential malicious activity like privilege escalation attempts. Immediate investigation is warranted to confirm legitimacy.  \\n- **Low values:** Normal or zero update events typically indicate stable IAM configurations with no recent permission changes, which is expected in steady-state operations.\\n\\n**Example Usage:**  \\nIn a dashboard, display a time series graph of IAM update events filtered by event name pattern \\\"Update*\\\". Set an alert rule to notify the SRE team if the count of these events exceeds 5 within any rolling 10-minute window, or if any update event modifies policies granting \\\"AdministratorAccess\\\". This enables rapid detection of potentially risky permission changes and supports proactive security posture management.\", \" - Lambda function \\\"Put*\\\" events in CloudTrail capture changes to function configurations, concurrency settings, event source mappings, and resource provisioning. These events indicate updates or deployments that can affect function behavior and performance. An SRE should monitor the frequency and success of these operations; unusually high rates of \\\"Put*\\\" events may signal automation errors or configuration churn, while absence of expected updates could indicate deployment issues. Alert thresholds might include more than 5 \\\"Put*\\\" events within 5 minutes or failed update attempts exceeding 10% of total \\\"Put*\\\" events. High volumes can lead to inconsistent function states or throttling, impacting availability and latency; low update activity during active development phases may delay critical fixes or optimizations. For example, a dashboard widget can track the count of \\\"Put*\\\" events per hour alongside error rates, and an alert rule could trigger when the number of failed \\\"Put*\\\" events surpasses a set threshold, prompting investigation into deployment or configuration problems.\", \" - This pattern captures all ECS update events recorded in CloudTrail, such as modifications to ECS services, task definitions, and cluster configurations. Its purpose is to monitor changes that could affect the stability, performance, or security of ECS workloads. An SRE should use this pattern to detect unexpected or frequent updates that may indicate configuration drift, deployment issues, or unauthorized changes.\\n\\n**Threshold guidance:**  \\n- Trigger an alert if the number of ECS update events exceeds a baseline threshold (e.g., more than 5 updates within 10 minutes), as this may signal rapid or unintended changes.  \\n- A low or zero count over a long period is typically normal but should be reviewed if updates are expected during deployments.\\n\\n**Impact:**  \\n- High frequency of update events can lead to service instability, deployment failures, or security risks if changes are unplanned or unauthorized.  \\n- Low frequency indicates stable ECS configurations but may also suggest stalled deployments or lack of necessary updates.\\n\\n**Example alert rule:**  \\n\\u201cAlert when the count of CloudTrail events with EventSource = 'ecs.amazonaws.com' and EventName starting with 'Update' exceeds 5 within a 10-minute window.\\u201d  \\n\\n**Example dashboard widget:**  \\nA time-series graph showing the count of ECS update events per 5-minute interval, annotated with deployment windows to correlate updates with expected changes.\", \" - This pattern captures all update-related events from AWS Systems Manager (SSM) recorded in CloudTrail, such as modifications to parameters, documents, and maintenance windows. It helps SREs monitor changes to critical SSM resources that could affect system configuration, automation workflows, or maintenance schedules.  \\n\\n**Purpose:** Detect when SSM resources are altered to ensure changes are authorized and to quickly identify unexpected or potentially disruptive updates.\\n\\n**Alert Threshold:** Trigger an alert if the number of update events exceeds a baseline threshold within a short time window (e.g., more than 5 update events in 10 minutes), indicating possible misconfiguration, automation errors, or unauthorized changes.\\n\\n**Impact:**  \\n- **High values:** A spike in update events may signal bulk or automated changes that could introduce instability or security risks if unplanned. Immediate investigation is warranted.  \\n- **Low or zero values:** Normal operation if no updates are expected; however, if updates are regularly scheduled, a sudden drop might indicate monitoring gaps or failures in deployment pipelines.\\n\\n**Example Usage:**  \\nIn a monitoring dashboard, display a time series graph of the count of **{\\\"EventSource\\\": \\\"ssm.amazonaws.com\\\", \\\"EventName\\\": \\\"Update*\\\"}** events over time. Configure an alert rule to notify the SRE team when update events exceed 5 within any rolling 10-minute window, enabling rapid response to unexpected configuration changes.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": true,
                        "score": 0.9,
                        "reason": "The retrieval context directly addresses the monitoring question by describing update events in CloudTrail, specifying thresholds (exceeding 5 events) that indicate potential misconfigurations or automation errors. It clearly explains what is measured (update event counts), includes units (events per 5 or 10 minutes), provides context on implications (instability, deployment issues, security risks), and offers example alert rules and dashboard visualizations. The description is clear, detailed, and enables effective response to the question. Minor deduction is due to the context covering multiple AWS services, which may require the user to identify the relevant pattern for their use case.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Compare the Input (monitoring question) with the Retrieval Context (metric description) to ensure the description directly addresses the question.\",\n    \"Evaluate the clarity of the description to determine if it is understandable and concise in relation to the question\u2019s intent.\",\n    \"Assess the coverage of the description by checking if it details what is measured, includes units, provides context, and describes implications necessary to answer the question.\",\n    \"Judge the utility of the description by verifying whether it enables a user to effectively respond to the monitoring question based on the information provided.\"\n] \n \nRubric:\nNone \n \nScore: 0.9"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Compare the Input (monitoring question) with the Retrieval Context (metric description) to ensure the description directly addresses the question.",
                            "Evaluate the clarity of the description to determine if it is understandable and concise in relation to the question\u2019s intent.",
                            "Assess the coverage of the description by checking if it details what is measured, includes units, provides context, and describes implications necessary to answer the question.",
                            "Judge the utility of the description by verifying whether it enables a user to effectively respond to the monitoring question based on the information provided."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"sns.amazonaws.com\\\", \\\"EventName\\\": \\\"Unsubscribe*\\\"}\", \"hyperparameters\": null, \"input\": \"Does the number of Unsubscribe events exceed a baseline threshold, indicating potential endpoint removals or service issues?\", \"retrieval_context\": [\" - API Gateway deletion events captured by CloudTrail indicate when APIs, stages, or related resources are removed. These events are critical for tracking decommissioning activities, ensuring that endpoint removals are intentional and authorized, and preventing accidental service disruptions.  \\n\\n**Purpose:**  \\nMonitor all delete operations initiated via API Gateway (e.g., DeleteRestApi, DeleteStage) to maintain visibility into changes that reduce API surface area or remove critical endpoints.\\n\\n**Alert Threshold:**  \\nTrigger an alert if the number of Delete* events exceeds a predefined baseline within a short time window (e.g., more than 3 deletions within 10 minutes), as this may indicate accidental mass deletions, unauthorized activity, or a misconfigured automation script.\\n\\n**Impact:**  \\n- **High frequency:** Could lead to service outages, broken integrations, or data loss if APIs or stages are removed unexpectedly. Immediate investigation is required.  \\n- **Low or zero frequency:** Normal operation; deletion events are infrequent and typically planned.\\n\\n**Example Usage:**  \\nIn a monitoring dashboard, display a time series graph of Delete* events from apigateway.amazonaws.com. Set an alert rule such as:  \\n`IF count(Delete* events) > 3 within 10 minutes THEN trigger high-severity alert \\\"Potential API Gateway mass deletion detected\\\"`  \\nThis enables rapid response to potentially disruptive changes in the API infrastructure.\", \" - CloudFormation Delete* events in CloudTrail indicate the initiation or completion of stack deletion operations, signaling infrastructure teardown and resource decommissioning activities. These events help SREs monitor environment lifecycle changes and ensure that deletions are intentional and controlled. \\n\\n**Alert Threshold:** Trigger an alert if the number of Delete* events exceeds a predefined baseline (e.g., more than 3 deletions within 1 hour) or occurs unexpectedly outside of scheduled maintenance windows, as this may indicate accidental or malicious infrastructure removal.\\n\\n**Impact of Values:**  \\n- **High frequency:** May lead to unintended service disruptions, data loss, or compliance risks due to rapid or bulk resource deletions. Requires immediate investigation.  \\n- **Low or zero frequency:** Normal in stable environments; indicates no recent stack deletions and stable infrastructure.\\n\\n**Example Usage:**  \\nCreate a dashboard widget tracking the count of CloudFormation Delete* events over time. Set an alert rule to notify the SRE team if Delete* events spike above the threshold within a rolling 1-hour window, enabling prompt response to potential infrastructure teardown incidents.\", \" - IAM deletion events (e.g., DeleteUser, DeleteRole) recorded by CloudTrail indicate removal of IAM identities or permissions. These events are critical for detecting unauthorized or accidental deletions that can disrupt access or signal a security breach. An alert threshold should be set to trigger on any unexpected deletion event or a sudden spike above normal baseline activity (e.g., more than 1 deletion event within 5 minutes), as even a single deletion can have significant impact. High volumes may indicate automated attacks or misconfigurations causing mass access removal, while low or zero values typically indicate normal operation.  \\nExample alert rule: trigger when count of iam.amazonaws.com Delete* events > 1 in 5 minutes.  \\nExample dashboard widget: a time series graph showing Delete* event counts over time, annotated with alert thresholds to quickly identify unusual deletion activity.\", \" - This pattern captures SNS unsubscription events recorded in CloudTrail, indicating when endpoints or subscribers are removed from SNS topics. For an SRE, monitoring these events helps track changes in notification delivery and detect potential disruptions or configuration changes.\\n\\n**Purpose:**  \\n- Identify when subscribers unsubscribe from SNS topics, which may reflect endpoint decommissioning, application changes, or user-initiated opt-outs.  \\n- Detect unusual spikes that could indicate mass unsubscriptions due to misconfigurations, security incidents, or service issues.\\n\\n**Alert Threshold:**  \\n- Trigger an alert if the number of Unsubscribe events exceeds a baseline threshold (e.g., more than 5 unsubscriptions within 5 minutes) or shows a sudden increase compared to historical averages. Thresholds should be tuned based on normal subscription churn rates.\\n\\n**Impact:**  \\n- **High values:** May signal widespread endpoint removals causing notification delivery failures, potential service degradation, or security concerns (e.g., unauthorized unsubscriptions). Immediate investigation is warranted.  \\n- **Low or zero values:** Typically expected during stable operations; a sudden drop to zero after a period of regular unsubscriptions might indicate logging issues or CloudTrail misconfigurations.\\n\\n**Example Usage:**  \\n- **Dashboard:** Display a time series graph of Unsubscribe event counts per minute to visualize trends and detect anomalies.  \\n- **Alert Rule (pseudo-code):**  \\n  ```\\n  WHEN count(Events where EventSource=\\\"sns.amazonaws.com\\\" AND EventName LIKE \\\"Unsubscribe%\\\") \\n  OVER last 5 minutes > 5 \\n  THEN trigger alert \\\"High SNS Unsubscription Rate\\\"\\n  ```\", \" - This pattern captures all Route 53 deletion events recorded in CloudTrail, such as deleting hosted zones, record sets, or health checks. It helps SREs monitor when DNS configurations are removed, which could be part of routine cleanup or signal accidental or malicious disruptions to DNS resolution.\\n\\n**Purpose:**  \\nTrack and alert on Route 53 resource deletions to quickly detect potential service impact caused by DNS changes.\\n\\n**Alert Threshold:**  \\nTrigger an alert if more than 3 deletion events occur within a 10-minute window, as multiple deletions in a short period may indicate an ongoing incident or misconfiguration.\\n\\n**Impact:**  \\n- **High volume:** May cause widespread DNS outages or service disruptions, requiring immediate investigation.  \\n- **Low volume (single event):** Could be routine maintenance but should still be reviewed to confirm legitimacy.\\n\\n**Example Alert Rule:**  \\n\\u201cAlert when count of events matching {EventSource: route53.amazonaws.com, EventName: Delete*} exceeds 3 within 10 minutes.\\u201d\\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of Route 53 deletion events over time, with a threshold line at 3 events per 10 minutes to highlight potential issues.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": true,
                        "score": 0.8989944883165274,
                        "reason": "The input directly aligns with the retrieval context by focusing on whether the number of Unsubscribe events exceeds a baseline threshold, indicating potential endpoint removals or service issues. The description is clear, concise, and uses understandable language relevant to SNS unsubscription monitoring. It covers what is measured (Unsubscribe events), the context (SNS topic subscriptions), threshold examples, and implications (endpoint removals, service degradation), enabling confident answers to the monitoring question. Minor detail on exact threshold tuning or example alert rules could improve completeness but overall coverage and utility are strong.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Compare the Input (metric description) with the Retrieval Context (monitoring question) to ensure the description clearly aligns with and directly addresses the question.\",\n    \"Evaluate the clarity of the Input by checking if the description uses understandable language and concise phrasing relevant to the Retrieval Context.\",\n    \"Assess the coverage of the Input in relation to the Retrieval Context by verifying if the description explains what is measured, units, context, and implications needed to answer the question.\",\n    \"Determine the utility by judging whether the Input sufficiently enables a user to confidently answer the Retrieval Context question without additional information.\"\n] \n \nRubric:\nNone \n \nScore: 0.8989944883165274"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Compare the Input (metric description) with the Retrieval Context (monitoring question) to ensure the description clearly aligns with and directly addresses the question.",
                            "Evaluate the clarity of the Input by checking if the description uses understandable language and concise phrasing relevant to the Retrieval Context.",
                            "Assess the coverage of the Input in relation to the Retrieval Context by verifying if the description explains what is measured, units, context, and implications needed to answer the question.",
                            "Determine the utility by judging whether the Input sufficiently enables a user to confidently answer the Retrieval Context question without additional information."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"rds.amazonaws.com\\\", \\\"EventName\\\": \\\"Stop*\\\"}\", \"hyperparameters\": null, \"input\": \"Does the count of RDS stop events exceed one within an hour, indicating potential automation issues or unexpected failures?\", \"retrieval_context\": [\" - **{\\\"EventName\\\": \\\"Stop*\\\"}**  \\nThis event captures all resource stop operations across cloud services, such as stopping virtual machines, containers, or other compute resources. It signals intentional halting of resources for cost optimization, maintenance, or deactivation purposes.  \\n\\n**Purpose:**  \\nTo monitor when resources are stopped, enabling tracking of operational changes that affect availability and cost.  \\n\\n**Alert Threshold:**  \\nTrigger an alert if the number of Stop* events exceeds a defined baseline (e.g., a 50% increase over the average daily stop events) within a short time window (e.g., 15 minutes), which may indicate unexpected or mass shutdowns.  \\n\\n**Impact:**  \\n- **High values:** May indicate large-scale maintenance, potential outages, or unauthorized shutdowns impacting service availability and user experience.  \\n- **Low values:** Normal or no stop activity, indicating stable resource operation or potential lack of expected maintenance.  \\n\\n**Example Usage:**  \\nIn a dashboard, plot the count of Stop* events over time to visualize stop operation trends. An alert rule could be:  \\n`WHEN count(Stop* events) > baseline * 1.5 FOR 15 minutes THEN trigger alert`  \\nThis helps SREs quickly detect abnormal stop activity and respond accordingly.\", \" - This pattern captures AWS CloudTrail events where Amazon RDS instances are stopped (EventSource: \\\"rds.amazonaws.com\\\", EventName starting with \\\"Stop\\\"). It helps SREs monitor when RDS databases are intentionally or unintentionally stopped, which can impact application availability and indicate maintenance or cost-saving actions.\\n\\n**Purpose:**  \\n- Detect RDS stop operations to quickly identify potential service disruptions or planned maintenance.  \\n- Provide visibility into operational changes affecting database availability.\\n\\n**Alert Threshold Guidance:**  \\n- Trigger an alert if the number of RDS stop events exceeds a defined threshold within a short time window (e.g., more than 1 stop event per hour per critical environment), as multiple stops may indicate automation issues or unexpected failures.  \\n- For low-frequency environments, even a single unexpected stop event should trigger an alert.\\n\\n**Impact of Values:**  \\n- **High frequency of stop events:** May indicate instability, automation misconfiguration, or repeated manual interventions, potentially causing downtime or degraded service.  \\n- **Low or zero stop events:** Normal operation, assuming no planned maintenance is ongoing.\\n\\n**Example Alert Rule:**  \\n- Alert when count of events matching {\\\"EventSource\\\": \\\"rds.amazonaws.com\\\", \\\"EventName\\\": \\\"Stop*\\\"} exceeds 1 within 60 minutes for production accounts.  \\n- Dashboard widget can display a time series graph of RDS stop events over the past 24 hours, segmented by environment or instance ID, to correlate stops with incidents or maintenance windows.\", \" - This pattern captures AWS RDS instance start events recorded in CloudTrail, indicating when one or more RDS instances transition from a stopped to a running state. Monitoring these events helps SREs track service availability changes and manage cost implications, as starting instances can increase resource usage and expenses.\\n\\n**Purpose:**  \\n- Detect when RDS instances are started to ensure expected service restoration or identify unexpected restarts.  \\n- Support cost optimization by alerting on frequent or unusual start activity that may indicate inefficient resource usage or automation issues.\\n\\n**Alert Threshold Guidance:**  \\n- Trigger an alert if the number of RDS start events exceeds a defined threshold within a short time window (e.g., more than 3 start events within 10 minutes), which may indicate instability or unintended restarts.  \\n- Alternatively, alert if no start events occur during a scheduled maintenance window when instances are expected to be restarted.\\n\\n**Impact of Values:**  \\n- **High frequency of start events:** Could signal recurring failures, automation loops, or misconfigurations causing service interruptions and increased costs. Immediate investigation is recommended.  \\n- **Low or zero start events:** May indicate stable operation or, if expected, a failure to restore service after downtime, requiring attention.\\n\\n**Example Usage:**  \\n- **Dashboard:** Display a time series graph of RDS start events per hour to visualize trends and detect spikes.  \\n- **Alert Rule:**  \\n  ```\\n  WHEN count(events where EventSource=\\\"rds.amazonaws.com\\\" AND EventName LIKE \\\"Start%\\\") \\n  IN last 10 minutes > 3 \\n  THEN trigger alert \\\"High frequency of RDS instance starts detected\\\"\\n  ```  \\nThis enables proactive monitoring of RDS instance lifecycle events to maintain service reliability and control costs.\", \" - This pattern captures all AWS CloudTrail events where RDS resources are deleted (e.g., DeleteDBInstance, DeleteDBSnapshot). Its purpose is to monitor and alert on potentially destructive actions affecting RDS databases, which could indicate intentional cleanup, accidental deletions, or malicious activity. \\n\\n**Threshold guidance:**  \\n- Trigger an alert if more than 1 deletion event occurs within a short time window (e.g., 5 minutes), as multiple deletions in quick succession are unusual and may signal a problem.  \\n- A single deletion event should also prompt review, especially if unexpected or outside maintenance windows.\\n\\n**Impact:**  \\n- **High values:** Multiple deletions in a short period can lead to significant data loss or service disruption, requiring immediate investigation and possible recovery actions.  \\n- **Low values:** Occasional single deletions may be normal during maintenance but still warrant confirmation to avoid unnoticed data loss.\\n\\n**Example usage:**  \\nIn a monitoring dashboard, display a time series count of RDS deletion events filtered by this pattern. Configure an alert rule to notify the SRE team if the count exceeds 1 event within any 5-minute interval, enabling rapid response to potential incidents.\", \" - This pattern detects all Amazon RDS database creation events captured in CloudTrail, identified by any event name starting with \\\"Create\\\" from the \\\"rds.amazonaws.com\\\" source. It enables SREs to monitor when new RDS instances or related resources are provisioned, providing visibility into changes that may impact database capacity, cost, or security posture. A typical alert threshold could be set to trigger if more than 3 RDS creation events occur within a 1-hour window, indicating potential unexpected scaling or automation issues. High volumes of creation events may signal rapid infrastructure changes or misconfigurations, increasing operational risk and cost, while low or zero events generally indicate stable database provisioning activity. For example, an alert rule could be configured as:  \\n`WHEN count of events matching {\\\"EventSource\\\": \\\"rds.amazonaws.com\\\", \\\"EventName\\\": \\\"Create*\\\"} > 3 IN 1 hour THEN trigger alert`  \\nThis can be visualized in a dashboard showing the count of RDS creation events over time, helping teams quickly identify unusual spikes in database provisioning activity.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": true,
                        "score": 0.9,
                        "reason": "The description is clear, concise, and unambiguous, effectively explaining the metric of counting RDS stop events within a time window. It covers what is measured (RDS stop events), the unit (count per hour), relevant context (potential automation issues or failures), and implications (service disruptions, maintenance, cost impact). The alert threshold guidance directly aligns with the question's focus on exceeding one stop event per hour. The description provides sufficient detail to answer the monitoring question, including example alert rules and impact of values. Minor deduction is due to slight lack of explicit mention of the exact one-hour window in all parts, but overall it fully addresses the question and context.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Assess clarity by verifying if the metric description is concise and easily understandable without ambiguity.\",\n    \"Evaluate coverage by checking if the description details what is measured, units of measurement, relevant context, and potential implications.\",\n    \"Determine utility by analyzing if the description provides sufficient information to effectively answer the provided monitoring question.\",\n    \"Compare the description to the question to ensure all critical aspects needed for the question's resolution are addressed; identify gaps between Input and Retrieval Context.\"\n] \n \nRubric:\nNone \n \nScore: 0.9"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Assess clarity by verifying if the metric description is concise and easily understandable without ambiguity.",
                            "Evaluate coverage by checking if the description details what is measured, units of measurement, relevant context, and potential implications.",
                            "Determine utility by analyzing if the description provides sufficient information to effectively answer the provided monitoring question.",
                            "Compare the description to the question to ensure all critical aspects needed for the question's resolution are addressed; identify gaps between Input and Retrieval Context."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"dynamodb.amazonaws.com\\\", \\\"EventName\\\": \\\"Delete*\\\"}\", \"hyperparameters\": null, \"input\": \"Are the Delete* events in DynamoDB indicative of a deliberate table removal or an unexpected error?\", \"retrieval_context\": [\" - IAM deletion events (e.g., DeleteUser, DeleteRole) recorded by CloudTrail indicate removal of IAM identities or permissions. These events are critical for detecting unauthorized or accidental deletions that can disrupt access or signal a security breach. An alert threshold should be set to trigger on any unexpected deletion event or a sudden spike above normal baseline activity (e.g., more than 1 deletion event within 5 minutes), as even a single deletion can have significant impact. High volumes may indicate automated attacks or misconfigurations causing mass access removal, while low or zero values typically indicate normal operation.  \\nExample alert rule: trigger when count of iam.amazonaws.com Delete* events > 1 in 5 minutes.  \\nExample dashboard widget: a time series graph showing Delete* event counts over time, annotated with alert thresholds to quickly identify unusual deletion activity.\", \" - This event pattern captures all CloudTrail events where CloudWatch Logs resources\\u2014such as log groups or log streams\\u2014are deleted (e.g., DeleteLogGroup, DeleteLogStream). Its purpose is to monitor and audit log deletion activities, which can be legitimate cleanup or indicate potential loss of critical log data needed for troubleshooting and compliance.\\n\\n**Alert Threshold:**  \\nTrigger an alert if the number of delete events exceeds a baseline threshold within a defined time window (e.g., more than 3 deletions within 1 hour), or if deletions occur unexpectedly outside of scheduled maintenance windows.\\n\\n**Impact:**  \\n- **High frequency of deletions:** May indicate accidental or malicious removal of logs, risking loss of observability and forensic data. Immediate investigation is recommended.  \\n- **Low or zero deletions:** Normal operation, indicating logs are retained as expected.\\n\\n**Example Alert Rule:**  \\n\\u201cAlert if DeleteLogGroup or DeleteLogStream events from logs.amazonaws.com exceed 3 occurrences in 60 minutes.\\u201d  \\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of Delete* events over time, annotated with alert thresholds and maintenance windows, enabling quick identification of unusual spikes in log deletions.\", \" - This pattern captures DynamoDB deletion events. It identifies when DynamoDB tables are removed, which can indicate cleanup operations or potential data loss incidents.\", \" - This pattern captures all AWS CloudTrail events where RDS resources are deleted (e.g., DeleteDBInstance, DeleteDBSnapshot). Its purpose is to monitor and alert on potentially destructive actions affecting RDS databases, which could indicate intentional cleanup, accidental deletions, or malicious activity. \\n\\n**Threshold guidance:**  \\n- Trigger an alert if more than 1 deletion event occurs within a short time window (e.g., 5 minutes), as multiple deletions in quick succession are unusual and may signal a problem.  \\n- A single deletion event should also prompt review, especially if unexpected or outside maintenance windows.\\n\\n**Impact:**  \\n- **High values:** Multiple deletions in a short period can lead to significant data loss or service disruption, requiring immediate investigation and possible recovery actions.  \\n- **Low values:** Occasional single deletions may be normal during maintenance but still warrant confirmation to avoid unnoticed data loss.\\n\\n**Example usage:**  \\nIn a monitoring dashboard, display a time series count of RDS deletion events filtered by this pattern. Configure an alert rule to notify the SRE team if the count exceeds 1 event within any 5-minute interval, enabling rapid response to potential incidents.\", \" - Tracks all AWS Lambda function deletion events captured in CloudTrail. Monitoring **{\\\"EventSource\\\": \\\"lambda.amazonaws.com\\\", \\\"EventName\\\": \\\"Delete*\\\"}** helps SREs detect when Lambda functions are removed, which is critical for maintaining application stability, ensuring proper resource cleanup, and preventing accidental or unauthorized deletions.  \\n\\n**Alert Threshold:** Trigger an alert if more than 3 Lambda function deletions occur within a 1-hour window, as this may indicate a misconfiguration, automated script error, or potential security breach.  \\n\\n**Impact:**  \\n- **High values:** A spike in deletions can lead to service disruptions, loss of critical functionality, or security incidents if unauthorized deletions occur. Immediate investigation is required.  \\n- **Low or zero values:** Normal operation; infrequent deletions are expected during routine maintenance or deployments.  \\n\\n**Example Alert Rule:**  \\n`WHEN count(events where EventSource=\\\"lambda.amazonaws.com\\\" AND EventName LIKE \\\"Delete%\\\") > 3 WITHIN 1 hour THEN alert \\\"Unusual number of Lambda deletions detected\\\"`  \\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of Lambda deletion events per hour, annotated with alert thresholds, enabling quick identification of abnormal deletion activity.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": false,
                        "score": 0.5011819152955188,
                        "reason": "The retrieval context partially addresses the question by explaining that DynamoDB Delete* events indicate table removals which can be due to cleanup or potential data loss incidents, implying both deliberate and error-related causes. However, it lacks explicit clarity on distinguishing deliberate table removal from unexpected errors, and does not provide detailed implications, alert thresholds, or examples specific to DynamoDB Delete* events. The description is somewhat concise but could be clearer and more comprehensive to fully inform the question.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Compare the Input (question) with the Retrieval Context (description) to assess if the description clearly addresses the question's intent.\",\n    \"Evaluate Clarity by checking if the description is concise and easy to understand when related to the specific question asked.\",\n    \"Assess Coverage by verifying the description includes what is measured, units, context, and implications that help answer the question.\",\n    \"Judge Utility by determining if the description provides sufficient information to directly answer or inform the question accurately.\"\n] \n \nRubric:\nNone \n \nScore: 0.5011819152955188"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Compare the Input (question) with the Retrieval Context (description) to assess if the description clearly addresses the question's intent.",
                            "Evaluate Clarity by checking if the description is concise and easy to understand when related to the specific question asked.",
                            "Assess Coverage by verifying the description includes what is measured, units, context, and implications that help answer the question.",
                            "Judge Utility by determining if the description provides sufficient information to directly answer or inform the question accurately."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"sns.amazonaws.com\\\", \\\"EventName\\\": \\\"Create*\\\"}\", \"hyperparameters\": null, \"input\": \"Does the number of Create* events exceed five, indicating potential automation errors or security issues?\", \"retrieval_context\": [\" - CloudFormation stack creation events (**EventSource: cloudformation.amazonaws.com**, **EventName: Create\\\\*** ) represent API calls initiating the provisioning of AWS infrastructure and resources via CloudFormation templates. These events in CloudTrail help SREs monitor the start of environment setups and infrastructure deployments as part of Infrastructure as Code workflows.\\n\\n**Purpose:** Track and audit when new CloudFormation stacks or stack components are being created, enabling visibility into changes in infrastructure state and deployment activities.\\n\\n**Alert Thresholds:**  \\n- Trigger an alert if the number of Create* events exceeds a baseline threshold within a short time window (e.g., >10 stack creation attempts in 5 minutes), which may indicate automated deployment loops, misconfigurations, or potential security incidents.  \\n- Alert if Create* events spike unexpectedly outside of scheduled deployment windows or change management periods.\\n\\n**Impact of Values:**  \\n- **High volume:** May signal rapid infrastructure changes that could lead to instability, resource contention, or deployment failures. It could also indicate unauthorized or accidental mass provisioning.  \\n- **Low or zero volume:** Normal during steady-state operations; however, a sudden drop during expected deployment windows might indicate pipeline failures or blocked deployments.\\n\\n**Example Usage:**  \\n- **Dashboard:** Visualize the count of CloudFormation Create* events over time, segmented by stack name or user identity, to correlate deployments with system performance or incidents.  \\n- **Alert Rule:**  \\n  ```  \\n  WHEN count(events where EventSource=\\\"cloudformation.amazonaws.com\\\" AND EventName LIKE \\\"Create%\\\") > 10 within 5 minutes  \\n  THEN trigger alert \\\"High rate of CloudFormation stack creation events detected\\\"  \\n  ```  \\nThis enables proactive detection of abnormal infrastructure provisioning activity and supports rapid investigation and response.\", \" - This pattern captures all AWS Systems Manager (SSM) resource creation events logged in CloudTrail, such as the creation of parameters, documents, and maintenance windows. It helps SREs monitor the provisioning of new SSM assets, which can indicate configuration changes or automation deployments.\\n\\n**Purpose:**  \\nTo detect when new SSM resources are created, enabling timely awareness of infrastructure changes that may affect system behavior or security posture.\\n\\n**Alert Threshold Guidance:**  \\nSet an alert threshold based on your environment\\u2019s baseline creation activity. For example, trigger an alert if more than 5 creation events occur within 10 minutes, which may indicate unexpected or unauthorized provisioning.\\n\\n**Impact of Values:**  \\n- **High values:** A spike in creation events could signal automated deployments, configuration drift, or potential security incidents such as unauthorized resource creation.  \\n- **Low or zero values:** Normal in stable environments; however, a sudden drop might indicate issues with deployment pipelines or monitoring gaps.\\n\\n**Example Alert Rule:**  \\nTrigger an alert when the count of events matching `{\\\"EventSource\\\": \\\"ssm.amazonaws.com\\\", \\\"EventName\\\": \\\"Create*\\\"}` exceeds 5 within a 10-minute window.\\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of SSM creation events over time, with thresholds marked to highlight unusual spikes, helping SREs quickly identify and investigate abnormal provisioning activity.\", \" - This pattern detects CloudTrail events where CloudWatch resources are created, such as alarms, dashboards, and log groups. Its purpose is to monitor the provisioning of new CloudWatch components, which can indicate changes in monitoring coverage or potential configuration drift. An alert should be triggered when the number of creation events exceeds a defined threshold within a short time window (e.g., more than 5 Create* events in 10 minutes), as a sudden spike may signal automated deployments, misconfigurations, or unauthorized activity. Conversely, a prolonged absence of creation events might suggest stagnation in monitoring updates or missed deployments. For example, in a monitoring dashboard, you can visualize the count of CloudWatch Create* events over time and set an alert rule to notify the SRE team if the event count surpasses the threshold, enabling timely investigation and response to unexpected changes in monitoring infrastructure.\", \" - This pattern detects SNS topic creation events recorded in CloudTrail, specifically any API calls starting with \\\"Create\\\" from the SNS service (e.g., CreateTopic). It helps SREs monitor when new SNS topics are provisioned, which can indicate changes in messaging architecture or potential unauthorized resource creation. An alert threshold could be set on the number of Create* events within a given time window (e.g., more than 5 topic creations in 10 minutes), as a sudden spike may signal automation errors or security issues. Low or expected values typically indicate normal operations, while high values may impact system stability by increasing resource usage or indicate potential misuse. For example, an alert rule could trigger if the count of {\\\"EventSource\\\": \\\"sns.amazonaws.com\\\", \\\"EventName\\\": \\\"Create*\\\"} events exceeds 5 in 10 minutes, and a dashboard widget could display a time series graph of topic creation events to track trends and detect anomalies.\", \" - This pattern detects Secrets Manager creation events in CloudTrail, specifically any API calls starting with \\\"Create\\\" (e.g., CreateSecret). It helps SREs monitor when new secrets, secret versions, or related configurations are added, which could indicate deployment changes or potential security risks.  \\n**Alert threshold:** Trigger an alert if the number of create events exceeds a baseline (e.g., more than 5 creates within 10 minutes), as a sudden spike may signal unauthorized secret creation or misconfiguration. Conversely, zero create events over an extended period in an active environment might indicate issues with deployment pipelines or automation failures.  \\n**Impact:**  \\n- High values: Could indicate potential security breaches, unauthorized secret provisioning, or rapid environment changes requiring immediate investigation.  \\n- Low values: May suggest stalled deployments or automation problems, potentially delaying application updates or secret rotations.  \\n**Example usage:**  \\nIn a dashboard, plot the count of Secrets Manager Create* events over time to visualize spikes. An alert rule could be:  \\n`WHEN count(secretsmanager.amazonaws.com Create* events) > 5 within 10 minutes THEN trigger alert \\\"Unusual Secrets Creation Activity\\\"`  \\nThis enables proactive detection of abnormal secret creation activity, helping maintain security and operational stability.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": true,
                        "score": 0.8962673115333132,
                        "reason": "The retrieval context clearly relates to the input question by describing multiple patterns of Create* events across AWS services, including SNS, Secrets Manager, CloudWatch, SSM, and CloudFormation. It is clear and concise in explaining what is measured (Create* events), the units (counts within time windows), and the context (monitoring for automation errors or security issues). The context provides alert threshold examples (exceeding 5 events in 10 minutes) directly addressing the input question's threshold and implications. The only minor shortcoming is that the context covers multiple services rather than focusing on a single one, which could slightly dilute directness but overall provides comprehensive coverage and utility for answering the question effectively.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Compare the Input (monitoring question) to the Retrieval Context (metric description) to assess if the description clearly relates to the question being asked.\",\n    \"Evaluate the Clarity of the Retrieval Context in terms of how understandable and concise it is in explaining the metric relevant to the Input.\",\n    \"Assess the Coverage by checking if the Retrieval Context adequately explains what is measured, the units used, the context of the metric, and its implications for the Input question.\",\n    \"Determine Utility by verifying if the Retrieval Context provides sufficient information to answer the Input question effectively and suggest improvements if the clarity, coverage, or utility is lacking.\"\n] \n \nRubric:\nNone \n \nScore: 0.8962673115333132"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Compare the Input (monitoring question) to the Retrieval Context (metric description) to assess if the description clearly relates to the question being asked.",
                            "Evaluate the Clarity of the Retrieval Context in terms of how understandable and concise it is in explaining the metric relevant to the Input.",
                            "Assess the Coverage by checking if the Retrieval Context adequately explains what is measured, the units used, the context of the metric, and its implications for the Input question.",
                            "Determine Utility by verifying if the Retrieval Context provides sufficient information to answer the Input question effectively and suggest improvements if the clarity, coverage, or utility is lacking."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"sqs.amazonaws.com\\\", \\\"EventName\\\": \\\"Send*\\\"}\", \"hyperparameters\": null, \"input\": \"Does the volume of SQS message sends exceed 150% of the normal rate, indicating potential flooding or unexpected load?\", \"retrieval_context\": [\" - This pattern captures AWS KMS Decrypt API calls recorded in CloudTrail, indicating when encrypted data is accessed and decrypted using KMS keys. It helps SREs monitor data access events for security auditing and anomaly detection. A sudden spike in Decrypt events may signal unusual or unauthorized data access, while consistently low or expected volumes suggest normal operation. As a threshold, alerting on a sustained increase exceeding 3 standard deviations above the historical average or a sudden burst of Decrypt calls within a short time window (e.g., 5 minutes) is recommended. For example, an alert rule could trigger when the count of Decrypt events exceeds 100 in 5 minutes, indicating potential data exfiltration or misuse. In dashboards, tracking the rate of Decrypt events over time alongside user identities and key IDs can help quickly identify suspicious patterns or compromised credentials.\", \" - This pattern captures AWS KMS encryption API calls (e.g., Encrypt, EncryptData) recorded in CloudTrail, indicating when data is being encrypted using customer-managed or AWS-managed KMS keys. It helps SREs monitor cryptographic operations to ensure data protection policies are enforced and to detect unusual encryption activity that could signal misuse or security incidents.\\n\\n**Purpose:** Track the frequency and context of encryption operations to verify normal application behavior and compliance with data security standards.\\n\\n**Alert Threshold:** Trigger an alert if the number of Encrypt* events exceeds a baseline threshold (e.g., a sudden spike beyond 3 standard deviations from the average hourly rate) or if encryption requests originate from unexpected principals or regions.\\n\\n**Impact of Values:**  \\n- **High volume:** May indicate increased data processing, potential automated encryption loops, or unauthorized bulk encryption attempts, which could impact performance or signal a security breach.  \\n- **Low or zero volume:** Could suggest application issues, disabled encryption, or misconfigured services failing to encrypt data as required, risking data exposure.\\n\\n**Example Alert Rule:**  \\nAlert when Encrypt* events exceed 500 per hour or when encryption requests come from an unrecognized IAM role, triggering an investigation into possible misuse or operational anomalies.\\n\\n**Dashboard Use:**  \\nVisualize Encrypt* event counts over time alongside related Decrypt* events and key usage metrics to correlate encryption activity with application workloads and detect deviations from normal patterns.\", \" - This pattern captures CloudTrail events where messages are received from Amazon SQS queues (EventSource: \\\"sqs.amazonaws.com\\\", EventName starting with \\\"Receive\\\"), indicating when consumers poll and retrieve messages for processing. Monitoring these events helps SREs track message consumption rates, detect potential processing delays, and ensure downstream systems are actively handling queued workloads. \\n\\n**Alert Threshold Guidance:**  \\n- Set alerts for unusually low receive event counts over a defined period (e.g., fewer than 10 receives in 5 minutes), which may indicate consumer failures or processing bottlenecks.  \\n- Conversely, a sudden spike in receive events (e.g., a 2x increase compared to baseline) could signal increased load or potential message flooding that might overwhelm downstream services.\\n\\n**Impact:**  \\n- **Low receive event counts** can lead to message backlog growth, increased latency, and potential service degradation.  \\n- **High receive event counts** may reflect healthy throughput or, if excessive, could cause resource exhaustion or indicate abnormal traffic patterns.\\n\\n**Example Alert Rule:**  \\nTrigger an alert if the count of ReceiveMessage events from SQS falls below 10 in a rolling 5-minute window, signaling possible consumer inactivity.  \\n```  \\nWHEN count(events where EventSource=\\\"sqs.amazonaws.com\\\" AND EventName LIKE \\\"Receive%\\\") < 10 OVER last 5 minutes  \\nTHEN alert \\\"SQS message consumption is below expected levels\\\"  \\n```  \\n\\nThis enables proactive detection of issues in message processing pipelines and helps maintain system reliability.\", \" - This pattern captures SNS unsubscription events recorded in CloudTrail, indicating when endpoints or subscribers are removed from SNS topics. For an SRE, monitoring these events helps track changes in notification delivery and detect potential disruptions or configuration changes.\\n\\n**Purpose:**  \\n- Identify when subscribers unsubscribe from SNS topics, which may reflect endpoint decommissioning, application changes, or user-initiated opt-outs.  \\n- Detect unusual spikes that could indicate mass unsubscriptions due to misconfigurations, security incidents, or service issues.\\n\\n**Alert Threshold:**  \\n- Trigger an alert if the number of Unsubscribe events exceeds a baseline threshold (e.g., more than 5 unsubscriptions within 5 minutes) or shows a sudden increase compared to historical averages. Thresholds should be tuned based on normal subscription churn rates.\\n\\n**Impact:**  \\n- **High values:** May signal widespread endpoint removals causing notification delivery failures, potential service degradation, or security concerns (e.g., unauthorized unsubscriptions). Immediate investigation is warranted.  \\n- **Low or zero values:** Typically expected during stable operations; a sudden drop to zero after a period of regular unsubscriptions might indicate logging issues or CloudTrail misconfigurations.\\n\\n**Example Usage:**  \\n- **Dashboard:** Display a time series graph of Unsubscribe event counts per minute to visualize trends and detect anomalies.  \\n- **Alert Rule (pseudo-code):**  \\n  ```\\n  WHEN count(Events where EventSource=\\\"sns.amazonaws.com\\\" AND EventName LIKE \\\"Unsubscribe%\\\") \\n  OVER last 5 minutes > 5 \\n  THEN trigger alert \\\"High SNS Unsubscription Rate\\\"\\n  ```\", \" - This pattern captures all Amazon SQS message send events recorded in CloudTrail, identifying when messages are sent to SQS queues by applications or services. It helps SREs monitor the volume and frequency of messages entering the queue, which is critical for understanding application throughput and detecting anomalies in message flow.\\n\\n**Threshold guidance:**  \\n- Set alert thresholds based on baseline message send rates for your application. For example, trigger an alert if the number of Send* events drops below 50% of the normal rate over a 5-minute window, indicating potential upstream issues or message loss.  \\n- Conversely, alert if the send rate spikes above 150% of the baseline, which may signal unexpected load, misbehaving producers, or potential flooding that could overwhelm downstream consumers.\\n\\n**Impact of values:**  \\n- **High send event volume:** May indicate increased application activity or a surge in workload; sustained spikes can lead to queue congestion, increased processing latency, or throttling.  \\n- **Low send event volume:** Could suggest upstream failures, application downtime, or message generation issues, potentially causing downstream starvation and impacting system responsiveness.\\n\\n**Example usage:**  \\nIn a monitoring dashboard, plot the count of **{\\\"EventSource\\\": \\\"sqs.amazonaws.com\\\", \\\"EventName\\\": \\\"Send*\\\"}** events per minute to visualize message inflow trends. Configure an alert rule to notify the SRE team if the send event count deviates by more than \\u00b150% from the established baseline over a rolling 5-minute period, enabling rapid detection and response to abnormal message flow patterns.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": true,
                        "score": 0.9022977372209864,
                        "reason": "The description directly addresses the question about SQS message send volume exceeding 150% of normal rate, clearly explaining what is measured (Send* events), the context (CloudTrail events for SQS sends), threshold guidance (alerts at >150% baseline), and implications (potential flooding or unexpected load). The language is clear and concise, providing actionable alerting and impact details that enable the user to understand and respond to abnormal send rates. Minor deduction is due to the description not explicitly stating units (e.g., per minute) in the threshold guidance, though it is implied in example usage.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Compare the Input (monitoring question) and Retrieval Context (metric description) to ensure the description directly addresses the question's intent.\",\n    \"Evaluate clarity by checking if the description uses concise, understandable language that aligns well with the question posed.\",\n    \"Assess coverage by verifying the description includes what is measured, units, context, and implications relevant to the question.\",\n    \"Determine utility by judging if the description effectively enables the user to answer the monitoring question based on the provided context.\"\n] \n \nRubric:\nNone \n \nScore: 0.9022977372209864"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Compare the Input (monitoring question) and Retrieval Context (metric description) to ensure the description directly addresses the question's intent.",
                            "Evaluate clarity by checking if the description uses concise, understandable language that aligns well with the question posed.",
                            "Assess coverage by verifying the description includes what is measured, units, context, and implications relevant to the question.",
                            "Determine utility by judging if the description effectively enables the user to answer the monitoring question based on the provided context."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"sqs.amazonaws.com\\\", \\\"EventName\\\": \\\"Create*\\\"}\", \"hyperparameters\": null, \"input\": \"Does this sudden spike in new SQS queues being created indicate unexpected automation or potential security issues?\", \"retrieval_context\": [\" - Redshift cluster creation events in CloudTrail capture all API calls initiating the provisioning of new Redshift clusters (e.g., CreateCluster). These events indicate when new data warehouse resources are being deployed or configured, impacting capacity and cost.  \\n**Purpose:** Enables SREs to monitor and audit cluster provisioning activities for operational control and security compliance.  \\n**Alert Threshold:** Trigger alerts on an unusually high number of cluster creation events within a short time window (e.g., >3 creates in 1 hour), which may indicate automation errors, misconfigurations, or unauthorized resource provisioning.  \\n**Impact:**  \\n- **High values:** May lead to resource sprawl, increased costs, and potential performance degradation due to over-provisioning. Could also signal security risks if unexpected clusters are created.  \\n- **Low or zero values:** Normal in stable environments; no new clusters being created means stable infrastructure.  \\n**Example Alert Rule:**  \\n\\u201cAlert if count of events with EventSource='redshift.amazonaws.com' and EventName starting with 'Create' exceeds 3 within 60 minutes.\\u201d  \\n**Dashboard Use:** Visualize the frequency of Redshift cluster creation events over time to detect spikes or anomalies, correlating with deployment activities or security incidents.\", \" - S3 bucket creation events captured by CloudTrail under **{\\\"EventSource\\\": \\\"s3.amazonaws.com\\\", \\\"EventName\\\": \\\"Create*\\\"}** indicate when new buckets or related resources (e.g., bucket policies, access points) are provisioned. These events help SREs monitor infrastructure changes that affect data storage, security posture, and compliance.\\n\\n**Purpose:**  \\nTrack and audit the creation of S3 buckets and associated configurations to ensure proper governance, prevent unauthorized resource sprawl, and maintain compliance with organizational policies.\\n\\n**Alert Threshold:**  \\nTrigger an alert if the number of S3 bucket creation events exceeds a defined threshold within a short time window (e.g., more than 5 bucket creations within 10 minutes), which may indicate automated provisioning errors, misconfigurations, or potential security incidents such as unauthorized resource creation.\\n\\n**Impact of Values:**  \\n- **High frequency:** May signal abnormal activity, such as a compromised credential or runaway automation scripts creating excessive buckets, leading to increased costs, security risks, or compliance violations.  \\n- **Low or zero frequency:** Normal in stable environments; however, sudden spikes should be investigated promptly.\\n\\n**Example Alert Rule:**  \\n\\u201cAlert when count of events with EventSource = 's3.amazonaws.com' and EventName starting with 'Create' exceeds 5 within 10 minutes.\\u201d\\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of S3 Create* events over time, with thresholds marked to highlight unusual spikes, enabling quick identification of abnormal bucket creation activity.\", \" - This pattern captures all CloudFront distribution creation events recorded in CloudTrail, identified by event names starting with \\\"Create\\\" from the CloudFront service. Its purpose is to monitor when new CloudFront distributions are provisioned, including their initial configuration details. Tracking these events helps SREs detect unexpected or unauthorized distribution creations that could impact content delivery, security, or cost.\\n\\n**Alert Threshold:**  \\nTrigger an alert if the number of CloudFront distribution creation events exceeds a defined threshold within a short time window (e.g., more than 3 creations within 1 hour), as this may indicate automation errors, misconfigurations, or potential security incidents.\\n\\n**Impact of Values:**  \\n- **High values:** A spike in creation events could signal rapid environment changes, possible misconfigurations, or unauthorized activity, potentially leading to increased costs or service disruptions.  \\n- **Low or zero values:** Normal operation typically involves infrequent distribution creations; zero or low values indicate stable infrastructure without unexpected provisioning.\\n\\n**Example Alert Rule:**  \\n\\\"Alert when count of events matching {EventSource: 'cloudfront.amazonaws.com', EventName: 'Create*'} exceeds 3 within 1 hour.\\\"\\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of CloudFront distribution creation events over time, enabling quick identification of unusual spikes or trends in distribution provisioning activity.\", \" - This pattern detects AWS CloudTrail events where new Amazon SQS queues are created (EventSource: \\\"sqs.amazonaws.com\\\", EventName starting with \\\"Create\\\"). It helps SREs monitor the provisioning of new queues, including their initial configurations such as visibility timeout and message retention settings. Alert thresholds should be set based on the expected rate of queue creation in your environment\\u2014for example, triggering an alert if more than 5 queues are created within a 10-minute window, which may indicate unexpected automation or potential security issues. A sudden spike in queue creation can impact resource limits and increase costs, while consistently low or zero creation events may suggest underutilization or stalled deployments. Example alert rule:  \\n`WHEN count() OF events WHERE EventSource=\\\"sqs.amazonaws.com\\\" AND EventName LIKE \\\"Create*\\\" OVER last 10 minutes > 5 THEN trigger alert`  \\nThis can be visualized in a dashboard as a time series graph showing the count of SQS queue creation events over time, enabling quick detection of anomalies in queue provisioning activity.\", \" - This pattern detects Secrets Manager creation events in CloudTrail, specifically any API calls starting with \\\"Create\\\" (e.g., CreateSecret). It helps SREs monitor when new secrets, secret versions, or related configurations are added, which could indicate deployment changes or potential security risks.  \\n**Alert threshold:** Trigger an alert if the number of create events exceeds a baseline (e.g., more than 5 creates within 10 minutes), as a sudden spike may signal unauthorized secret creation or misconfiguration. Conversely, zero create events over an extended period in an active environment might indicate issues with deployment pipelines or automation failures.  \\n**Impact:**  \\n- High values: Could indicate potential security breaches, unauthorized secret provisioning, or rapid environment changes requiring immediate investigation.  \\n- Low values: May suggest stalled deployments or automation problems, potentially delaying application updates or secret rotations.  \\n**Example usage:**  \\nIn a dashboard, plot the count of Secrets Manager Create* events over time to visualize spikes. An alert rule could be:  \\n`WHEN count(secretsmanager.amazonaws.com Create* events) > 5 within 10 minutes THEN trigger alert \\\"Unusual Secrets Creation Activity\\\"`  \\nThis enables proactive detection of abnormal secret creation activity, helping maintain security and operational stability.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": true,
                        "score": 0.8962673110514062,
                        "reason": "The description directly addresses the monitoring question about sudden spikes in new SQS queue creation by explaining what is measured (SQS queue creation events), the alert threshold (more than 5 creates within 10 minutes), and the potential implications (unexpected automation or security issues). The language is clear and concise, covering the context, units, and practical impact, and includes an example alert rule and visualization guidance, making it highly useful for answering the question. The only minor shortcoming is a lack of explicit mention of security risks beyond automation and resource impact, but overall it aligns very well with the evaluation criteria.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Compare the Input (monitoring question) and the Retrieval Context (metric description) to ensure the description clearly addresses the question's focus.\",\n    \"Evaluate the clarity of the description in terms of language simplicity and conciseness relevant to the Input question.\",\n    \"Check that the description covers all necessary elements (what is measured, units, context, implications) to fully support the Input question.\",\n    \"Assess the practical utility of the description in helping a user answer the monitoring question, ensuring alignment between Input and Retrieval Context.\"\n] \n \nRubric:\nNone \n \nScore: 0.8962673110514062"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Compare the Input (monitoring question) and the Retrieval Context (metric description) to ensure the description clearly addresses the question's focus.",
                            "Evaluate the clarity of the description in terms of language simplicity and conciseness relevant to the Input question.",
                            "Check that the description covers all necessary elements (what is measured, units, context, implications) to fully support the Input question.",
                            "Assess the practical utility of the description in helping a user answer the monitoring question, ensuring alignment between Input and Retrieval Context."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"rds.amazonaws.com\\\", \\\"EventName\\\": \\\"Start*\\\"}\", \"hyperparameters\": null, \"input\": \"Does the number of RDS start events exceed three within a short time window, indicating potential instability or automation issues?\", \"retrieval_context\": [\" - **{\\\"EventName\\\": \\\"Start*\\\"}** events in CloudTrail indicate the initiation of resource start operations across various AWS services, such as starting EC2 instances, RDS databases, or other managed resources. These events help SREs track when resources transition from a stopped or inactive state to an active state, which is critical for service availability, cost management, and operational recovery.\\n\\n**Purpose:**  \\nTo monitor and audit the activation of cloud resources, ensuring that start operations align with expected usage patterns and do not indicate unauthorized or unexpected activity.\\n\\n**Alert Thresholds:**  \\n- Trigger an alert if the number of **Start*** events exceeds a predefined threshold within a short time window (e.g., more than 10 start operations within 5 minutes), which may indicate an automated scaling event, a potential misconfiguration, or a security incident.  \\n- Conversely, alert if expected start operations do not occur during scheduled maintenance windows, indicating possible failures in recovery or deployment processes.\\n\\n**Impact of Values:**  \\n- **High volume of Start* events:** Could lead to increased costs due to resource activation, potential service disruptions if resources are started unexpectedly, or indicate automated scaling or recovery actions.  \\n- **Low or zero Start* events during expected periods:** May signal failed recovery attempts, stalled deployments, or issues in operational workflows, potentially impacting service availability.\\n\\n**Example Usage:**  \\nIn a CloudWatch dashboard, plot the count of **Start*** events over time to visualize spikes or drops. An alert rule can be configured as:  \\n```\\nIF count(Start* events) > 10 within 5 minutes THEN trigger alert \\\"Unusual spike in resource start operations\\\"\\n```\\nThis enables proactive investigation into unexpected resource activations or failures to start critical services.\", \" - Redshift cluster creation events in CloudTrail capture all API calls initiating the provisioning of new Redshift clusters (e.g., CreateCluster). These events indicate when new data warehouse resources are being deployed or configured, impacting capacity and cost.  \\n**Purpose:** Enables SREs to monitor and audit cluster provisioning activities for operational control and security compliance.  \\n**Alert Threshold:** Trigger alerts on an unusually high number of cluster creation events within a short time window (e.g., >3 creates in 1 hour), which may indicate automation errors, misconfigurations, or unauthorized resource provisioning.  \\n**Impact:**  \\n- **High values:** May lead to resource sprawl, increased costs, and potential performance degradation due to over-provisioning. Could also signal security risks if unexpected clusters are created.  \\n- **Low or zero values:** Normal in stable environments; no new clusters being created means stable infrastructure.  \\n**Example Alert Rule:**  \\n\\u201cAlert if count of events with EventSource='redshift.amazonaws.com' and EventName starting with 'Create' exceeds 3 within 60 minutes.\\u201d  \\n**Dashboard Use:** Visualize the frequency of Redshift cluster creation events over time to detect spikes or anomalies, correlating with deployment activities or security incidents.\", \" - This pattern captures AWS RDS instance start events recorded in CloudTrail, indicating when one or more RDS instances transition from a stopped to a running state. Monitoring these events helps SREs track service availability changes and manage cost implications, as starting instances can increase resource usage and expenses.\\n\\n**Purpose:**  \\n- Detect when RDS instances are started to ensure expected service restoration or identify unexpected restarts.  \\n- Support cost optimization by alerting on frequent or unusual start activity that may indicate inefficient resource usage or automation issues.\\n\\n**Alert Threshold Guidance:**  \\n- Trigger an alert if the number of RDS start events exceeds a defined threshold within a short time window (e.g., more than 3 start events within 10 minutes), which may indicate instability or unintended restarts.  \\n- Alternatively, alert if no start events occur during a scheduled maintenance window when instances are expected to be restarted.\\n\\n**Impact of Values:**  \\n- **High frequency of start events:** Could signal recurring failures, automation loops, or misconfigurations causing service interruptions and increased costs. Immediate investigation is recommended.  \\n- **Low or zero start events:** May indicate stable operation or, if expected, a failure to restore service after downtime, requiring attention.\\n\\n**Example Usage:**  \\n- **Dashboard:** Display a time series graph of RDS start events per hour to visualize trends and detect spikes.  \\n- **Alert Rule:**  \\n  ```\\n  WHEN count(events where EventSource=\\\"rds.amazonaws.com\\\" AND EventName LIKE \\\"Start%\\\") \\n  IN last 10 minutes > 3 \\n  THEN trigger alert \\\"High frequency of RDS instance starts detected\\\"\\n  ```  \\nThis enables proactive monitoring of RDS instance lifecycle events to maintain service reliability and control costs.\", \" - This pattern captures all update-related events from Amazon EKS recorded in CloudTrail, such as cluster version upgrades, managed node group modifications, and add-on updates. Its purpose is to monitor changes that can affect cluster stability, security, or performance. An SRE should set alert thresholds based on the frequency and timing of these update events\\u2014for example, triggering an alert if more than 3 update events occur within a 1-hour window, which may indicate unexpected or automated changes that require investigation. High volumes of update events in a short period could signal potential configuration drift, deployment issues, or unauthorized modifications, increasing risk to cluster availability and security. Conversely, low or no update events over extended periods may suggest stagnation in maintenance or missed critical updates. An example alert rule could be: \\u201cAlert if count of events matching {EventSource: 'eks.amazonaws.com', EventName: 'Update*'} exceeds 3 within 60 minutes.\\u201d In a dashboard, this pattern can be visualized as a time series graph showing update event counts per hour, helping SREs quickly identify unusual spikes or trends in cluster modifications.\", \" - This pattern detects all Amazon RDS database creation events captured in CloudTrail, identified by any event name starting with \\\"Create\\\" from the \\\"rds.amazonaws.com\\\" source. It enables SREs to monitor when new RDS instances or related resources are provisioned, providing visibility into changes that may impact database capacity, cost, or security posture. A typical alert threshold could be set to trigger if more than 3 RDS creation events occur within a 1-hour window, indicating potential unexpected scaling or automation issues. High volumes of creation events may signal rapid infrastructure changes or misconfigurations, increasing operational risk and cost, while low or zero events generally indicate stable database provisioning activity. For example, an alert rule could be configured as:  \\n`WHEN count of events matching {\\\"EventSource\\\": \\\"rds.amazonaws.com\\\", \\\"EventName\\\": \\\"Create*\\\"} > 3 IN 1 hour THEN trigger alert`  \\nThis can be visualized in a dashboard showing the count of RDS creation events over time, helping teams quickly identify unusual spikes in database provisioning activity.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": true,
                        "score": 0.9320821307318384,
                        "reason": "The description directly addresses the monitoring question by focusing on RDS start events and the threshold of more than 3 events within a short time window, indicating instability or automation issues. It clearly explains what is measured (RDS start events), relevant units (count within 10 minutes), operational context (service availability, cost implications), and impact of values (high frequency signals failures or automation loops). The inclusion of alert threshold guidance, impact, and example alert rules enhances clarity and utility, enabling effective monitoring. Minor deduction is due to slight ambiguity in the exact time window definition ('short time window' is exemplified as 10 minutes but not rigidly defined), but overall the description is comprehensive and clear.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Compare the Input (monitoring question) against the Retrieval Context (metric description) to assess if the description clearly addresses the question's intent and specific focus.\",\n    \"Evaluate the description's clarity by checking if the terminology and explanation are understandable without ambiguity relative to the question asked.\",\n    \"Assess coverage by verifying that the description includes what is measured, relevant units, operational context, and implications that help interpret the metric in relation to the question.\",\n    \"Determine utility by judging if the description provides sufficient and relevant information to directly or indirectly answer the user\u2019s monitoring question effectively.\"\n] \n \nRubric:\nNone \n \nScore: 0.9320821307318384"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Compare the Input (monitoring question) against the Retrieval Context (metric description) to assess if the description clearly addresses the question's intent and specific focus.",
                            "Evaluate the description's clarity by checking if the terminology and explanation are understandable without ambiguity relative to the question asked.",
                            "Assess coverage by verifying that the description includes what is measured, relevant units, operational context, and implications that help interpret the metric in relation to the question.",
                            "Determine utility by judging if the description provides sufficient and relevant information to directly or indirectly answer the user\u2019s monitoring question effectively."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"dynamodb.amazonaws.com\\\", \\\"EventName\\\": \\\"Create*\\\"}\", \"hyperparameters\": null, \"input\": \"Are there multiple Create* events in a short period, indicating potential over-creation of DynamoDB tables?\", \"retrieval_context\": [\" - Redshift cluster creation events in CloudTrail capture all API calls initiating the provisioning of new Redshift clusters (e.g., CreateCluster). These events indicate when new data warehouse resources are being deployed or configured, impacting capacity and cost.  \\n**Purpose:** Enables SREs to monitor and audit cluster provisioning activities for operational control and security compliance.  \\n**Alert Threshold:** Trigger alerts on an unusually high number of cluster creation events within a short time window (e.g., >3 creates in 1 hour), which may indicate automation errors, misconfigurations, or unauthorized resource provisioning.  \\n**Impact:**  \\n- **High values:** May lead to resource sprawl, increased costs, and potential performance degradation due to over-provisioning. Could also signal security risks if unexpected clusters are created.  \\n- **Low or zero values:** Normal in stable environments; no new clusters being created means stable infrastructure.  \\n**Example Alert Rule:**  \\n\\u201cAlert if count of events with EventSource='redshift.amazonaws.com' and EventName starting with 'Create' exceeds 3 within 60 minutes.\\u201d  \\n**Dashboard Use:** Visualize the frequency of Redshift cluster creation events over time to detect spikes or anomalies, correlating with deployment activities or security incidents.\", \" - S3 bucket creation events captured by CloudTrail under **{\\\"EventSource\\\": \\\"s3.amazonaws.com\\\", \\\"EventName\\\": \\\"Create*\\\"}** indicate when new buckets or related resources (e.g., bucket policies, access points) are provisioned. These events help SREs monitor infrastructure changes that affect data storage, security posture, and compliance.\\n\\n**Purpose:**  \\nTrack and audit the creation of S3 buckets and associated configurations to ensure proper governance, prevent unauthorized resource sprawl, and maintain compliance with organizational policies.\\n\\n**Alert Threshold:**  \\nTrigger an alert if the number of S3 bucket creation events exceeds a defined threshold within a short time window (e.g., more than 5 bucket creations within 10 minutes), which may indicate automated provisioning errors, misconfigurations, or potential security incidents such as unauthorized resource creation.\\n\\n**Impact of Values:**  \\n- **High frequency:** May signal abnormal activity, such as a compromised credential or runaway automation scripts creating excessive buckets, leading to increased costs, security risks, or compliance violations.  \\n- **Low or zero frequency:** Normal in stable environments; however, sudden spikes should be investigated promptly.\\n\\n**Example Alert Rule:**  \\n\\u201cAlert when count of events with EventSource = 's3.amazonaws.com' and EventName starting with 'Create' exceeds 5 within 10 minutes.\\u201d\\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of S3 Create* events over time, with thresholds marked to highlight unusual spikes, enabling quick identification of abnormal bucket creation activity.\", \" - This pattern captures all CloudFront distribution creation events recorded in CloudTrail, identified by event names starting with \\\"Create\\\" from the CloudFront service. Its purpose is to monitor when new CloudFront distributions are provisioned, including their initial configuration details. Tracking these events helps SREs detect unexpected or unauthorized distribution creations that could impact content delivery, security, or cost.\\n\\n**Alert Threshold:**  \\nTrigger an alert if the number of CloudFront distribution creation events exceeds a defined threshold within a short time window (e.g., more than 3 creations within 1 hour), as this may indicate automation errors, misconfigurations, or potential security incidents.\\n\\n**Impact of Values:**  \\n- **High values:** A spike in creation events could signal rapid environment changes, possible misconfigurations, or unauthorized activity, potentially leading to increased costs or service disruptions.  \\n- **Low or zero values:** Normal operation typically involves infrequent distribution creations; zero or low values indicate stable infrastructure without unexpected provisioning.\\n\\n**Example Alert Rule:**  \\n\\\"Alert when count of events matching {EventSource: 'cloudfront.amazonaws.com', EventName: 'Create*'} exceeds 3 within 1 hour.\\\"\\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of CloudFront distribution creation events over time, enabling quick identification of unusual spikes or trends in distribution provisioning activity.\", \" - This pattern captures all DynamoDB update events recorded in CloudTrail, specifically those where the event name starts with \\\"Update\\\" (e.g., UpdateTable, UpdateGlobalTable). It helps SREs monitor changes to DynamoDB table configurations such as capacity adjustments (read/write throughput), index modifications, and other table settings.\\n\\n**Purpose:**  \\nBy tracking these update events, SREs can detect configuration changes that may impact application performance, availability, or cost. Unexpected or frequent updates could indicate misconfigurations, automation errors, or unauthorized changes.\\n\\n**Alert Thresholds:**  \\n- Trigger an alert if more than 5 update events occur within a 10-minute window, which may suggest excessive or unintended configuration changes.  \\n- Trigger an alert if update events occur outside of scheduled maintenance windows or change management periods.\\n\\n**Impact of Values:**  \\n- **High frequency of updates:** May lead to instability, performance degradation, or increased costs due to rapid scaling or misconfigured indexes.  \\n- **Low or no updates:** Generally indicates stable table configurations, but lack of expected updates during deployments could signal deployment failures.\\n\\n**Example Usage:**  \\n- **Dashboard:** Display a time series graph showing the count of DynamoDB Update* events over time, annotated with deployment windows.  \\n- **Alert Rule:**  \\n  ```\\n  WHEN count(events where EventSource=\\\"dynamodb.amazonaws.com\\\" AND EventName LIKE \\\"Update%\\\") > 5 \\n  WITHIN 10 minutes \\n  AND current_time NOT IN maintenance_window \\n  THEN trigger alert \\\"Excessive DynamoDB table updates detected\\\"\\n  ```\", \" - This pattern detects Secrets Manager creation events in CloudTrail, specifically any API calls starting with \\\"Create\\\" (e.g., CreateSecret). It helps SREs monitor when new secrets, secret versions, or related configurations are added, which could indicate deployment changes or potential security risks.  \\n**Alert threshold:** Trigger an alert if the number of create events exceeds a baseline (e.g., more than 5 creates within 10 minutes), as a sudden spike may signal unauthorized secret creation or misconfiguration. Conversely, zero create events over an extended period in an active environment might indicate issues with deployment pipelines or automation failures.  \\n**Impact:**  \\n- High values: Could indicate potential security breaches, unauthorized secret provisioning, or rapid environment changes requiring immediate investigation.  \\n- Low values: May suggest stalled deployments or automation problems, potentially delaying application updates or secret rotations.  \\n**Example usage:**  \\nIn a dashboard, plot the count of Secrets Manager Create* events over time to visualize spikes. An alert rule could be:  \\n`WHEN count(secretsmanager.amazonaws.com Create* events) > 5 within 10 minutes THEN trigger alert \\\"Unusual Secrets Creation Activity\\\"`  \\nThis enables proactive detection of abnormal secret creation activity, helping maintain security and operational stability.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": false,
                        "score": 0.20795637516895998,
                        "reason": "The retrieval context does not include any description related to DynamoDB Create* events, only Redshift, S3, Secrets Manager creation events, DynamoDB update events, and CloudFront creation events. Therefore, it fails to address the specific monitoring question about multiple DynamoDB Create* events. While the descriptions are clear and detailed for other services, the lack of relevant coverage for DynamoDB table creation severely limits utility and alignment with the question.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Compare the Input (monitoring question) and the Retrieval Context (metric description) to ensure the description addresses the specific question asked.\",\n    \"Evaluate Clarity by checking if the metric description is concise and easy to understand in relation to the question posed.\",\n    \"Assess Coverage by verifying that the description explains what is measured, the units involved, relevant context, and implications that help answer the question.\",\n    \"Judge Utility by determining if the description provides actionable or insightful information that directly supports answering the monitoring question.\"\n] \n \nRubric:\nNone \n \nScore: 0.20795637516895998"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Compare the Input (monitoring question) and the Retrieval Context (metric description) to ensure the description addresses the specific question asked.",
                            "Evaluate Clarity by checking if the metric description is concise and easy to understand in relation to the question posed.",
                            "Assess Coverage by verifying that the description explains what is measured, the units involved, relevant context, and implications that help answer the question.",
                            "Judge Utility by determining if the description provides actionable or insightful information that directly supports answering the monitoring question."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"elasticache.amazonaws.com\\\", \\\"EventName\\\": \\\"Modify*\\\"}\", \"hyperparameters\": null, \"input\": \"Are the Modify* events related to scaling operations that increase or decrease node count by more than 1?\", \"retrieval_context\": [\" - Auto-scaling events triggered to adjust service capacity based on demand. Measures the number of scaling actions performed, including scale-up and scale-down operations. Units are counted as discrete scaling events per service. This metric helps monitor resource allocation efficiency and cost optimization.\", \" - This pattern captures CloudTrail events where ElastiCache clusters are modified, including scaling operations (e.g., changing node count or instance types), parameter group updates, and configuration changes. It helps SREs monitor critical changes that can impact cache performance, availability, or cost.\\n\\n**Purpose:**  \\nDetect when ElastiCache resources are altered to ensure changes are intentional, authorized, and do not degrade system stability.\\n\\n**Alert Threshold:**  \\nTrigger an alert on any **Modify\\\\*** event to catch all configuration changes. For noisy environments, consider alerting only on modifications that increase or decrease node count by more than 1, or changes to parameter groups affecting performance-critical settings.\\n\\n**Impact of Values:**  \\n- **High frequency of Modify events:** May indicate repeated scaling or configuration changes, potentially causing instability or unexpected behavior.  \\n- **Low or zero Modify events:** Suggests stable cache configuration, but lack of changes during scaling needs may indicate missed updates.\\n\\n**Example Alert Rule:**  \\nAlert when an event with `EventSource = \\\"elasticache.amazonaws.com\\\"` and `EventName` matching `Modify*` occurs, optionally filtering for changes in node count or parameter group names. This can be visualized in a dashboard showing a timeline of modification events alongside cluster performance metrics to correlate changes with impact.\", \" - This pattern captures all modification events related to EC2 resources in AWS CloudTrail, triggered by any API calls starting with \\\"Modify\\\" (e.g., ModifyInstanceAttribute, ModifyNetworkInterfaceAttribute). Its purpose is to monitor changes to critical EC2 configurations such as instance attributes, security group rules, and network settings, which can directly impact system security, availability, and performance.\\n\\n**Threshold guidance:**  \\n- Alert when the number of Modify* events exceeds a baseline threshold (e.g., more than 5 modifications within 10 minutes), indicating unusual or potentially unauthorized changes.  \\n- A sudden spike in modification events may signal misconfigurations, automation errors, or security incidents like privilege escalation or lateral movement.\\n\\n**Impact of values:**  \\n- **High frequency:** Could indicate active troubleshooting, automated scaling/configuration changes, or suspicious activity requiring immediate investigation.  \\n- **Low or zero frequency:** Normal steady state; no unexpected modifications detected.\\n\\n**Example alert rule:**  \\nTrigger an alert if the count of events matching {\\\"EventSource\\\": \\\"ec2.amazonaws.com\\\", \\\"EventName\\\": \\\"Modify*\\\"} exceeds 5 within a rolling 10-minute window.\\n\\n**Example dashboard widget:**  \\nA time-series graph showing the count of EC2 Modify* events per 5-minute interval, overlaid with a threshold line at 5 events, enabling quick identification of abnormal modification activity.\", \" - This pattern captures all modification events related to Elastic Load Balancing (ELB) resources in AWS, such as changes to load balancer configurations, target groups, and listeners. In CloudTrail, these events indicate when an ELB\\u2019s setup is altered, which can affect traffic routing, availability, and security posture.\\n\\n**Purpose:**  \\nTo monitor and audit any configuration changes to ELB components that could impact application availability or security.\\n\\n**Alert Threshold:**  \\nTrigger an alert if the number of ELB modification events exceeds a defined threshold within a short time window (e.g., more than 3 Modify* events within 10 minutes), as this may indicate unintended or unauthorized changes.\\n\\n**Impact of Values:**  \\n- **High frequency of Modify* events:** Could signal potential misconfigurations, automated deployment issues, or malicious activity altering load balancer behavior, risking downtime or security breaches.  \\n- **Low or no Modify* events:** Typically expected during stable operation; absence of changes suggests configuration stability.\\n\\n**Example Usage:**  \\nIn a monitoring dashboard or alert rule, track the count of **{\\\"EventSource\\\": \\\"elasticloadbalancing.amazonaws.com\\\", \\\"EventName\\\": \\\"Modify*\\\"}** events over rolling 10-minute intervals. Configure alerts to notify the SRE team when this count spikes above the threshold, enabling prompt investigation and rollback if necessary.\", \" - This pattern matches AWS RDS events where the event name begins with \\\"Modify,\\\" indicating changes to RDS resources. It captures actions such as instance configuration updates, parameter group modifications, and scaling adjustments. Each event represents a discrete modification operation recorded as an individual API call. The measurement unit is the count of these modification events occurring within the monitored timeframe.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": false,
                        "score": 0.7562176500885799,
                        "reason": "The description clearly explains that Modify* events include scaling operations that change node count, and it mentions alerting on modifications increasing or decreasing node count by more than 1, directly addressing the input question. It provides context on measurement units (counts of events) and implications for monitoring. However, it could improve clarity by explicitly stating whether all Modify* events always involve node count changes or only some, and by more directly linking the scaling magnitude criterion to the metric measurement.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Compare the Input (monitoring question) and the Retrieval Context (metric description) to ensure the description clearly addresses the specific question asked.\",\n    \"Evaluate the description's clarity in explaining what is measured, the units used, and the context provided to see if it is understandable and concise relative to the question.\",\n    \"Assess the coverage in the description to verify if it includes all necessary information (measurement, units, context, implications) to answer the monitoring question effectively.\",\n    \"Judge the utility by determining if the description enables a user to resolve the question based on the linkage between the input and the context; if gaps exist, suggest targeted improvements.\"\n] \n \nRubric:\nNone \n \nScore: 0.7562176500885799"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Compare the Input (monitoring question) and the Retrieval Context (metric description) to ensure the description clearly addresses the specific question asked.",
                            "Evaluate the description's clarity in explaining what is measured, the units used, and the context provided to see if it is understandable and concise relative to the question.",
                            "Assess the coverage in the description to verify if it includes all necessary information (measurement, units, context, implications) to answer the monitoring question effectively.",
                            "Judge the utility by determining if the description enables a user to resolve the question based on the linkage between the input and the context; if gaps exist, suggest targeted improvements."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"elasticache.amazonaws.com\\\", \\\"EventName\\\": \\\"Delete*\\\"}\", \"hyperparameters\": null, \"input\": \"Are multiple ElastiCache deletion events occurring within a short period, indicating potential misconfiguration or security incident?\", \"retrieval_context\": [\" - IAM deletion events (e.g., DeleteUser, DeleteRole) recorded by CloudTrail indicate removal of IAM identities or permissions. These events are critical for detecting unauthorized or accidental deletions that can disrupt access or signal a security breach. An alert threshold should be set to trigger on any unexpected deletion event or a sudden spike above normal baseline activity (e.g., more than 1 deletion event within 5 minutes), as even a single deletion can have significant impact. High volumes may indicate automated attacks or misconfigurations causing mass access removal, while low or zero values typically indicate normal operation.  \\nExample alert rule: trigger when count of iam.amazonaws.com Delete* events > 1 in 5 minutes.  \\nExample dashboard widget: a time series graph showing Delete* event counts over time, annotated with alert thresholds to quickly identify unusual deletion activity.\", \" - This pattern captures Secrets Manager deletion events. It identifies when secrets are removed, which can indicate cleanup operations or potential credential loss incidents.\", \" - This pattern captures all EC2 resource deletion events recorded in CloudTrail, triggered by any API calls starting with \\\"Delete\\\" from the EC2 service (e.g., DeleteSecurityGroup, DeleteNetworkInterface). Its purpose is to monitor and alert on the removal of critical EC2 components, which can impact infrastructure stability and security.\\n\\n**Threshold guidance:**  \\n- Set an alert if the number of deletion events exceeds a baseline threshold within a short time window (e.g., more than 5 deletions in 10 minutes), as this may indicate accidental mass deletions or malicious activity.  \\n- A low or zero count is typical during normal operations, while sudden spikes warrant immediate investigation.\\n\\n**Impact:**  \\n- High deletion event counts can lead to service disruptions, loss of network connectivity, or security vulnerabilities if key resources like security groups or network interfaces are removed unexpectedly.  \\n- Low or no deletion activity generally indicates stable infrastructure management.\\n\\n**Example alert rule:**  \\nTrigger an alert when the count of events matching {\\\"EventSource\\\": \\\"ec2.amazonaws.com\\\", \\\"EventName\\\": \\\"Delete*\\\"} exceeds 5 within 10 minutes.\\n\\n**Example dashboard usage:**  \\nVisualize the count of EC2 deletion events over time to identify unusual spikes, correlating with other operational metrics to assess potential impact on system availability or security posture.\", \" - This pattern captures all ElastiCache deletion events recorded in CloudTrail, specifically any API calls starting with \\\"Delete\\\" (e.g., DeleteCacheCluster, DeleteReplicationGroup). Its primary purpose is to monitor when ElastiCache resources are removed, which can signal intentional cleanup or unintended cache loss that may impact application performance or availability.\\n\\n**Alert Threshold:**  \\nTrigger an alert if more than 1 deletion event occurs within a 5-minute window, as multiple deletions in a short period may indicate a misconfiguration, automation error, or potential security incident.\\n\\n**Impact:**  \\n- **High frequency:** Multiple deletions can lead to significant cache data loss, increased latency due to cache warm-up, or service disruption. Immediate investigation is required.  \\n- **Low frequency (single event):** Usually expected during planned maintenance or scaling down, but should still be reviewed to confirm authorization.\\n\\n**Example Alert Rule:**  \\n- **Condition:** Count of events matching {\\\"EventSource\\\": \\\"elasticache.amazonaws.com\\\", \\\"EventName\\\": \\\"Delete*\\\"} > 1 in 5 minutes  \\n- **Action:** Send notification to SRE team and trigger incident response workflow.\\n\\n**Dashboard Use Case:**  \\nVisualize the count of ElastiCache deletion events over time to quickly identify spikes or unusual patterns, correlating with deployment or incident timelines for root cause analysis.\", \" - This pattern captures all deletion events related to Elastic Load Balancers (ELBs) in AWS, as recorded by CloudTrail under the event source \\\"elasticloadbalancing.amazonaws.com\\\" with event names starting with \\\"Delete\\\". Its primary purpose is to monitor when ELBs are removed, which can be part of routine cleanup or indicate unintended service disruptions due to the loss of load balancing resources.\\n\\n**Purpose:**  \\nSREs use this pattern to track ELB deletions to quickly detect and investigate potential impacts on application availability and traffic routing.\\n\\n**Alert Threshold:**  \\nAn alert should be triggered if the number of ELB deletion events exceeds a predefined threshold within a short time window\\u2014for example, more than 1 deletion event within 5 minutes\\u2014since multiple deletions in quick succession may indicate a misconfiguration, automation error, or malicious activity.\\n\\n**Impact of Values:**  \\n- **High values:** Frequent or bulk ELB deletions can cause significant service disruption, leading to downtime or degraded performance due to loss of traffic distribution. Immediate investigation and remediation are required.  \\n- **Low values:** Occasional single deletions may be expected during normal maintenance or scaling operations and typically do not require urgent action but should still be logged for audit purposes.\\n\\n**Example Usage:**  \\nIn a monitoring dashboard or alert rule, you might configure a query to count ELB deletion events over a rolling 5-minute window and trigger an alert if the count exceeds 1. For example:\\n\\n```\\ncount_over_time({EventSource=\\\"elasticloadbalancing.amazonaws.com\\\", EventName=~\\\"Delete.*\\\"}[5m]) > 1\\n```\\n\\nThis alert helps ensure that unexpected or excessive ELB deletions are promptly detected and addressed to maintain service reliability.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": true,
                        "score": 0.9,
                        "reason": "The Retrieval Context is well aligned with the Input, specifically addressing ElastiCache deletion events and their monitoring. It clearly explains what is measured (ElastiCache deletion API calls), the alert threshold (more than 1 deletion in 5 minutes), and the implications (potential misconfiguration or security incident). The description is concise, understandable, and provides actionable guidance including alert rules and dashboard use cases, directly aiding in answering the monitoring question. The only minor shortcoming is the lack of explicit units for the time window beyond the textual mention, but overall coverage and utility are strong.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Evaluate if the Input (monitoring question) and Retrieval Context (metric description) are clearly aligned, ensuring the description addresses the user's specific query.\",\n    \"Assess the Clarity of the Retrieval Context in light of the Input, verifying the description is concise and understandable to effectively inform the question.\",\n    \"Check Coverage by confirming the description includes what is measured, units, relevant context, and implications necessary to answer the Input accurately.\",\n    \"Determine Utility by evaluating whether the Retrieval Context provides actionable information that directly aids in resolving the Input\u2019s monitoring question.\"\n] \n \nRubric:\nNone \n \nScore: 0.9"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Evaluate if the Input (monitoring question) and Retrieval Context (metric description) are clearly aligned, ensuring the description addresses the user's specific query.",
                            "Assess the Clarity of the Retrieval Context in light of the Input, verifying the description is concise and understandable to effectively inform the question.",
                            "Check Coverage by confirming the description includes what is measured, units, relevant context, and implications necessary to answer the Input accurately.",
                            "Determine Utility by evaluating whether the Retrieval Context provides actionable information that directly aids in resolving the Input\u2019s monitoring question."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"elasticloadbalancing.amazonaws.com\\\", \\\"EventName\\\": \\\"Create*\\\"}\", \"hyperparameters\": null, \"input\": \"Are there spikes in Create* events indicating a sudden increase in load balancer provisioning?\", \"retrieval_context\": [\" - CloudFormation stack creation events (**EventSource: cloudformation.amazonaws.com**, **EventName: Create\\\\*** ) represent API calls initiating the provisioning of AWS infrastructure and resources via CloudFormation templates. These events in CloudTrail help SREs monitor the start of environment setups and infrastructure deployments as part of Infrastructure as Code workflows.\\n\\n**Purpose:** Track and audit when new CloudFormation stacks or stack components are being created, enabling visibility into changes in infrastructure state and deployment activities.\\n\\n**Alert Thresholds:**  \\n- Trigger an alert if the number of Create* events exceeds a baseline threshold within a short time window (e.g., >10 stack creation attempts in 5 minutes), which may indicate automated deployment loops, misconfigurations, or potential security incidents.  \\n- Alert if Create* events spike unexpectedly outside of scheduled deployment windows or change management periods.\\n\\n**Impact of Values:**  \\n- **High volume:** May signal rapid infrastructure changes that could lead to instability, resource contention, or deployment failures. It could also indicate unauthorized or accidental mass provisioning.  \\n- **Low or zero volume:** Normal during steady-state operations; however, a sudden drop during expected deployment windows might indicate pipeline failures or blocked deployments.\\n\\n**Example Usage:**  \\n- **Dashboard:** Visualize the count of CloudFormation Create* events over time, segmented by stack name or user identity, to correlate deployments with system performance or incidents.  \\n- **Alert Rule:**  \\n  ```  \\n  WHEN count(events where EventSource=\\\"cloudformation.amazonaws.com\\\" AND EventName LIKE \\\"Create%\\\") > 10 within 5 minutes  \\n  THEN trigger alert \\\"High rate of CloudFormation stack creation events detected\\\"  \\n  ```  \\nThis enables proactive detection of abnormal infrastructure provisioning activity and supports rapid investigation and response.\", \" - Redshift cluster creation events in CloudTrail capture all API calls initiating the provisioning of new Redshift clusters (e.g., CreateCluster). These events indicate when new data warehouse resources are being deployed or configured, impacting capacity and cost.  \\n**Purpose:** Enables SREs to monitor and audit cluster provisioning activities for operational control and security compliance.  \\n**Alert Threshold:** Trigger alerts on an unusually high number of cluster creation events within a short time window (e.g., >3 creates in 1 hour), which may indicate automation errors, misconfigurations, or unauthorized resource provisioning.  \\n**Impact:**  \\n- **High values:** May lead to resource sprawl, increased costs, and potential performance degradation due to over-provisioning. Could also signal security risks if unexpected clusters are created.  \\n- **Low or zero values:** Normal in stable environments; no new clusters being created means stable infrastructure.  \\n**Example Alert Rule:**  \\n\\u201cAlert if count of events with EventSource='redshift.amazonaws.com' and EventName starting with 'Create' exceeds 3 within 60 minutes.\\u201d  \\n**Dashboard Use:** Visualize the frequency of Redshift cluster creation events over time to detect spikes or anomalies, correlating with deployment activities or security incidents.\", \" - S3 bucket creation events captured by CloudTrail under **{\\\"EventSource\\\": \\\"s3.amazonaws.com\\\", \\\"EventName\\\": \\\"Create*\\\"}** indicate when new buckets or related resources (e.g., bucket policies, access points) are provisioned. These events help SREs monitor infrastructure changes that affect data storage, security posture, and compliance.\\n\\n**Purpose:**  \\nTrack and audit the creation of S3 buckets and associated configurations to ensure proper governance, prevent unauthorized resource sprawl, and maintain compliance with organizational policies.\\n\\n**Alert Threshold:**  \\nTrigger an alert if the number of S3 bucket creation events exceeds a defined threshold within a short time window (e.g., more than 5 bucket creations within 10 minutes), which may indicate automated provisioning errors, misconfigurations, or potential security incidents such as unauthorized resource creation.\\n\\n**Impact of Values:**  \\n- **High frequency:** May signal abnormal activity, such as a compromised credential or runaway automation scripts creating excessive buckets, leading to increased costs, security risks, or compliance violations.  \\n- **Low or zero frequency:** Normal in stable environments; however, sudden spikes should be investigated promptly.\\n\\n**Example Alert Rule:**  \\n\\u201cAlert when count of events with EventSource = 's3.amazonaws.com' and EventName starting with 'Create' exceeds 5 within 10 minutes.\\u201d\\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of S3 Create* events over time, with thresholds marked to highlight unusual spikes, enabling quick identification of abnormal bucket creation activity.\", \" - This pattern captures all CloudFront distribution creation events recorded in CloudTrail, identified by event names starting with \\\"Create\\\" from the CloudFront service. Its purpose is to monitor when new CloudFront distributions are provisioned, including their initial configuration details. Tracking these events helps SREs detect unexpected or unauthorized distribution creations that could impact content delivery, security, or cost.\\n\\n**Alert Threshold:**  \\nTrigger an alert if the number of CloudFront distribution creation events exceeds a defined threshold within a short time window (e.g., more than 3 creations within 1 hour), as this may indicate automation errors, misconfigurations, or potential security incidents.\\n\\n**Impact of Values:**  \\n- **High values:** A spike in creation events could signal rapid environment changes, possible misconfigurations, or unauthorized activity, potentially leading to increased costs or service disruptions.  \\n- **Low or zero values:** Normal operation typically involves infrequent distribution creations; zero or low values indicate stable infrastructure without unexpected provisioning.\\n\\n**Example Alert Rule:**  \\n\\\"Alert when count of events matching {EventSource: 'cloudfront.amazonaws.com', EventName: 'Create*'} exceeds 3 within 1 hour.\\\"\\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of CloudFront distribution creation events over time, enabling quick identification of unusual spikes or trends in distribution provisioning activity.\", \" - This pattern detects CloudTrail events where CloudWatch resources are created, such as alarms, dashboards, and log groups. Its purpose is to monitor the provisioning of new CloudWatch components, which can indicate changes in monitoring coverage or potential configuration drift. An alert should be triggered when the number of creation events exceeds a defined threshold within a short time window (e.g., more than 5 Create* events in 10 minutes), as a sudden spike may signal automated deployments, misconfigurations, or unauthorized activity. Conversely, a prolonged absence of creation events might suggest stagnation in monitoring updates or missed deployments. For example, in a monitoring dashboard, you can visualize the count of CloudWatch Create* events over time and set an alert rule to notify the SRE team if the event count surpasses the threshold, enabling timely investigation and response to unexpected changes in monitoring infrastructure.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": false,
                        "score": 0.002812725480965094,
                        "reason": "No response was provided to evaluate against the input and retrieval context, so alignment with the evaluation steps cannot be assessed.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Compare the Input's metric description with the Retrieval Context to ensure that the description addresses the specific monitoring question directly.\",\n    \"Evaluate Clarity by checking if the description uses concise language and avoids ambiguity, considering the terminology used in both Input and Retrieval Context.\",\n    \"Assess Coverage by verifying that the description explains what is measured, units, relevant operational context, and implications relevant to the monitoring question in the Retrieval Context.\",\n    \"Determine Utility by judging if the description sufficiently enables a user to answer the monitoring question based on information from both the Input and the Retrieval Context.\"\n] \n \nRubric:\nNone \n \nScore: 0.002812725480965094"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Compare the Input's metric description with the Retrieval Context to ensure that the description addresses the specific monitoring question directly.",
                            "Evaluate Clarity by checking if the description uses concise language and avoids ambiguity, considering the terminology used in both Input and Retrieval Context.",
                            "Assess Coverage by verifying that the description explains what is measured, units, relevant operational context, and implications relevant to the monitoring question in the Retrieval Context.",
                            "Determine Utility by judging if the description sufficiently enables a user to answer the monitoring question based on information from both the Input and the Retrieval Context."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"elasticache.amazonaws.com\\\", \\\"EventName\\\": \\\"Create*\\\"}\", \"hyperparameters\": null, \"input\": \"Are there any Create* events in the ElastiCache API that indicate a large number of new resources being created?\", \"retrieval_context\": [\" - Redshift cluster creation events in CloudTrail capture all API calls initiating the provisioning of new Redshift clusters (e.g., CreateCluster). These events indicate when new data warehouse resources are being deployed or configured, impacting capacity and cost.  \\n**Purpose:** Enables SREs to monitor and audit cluster provisioning activities for operational control and security compliance.  \\n**Alert Threshold:** Trigger alerts on an unusually high number of cluster creation events within a short time window (e.g., >3 creates in 1 hour), which may indicate automation errors, misconfigurations, or unauthorized resource provisioning.  \\n**Impact:**  \\n- **High values:** May lead to resource sprawl, increased costs, and potential performance degradation due to over-provisioning. Could also signal security risks if unexpected clusters are created.  \\n- **Low or zero values:** Normal in stable environments; no new clusters being created means stable infrastructure.  \\n**Example Alert Rule:**  \\n\\u201cAlert if count of events with EventSource='redshift.amazonaws.com' and EventName starting with 'Create' exceeds 3 within 60 minutes.\\u201d  \\n**Dashboard Use:** Visualize the frequency of Redshift cluster creation events over time to detect spikes or anomalies, correlating with deployment activities or security incidents.\", \" - S3 bucket creation events captured by CloudTrail under **{\\\"EventSource\\\": \\\"s3.amazonaws.com\\\", \\\"EventName\\\": \\\"Create*\\\"}** indicate when new buckets or related resources (e.g., bucket policies, access points) are provisioned. These events help SREs monitor infrastructure changes that affect data storage, security posture, and compliance.\\n\\n**Purpose:**  \\nTrack and audit the creation of S3 buckets and associated configurations to ensure proper governance, prevent unauthorized resource sprawl, and maintain compliance with organizational policies.\\n\\n**Alert Threshold:**  \\nTrigger an alert if the number of S3 bucket creation events exceeds a defined threshold within a short time window (e.g., more than 5 bucket creations within 10 minutes), which may indicate automated provisioning errors, misconfigurations, or potential security incidents such as unauthorized resource creation.\\n\\n**Impact of Values:**  \\n- **High frequency:** May signal abnormal activity, such as a compromised credential or runaway automation scripts creating excessive buckets, leading to increased costs, security risks, or compliance violations.  \\n- **Low or zero frequency:** Normal in stable environments; however, sudden spikes should be investigated promptly.\\n\\n**Example Alert Rule:**  \\n\\u201cAlert when count of events with EventSource = 's3.amazonaws.com' and EventName starting with 'Create' exceeds 5 within 10 minutes.\\u201d\\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of S3 Create* events over time, with thresholds marked to highlight unusual spikes, enabling quick identification of abnormal bucket creation activity.\", \" - This pattern captures all ElastiCache deletion events recorded in CloudTrail, specifically any API calls starting with \\\"Delete\\\" (e.g., DeleteCacheCluster, DeleteReplicationGroup). Its primary purpose is to monitor when ElastiCache resources are removed, which can signal intentional cleanup or unintended cache loss that may impact application performance or availability.\\n\\n**Alert Threshold:**  \\nTrigger an alert if more than 1 deletion event occurs within a 5-minute window, as multiple deletions in a short period may indicate a misconfiguration, automation error, or potential security incident.\\n\\n**Impact:**  \\n- **High frequency:** Multiple deletions can lead to significant cache data loss, increased latency due to cache warm-up, or service disruption. Immediate investigation is required.  \\n- **Low frequency (single event):** Usually expected during planned maintenance or scaling down, but should still be reviewed to confirm authorization.\\n\\n**Example Alert Rule:**  \\n- **Condition:** Count of events matching {\\\"EventSource\\\": \\\"elasticache.amazonaws.com\\\", \\\"EventName\\\": \\\"Delete*\\\"} > 1 in 5 minutes  \\n- **Action:** Send notification to SRE team and trigger incident response workflow.\\n\\n**Dashboard Use Case:**  \\nVisualize the count of ElastiCache deletion events over time to quickly identify spikes or unusual patterns, correlating with deployment or incident timelines for root cause analysis.\", \" - This pattern matches AWS Elastic Load Balancing API calls that create resources, such as load balancers and related components. It captures events where new load balancers or their configurations are initiated. The data measured is the occurrence of creation events, counted as discrete API calls. This helps track when and how often load balancing resources are provisioned.\", \" - This pattern matches all AWS ElastiCache API events where a resource creation action is initiated, indicated by event names starting with \\\"Create\\\". It captures detailed records of new ElastiCache resource creations, such as clusters, snapshots, or parameter groups. The data includes configuration parameters and initial settings specified during creation. Events are measured as discrete API calls logged by AWS CloudTrail.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": true,
                        "score": 0.9,
                        "reason": "The retrieval context clearly addresses the input question by describing ElastiCache Create* events, specifying that these events capture new resource creations such as clusters, snapshots, or parameter groups. It includes details on the nature of the data (discrete API calls logged by CloudTrail) and the types of resources involved, enabling users to understand and monitor creation activity. However, it lacks explicit mention of alert thresholds or implications of high creation event volumes, which would enhance utility and completeness.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Compare the Input (monitoring question) with the Retrieval Context (metric description) to ensure the description addresses the specific query clearly and concisely.\",\n    \"Evaluate if the Retrieval Context fully covers what is measured, including units, contextual background, and potential implications relevant to the Input question.\",\n    \"Assess whether the clarity of the description enables a user to understand and effectively use the information to answer the Input question.\",\n    \"If any aspect (clarity, coverage, utility) related to the Input and Retrieval Context alignment scores below 8, suggest improvements focused on enhancing relevance, detail, or simplicity.\"\n] \n \nRubric:\nNone \n \nScore: 0.9"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Compare the Input (monitoring question) with the Retrieval Context (metric description) to ensure the description addresses the specific query clearly and concisely.",
                            "Evaluate if the Retrieval Context fully covers what is measured, including units, contextual background, and potential implications relevant to the Input question.",
                            "Assess whether the clarity of the description enables a user to understand and effectively use the information to answer the Input question.",
                            "If any aspect (clarity, coverage, utility) related to the Input and Retrieval Context alignment scores below 8, suggest improvements focused on enhancing relevance, detail, or simplicity."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"elasticloadbalancing.amazonaws.com\\\", \\\"EventName\\\": \\\"Register*\\\"}\", \"hyperparameters\": null, \"input\": \"Are there multiple Register* events occurring in rapid succession, indicating potential load balancer instability?\", \"retrieval_context\": [\" - This pattern captures Elastic Load Balancing (ELB) target deregistration events from CloudTrail, indicating when backend targets (such as EC2 instances or IP addresses) are removed from a load balancer. These events typically occur during scaling operations, deployments, or maintenance activities that affect service availability.\\n\\n**Purpose:**  \\nMonitoring deregistration events helps SREs track changes in load balancer target groups, ensuring that scaling or maintenance actions do not inadvertently reduce capacity or cause service disruptions.\\n\\n**Alert Threshold Guidance:**  \\n- Trigger an alert if the number of deregistration events exceeds a defined threshold within a short time window (e.g., more than 5 deregistrations within 5 minutes), which may indicate unexpected or excessive target removals.  \\n- Conversely, a prolonged absence of deregistration events during expected scaling periods might signal issues with autoscaling or deployment processes.\\n\\n**Impact of Values:**  \\n- **High deregistration rate:** Could lead to reduced backend capacity, increased latency, or service outages if targets are removed too quickly or unexpectedly. Immediate investigation is warranted.  \\n- **Low or no deregistration events:** May indicate stable operations or, if scaling is expected, potential failures in scaling mechanisms.\\n\\n**Example Alert Rule:**  \\n```\\nWHEN count of events WHERE EventSource = \\\"elasticloadbalancing.amazonaws.com\\\" AND EventName LIKE \\\"Deregister%\\\"  \\nIN last 5 minutes > 5  \\nTHEN trigger alert \\\"High ELB Target Deregistration Rate\\\"\\n```\\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of deregistration events per minute, overlaid with thresholds, to visualize spikes or drops in deregistration activity aligned with deployment or scaling events.\", \" - This pattern captures SNS unsubscription events recorded in CloudTrail, indicating when endpoints or subscribers are removed from SNS topics. For an SRE, monitoring these events helps track changes in notification delivery and detect potential disruptions or configuration changes.\\n\\n**Purpose:**  \\n- Identify when subscribers unsubscribe from SNS topics, which may reflect endpoint decommissioning, application changes, or user-initiated opt-outs.  \\n- Detect unusual spikes that could indicate mass unsubscriptions due to misconfigurations, security incidents, or service issues.\\n\\n**Alert Threshold:**  \\n- Trigger an alert if the number of Unsubscribe events exceeds a baseline threshold (e.g., more than 5 unsubscriptions within 5 minutes) or shows a sudden increase compared to historical averages. Thresholds should be tuned based on normal subscription churn rates.\\n\\n**Impact:**  \\n- **High values:** May signal widespread endpoint removals causing notification delivery failures, potential service degradation, or security concerns (e.g., unauthorized unsubscriptions). Immediate investigation is warranted.  \\n- **Low or zero values:** Typically expected during stable operations; a sudden drop to zero after a period of regular unsubscriptions might indicate logging issues or CloudTrail misconfigurations.\\n\\n**Example Usage:**  \\n- **Dashboard:** Display a time series graph of Unsubscribe event counts per minute to visualize trends and detect anomalies.  \\n- **Alert Rule (pseudo-code):**  \\n  ```\\n  WHEN count(Events where EventSource=\\\"sns.amazonaws.com\\\" AND EventName LIKE \\\"Unsubscribe%\\\") \\n  OVER last 5 minutes > 5 \\n  THEN trigger alert \\\"High SNS Unsubscription Rate\\\"\\n  ```\", \" - This pattern captures all Route 53 deletion events recorded in CloudTrail, such as deleting hosted zones, record sets, or health checks. It helps SREs monitor when DNS configurations are removed, which could be part of routine cleanup or signal accidental or malicious disruptions to DNS resolution.\\n\\n**Purpose:**  \\nTrack and alert on Route 53 resource deletions to quickly detect potential service impact caused by DNS changes.\\n\\n**Alert Threshold:**  \\nTrigger an alert if more than 3 deletion events occur within a 10-minute window, as multiple deletions in a short period may indicate an ongoing incident or misconfiguration.\\n\\n**Impact:**  \\n- **High volume:** May cause widespread DNS outages or service disruptions, requiring immediate investigation.  \\n- **Low volume (single event):** Could be routine maintenance but should still be reviewed to confirm legitimacy.\\n\\n**Example Alert Rule:**  \\n\\u201cAlert when count of events matching {EventSource: route53.amazonaws.com, EventName: Delete*} exceeds 3 within 10 minutes.\\u201d\\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of Route 53 deletion events over time, with a threshold line at 3 events per 10 minutes to highlight potential issues.\", \" - This pattern captures all deletion events related to Elastic Load Balancers (ELBs) in AWS, as recorded by CloudTrail under the event source \\\"elasticloadbalancing.amazonaws.com\\\" with event names starting with \\\"Delete\\\". Its primary purpose is to monitor when ELBs are removed, which can be part of routine cleanup or indicate unintended service disruptions due to the loss of load balancing resources.\\n\\n**Purpose:**  \\nSREs use this pattern to track ELB deletions to quickly detect and investigate potential impacts on application availability and traffic routing.\\n\\n**Alert Threshold:**  \\nAn alert should be triggered if the number of ELB deletion events exceeds a predefined threshold within a short time window\\u2014for example, more than 1 deletion event within 5 minutes\\u2014since multiple deletions in quick succession may indicate a misconfiguration, automation error, or malicious activity.\\n\\n**Impact of Values:**  \\n- **High values:** Frequent or bulk ELB deletions can cause significant service disruption, leading to downtime or degraded performance due to loss of traffic distribution. Immediate investigation and remediation are required.  \\n- **Low values:** Occasional single deletions may be expected during normal maintenance or scaling operations and typically do not require urgent action but should still be logged for audit purposes.\\n\\n**Example Usage:**  \\nIn a monitoring dashboard or alert rule, you might configure a query to count ELB deletion events over a rolling 5-minute window and trigger an alert if the count exceeds 1. For example:\\n\\n```\\ncount_over_time({EventSource=\\\"elasticloadbalancing.amazonaws.com\\\", EventName=~\\\"Delete.*\\\"}[5m]) > 1\\n```\\n\\nThis alert helps ensure that unexpected or excessive ELB deletions are promptly detected and addressed to maintain service reliability.\", \" - This pattern captures all modification events related to Elastic Load Balancing (ELB) resources in AWS, such as changes to load balancer configurations, target groups, and listeners. In CloudTrail, these events indicate when an ELB\\u2019s setup is altered, which can affect traffic routing, availability, and security posture.\\n\\n**Purpose:**  \\nTo monitor and audit any configuration changes to ELB components that could impact application availability or security.\\n\\n**Alert Threshold:**  \\nTrigger an alert if the number of ELB modification events exceeds a defined threshold within a short time window (e.g., more than 3 Modify* events within 10 minutes), as this may indicate unintended or unauthorized changes.\\n\\n**Impact of Values:**  \\n- **High frequency of Modify* events:** Could signal potential misconfigurations, automated deployment issues, or malicious activity altering load balancer behavior, risking downtime or security breaches.  \\n- **Low or no Modify* events:** Typically expected during stable operation; absence of changes suggests configuration stability.\\n\\n**Example Usage:**  \\nIn a monitoring dashboard or alert rule, track the count of **{\\\"EventSource\\\": \\\"elasticloadbalancing.amazonaws.com\\\", \\\"EventName\\\": \\\"Modify*\\\"}** events over rolling 10-minute intervals. Configure alerts to notify the SRE team when this count spikes above the threshold, enabling prompt investigation and rollback if necessary.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": true,
                        "score": 0.8310577292713972,
                        "reason": "The retrieval context directly addresses the monitoring question by describing deregistration events from ELB targets, their typical causes, and how multiple events in a short time frame can indicate instability. The description uses clear and precise language, is concise, and includes what is measured (deregistration events), units (counts within time windows), relevant context (scaling, deployments), and implications (service disruptions). However, it could improve utility slightly by explicitly linking 'Register*' events to the deregistration pattern or clarifying if 'Register*' events are also monitored, as the input asks about multiple 'Register*' events, while the context focuses on 'Deregister*' events.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Compare the Input (monitoring question) against the Retrieval Context (metric description) to ensure the description addresses the question directly.\",\n    \"Evaluate Clarity by assessing if the description uses simple, precise language and is concise enough for quick understanding.\",\n    \"Assess Coverage to confirm the description includes what is measured, units, relevant context, and possible implications or outcomes.\",\n    \"Determine Utility by considering whether the description provides sufficient information to effectively answer the monitoring question.\"\n] \n \nRubric:\nNone \n \nScore: 0.8310577292713972"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Compare the Input (monitoring question) against the Retrieval Context (metric description) to ensure the description addresses the question directly.",
                            "Evaluate Clarity by assessing if the description uses simple, precise language and is concise enough for quick understanding.",
                            "Assess Coverage to confirm the description includes what is measured, units, relevant context, and possible implications or outcomes.",
                            "Determine Utility by considering whether the description provides sufficient information to effectively answer the monitoring question."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"elasticloadbalancing.amazonaws.com\\\", \\\"EventName\\\": \\\"Modify*\\\"}\", \"hyperparameters\": null, \"input\": \"Does a high frequency of Modify* events indicate potential misconfigurations or malicious activity altering load balancer behavior?\", \"retrieval_context\": [\" - This pattern captures CloudTrail events where ElastiCache clusters are modified, including scaling operations (e.g., changing node count or instance types), parameter group updates, and configuration changes. It helps SREs monitor critical changes that can impact cache performance, availability, or cost.\\n\\n**Purpose:**  \\nDetect when ElastiCache resources are altered to ensure changes are intentional, authorized, and do not degrade system stability.\\n\\n**Alert Threshold:**  \\nTrigger an alert on any **Modify\\\\*** event to catch all configuration changes. For noisy environments, consider alerting only on modifications that increase or decrease node count by more than 1, or changes to parameter groups affecting performance-critical settings.\\n\\n**Impact of Values:**  \\n- **High frequency of Modify events:** May indicate repeated scaling or configuration changes, potentially causing instability or unexpected behavior.  \\n- **Low or zero Modify events:** Suggests stable cache configuration, but lack of changes during scaling needs may indicate missed updates.\\n\\n**Example Alert Rule:**  \\nAlert when an event with `EventSource = \\\"elasticache.amazonaws.com\\\"` and `EventName` matching `Modify*` occurs, optionally filtering for changes in node count or parameter group names. This can be visualized in a dashboard showing a timeline of modification events alongside cluster performance metrics to correlate changes with impact.\", \" - This pattern captures all ECS update events recorded in CloudTrail, such as modifications to ECS services, task definitions, and cluster configurations. Its purpose is to monitor changes that could affect the stability, performance, or security of ECS workloads. An SRE should use this pattern to detect unexpected or frequent updates that may indicate configuration drift, deployment issues, or unauthorized changes.\\n\\n**Threshold guidance:**  \\n- Trigger an alert if the number of ECS update events exceeds a baseline threshold (e.g., more than 5 updates within 10 minutes), as this may signal rapid or unintended changes.  \\n- A low or zero count over a long period is typically normal but should be reviewed if updates are expected during deployments.\\n\\n**Impact:**  \\n- High frequency of update events can lead to service instability, deployment failures, or security risks if changes are unplanned or unauthorized.  \\n- Low frequency indicates stable ECS configurations but may also suggest stalled deployments or lack of necessary updates.\\n\\n**Example alert rule:**  \\n\\u201cAlert when the count of CloudTrail events with EventSource = 'ecs.amazonaws.com' and EventName starting with 'Update' exceeds 5 within a 10-minute window.\\u201d  \\n\\n**Example dashboard widget:**  \\nA time-series graph showing the count of ECS update events per 5-minute interval, annotated with deployment windows to correlate updates with expected changes.\", \" - This pattern captures all deletion events related to Elastic Load Balancers (ELBs) in AWS, as recorded by CloudTrail under the event source \\\"elasticloadbalancing.amazonaws.com\\\" with event names starting with \\\"Delete\\\". Its primary purpose is to monitor when ELBs are removed, which can be part of routine cleanup or indicate unintended service disruptions due to the loss of load balancing resources.\\n\\n**Purpose:**  \\nSREs use this pattern to track ELB deletions to quickly detect and investigate potential impacts on application availability and traffic routing.\\n\\n**Alert Threshold:**  \\nAn alert should be triggered if the number of ELB deletion events exceeds a predefined threshold within a short time window\\u2014for example, more than 1 deletion event within 5 minutes\\u2014since multiple deletions in quick succession may indicate a misconfiguration, automation error, or malicious activity.\\n\\n**Impact of Values:**  \\n- **High values:** Frequent or bulk ELB deletions can cause significant service disruption, leading to downtime or degraded performance due to loss of traffic distribution. Immediate investigation and remediation are required.  \\n- **Low values:** Occasional single deletions may be expected during normal maintenance or scaling operations and typically do not require urgent action but should still be logged for audit purposes.\\n\\n**Example Usage:**  \\nIn a monitoring dashboard or alert rule, you might configure a query to count ELB deletion events over a rolling 5-minute window and trigger an alert if the count exceeds 1. For example:\\n\\n```\\ncount_over_time({EventSource=\\\"elasticloadbalancing.amazonaws.com\\\", EventName=~\\\"Delete.*\\\"}[5m]) > 1\\n```\\n\\nThis alert helps ensure that unexpected or excessive ELB deletions are promptly detected and addressed to maintain service reliability.\", \" - This pattern captures all modification events related to EC2 resources in AWS CloudTrail, triggered by any API calls starting with \\\"Modify\\\" (e.g., ModifyInstanceAttribute, ModifyNetworkInterfaceAttribute). Its purpose is to monitor changes to critical EC2 configurations such as instance attributes, security group rules, and network settings, which can directly impact system security, availability, and performance.\\n\\n**Threshold guidance:**  \\n- Alert when the number of Modify* events exceeds a baseline threshold (e.g., more than 5 modifications within 10 minutes), indicating unusual or potentially unauthorized changes.  \\n- A sudden spike in modification events may signal misconfigurations, automation errors, or security incidents like privilege escalation or lateral movement.\\n\\n**Impact of values:**  \\n- **High frequency:** Could indicate active troubleshooting, automated scaling/configuration changes, or suspicious activity requiring immediate investigation.  \\n- **Low or zero frequency:** Normal steady state; no unexpected modifications detected.\\n\\n**Example alert rule:**  \\nTrigger an alert if the count of events matching {\\\"EventSource\\\": \\\"ec2.amazonaws.com\\\", \\\"EventName\\\": \\\"Modify*\\\"} exceeds 5 within a rolling 10-minute window.\\n\\n**Example dashboard widget:**  \\nA time-series graph showing the count of EC2 Modify* events per 5-minute interval, overlaid with a threshold line at 5 events, enabling quick identification of abnormal modification activity.\", \" - This pattern captures all modification events related to Elastic Load Balancing (ELB) resources in AWS, such as changes to load balancer configurations, target groups, and listeners. In CloudTrail, these events indicate when an ELB\\u2019s setup is altered, which can affect traffic routing, availability, and security posture.\\n\\n**Purpose:**  \\nTo monitor and audit any configuration changes to ELB components that could impact application availability or security.\\n\\n**Alert Threshold:**  \\nTrigger an alert if the number of ELB modification events exceeds a defined threshold within a short time window (e.g., more than 3 Modify* events within 10 minutes), as this may indicate unintended or unauthorized changes.\\n\\n**Impact of Values:**  \\n- **High frequency of Modify* events:** Could signal potential misconfigurations, automated deployment issues, or malicious activity altering load balancer behavior, risking downtime or security breaches.  \\n- **Low or no Modify* events:** Typically expected during stable operation; absence of changes suggests configuration stability.\\n\\n**Example Usage:**  \\nIn a monitoring dashboard or alert rule, track the count of **{\\\"EventSource\\\": \\\"elasticloadbalancing.amazonaws.com\\\", \\\"EventName\\\": \\\"Modify*\\\"}** events over rolling 10-minute intervals. Configure alerts to notify the SRE team when this count spikes above the threshold, enabling prompt investigation and rollback if necessary.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": true,
                        "score": 0.9,
                        "reason": "The description directly addresses the monitoring question by explaining that a high frequency of Modify* events related to ELB can indicate misconfigurations or malicious activity altering load balancer behavior. It clearly covers what is measured (modification events in CloudTrail for ELB), includes units and thresholds (e.g., more than 3 events in 10 minutes), and explains the implications for availability and security. The description also provides actionable guidance for alerting and investigation, making it highly useful for answering the monitoring question. Minor improvement could be made by explicitly linking the threshold to specific security or operational actions.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Compare the Input (metric description) and Retrieval Context to ensure the description directly addresses the monitoring question in clear, concise language.\",\n    \"Evaluate if the description sufficiently covers what is measured, including units, context, and implications relevant to the question posed.\",\n    \"Assess the utility by determining whether the description provides actionable insight or clear guidance to answer the monitoring question effectively.\",\n    \"If deficiencies are found, identify specific gaps between the description and question to suggest targeted improvements that increase clarity, coverage, or utility.\"\n] \n \nRubric:\nNone \n \nScore: 0.9"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Compare the Input (metric description) and Retrieval Context to ensure the description directly addresses the monitoring question in clear, concise language.",
                            "Evaluate if the description sufficiently covers what is measured, including units, context, and implications relevant to the question posed.",
                            "Assess the utility by determining whether the description provides actionable insight or clear guidance to answer the monitoring question effectively.",
                            "If deficiencies are found, identify specific gaps between the description and question to suggest targeted improvements that increase clarity, coverage, or utility."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"elasticache.amazonaws.com\\\", \\\"EventName\\\": \\\"Reboot*\\\"}\", \"hyperparameters\": null, \"input\": \"Are there more than three ElastiCache reboot events recorded in CloudTrail, indicating potential instability or misconfiguration?\", \"retrieval_context\": [\" - EMR cluster events captured by CloudTrail provide detailed records of actions and changes within Amazon EMR, including cluster creation, modification, scaling, and termination. These events enable SREs to monitor the health and lifecycle of big data processing jobs and Hadoop ecosystem workflows. \\n\\n**Purpose:** Track operational changes and anomalies in EMR clusters to ensure data processing pipelines run smoothly and to quickly identify failures or misconfigurations.\\n\\n**Alert Thresholds:**  \\n- Alert on unexpected cluster terminations or failures (e.g., `TerminateJobFlows` or `RunJobFlow` failures).  \\n- Alert if cluster scaling events occur too frequently within a short time window, indicating instability.  \\n- Alert on prolonged cluster startup or shutdown times exceeding defined SLAs.\\n\\n**Impact:**  \\n- High frequency of failure or termination events may indicate systemic issues causing job interruptions or data loss.  \\n- Low or no cluster activity during expected processing windows could signal pipeline stalls or misconfigurations.  \\n- Frequent scaling events might degrade performance or increase costs unnecessarily.\\n\\n**Example Alert Rule:**  \\nTrigger an alert if more than 3 `TerminateJobFlows` events occur within 1 hour, or if a cluster remains in `Starting` state for over 15 minutes without transitioning to `Running`.  \\n\\n**Dashboard Use:**  \\nVisualize event counts over time by event name (e.g., `RunJobFlow`, `AddInstanceGroups`, `TerminateJobFlows`) alongside cluster status metrics to correlate operational events with cluster health and job success rates.\", \" - This pattern captures CloudTrail events where ElastiCache clusters are modified, including scaling operations (e.g., changing node count or instance types), parameter group updates, and configuration changes. It helps SREs monitor critical changes that can impact cache performance, availability, or cost.\\n\\n**Purpose:**  \\nDetect when ElastiCache resources are altered to ensure changes are intentional, authorized, and do not degrade system stability.\\n\\n**Alert Threshold:**  \\nTrigger an alert on any **Modify\\\\*** event to catch all configuration changes. For noisy environments, consider alerting only on modifications that increase or decrease node count by more than 1, or changes to parameter groups affecting performance-critical settings.\\n\\n**Impact of Values:**  \\n- **High frequency of Modify events:** May indicate repeated scaling or configuration changes, potentially causing instability or unexpected behavior.  \\n- **Low or zero Modify events:** Suggests stable cache configuration, but lack of changes during scaling needs may indicate missed updates.\\n\\n**Example Alert Rule:**  \\nAlert when an event with `EventSource = \\\"elasticache.amazonaws.com\\\"` and `EventName` matching `Modify*` occurs, optionally filtering for changes in node count or parameter group names. This can be visualized in a dashboard showing a timeline of modification events alongside cluster performance metrics to correlate changes with impact.\", \" - This pattern captures ElastiCache reboot events recorded in CloudTrail, specifically any API calls starting with \\\"Reboot\\\" (e.g., RebootCacheCluster). It helps SREs monitor when ElastiCache nodes undergo reboots, which typically occur during maintenance, configuration changes, or troubleshooting. Frequent or unexpected reboots may indicate instability or underlying issues affecting cache availability and performance.\\n\\n**Alert Threshold:**  \\nTrigger an alert if the number of reboot events exceeds a defined threshold within a short time window (e.g., more than 3 reboots per node within 1 hour), as this may signal recurring failures or misconfigurations.\\n\\n**Impact:**  \\n- **High reboot frequency:** Can cause increased latency, cache misses, and potential downtime for applications relying on ElastiCache, impacting user experience and system reliability.  \\n- **Low or expected reboot frequency:** Indicates normal maintenance or controlled troubleshooting with minimal impact.\\n\\n**Example Alert Rule (CloudWatch or SIEM):**  \\nMonitor CloudTrail logs for events matching `{\\\"EventSource\\\": \\\"elasticache.amazonaws.com\\\", \\\"EventName\\\": \\\"Reboot*\\\"}` and trigger an alert if the count of such events per cache cluster exceeds 3 within 60 minutes. This helps proactively detect and respond to abnormal reboot patterns before they affect service stability.\", \" - This pattern captures all modification events related to Elastic Load Balancing (ELB) resources in AWS, such as changes to load balancer configurations, target groups, and listeners. In CloudTrail, these events indicate when an ELB\\u2019s setup is altered, which can affect traffic routing, availability, and security posture.\\n\\n**Purpose:**  \\nTo monitor and audit any configuration changes to ELB components that could impact application availability or security.\\n\\n**Alert Threshold:**  \\nTrigger an alert if the number of ELB modification events exceeds a defined threshold within a short time window (e.g., more than 3 Modify* events within 10 minutes), as this may indicate unintended or unauthorized changes.\\n\\n**Impact of Values:**  \\n- **High frequency of Modify* events:** Could signal potential misconfigurations, automated deployment issues, or malicious activity altering load balancer behavior, risking downtime or security breaches.  \\n- **Low or no Modify* events:** Typically expected during stable operation; absence of changes suggests configuration stability.\\n\\n**Example Usage:**  \\nIn a monitoring dashboard or alert rule, track the count of **{\\\"EventSource\\\": \\\"elasticloadbalancing.amazonaws.com\\\", \\\"EventName\\\": \\\"Modify*\\\"}** events over rolling 10-minute intervals. Configure alerts to notify the SRE team when this count spikes above the threshold, enabling prompt investigation and rollback if necessary.\", \" - This pattern detects ElastiCache failover events recorded in CloudTrail, indicating when a primary node in a cluster is replaced due to failure or maintenance to maintain high availability. Monitoring these events helps SREs quickly identify potential service disruptions or instability in cache performance.\\n\\n**Purpose:**  \\nTrack failover occurrences to ensure cluster resilience and detect abnormal failover frequency that may signal underlying issues.\\n\\n**Alert Threshold:**  \\nTrigger an alert if the number of failover events exceeds a defined threshold within a given time window (e.g., more than 1 failover per hour or 3 failovers within 24 hours), as frequent failovers can degrade application performance and availability.\\n\\n**Impact:**  \\n- **High failover frequency:** May indicate hardware problems, network instability, or misconfiguration, potentially causing increased latency or downtime. Immediate investigation and remediation are required.  \\n- **Low or zero failovers:** Reflects stable cluster operation and healthy failover mechanisms.\\n\\n**Example Alert Rule:**  \\nAlert when `count({\\\"EventSource\\\": \\\"elasticache.amazonaws.com\\\", \\\"EventName\\\": \\\"Failover*\\\"}) > 1` within 1 hour.\\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of ElastiCache failover events per hour, enabling trend analysis and rapid detection of spikes in failovers.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": true,
                        "score": 0.9075858178976617,
                        "reason": "The description directly addresses the monitoring question by explaining that the pattern captures ElastiCache reboot events in CloudTrail and specifies the alert threshold of more than 3 reboots within 1 hour, matching the input's focus on more than three reboot events. It clearly states what is measured (reboot events), the units (count within time window), relevant context (maintenance, configuration changes, troubleshooting), and implications (instability, increased latency, downtime). The explanation is concise, clear, and provides example alert rules, making it highly useful for answering the question. Minor deduction is due to slight complexity in wording that could be simplified for absolute clarity.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Compare the Input (monitoring question) and Retrieval Context (metric description) to ensure that the description clearly addresses the specific question asked.\",\n    \"Evaluate the description's Clarity by checking if it is concise, easy to understand, and free of ambiguous terminology in relation to the question.\",\n    \"Assess the Coverage by verifying that the description includes what is measured, units, relevant context, and implications that directly relate to the input question.\",\n    \"Determine Utility by analyzing whether the description provides sufficient and relevant information to answer the monitoring question effectively.\"\n] \n \nRubric:\nNone \n \nScore: 0.9075858178976617"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Compare the Input (monitoring question) and Retrieval Context (metric description) to ensure that the description clearly addresses the specific question asked.",
                            "Evaluate the description's Clarity by checking if it is concise, easy to understand, and free of ambiguous terminology in relation to the question.",
                            "Assess the Coverage by verifying that the description includes what is measured, units, relevant context, and implications that directly relate to the input question.",
                            "Determine Utility by analyzing whether the description provides sufficient and relevant information to answer the monitoring question effectively."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"elasticloadbalancing.amazonaws.com\\\", \\\"EventName\\\": \\\"Delete*\\\"}\", \"hyperparameters\": null, \"input\": \"Does the number of ELB deletion events exceed one, indicating a potential misconfiguration, automation error, or malicious activity?\", \"retrieval_context\": [\" - IAM deletion events (e.g., DeleteUser, DeleteRole) recorded by CloudTrail indicate removal of IAM identities or permissions. These events are critical for detecting unauthorized or accidental deletions that can disrupt access or signal a security breach. An alert threshold should be set to trigger on any unexpected deletion event or a sudden spike above normal baseline activity (e.g., more than 1 deletion event within 5 minutes), as even a single deletion can have significant impact. High volumes may indicate automated attacks or misconfigurations causing mass access removal, while low or zero values typically indicate normal operation.  \\nExample alert rule: trigger when count of iam.amazonaws.com Delete* events > 1 in 5 minutes.  \\nExample dashboard widget: a time series graph showing Delete* event counts over time, annotated with alert thresholds to quickly identify unusual deletion activity.\", \" - This pattern captures all AWS CloudTrail events where RDS resources are deleted (e.g., DeleteDBInstance, DeleteDBSnapshot). Its purpose is to monitor and alert on potentially destructive actions affecting RDS databases, which could indicate intentional cleanup, accidental deletions, or malicious activity. \\n\\n**Threshold guidance:**  \\n- Trigger an alert if more than 1 deletion event occurs within a short time window (e.g., 5 minutes), as multiple deletions in quick succession are unusual and may signal a problem.  \\n- A single deletion event should also prompt review, especially if unexpected or outside maintenance windows.\\n\\n**Impact:**  \\n- **High values:** Multiple deletions in a short period can lead to significant data loss or service disruption, requiring immediate investigation and possible recovery actions.  \\n- **Low values:** Occasional single deletions may be normal during maintenance but still warrant confirmation to avoid unnoticed data loss.\\n\\n**Example usage:**  \\nIn a monitoring dashboard, display a time series count of RDS deletion events filtered by this pattern. Configure an alert rule to notify the SRE team if the count exceeds 1 event within any 5-minute interval, enabling rapid response to potential incidents.\", \" - This pattern captures all deletion events related to Elastic Load Balancers (ELBs) in AWS, as recorded by CloudTrail under the event source \\\"elasticloadbalancing.amazonaws.com\\\" with event names starting with \\\"Delete\\\". Its primary purpose is to monitor when ELBs are removed, which can be part of routine cleanup or indicate unintended service disruptions due to the loss of load balancing resources.\\n\\n**Purpose:**  \\nSREs use this pattern to track ELB deletions to quickly detect and investigate potential impacts on application availability and traffic routing.\\n\\n**Alert Threshold:**  \\nAn alert should be triggered if the number of ELB deletion events exceeds a predefined threshold within a short time window\\u2014for example, more than 1 deletion event within 5 minutes\\u2014since multiple deletions in quick succession may indicate a misconfiguration, automation error, or malicious activity.\\n\\n**Impact of Values:**  \\n- **High values:** Frequent or bulk ELB deletions can cause significant service disruption, leading to downtime or degraded performance due to loss of traffic distribution. Immediate investigation and remediation are required.  \\n- **Low values:** Occasional single deletions may be expected during normal maintenance or scaling operations and typically do not require urgent action but should still be logged for audit purposes.\\n\\n**Example Usage:**  \\nIn a monitoring dashboard or alert rule, you might configure a query to count ELB deletion events over a rolling 5-minute window and trigger an alert if the count exceeds 1. For example:\\n\\n```\\ncount_over_time({EventSource=\\\"elasticloadbalancing.amazonaws.com\\\", EventName=~\\\"Delete.*\\\"}[5m]) > 1\\n```\\n\\nThis alert helps ensure that unexpected or excessive ELB deletions are promptly detected and addressed to maintain service reliability.\", \" - This pattern captures all modification events related to Elastic Load Balancing (ELB) resources in AWS, such as changes to load balancer configurations, target groups, and listeners. In CloudTrail, these events indicate when an ELB\\u2019s setup is altered, which can affect traffic routing, availability, and security posture.\\n\\n**Purpose:**  \\nTo monitor and audit any configuration changes to ELB components that could impact application availability or security.\\n\\n**Alert Threshold:**  \\nTrigger an alert if the number of ELB modification events exceeds a defined threshold within a short time window (e.g., more than 3 Modify* events within 10 minutes), as this may indicate unintended or unauthorized changes.\\n\\n**Impact of Values:**  \\n- **High frequency of Modify* events:** Could signal potential misconfigurations, automated deployment issues, or malicious activity altering load balancer behavior, risking downtime or security breaches.  \\n- **Low or no Modify* events:** Typically expected during stable operation; absence of changes suggests configuration stability.\\n\\n**Example Usage:**  \\nIn a monitoring dashboard or alert rule, track the count of **{\\\"EventSource\\\": \\\"elasticloadbalancing.amazonaws.com\\\", \\\"EventName\\\": \\\"Modify*\\\"}** events over rolling 10-minute intervals. Configure alerts to notify the SRE team when this count spikes above the threshold, enabling prompt investigation and rollback if necessary.\", \" - Tracks all AWS Lambda function deletion events captured in CloudTrail. Monitoring **{\\\"EventSource\\\": \\\"lambda.amazonaws.com\\\", \\\"EventName\\\": \\\"Delete*\\\"}** helps SREs detect when Lambda functions are removed, which is critical for maintaining application stability, ensuring proper resource cleanup, and preventing accidental or unauthorized deletions.  \\n\\n**Alert Threshold:** Trigger an alert if more than 3 Lambda function deletions occur within a 1-hour window, as this may indicate a misconfiguration, automated script error, or potential security breach.  \\n\\n**Impact:**  \\n- **High values:** A spike in deletions can lead to service disruptions, loss of critical functionality, or security incidents if unauthorized deletions occur. Immediate investigation is required.  \\n- **Low or zero values:** Normal operation; infrequent deletions are expected during routine maintenance or deployments.  \\n\\n**Example Alert Rule:**  \\n`WHEN count(events where EventSource=\\\"lambda.amazonaws.com\\\" AND EventName LIKE \\\"Delete%\\\") > 3 WITHIN 1 hour THEN alert \\\"Unusual number of Lambda deletions detected\\\"`  \\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of Lambda deletion events per hour, annotated with alert thresholds, enabling quick identification of abnormal deletion activity.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": true,
                        "score": 0.9010986944684947,
                        "reason": "The retrieval context directly addresses the input question by describing ELB deletion events, their monitoring via CloudTrail, and the alert threshold of more than one deletion event within a short time window, matching the question's focus on exceeding one deletion event. The description is clear, concise, and includes what is measured (ELB deletion events), units (count within 5 minutes), relevant context (potential misconfiguration, automation error, or malicious activity), and implications (service disruption, need for investigation). It provides sufficient information for a user to understand and act on the monitoring question. The only minor shortcoming is the lack of explicit mention of the exact unit 'number of events' in a single phrase, but overall coverage and utility are strong.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Compare the Input (monitoring question) and the Retrieval Context (metric description) to ensure the description directly addresses the question's intent.\",\n    \"Evaluate Clarity: Check if the description is concise and easily understandable without ambiguity in relation to the question posed.\",\n    \"Assess Coverage: Confirm the description includes what is measured, units, relevant context, and implications necessary to comprehend and answer the input question.\",\n    \"Judge Utility: Determine whether the description provides sufficient information to enable the user to effectively answer the monitoring question; if not, identify specific missing elements.\"\n] \n \nRubric:\nNone \n \nScore: 0.9010986944684947"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Compare the Input (monitoring question) and the Retrieval Context (metric description) to ensure the description directly addresses the question's intent.",
                            "Evaluate Clarity: Check if the description is concise and easily understandable without ambiguity in relation to the question posed.",
                            "Assess Coverage: Confirm the description includes what is measured, units, relevant context, and implications necessary to comprehend and answer the input question.",
                            "Judge Utility: Determine whether the description provides sufficient information to enable the user to effectively answer the monitoring question; if not, identify specific missing elements."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"route53.amazonaws.com\\\", \\\"EventName\\\": \\\"Create*\\\"}\", \"hyperparameters\": null, \"input\": \"Does the number of Route 53 resource creation events exceed five, indicating potential unauthorized changes or misconfigurations?\", \"retrieval_context\": [\" - This pattern captures Route 53 change events. It identifies when Route 53 resources are modified, including record set changes, health check updates, and routing policy modifications.\", \" - This pattern captures all Route 53 \\\"Get\\\" API operations logged in CloudTrail, such as retrieving hosted zone details, record sets, and health check statuses. It helps SREs monitor read access to DNS configurations and health data, which can indicate normal operational queries or potential reconnaissance activity. A sudden spike in these \\\"Get\\\" requests\\u2014exceeding a baseline threshold (e.g., 3 standard deviations above the average hourly rate)\\u2014may signal unusual interest in DNS infrastructure, warranting investigation. Conversely, a significant drop could indicate issues with monitoring or automation systems relying on these queries. For example, an alert rule could trigger when the count of **{\\\"EventSource\\\": \\\"route53.amazonaws.com\\\", \\\"EventName\\\": \\\"Get*\\\"}** events exceeds 100 requests per hour, and a dashboard widget might display a time series graph of these events to track trends and detect anomalies in DNS query activity.\", \" - This pattern captures all Route 53 deletion events recorded in CloudTrail, such as deleting hosted zones, record sets, or health checks. It helps SREs monitor when DNS configurations are removed, which could be part of routine cleanup or signal accidental or malicious disruptions to DNS resolution.\\n\\n**Purpose:**  \\nTrack and alert on Route 53 resource deletions to quickly detect potential service impact caused by DNS changes.\\n\\n**Alert Threshold:**  \\nTrigger an alert if more than 3 deletion events occur within a 10-minute window, as multiple deletions in a short period may indicate an ongoing incident or misconfiguration.\\n\\n**Impact:**  \\n- **High volume:** May cause widespread DNS outages or service disruptions, requiring immediate investigation.  \\n- **Low volume (single event):** Could be routine maintenance but should still be reviewed to confirm legitimacy.\\n\\n**Example Alert Rule:**  \\n\\u201cAlert when count of events matching {EventSource: route53.amazonaws.com, EventName: Delete*} exceeds 3 within 10 minutes.\\u201d\\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of Route 53 deletion events over time, with a threshold line at 3 events per 10 minutes to highlight potential issues.\", \" - This pattern captures all Route 53 resource creation events recorded in CloudTrail, such as the creation of hosted zones, DNS record sets, and health checks. Monitoring these events helps SREs detect configuration changes that could impact DNS resolution and application availability. \\n\\n**Purpose:** Track when new Route 53 resources are created to identify potential unauthorized changes or misconfigurations early.\\n\\n**Alert Threshold:** Trigger an alert if the number of creation events exceeds a baseline threshold (e.g., more than 5 creation events within 10 minutes), which may indicate automated misconfigurations, security breaches, or unintended mass changes.\\n\\n**Impact:**  \\n- **High values:** A spike in creation events could lead to DNS inconsistencies, increased attack surface, or service disruptions if malicious or erroneous resources are introduced.  \\n- **Low or zero values:** Normal operation, assuming no planned infrastructure changes.\\n\\n**Example Alert Rule:**  \\nAlert when `count({\\\"EventSource\\\": \\\"route53.amazonaws.com\\\", \\\"EventName\\\": \\\"Create*\\\"})` > 5 within 10 minutes.\\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of Route 53 creation events over time, enabling quick identification of unusual spikes in resource creation activity.\", \" - This pattern detects API calls made to Amazon Route 53 that begin with \\\"List,\\\" such as ListHostedZones, ListResourceRecordSets, and ListHealthChecks. It measures the count of these list operations performed within a given time frame. Each event corresponds to a single request to retrieve a collection of Route 53 resources. The unit of measurement is the number of list API calls executed.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": true,
                        "score": 0.902297736844649,
                        "reason": "The description directly addresses the monitoring question by explaining the capture of Route 53 resource creation events and the significance of exceeding five events, including alert thresholds and potential impacts. It is clear, concise, and includes units (event counts within 10 minutes), measurement context, and implications relevant to unauthorized changes or misconfigurations. The inclusion of example alert rules and dashboard widgets enhances utility by providing actionable insights. Minor deduction is due to slight verbosity that could be more concise.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Compare the Input (monitoring question) and Retrieval Context (metric description) to check if the description clearly addresses the question's core concern.\",\n    \"Evaluate the description for clarity and conciseness to ensure the user can easily understand what is measured and how it relates to the question.\",\n    \"Assess coverage by verifying if the description includes units, measurement context, and implications specifically relevant to answering the question.\",\n    \"Determine utility by confirming whether the description provides actionable insights that directly help answer the monitoring question.\"\n] \n \nRubric:\nNone \n \nScore: 0.902297736844649"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Compare the Input (monitoring question) and Retrieval Context (metric description) to check if the description clearly addresses the question's core concern.",
                            "Evaluate the description for clarity and conciseness to ensure the user can easily understand what is measured and how it relates to the question.",
                            "Assess coverage by verifying if the description includes units, measurement context, and implications specifically relevant to answering the question.",
                            "Determine utility by confirming whether the description provides actionable insights that directly help answer the monitoring question."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"route53.amazonaws.com\\\", \\\"EventName\\\": \\\"Change*\\\"}\", \"hyperparameters\": null, \"input\": \"Are there any Route 53 resource modifications that could be causing a disruption to service?\", \"retrieval_context\": [\" - This pattern captures Route 53 change events. It identifies when Route 53 resources are modified, including record set changes, health check updates, and routing policy modifications.\", \" - This pattern captures all Route 53 \\\"Get\\\" API operations logged in CloudTrail, such as retrieving hosted zone details, record sets, and health check statuses. It helps SREs monitor read access to DNS configurations and health data, which can indicate normal operational queries or potential reconnaissance activity. A sudden spike in these \\\"Get\\\" requests\\u2014exceeding a baseline threshold (e.g., 3 standard deviations above the average hourly rate)\\u2014may signal unusual interest in DNS infrastructure, warranting investigation. Conversely, a significant drop could indicate issues with monitoring or automation systems relying on these queries. For example, an alert rule could trigger when the count of **{\\\"EventSource\\\": \\\"route53.amazonaws.com\\\", \\\"EventName\\\": \\\"Get*\\\"}** events exceeds 100 requests per hour, and a dashboard widget might display a time series graph of these events to track trends and detect anomalies in DNS query activity.\", \" - This pattern captures all Route 53 deletion events recorded in CloudTrail, such as deleting hosted zones, record sets, or health checks. It helps SREs monitor when DNS configurations are removed, which could be part of routine cleanup or signal accidental or malicious disruptions to DNS resolution.\\n\\n**Purpose:**  \\nTrack and alert on Route 53 resource deletions to quickly detect potential service impact caused by DNS changes.\\n\\n**Alert Threshold:**  \\nTrigger an alert if more than 3 deletion events occur within a 10-minute window, as multiple deletions in a short period may indicate an ongoing incident or misconfiguration.\\n\\n**Impact:**  \\n- **High volume:** May cause widespread DNS outages or service disruptions, requiring immediate investigation.  \\n- **Low volume (single event):** Could be routine maintenance but should still be reviewed to confirm legitimacy.\\n\\n**Example Alert Rule:**  \\n\\u201cAlert when count of events matching {EventSource: route53.amazonaws.com, EventName: Delete*} exceeds 3 within 10 minutes.\\u201d\\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of Route 53 deletion events over time, with a threshold line at 3 events per 10 minutes to highlight potential issues.\", \" - This pattern captures all Route 53 resource creation events recorded in CloudTrail, such as the creation of hosted zones, DNS record sets, and health checks. Monitoring these events helps SREs detect configuration changes that could impact DNS resolution and application availability. \\n\\n**Purpose:** Track when new Route 53 resources are created to identify potential unauthorized changes or misconfigurations early.\\n\\n**Alert Threshold:** Trigger an alert if the number of creation events exceeds a baseline threshold (e.g., more than 5 creation events within 10 minutes), which may indicate automated misconfigurations, security breaches, or unintended mass changes.\\n\\n**Impact:**  \\n- **High values:** A spike in creation events could lead to DNS inconsistencies, increased attack surface, or service disruptions if malicious or erroneous resources are introduced.  \\n- **Low or zero values:** Normal operation, assuming no planned infrastructure changes.\\n\\n**Example Alert Rule:**  \\nAlert when `count({\\\"EventSource\\\": \\\"route53.amazonaws.com\\\", \\\"EventName\\\": \\\"Create*\\\"})` > 5 within 10 minutes.\\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of Route 53 creation events over time, enabling quick identification of unusual spikes in resource creation activity.\", \" - This pattern detects API calls made to Amazon Route 53 that begin with \\\"List,\\\" such as ListHostedZones, ListResourceRecordSets, and ListHealthChecks. It measures the count of these list operations performed within a given time frame. Each event corresponds to a single request to retrieve a collection of Route 53 resources. The unit of measurement is the number of list API calls executed.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": true,
                        "score": 0.8817574471748733,
                        "reason": "The retrieval context directly addresses the input question by describing Route 53 resource modification events including creation, deletion, and change events, which are relevant to potential service disruptions. The descriptions are clear, detailed, and provide operational context such as alert thresholds, impact, and example alert rules, enabling confident monitoring of modifications that could cause disruptions. Minor gaps include no explicit mention of how to correlate these events specifically to service disruption, but overall coverage and utility are strong.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Compare the Input (monitoring question) and the Retrieval Context (metric description) to check if the description clearly and directly addresses the question.\",\n    \"Evaluate clarity by verifying if the metric description is concise and understandable without ambiguity or jargon that could confuse the user.\",\n    \"Assess coverage by ensuring the description explains what is measured, the units used, the operational context, and potential implications related to the input question.\",\n    \"Judge utility by determining whether the description provides enough relevant information to confidently answer the monitoring question; if not, identify gaps.\"\n] \n \nRubric:\nNone \n \nScore: 0.8817574471748733"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Compare the Input (monitoring question) and the Retrieval Context (metric description) to check if the description clearly and directly addresses the question.",
                            "Evaluate clarity by verifying if the metric description is concise and understandable without ambiguity or jargon that could confuse the user.",
                            "Assess coverage by ensuring the description explains what is measured, the units used, the operational context, and potential implications related to the input question.",
                            "Judge utility by determining whether the description provides enough relevant information to confidently answer the monitoring question; if not, identify gaps."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"cloudfront.amazonaws.com\\\", \\\"EventName\\\": \\\"Tag*\\\"}\", \"hyperparameters\": null, \"input\": \"Does the number of CloudFront Tag* events exceed five, indicating potential automated misconfigurations or security breaches?\", \"retrieval_context\": [\" - This pattern captures CloudFront cache invalidation events recorded in CloudTrail, which occur when cached content is explicitly removed or refreshed to ensure users receive the latest versions of assets. For an SRE, monitoring these events helps track content deployment activities and detect potential operational issues such as excessive invalidations that may indicate misconfigurations or abuse.\\n\\n**Purpose:**  \\n- Identify when CloudFront distributions are updated via cache invalidations.  \\n- Correlate invalidation frequency with deployment cycles or troubleshooting efforts.\\n\\n**Alert Threshold Guidance:**  \\n- Trigger an alert if the number of invalidation requests exceeds a defined threshold within a short time window (e.g., more than 10 invalidations in 5 minutes), as this may signal abnormal activity or inefficient cache management.  \\n- Conversely, unusually low invalidation activity during expected deployment periods might indicate deployment failures or monitoring gaps.\\n\\n**Impact:**  \\n- **High invalidation rates:** Can increase latency and cost, as CloudFront must fetch fresh content from origin servers more frequently, potentially degrading user experience.  \\n- **Low invalidation rates:** May cause users to receive stale content, impacting application correctness and user satisfaction.\\n\\n**Example Usage:**  \\n- **Dashboard:** Display a time-series graph of invalidation event counts per minute to visualize spikes or drops in cache refresh activity.  \\n- **Alert Rule (pseudo-code):**  \\n  ```  \\n  WHEN count(EventName LIKE \\\"Invalidate*\\\") FROM cloudtrail  \\n  OVER last 5 minutes > 10  \\n  THEN alert \\\"High CloudFront invalidation rate detected\\\"  \\n  ```\", \" - This pattern captures CloudFront tagging events recorded in CloudTrail, specifically when CloudFront distributions are tagged or untagged. Tagging actions are critical for resource organization, cost allocation, and access management. Monitoring these events helps SREs detect unauthorized or unexpected changes to distribution metadata that could affect billing, security policies, or operational workflows.\\n\\n**Alert Threshold:**  \\nTrigger an alert if the number of CloudFront Tag* events exceeds a baseline threshold within a short time window (e.g., more than 5 tagging operations in 10 minutes), as this may indicate automated misconfigurations, potential security breaches, or bulk updates requiring review.\\n\\n**Impact of Values:**  \\n- **High frequency:** Could signal mass tagging/untagging possibly due to automation errors, policy violations, or malicious activity, potentially leading to misallocated costs or broken access controls.  \\n- **Low or zero frequency:** Normal state; tagging changes are typically infrequent and deliberate.\\n\\n**Example Usage:**  \\nIn a monitoring dashboard, plot the count of CloudFront Tag* events over time to visualize tagging activity spikes. An alert rule might be:  \\n`WHEN count(events where EventSource=\\\"cloudfront.amazonaws.com\\\" AND EventName LIKE \\\"Tag%\\\") > 5 within 10 minutes THEN trigger alert \\\"Unusual CloudFront tagging activity detected\\\"`  \\nThis enables proactive investigation and mitigation of tagging anomalies impacting resource governance.\", \" - This pattern captures all CloudFront distribution creation events recorded in CloudTrail, identified by event names starting with \\\"Create\\\" from the CloudFront service. Its purpose is to monitor when new CloudFront distributions are provisioned, including their initial configuration details. Tracking these events helps SREs detect unexpected or unauthorized distribution creations that could impact content delivery, security, or cost.\\n\\n**Alert Threshold:**  \\nTrigger an alert if the number of CloudFront distribution creation events exceeds a defined threshold within a short time window (e.g., more than 3 creations within 1 hour), as this may indicate automation errors, misconfigurations, or potential security incidents.\\n\\n**Impact of Values:**  \\n- **High values:** A spike in creation events could signal rapid environment changes, possible misconfigurations, or unauthorized activity, potentially leading to increased costs or service disruptions.  \\n- **Low or zero values:** Normal operation typically involves infrequent distribution creations; zero or low values indicate stable infrastructure without unexpected provisioning.\\n\\n**Example Alert Rule:**  \\n\\\"Alert when count of events matching {EventSource: 'cloudfront.amazonaws.com', EventName: 'Create*'} exceeds 3 within 1 hour.\\\"\\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of CloudFront distribution creation events over time, enabling quick identification of unusual spikes or trends in distribution provisioning activity.\", \" - This pattern detects CloudTrail events where CloudWatch resources are created, such as alarms, dashboards, and log groups. Its purpose is to monitor the provisioning of new CloudWatch components, which can indicate changes in monitoring coverage or potential configuration drift. An alert should be triggered when the number of creation events exceeds a defined threshold within a short time window (e.g., more than 5 Create* events in 10 minutes), as a sudden spike may signal automated deployments, misconfigurations, or unauthorized activity. Conversely, a prolonged absence of creation events might suggest stagnation in monitoring updates or missed deployments. For example, in a monitoring dashboard, you can visualize the count of CloudWatch Create* events over time and set an alert rule to notify the SRE team if the event count surpasses the threshold, enabling timely investigation and response to unexpected changes in monitoring infrastructure.\", \" - This pattern detects SNS topic creation events recorded in CloudTrail, specifically any API calls starting with \\\"Create\\\" from the SNS service (e.g., CreateTopic). It helps SREs monitor when new SNS topics are provisioned, which can indicate changes in messaging architecture or potential unauthorized resource creation. An alert threshold could be set on the number of Create* events within a given time window (e.g., more than 5 topic creations in 10 minutes), as a sudden spike may signal automation errors or security issues. Low or expected values typically indicate normal operations, while high values may impact system stability by increasing resource usage or indicate potential misuse. For example, an alert rule could trigger if the count of {\\\"EventSource\\\": \\\"sns.amazonaws.com\\\", \\\"EventName\\\": \\\"Create*\\\"} events exceeds 5 in 10 minutes, and a dashboard widget could display a time series graph of topic creation events to track trends and detect anomalies.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": true,
                        "score": 0.9014063628386257,
                        "reason": "The retrieval context clearly addresses the input question by describing CloudFront Tag* events, their significance, and the alert threshold of more than 5 events within 10 minutes, which aligns with the question's focus on exceeding five events indicating potential issues. The description is clear, concise, and provides relevant context including impact, example alert rules, and usage, enabling effective monitoring and interpretation. Minor deduction is due to the lack of explicit units for the event count (though implied) and slightly dense formatting that could affect immediate clarity.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Compare the Input (monitoring question) with the Retrieval Context (metric description) to assess whether the description clearly addresses the question's focus.\",\n    \"Evaluate Clarity by checking if the description is understandable and concise in the context of the provided question.\",\n    \"Assess Coverage by verifying if the description explains what is measured, includes units, provides relevant context, and outlines implications that relate directly to the question.\",\n    \"Determine Utility by judging if the description enables the user to effectively answer the monitoring question, ensuring both Input and Retrieval Context align purposefully.\"\n] \n \nRubric:\nNone \n \nScore: 0.9014063628386257"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Compare the Input (monitoring question) with the Retrieval Context (metric description) to assess whether the description clearly addresses the question's focus.",
                            "Evaluate Clarity by checking if the description is understandable and concise in the context of the provided question.",
                            "Assess Coverage by verifying if the description explains what is measured, includes units, provides relevant context, and outlines implications that relate directly to the question.",
                            "Determine Utility by judging if the description enables the user to effectively answer the monitoring question, ensuring both Input and Retrieval Context align purposefully."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"cloudfront.amazonaws.com\\\", \\\"EventName\\\": \\\"Create*\\\"}\", \"hyperparameters\": null, \"input\": \"Does a spike in CloudFront distribution creation events exceed three, indicating potential automation errors or misconfigurations?\", \"retrieval_context\": [\" - CloudFormation stack creation events (**EventSource: cloudformation.amazonaws.com**, **EventName: Create\\\\*** ) represent API calls initiating the provisioning of AWS infrastructure and resources via CloudFormation templates. These events in CloudTrail help SREs monitor the start of environment setups and infrastructure deployments as part of Infrastructure as Code workflows.\\n\\n**Purpose:** Track and audit when new CloudFormation stacks or stack components are being created, enabling visibility into changes in infrastructure state and deployment activities.\\n\\n**Alert Thresholds:**  \\n- Trigger an alert if the number of Create* events exceeds a baseline threshold within a short time window (e.g., >10 stack creation attempts in 5 minutes), which may indicate automated deployment loops, misconfigurations, or potential security incidents.  \\n- Alert if Create* events spike unexpectedly outside of scheduled deployment windows or change management periods.\\n\\n**Impact of Values:**  \\n- **High volume:** May signal rapid infrastructure changes that could lead to instability, resource contention, or deployment failures. It could also indicate unauthorized or accidental mass provisioning.  \\n- **Low or zero volume:** Normal during steady-state operations; however, a sudden drop during expected deployment windows might indicate pipeline failures or blocked deployments.\\n\\n**Example Usage:**  \\n- **Dashboard:** Visualize the count of CloudFormation Create* events over time, segmented by stack name or user identity, to correlate deployments with system performance or incidents.  \\n- **Alert Rule:**  \\n  ```  \\n  WHEN count(events where EventSource=\\\"cloudformation.amazonaws.com\\\" AND EventName LIKE \\\"Create%\\\") > 10 within 5 minutes  \\n  THEN trigger alert \\\"High rate of CloudFormation stack creation events detected\\\"  \\n  ```  \\nThis enables proactive detection of abnormal infrastructure provisioning activity and supports rapid investigation and response.\", \" - Redshift cluster creation events in CloudTrail capture all API calls initiating the provisioning of new Redshift clusters (e.g., CreateCluster). These events indicate when new data warehouse resources are being deployed or configured, impacting capacity and cost.  \\n**Purpose:** Enables SREs to monitor and audit cluster provisioning activities for operational control and security compliance.  \\n**Alert Threshold:** Trigger alerts on an unusually high number of cluster creation events within a short time window (e.g., >3 creates in 1 hour), which may indicate automation errors, misconfigurations, or unauthorized resource provisioning.  \\n**Impact:**  \\n- **High values:** May lead to resource sprawl, increased costs, and potential performance degradation due to over-provisioning. Could also signal security risks if unexpected clusters are created.  \\n- **Low or zero values:** Normal in stable environments; no new clusters being created means stable infrastructure.  \\n**Example Alert Rule:**  \\n\\u201cAlert if count of events with EventSource='redshift.amazonaws.com' and EventName starting with 'Create' exceeds 3 within 60 minutes.\\u201d  \\n**Dashboard Use:** Visualize the frequency of Redshift cluster creation events over time to detect spikes or anomalies, correlating with deployment activities or security incidents.\", \" - This pattern captures CloudFront tagging events recorded in CloudTrail, specifically when CloudFront distributions are tagged or untagged. Tagging actions are critical for resource organization, cost allocation, and access management. Monitoring these events helps SREs detect unauthorized or unexpected changes to distribution metadata that could affect billing, security policies, or operational workflows.\\n\\n**Alert Threshold:**  \\nTrigger an alert if the number of CloudFront Tag* events exceeds a baseline threshold within a short time window (e.g., more than 5 tagging operations in 10 minutes), as this may indicate automated misconfigurations, potential security breaches, or bulk updates requiring review.\\n\\n**Impact of Values:**  \\n- **High frequency:** Could signal mass tagging/untagging possibly due to automation errors, policy violations, or malicious activity, potentially leading to misallocated costs or broken access controls.  \\n- **Low or zero frequency:** Normal state; tagging changes are typically infrequent and deliberate.\\n\\n**Example Usage:**  \\nIn a monitoring dashboard, plot the count of CloudFront Tag* events over time to visualize tagging activity spikes. An alert rule might be:  \\n`WHEN count(events where EventSource=\\\"cloudfront.amazonaws.com\\\" AND EventName LIKE \\\"Tag%\\\") > 5 within 10 minutes THEN trigger alert \\\"Unusual CloudFront tagging activity detected\\\"`  \\nThis enables proactive investigation and mitigation of tagging anomalies impacting resource governance.\", \" - This pattern captures all CloudFront distribution creation events recorded in CloudTrail, identified by event names starting with \\\"Create\\\" from the CloudFront service. Its purpose is to monitor when new CloudFront distributions are provisioned, including their initial configuration details. Tracking these events helps SREs detect unexpected or unauthorized distribution creations that could impact content delivery, security, or cost.\\n\\n**Alert Threshold:**  \\nTrigger an alert if the number of CloudFront distribution creation events exceeds a defined threshold within a short time window (e.g., more than 3 creations within 1 hour), as this may indicate automation errors, misconfigurations, or potential security incidents.\\n\\n**Impact of Values:**  \\n- **High values:** A spike in creation events could signal rapid environment changes, possible misconfigurations, or unauthorized activity, potentially leading to increased costs or service disruptions.  \\n- **Low or zero values:** Normal operation typically involves infrequent distribution creations; zero or low values indicate stable infrastructure without unexpected provisioning.\\n\\n**Example Alert Rule:**  \\n\\\"Alert when count of events matching {EventSource: 'cloudfront.amazonaws.com', EventName: 'Create*'} exceeds 3 within 1 hour.\\\"\\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of CloudFront distribution creation events over time, enabling quick identification of unusual spikes or trends in distribution provisioning activity.\", \" - This pattern detects SNS topic creation events recorded in CloudTrail, specifically any API calls starting with \\\"Create\\\" from the SNS service (e.g., CreateTopic). It helps SREs monitor when new SNS topics are provisioned, which can indicate changes in messaging architecture or potential unauthorized resource creation. An alert threshold could be set on the number of Create* events within a given time window (e.g., more than 5 topic creations in 10 minutes), as a sudden spike may signal automation errors or security issues. Low or expected values typically indicate normal operations, while high values may impact system stability by increasing resource usage or indicate potential misuse. For example, an alert rule could trigger if the count of {\\\"EventSource\\\": \\\"sns.amazonaws.com\\\", \\\"EventName\\\": \\\"Create*\\\"} events exceeds 5 in 10 minutes, and a dashboard widget could display a time series graph of topic creation events to track trends and detect anomalies.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": true,
                        "score": 0.922270013882531,
                        "reason": "The retrieval context clearly and concisely addresses the input question by describing CloudFront distribution creation events, including the event pattern, alert threshold (exceeding 3 creations within 1 hour), and implications of spikes indicating automation errors or misconfigurations. It provides sufficient detail on what is measured, units (count within time window), and impact, enabling effective user understanding and response. Minor improvement could be made by explicitly linking the threshold to the exact question phrasing, but overall coverage and utility are strong.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Compare the Input (monitoring question) with the Retrieval Context (metric description) to check if the description clearly addresses the question's focus.\",\n    \"Evaluate the Clarity of the Retrieval Context in relation to the Input by assessing whether the description is understandable and concise enough to answer the question directly.\",\n    \"Assess Coverage by verifying if the description fully explains what is measured, including units, relevant context, and implications that are necessary to address the Input's inquiry.\",\n    \"Determine Utility by judging whether the information provided in the Retrieval Context enables a user to effectively answer the Input question; if not, identify gaps and suggest improvements.\"\n] \n \nRubric:\nNone \n \nScore: 0.922270013882531"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Compare the Input (monitoring question) with the Retrieval Context (metric description) to check if the description clearly addresses the question's focus.",
                            "Evaluate the Clarity of the Retrieval Context in relation to the Input by assessing whether the description is understandable and concise enough to answer the question directly.",
                            "Assess Coverage by verifying if the description fully explains what is measured, including units, relevant context, and implications that are necessary to address the Input's inquiry.",
                            "Determine Utility by judging whether the information provided in the Retrieval Context enables a user to effectively answer the Input question; if not, identify gaps and suggest improvements."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"cloudfront.amazonaws.com\\\", \\\"EventName\\\": \\\"Delete*\\\"}\", \"hyperparameters\": null, \"input\": \"Are there spikes in Delete* API calls to CloudFront, indicating potential resource removal impacting content delivery?\", \"retrieval_context\": [\" - This pattern captures CloudFront cache invalidation events recorded in CloudTrail, which occur when cached content is explicitly removed or refreshed to ensure users receive the latest versions of assets. For an SRE, monitoring these events helps track content deployment activities and detect potential operational issues such as excessive invalidations that may indicate misconfigurations or abuse.\\n\\n**Purpose:**  \\n- Identify when CloudFront distributions are updated via cache invalidations.  \\n- Correlate invalidation frequency with deployment cycles or troubleshooting efforts.\\n\\n**Alert Threshold Guidance:**  \\n- Trigger an alert if the number of invalidation requests exceeds a defined threshold within a short time window (e.g., more than 10 invalidations in 5 minutes), as this may signal abnormal activity or inefficient cache management.  \\n- Conversely, unusually low invalidation activity during expected deployment periods might indicate deployment failures or monitoring gaps.\\n\\n**Impact:**  \\n- **High invalidation rates:** Can increase latency and cost, as CloudFront must fetch fresh content from origin servers more frequently, potentially degrading user experience.  \\n- **Low invalidation rates:** May cause users to receive stale content, impacting application correctness and user satisfaction.\\n\\n**Example Usage:**  \\n- **Dashboard:** Display a time-series graph of invalidation event counts per minute to visualize spikes or drops in cache refresh activity.  \\n- **Alert Rule (pseudo-code):**  \\n  ```  \\n  WHEN count(EventName LIKE \\\"Invalidate*\\\") FROM cloudtrail  \\n  OVER last 5 minutes > 10  \\n  THEN alert \\\"High CloudFront invalidation rate detected\\\"  \\n  ```\", \" - This pattern captures ECS deletion events recorded in CloudTrail, specifically any API calls starting with \\\"Delete\\\" from the ECS service (e.g., DeleteCluster, DeleteService, DeleteTaskSet). Its purpose is to monitor when ECS resources are removed, which can signal intentional cleanup or unintended disruptions affecting service availability.\\n\\n**Threshold guidance:**  \\n- Trigger an alert if the number of ECS deletion events exceeds a baseline threshold within a short time window (e.g., more than 3 Delete* events in 5 minutes), as this may indicate accidental mass deletion or a security incident.  \\n- Low or expected deletion rates typically reflect routine maintenance or scaling down of resources and generally have minimal impact.\\n\\n**Impact:**  \\n- High deletion event counts can lead to service downtime, loss of running tasks, or cluster instability, requiring immediate investigation.  \\n- Low or zero deletion events usually indicate stable ECS resource management.\\n\\n**Example alert rule:**  \\n- Alert when `count(events where EventSource=\\\"ecs.amazonaws.com\\\" and EventName starts with \\\"Delete\\\") > 3` within 5 minutes.  \\n- This alert can be visualized on a dashboard showing ECS Delete* event counts over time, helping SREs quickly identify unusual spikes and correlate with service health metrics.\", \" - This pattern captures all CloudFront distribution creation events recorded in CloudTrail, identified by event names starting with \\\"Create\\\" from the CloudFront service. Its purpose is to monitor when new CloudFront distributions are provisioned, including their initial configuration details. Tracking these events helps SREs detect unexpected or unauthorized distribution creations that could impact content delivery, security, or cost.\\n\\n**Alert Threshold:**  \\nTrigger an alert if the number of CloudFront distribution creation events exceeds a defined threshold within a short time window (e.g., more than 3 creations within 1 hour), as this may indicate automation errors, misconfigurations, or potential security incidents.\\n\\n**Impact of Values:**  \\n- **High values:** A spike in creation events could signal rapid environment changes, possible misconfigurations, or unauthorized activity, potentially leading to increased costs or service disruptions.  \\n- **Low or zero values:** Normal operation typically involves infrequent distribution creations; zero or low values indicate stable infrastructure without unexpected provisioning.\\n\\n**Example Alert Rule:**  \\n\\\"Alert when count of events matching {EventSource: 'cloudfront.amazonaws.com', EventName: 'Create*'} exceeds 3 within 1 hour.\\\"\\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of CloudFront distribution creation events over time, enabling quick identification of unusual spikes or trends in distribution provisioning activity.\", \" - This pattern captures all EC2 resource deletion events recorded in CloudTrail, triggered by any API calls starting with \\\"Delete\\\" from the EC2 service (e.g., DeleteSecurityGroup, DeleteNetworkInterface). Its purpose is to monitor and alert on the removal of critical EC2 components, which can impact infrastructure stability and security.\\n\\n**Threshold guidance:**  \\n- Set an alert if the number of deletion events exceeds a baseline threshold within a short time window (e.g., more than 5 deletions in 10 minutes), as this may indicate accidental mass deletions or malicious activity.  \\n- A low or zero count is typical during normal operations, while sudden spikes warrant immediate investigation.\\n\\n**Impact:**  \\n- High deletion event counts can lead to service disruptions, loss of network connectivity, or security vulnerabilities if key resources like security groups or network interfaces are removed unexpectedly.  \\n- Low or no deletion activity generally indicates stable infrastructure management.\\n\\n**Example alert rule:**  \\nTrigger an alert when the count of events matching {\\\"EventSource\\\": \\\"ec2.amazonaws.com\\\", \\\"EventName\\\": \\\"Delete*\\\"} exceeds 5 within 10 minutes.\\n\\n**Example dashboard usage:**  \\nVisualize the count of EC2 deletion events over time to identify unusual spikes, correlating with other operational metrics to assess potential impact on system availability or security posture.\", \" - This pattern detects API calls to CloudFront that delete resources, such as distributions or configurations. It captures all events where the event name starts with \\\"Delete\\\" from the CloudFront service. The measurement is the count of deletion events recorded in AWS CloudTrail logs. Monitoring these events helps track resource removals that may impact content delivery or indicate cleanup activities.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": true,
                        "score": 0.8244692273408052,
                        "reason": "The retrieval context includes a specific pattern describing CloudFront Delete* API calls, explaining that it captures deletion events from CloudFront via CloudTrail, measuring counts of deletion events, and highlighting their impact on content delivery. The description is clear and concise, using terminology aligned with the question. It covers what is measured (deletion events), the context (CloudFront service), and implications (impact on content delivery). However, it lacks explicit units or threshold guidance for spikes and does not provide example alert rules or visualization details specifically for Delete* calls, which would improve utility for answering the monitoring question about spikes.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Compare the Input (monitoring question) and the Retrieval Context (metric description) to ensure the description directly addresses the question.\",\n    \"Evaluate the clarity of the description by checking if the language is understandable and concise in relation to the terms used in the question.\",\n    \"Assess the coverage by verifying the description explains what is measured, the units, the context, and the implications relevant to the question.\",\n    \"Determine the utility by judging whether the description provides enough information to answer the monitoring question effectively.\"\n] \n \nRubric:\nNone \n \nScore: 0.8244692273408052"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Compare the Input (monitoring question) and the Retrieval Context (metric description) to ensure the description directly addresses the question.",
                            "Evaluate the clarity of the description by checking if the language is understandable and concise in relation to the terms used in the question.",
                            "Assess the coverage by verifying the description explains what is measured, the units, the context, and the implications relevant to the question.",
                            "Determine the utility by judging whether the description provides enough information to answer the monitoring question effectively."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"cloudfront.amazonaws.com\\\", \\\"EventName\\\": \\\"Invalidate*\\\"}\", \"hyperparameters\": null, \"input\": \"Does the number of cache invalidations exceed ten, indicating a potential deployment issue or abuse?\", \"retrieval_context\": [\" - Lambda function \\\"Put*\\\" events in CloudTrail capture changes to function configurations, concurrency settings, event source mappings, and resource provisioning. These events indicate updates or deployments that can affect function behavior and performance. An SRE should monitor the frequency and success of these operations; unusually high rates of \\\"Put*\\\" events may signal automation errors or configuration churn, while absence of expected updates could indicate deployment issues. Alert thresholds might include more than 5 \\\"Put*\\\" events within 5 minutes or failed update attempts exceeding 10% of total \\\"Put*\\\" events. High volumes can lead to inconsistent function states or throttling, impacting availability and latency; low update activity during active development phases may delay critical fixes or optimizations. For example, a dashboard widget can track the count of \\\"Put*\\\" events per hour alongside error rates, and an alert rule could trigger when the number of failed \\\"Put*\\\" events surpasses a set threshold, prompting investigation into deployment or configuration problems.\", \" - This pattern captures CloudFront cache invalidation events recorded in CloudTrail, which occur when cached content is explicitly removed or refreshed to ensure users receive the latest versions of assets. For an SRE, monitoring these events helps track content deployment activities and detect potential operational issues such as excessive invalidations that may indicate misconfigurations or abuse.\\n\\n**Purpose:**  \\n- Identify when CloudFront distributions are updated via cache invalidations.  \\n- Correlate invalidation frequency with deployment cycles or troubleshooting efforts.\\n\\n**Alert Threshold Guidance:**  \\n- Trigger an alert if the number of invalidation requests exceeds a defined threshold within a short time window (e.g., more than 10 invalidations in 5 minutes), as this may signal abnormal activity or inefficient cache management.  \\n- Conversely, unusually low invalidation activity during expected deployment periods might indicate deployment failures or monitoring gaps.\\n\\n**Impact:**  \\n- **High invalidation rates:** Can increase latency and cost, as CloudFront must fetch fresh content from origin servers more frequently, potentially degrading user experience.  \\n- **Low invalidation rates:** May cause users to receive stale content, impacting application correctness and user satisfaction.\\n\\n**Example Usage:**  \\n- **Dashboard:** Display a time-series graph of invalidation event counts per minute to visualize spikes or drops in cache refresh activity.  \\n- **Alert Rule (pseudo-code):**  \\n  ```  \\n  WHEN count(EventName LIKE \\\"Invalidate*\\\") FROM cloudtrail  \\n  OVER last 5 minutes > 10  \\n  THEN alert \\\"High CloudFront invalidation rate detected\\\"  \\n  ```\", \" - This pattern captures ElastiCache reboot events recorded in CloudTrail, specifically any API calls starting with \\\"Reboot\\\" (e.g., RebootCacheCluster). It helps SREs monitor when ElastiCache nodes undergo reboots, which typically occur during maintenance, configuration changes, or troubleshooting. Frequent or unexpected reboots may indicate instability or underlying issues affecting cache availability and performance.\\n\\n**Alert Threshold:**  \\nTrigger an alert if the number of reboot events exceeds a defined threshold within a short time window (e.g., more than 3 reboots per node within 1 hour), as this may signal recurring failures or misconfigurations.\\n\\n**Impact:**  \\n- **High reboot frequency:** Can cause increased latency, cache misses, and potential downtime for applications relying on ElastiCache, impacting user experience and system reliability.  \\n- **Low or expected reboot frequency:** Indicates normal maintenance or controlled troubleshooting with minimal impact.\\n\\n**Example Alert Rule (CloudWatch or SIEM):**  \\nMonitor CloudTrail logs for events matching `{\\\"EventSource\\\": \\\"elasticache.amazonaws.com\\\", \\\"EventName\\\": \\\"Reboot*\\\"}` and trigger an alert if the count of such events per cache cluster exceeds 3 within 60 minutes. This helps proactively detect and respond to abnormal reboot patterns before they affect service stability.\", \" - This pattern captures all Amazon EKS \\\"Describe\\\" API operations logged in CloudTrail, which occur when cluster metadata, node group configurations, or add-on details are queried. It helps SREs monitor how often EKS cluster information is accessed, providing visibility into potential reconnaissance or troubleshooting activities. A sudden spike in Describe calls\\u2014such as exceeding 100 requests within 5 minutes\\u2014may indicate unusual or automated querying that could precede configuration changes or security incidents, warranting an alert. Conversely, consistently low or zero Describe activity might suggest lack of monitoring or insufficient operational visibility. For example, an alert rule could trigger when Describe API calls surpass 100 in a 5-minute window, and a dashboard widget might display a time series graph of Describe call counts to track trends and detect anomalies in cluster information access patterns.\", \" - This pattern captures all ECS update events recorded in CloudTrail, such as modifications to ECS services, task definitions, and cluster configurations. Its purpose is to monitor changes that could affect the stability, performance, or security of ECS workloads. An SRE should use this pattern to detect unexpected or frequent updates that may indicate configuration drift, deployment issues, or unauthorized changes.\\n\\n**Threshold guidance:**  \\n- Trigger an alert if the number of ECS update events exceeds a baseline threshold (e.g., more than 5 updates within 10 minutes), as this may signal rapid or unintended changes.  \\n- A low or zero count over a long period is typically normal but should be reviewed if updates are expected during deployments.\\n\\n**Impact:**  \\n- High frequency of update events can lead to service instability, deployment failures, or security risks if changes are unplanned or unauthorized.  \\n- Low frequency indicates stable ECS configurations but may also suggest stalled deployments or lack of necessary updates.\\n\\n**Example alert rule:**  \\n\\u201cAlert when the count of CloudTrail events with EventSource = 'ecs.amazonaws.com' and EventName starting with 'Update' exceeds 5 within a 10-minute window.\\u201d  \\n\\n**Example dashboard widget:**  \\nA time-series graph showing the count of ECS update events per 5-minute interval, annotated with deployment windows to correlate updates with expected changes.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": true,
                        "score": 0.9562176500885797,
                        "reason": "The retrieval context directly addresses the input question by explaining CloudFront cache invalidation events, their significance, and providing a clear alert threshold of more than 10 invalidations within 5 minutes, which matches the input's threshold. It is clear, concise, and uses terminology appropriate for an SRE audience. The context covers what is measured (cache invalidations), units (counts within time windows), relevant conditions (deployment cycles), and implications (potential misconfigurations or abuse). It also offers actionable guidance with example alert rules and dashboard usage, enabling effective monitoring and response.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Compare the Input (question) and Retrieval Context (description) to confirm the description addresses the specific monitoring question directly and sufficiently.\",\n    \"Evaluate the Clarity of the Retrieval Context in terms of how understandable and concise it is relative to the terminology and focus implied by the Input.\",\n    \"Assess Coverage by checking if the Retrieval Context explains key aspects like what is measured, units, relevant environment or conditions, and the implications that inform the Input's question.\",\n    \"Determine Utility by verifying whether the Retrieval Context provides actionable or insightful information that enables the user to effectively answer the Input's question.\"\n] \n \nRubric:\nNone \n \nScore: 0.9562176500885797"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Compare the Input (question) and Retrieval Context (description) to confirm the description addresses the specific monitoring question directly and sufficiently.",
                            "Evaluate the Clarity of the Retrieval Context in terms of how understandable and concise it is relative to the terminology and focus implied by the Input.",
                            "Assess Coverage by checking if the Retrieval Context explains key aspects like what is measured, units, relevant environment or conditions, and the implications that inform the Input's question.",
                            "Determine Utility by verifying whether the Retrieval Context provides actionable or insightful information that enables the user to effectively answer the Input's question."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"elasticloadbalancing.amazonaws.com\\\", \\\"EventName\\\": \\\"Deregister*\\\"}\", \"hyperparameters\": null, \"input\": \"Does the number of deregistration events exceed five within a short time window, indicating potential unexpected target removals?\", \"retrieval_context\": [\" - IAM Detach API events recorded by CloudTrail when IAM entities (users, groups, or roles) have policies detached from them. These events indicate the removal of permissions previously granted via managed or inline policies. Each event includes details such as the identity performing the detachment, the target entity, the detached policy ARN or name, timestamps, and request parameters. Metrics derived from these events typically count the number of detach operations over time (unit: count per minute/hour) sourced directly from CloudTrail logs. An unusual spike or unexpected detach activity\\u2014especially outside normal change windows or by unauthorized principals\\u2014may indicate potential privilege revocation due to security incidents, misconfigurations, or insider threats and should trigger an alert for immediate investigation.\", \" - IAM deletion events (e.g., DeleteUser, DeleteRole) recorded by CloudTrail indicate removal of IAM identities or permissions. These events are critical for detecting unauthorized or accidental deletions that can disrupt access or signal a security breach. An alert threshold should be set to trigger on any unexpected deletion event or a sudden spike above normal baseline activity (e.g., more than 1 deletion event within 5 minutes), as even a single deletion can have significant impact. High volumes may indicate automated attacks or misconfigurations causing mass access removal, while low or zero values typically indicate normal operation.  \\nExample alert rule: trigger when count of iam.amazonaws.com Delete* events > 1 in 5 minutes.  \\nExample dashboard widget: a time series graph showing Delete* event counts over time, annotated with alert thresholds to quickly identify unusual deletion activity.\", \" - This pattern captures ECS deletion events recorded in CloudTrail, specifically any API calls starting with \\\"Delete\\\" from the ECS service (e.g., DeleteCluster, DeleteService, DeleteTaskSet). Its purpose is to monitor when ECS resources are removed, which can signal intentional cleanup or unintended disruptions affecting service availability.\\n\\n**Threshold guidance:**  \\n- Trigger an alert if the number of ECS deletion events exceeds a baseline threshold within a short time window (e.g., more than 3 Delete* events in 5 minutes), as this may indicate accidental mass deletion or a security incident.  \\n- Low or expected deletion rates typically reflect routine maintenance or scaling down of resources and generally have minimal impact.\\n\\n**Impact:**  \\n- High deletion event counts can lead to service downtime, loss of running tasks, or cluster instability, requiring immediate investigation.  \\n- Low or zero deletion events usually indicate stable ECS resource management.\\n\\n**Example alert rule:**  \\n- Alert when `count(events where EventSource=\\\"ecs.amazonaws.com\\\" and EventName starts with \\\"Delete\\\") > 3` within 5 minutes.  \\n- This alert can be visualized on a dashboard showing ECS Delete* event counts over time, helping SREs quickly identify unusual spikes and correlate with service health metrics.\", \" - This pattern captures Elastic Load Balancing (ELB) target deregistration events from CloudTrail, indicating when backend targets (such as EC2 instances or IP addresses) are removed from a load balancer. These events typically occur during scaling operations, deployments, or maintenance activities that affect service availability.\\n\\n**Purpose:**  \\nMonitoring deregistration events helps SREs track changes in load balancer target groups, ensuring that scaling or maintenance actions do not inadvertently reduce capacity or cause service disruptions.\\n\\n**Alert Threshold Guidance:**  \\n- Trigger an alert if the number of deregistration events exceeds a defined threshold within a short time window (e.g., more than 5 deregistrations within 5 minutes), which may indicate unexpected or excessive target removals.  \\n- Conversely, a prolonged absence of deregistration events during expected scaling periods might signal issues with autoscaling or deployment processes.\\n\\n**Impact of Values:**  \\n- **High deregistration rate:** Could lead to reduced backend capacity, increased latency, or service outages if targets are removed too quickly or unexpectedly. Immediate investigation is warranted.  \\n- **Low or no deregistration events:** May indicate stable operations or, if scaling is expected, potential failures in scaling mechanisms.\\n\\n**Example Alert Rule:**  \\n```\\nWHEN count of events WHERE EventSource = \\\"elasticloadbalancing.amazonaws.com\\\" AND EventName LIKE \\\"Deregister%\\\"  \\nIN last 5 minutes > 5  \\nTHEN trigger alert \\\"High ELB Target Deregistration Rate\\\"\\n```\\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of deregistration events per minute, overlaid with thresholds, to visualize spikes or drops in deregistration activity aligned with deployment or scaling events.\", \" - This pattern captures all deletion events related to Elastic Load Balancers (ELBs) in AWS, as recorded by CloudTrail under the event source \\\"elasticloadbalancing.amazonaws.com\\\" with event names starting with \\\"Delete\\\". Its primary purpose is to monitor when ELBs are removed, which can be part of routine cleanup or indicate unintended service disruptions due to the loss of load balancing resources.\\n\\n**Purpose:**  \\nSREs use this pattern to track ELB deletions to quickly detect and investigate potential impacts on application availability and traffic routing.\\n\\n**Alert Threshold:**  \\nAn alert should be triggered if the number of ELB deletion events exceeds a predefined threshold within a short time window\\u2014for example, more than 1 deletion event within 5 minutes\\u2014since multiple deletions in quick succession may indicate a misconfiguration, automation error, or malicious activity.\\n\\n**Impact of Values:**  \\n- **High values:** Frequent or bulk ELB deletions can cause significant service disruption, leading to downtime or degraded performance due to loss of traffic distribution. Immediate investigation and remediation are required.  \\n- **Low values:** Occasional single deletions may be expected during normal maintenance or scaling operations and typically do not require urgent action but should still be logged for audit purposes.\\n\\n**Example Usage:**  \\nIn a monitoring dashboard or alert rule, you might configure a query to count ELB deletion events over a rolling 5-minute window and trigger an alert if the count exceeds 1. For example:\\n\\n```\\ncount_over_time({EventSource=\\\"elasticloadbalancing.amazonaws.com\\\", EventName=~\\\"Delete.*\\\"}[5m]) > 1\\n```\\n\\nThis alert helps ensure that unexpected or excessive ELB deletions are promptly detected and addressed to maintain service reliability.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": true,
                        "score": 0.9182425523806357,
                        "reason": "The retrieval context clearly and concisely addresses the input question by describing ELB target deregistration events, their typical causes, and the significance of monitoring them. It provides specific alert threshold guidance (e.g., more than 5 deregistrations within 5 minutes) directly aligned with the question about exceeding five events in a short time window. The description includes what is measured (deregistration events), units (count within time window), context (scaling, deployments, maintenance), and implications (potential service disruptions), enabling confident user understanding. The only minor shortcoming is the lack of explicit definition of the exact 'short time window' beyond the example, but overall coverage and clarity are strong.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Compare the Input (monitoring question) with the Retrieval Context (metric description) to check if the description clearly and concisely addresses the question.\",\n    \"Evaluate the clarity of the Retrieval Context by verifying if the metric description is understandable and free of ambiguity in relation to the Input question.\",\n    \"Assess the coverage in the Retrieval Context by confirming it explains what is measured, units, context, and implications that directly support answering the Input question.\",\n    \"Determine the utility of the Retrieval Context by judging whether the description enables the user to confidently answer the Input question; if not, identify specific gaps.\"\n] \n \nRubric:\nNone \n \nScore: 0.9182425523806357"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Compare the Input (monitoring question) with the Retrieval Context (metric description) to check if the description clearly and concisely addresses the question.",
                            "Evaluate the clarity of the Retrieval Context by verifying if the metric description is understandable and free of ambiguity in relation to the Input question.",
                            "Assess the coverage in the Retrieval Context by confirming it explains what is measured, units, context, and implications that directly support answering the Input question.",
                            "Determine the utility of the Retrieval Context by judging whether the description enables the user to confidently answer the Input question; if not, identify specific gaps."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"cloudfront.amazonaws.com\\\", \\\"EventName\\\": \\\"Update*\\\"}\", \"hyperparameters\": null, \"input\": \"Are these update events triggered by the CloudFront service causing modifications to CloudFront distributions?\", \"retrieval_context\": [\" - API Gateway update events. API modifications, configuration changes, and deployment updates. API versioning, performance tuning, and security policy updates.\", \" - This pattern captures CloudFront cache invalidation events recorded in CloudTrail, which occur when cached content is explicitly removed or refreshed to ensure users receive the latest versions of assets. For an SRE, monitoring these events helps track content deployment activities and detect potential operational issues such as excessive invalidations that may indicate misconfigurations or abuse.\\n\\n**Purpose:**  \\n- Identify when CloudFront distributions are updated via cache invalidations.  \\n- Correlate invalidation frequency with deployment cycles or troubleshooting efforts.\\n\\n**Alert Threshold Guidance:**  \\n- Trigger an alert if the number of invalidation requests exceeds a defined threshold within a short time window (e.g., more than 10 invalidations in 5 minutes), as this may signal abnormal activity or inefficient cache management.  \\n- Conversely, unusually low invalidation activity during expected deployment periods might indicate deployment failures or monitoring gaps.\\n\\n**Impact:**  \\n- **High invalidation rates:** Can increase latency and cost, as CloudFront must fetch fresh content from origin servers more frequently, potentially degrading user experience.  \\n- **Low invalidation rates:** May cause users to receive stale content, impacting application correctness and user satisfaction.\\n\\n**Example Usage:**  \\n- **Dashboard:** Display a time-series graph of invalidation event counts per minute to visualize spikes or drops in cache refresh activity.  \\n- **Alert Rule (pseudo-code):**  \\n  ```  \\n  WHEN count(EventName LIKE \\\"Invalidate*\\\") FROM cloudtrail  \\n  OVER last 5 minutes > 10  \\n  THEN alert \\\"High CloudFront invalidation rate detected\\\"  \\n  ```\", \" - This pattern captures CloudFront tagging events recorded in CloudTrail, specifically when CloudFront distributions are tagged or untagged. Tagging actions are critical for resource organization, cost allocation, and access management. Monitoring these events helps SREs detect unauthorized or unexpected changes to distribution metadata that could affect billing, security policies, or operational workflows.\\n\\n**Alert Threshold:**  \\nTrigger an alert if the number of CloudFront Tag* events exceeds a baseline threshold within a short time window (e.g., more than 5 tagging operations in 10 minutes), as this may indicate automated misconfigurations, potential security breaches, or bulk updates requiring review.\\n\\n**Impact of Values:**  \\n- **High frequency:** Could signal mass tagging/untagging possibly due to automation errors, policy violations, or malicious activity, potentially leading to misallocated costs or broken access controls.  \\n- **Low or zero frequency:** Normal state; tagging changes are typically infrequent and deliberate.\\n\\n**Example Usage:**  \\nIn a monitoring dashboard, plot the count of CloudFront Tag* events over time to visualize tagging activity spikes. An alert rule might be:  \\n`WHEN count(events where EventSource=\\\"cloudfront.amazonaws.com\\\" AND EventName LIKE \\\"Tag%\\\") > 5 within 10 minutes THEN trigger alert \\\"Unusual CloudFront tagging activity detected\\\"`  \\nThis enables proactive investigation and mitigation of tagging anomalies impacting resource governance.\", \" - This pattern captures all CloudFront distribution creation events recorded in CloudTrail, identified by event names starting with \\\"Create\\\" from the CloudFront service. Its purpose is to monitor when new CloudFront distributions are provisioned, including their initial configuration details. Tracking these events helps SREs detect unexpected or unauthorized distribution creations that could impact content delivery, security, or cost.\\n\\n**Alert Threshold:**  \\nTrigger an alert if the number of CloudFront distribution creation events exceeds a defined threshold within a short time window (e.g., more than 3 creations within 1 hour), as this may indicate automation errors, misconfigurations, or potential security incidents.\\n\\n**Impact of Values:**  \\n- **High values:** A spike in creation events could signal rapid environment changes, possible misconfigurations, or unauthorized activity, potentially leading to increased costs or service disruptions.  \\n- **Low or zero values:** Normal operation typically involves infrequent distribution creations; zero or low values indicate stable infrastructure without unexpected provisioning.\\n\\n**Example Alert Rule:**  \\n\\\"Alert when count of events matching {EventSource: 'cloudfront.amazonaws.com', EventName: 'Create*'} exceeds 3 within 1 hour.\\\"\\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of CloudFront distribution creation events over time, enabling quick identification of unusual spikes or trends in distribution provisioning activity.\", \" - This pattern captures all update events triggered by the CloudFront service. It specifically detects modifications to CloudFront distributions, such as changes to distribution settings, cache behaviors, and origin configurations. Each event represents a single update action performed on a CloudFront distribution. The unit of measurement is individual update events logged by AWS CloudTrail.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": true,
                        "score": 0.9222700138825308,
                        "reason": "The description directly addresses the question by explaining that the pattern captures update events triggered by CloudFront that modify distributions, including specific changes like distribution settings and cache behaviors. It is clear and concise, using terminology consistent with the question. The description covers what is measured (individual update events), the unit (events logged by CloudTrail), and relevant context (types of modifications). It provides actionable information for monitoring and alerting on these update events, effectively supporting the monitoring question. The only minor shortcoming is the lack of explicit alert threshold guidance or impact details, which slightly limits utility.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Compare the Input (metric description) with the Retrieval Context (monitoring question) to ensure the description directly addresses the question.\",\n    \"Evaluate the description's clarity by checking if it is understandable and concise in relation to the terminology and concepts used in the question.\",\n    \"Assess coverage by verifying if the description explains what is measured, units, relevant context, and implications necessary to answer the question.\",\n    \"Determine utility by confirming whether the description provides enough actionable information to effectively respond to the monitoring question.\"\n] \n \nRubric:\nNone \n \nScore: 0.9222700138825308"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Compare the Input (metric description) with the Retrieval Context (monitoring question) to ensure the description directly addresses the question.",
                            "Evaluate the description's clarity by checking if it is understandable and concise in relation to the terminology and concepts used in the question.",
                            "Assess coverage by verifying if the description explains what is measured, units, relevant context, and implications necessary to answer the question.",
                            "Determine utility by confirming whether the description provides enough actionable information to effectively respond to the monitoring question."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"cloudwatch.amazonaws.com\\\", \\\"EventName\\\": \\\"Put*\\\"}\", \"hyperparameters\": null, \"input\": \"Does the rate of Put* events exceed three times the baseline threshold, indicating potential automated scripts or unauthorized changes?\", \"retrieval_context\": [\" - Lambda function \\\"Put*\\\" events in CloudTrail capture changes to function configurations, concurrency settings, event source mappings, and resource provisioning. These events indicate updates or deployments that can affect function behavior and performance. An SRE should monitor the frequency and success of these operations; unusually high rates of \\\"Put*\\\" events may signal automation errors or configuration churn, while absence of expected updates could indicate deployment issues. Alert thresholds might include more than 5 \\\"Put*\\\" events within 5 minutes or failed update attempts exceeding 10% of total \\\"Put*\\\" events. High volumes can lead to inconsistent function states or throttling, impacting availability and latency; low update activity during active development phases may delay critical fixes or optimizations. For example, a dashboard widget can track the count of \\\"Put*\\\" events per hour alongside error rates, and an alert rule could trigger when the number of failed \\\"Put*\\\" events surpasses a set threshold, prompting investigation into deployment or configuration problems.\", \" - This pattern captures AWS KMS Decrypt API calls recorded in CloudTrail, indicating when encrypted data is accessed and decrypted using KMS keys. It helps SREs monitor data access events for security auditing and anomaly detection. A sudden spike in Decrypt events may signal unusual or unauthorized data access, while consistently low or expected volumes suggest normal operation. As a threshold, alerting on a sustained increase exceeding 3 standard deviations above the historical average or a sudden burst of Decrypt calls within a short time window (e.g., 5 minutes) is recommended. For example, an alert rule could trigger when the count of Decrypt events exceeds 100 in 5 minutes, indicating potential data exfiltration or misuse. In dashboards, tracking the rate of Decrypt events over time alongside user identities and key IDs can help quickly identify suspicious patterns or compromised credentials.\", \" - This pattern captures CloudWatch Logs Put operations, which occur when log events are written to log streams from applications, systems, or custom sources. In CloudTrail, these events indicate active ingestion of log data into CloudWatch Logs, essential for monitoring application health and troubleshooting.\\n\\n**Purpose:**  \\nMonitor the frequency and volume of log ingestion to detect anomalies such as sudden drops (potentially indicating logging failures or agent issues) or spikes (which may signal increased application activity or potential log flooding).\\n\\n**Alert Threshold Guidance:**  \\n- Trigger an alert if the number of Put operations drops below a baseline threshold for a sustained period (e.g., less than 50% of average daily Put events over 15 minutes), indicating possible logging disruptions.  \\n- Trigger an alert if Put operations spike above a defined upper threshold (e.g., 2x the average rate), which could indicate abnormal application behavior or excessive logging that may impact costs and performance.\\n\\n**Impact:**  \\n- **High values:** May lead to increased CloudWatch Logs ingestion costs and potential performance degradation; could also indicate abnormal application behavior or security events generating excessive logs.  \\n- **Low values:** May result in loss of critical log data, hindering troubleshooting and incident response.\\n\\n**Example Usage:**  \\nIn a monitoring dashboard or alert rule, track the count of CloudTrail events where `EventSource` is `logs.amazonaws.com` and `EventName` matches `Put*` over rolling 5-minute intervals. Set alerts to notify the SRE team if counts fall below or exceed defined thresholds, enabling timely investigation into logging pipeline health.\", \" - This pattern captures all CloudWatch API operations that begin with \\\"Put\\\", such as PutMetricData, PutLogEvents, and PutAlarm, indicating when CloudWatch resources or configurations are created, updated, or modified. In CloudTrail, monitoring these events helps SREs detect changes to monitoring metrics, log ingestion, and alarm settings that could impact observability or alerting behavior.\\n\\n**Threshold guidance:**  \\nAn alert should trigger if the rate of Put* events exceeds a baseline threshold (e.g., a sudden spike beyond normal operational patterns, such as a 3x increase within 5 minutes), which may indicate automated scripts or unauthorized changes modifying monitoring configurations. Conversely, an unusually low rate over an extended period might suggest disruptions in metric or log ingestion.\\n\\n**Impact:**  \\n- High volumes of Put* events can lead to configuration drift, unexpected alert noise, or resource misconfigurations affecting system reliability.  \\n- Low volumes may result in missing critical metrics or logs, reducing visibility into system health.\\n\\n**Example alert rule:**  \\nTrigger an alert when the count of CloudTrail events with EventSource = \\\"cloudwatch.amazonaws.com\\\" and EventName starting with \\\"Put\\\" exceeds 100 events within 5 minutes, signaling potential bulk updates to monitoring configurations that require investigation. This can be visualized in a dashboard showing Put* event counts over time alongside key system metrics to correlate changes with system behavior.\", \" - This pattern detects SNS topic creation events recorded in CloudTrail, specifically any API calls starting with \\\"Create\\\" from the SNS service (e.g., CreateTopic). It helps SREs monitor when new SNS topics are provisioned, which can indicate changes in messaging architecture or potential unauthorized resource creation. An alert threshold could be set on the number of Create* events within a given time window (e.g., more than 5 topic creations in 10 minutes), as a sudden spike may signal automation errors or security issues. Low or expected values typically indicate normal operations, while high values may impact system stability by increasing resource usage or indicate potential misuse. For example, an alert rule could trigger if the count of {\\\"EventSource\\\": \\\"sns.amazonaws.com\\\", \\\"EventName\\\": \\\"Create*\\\"} events exceeds 5 in 10 minutes, and a dashboard widget could display a time series graph of topic creation events to track trends and detect anomalies.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": true,
                        "score": 0.8962673116002448,
                        "reason": "The retrieval context directly addresses the monitoring question by explaining what 'Put*' events represent, their significance, and how spikes beyond baseline thresholds (including a 3x increase) may indicate automated scripts or unauthorized changes. It clearly describes measurement units (event counts over time), context (CloudTrail events affecting configurations and monitoring), and implications (configuration drift, alert noise, or security issues). The description is detailed and clear, providing threshold guidance and example alert rules, enabling effective user response. Minor complexity in the text slightly reduces immediate clarity but overall it is comprehensive and highly useful.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Compare the Input (monitoring question) and Retrieval Context (metric description) to ensure the description directly addresses the question.\",\n    \"Evaluate Clarity by checking if the description is understandable and concise, enabling quick comprehension of its relevance to the question.\",\n    \"Assess Coverage by verifying if the description explains what is measured, including units, context, and implications related to the question.\",\n    \"Judge Utility by determining if the description provides sufficient detail for the user to effectively answer the monitoring question.\"\n] \n \nRubric:\nNone \n \nScore: 0.8962673116002448"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Compare the Input (monitoring question) and Retrieval Context (metric description) to ensure the description directly addresses the question.",
                            "Evaluate Clarity by checking if the description is understandable and concise, enabling quick comprehension of its relevance to the question.",
                            "Assess Coverage by verifying if the description explains what is measured, including units, context, and implications related to the question.",
                            "Judge Utility by determining if the description provides sufficient detail for the user to effectively answer the monitoring question."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"route53.amazonaws.com\\\", \\\"EventName\\\": \\\"List*\\\"}\", \"hyperparameters\": null, \"input\": \"Are there spikes in List* API calls, indicating potential issues with resource retrieval?\", \"retrieval_context\": [\" - EKS List* events in CloudTrail capture API calls that enumerate EKS resources such as clusters, node groups, add-ons, and other related components. These operations are primarily read-only and used for infrastructure discovery, capacity planning, and operational visibility. Monitoring the frequency of List* calls helps detect unusual activity patterns: a sudden spike may indicate automated scanning, reconnaissance, or potential misuse, while an abnormally low rate could suggest monitoring gaps or service disruptions. A practical alert threshold might be set at a rate exceeding the baseline average by 3x within a 5-minute window. For example, a dashboard widget could track the count of eks.amazonaws.com List* events per minute, with an alert rule triggering when this count surpasses the defined threshold, enabling timely investigation of unexpected enumeration activity.\", \" - Resource listing operations (events with names starting with \\\"List\\\") in CloudTrail capture API calls that enumerate or retrieve metadata about cloud resources across services (e.g., ListBuckets, ListInstances). These events help SREs monitor inventory changes, detect unusual enumeration activity, and maintain infrastructure visibility. \\n\\n**Purpose:** Track and audit resource discovery actions to identify potential reconnaissance or automation behaviors.\\n\\n**Alert Threshold:** Trigger alerts when the rate of List* events exceeds a baseline by 3x within a 5-minute window, indicating possible automated scanning or misconfigured scripts.\\n\\n**Impact:**  \\n- **High values:** May signal excessive resource enumeration, potentially due to unauthorized scanning, automation loops, or misconfigured monitoring tools, increasing API costs and risk exposure.  \\n- **Low values:** Could indicate loss of visibility or failures in inventory processes, risking outdated infrastructure awareness.\\n\\n**Example Alert Rule:**  \\n`IF count(List*) > 300 events in 5 minutes THEN alert \\\"High resource enumeration activity detected\\\"`  \\n\\n**Dashboard Use:** Visualize List* event counts over time alongside other API calls to correlate spikes with deployments or incidents, aiding in capacity planning and anomaly detection.\", \" - S3 List operations (EventName starting with \\\"List\\\") in CloudTrail capture requests to enumerate buckets, list objects, or browse directories within S3. These events help track data discovery activities, such as inventory management or security reconnaissance attempts by identifying who is accessing or exploring bucket contents.  \\n\\n**Purpose:**  \\n- Monitor access patterns to detect unusual or excessive listing activity that may indicate unauthorized data exploration or reconnaissance.  \\n- Support auditing and compliance by providing visibility into how and when bucket contents are being queried.\\n\\n**Alert Threshold Guidance:**  \\n- Trigger alerts when the number of List operations exceeds a baseline threshold (e.g., a sudden spike above normal daily averages or a sustained high rate over a short period).  \\n- Thresholds should be customized per environment but a common starting point is alerting on a 3x increase over the average hourly count or more than 100 List requests per minute from a single principal or IP.\\n\\n**Impact of Values:**  \\n- **High values:** May indicate automated scanning, data scraping, or reconnaissance by malicious actors, potentially preceding data exfiltration attempts. Could also reflect legitimate bulk inventory or analytics jobs\\u2014context matters.  \\n- **Low values:** Normal or expected in environments with limited or infrequent bucket browsing; very low values typically pose no risk.\\n\\n**Example Usage:**  \\n- **Dashboard:** Visualize the count of List* events over time, segmented by user or source IP, to identify unusual spikes or patterns.  \\n- **Alert Rule (pseudo-code):**  \\n  ```  \\n  IF count(EventName LIKE \\\"List*\\\") BY user OVER 15 minutes > 3x baseline THEN alert(\\\"Unusual S3 List activity detected for user\\\")  \\n  ```  \\nThis enables proactive detection of suspicious enumeration behavior while minimizing false positives from routine operations.\", \" - This pattern captures CloudWatch API operations that list resources, such as metrics, log groups, and alarms, as recorded in CloudTrail under EventSource \\\"cloudwatch.amazonaws.com\\\" with EventNames starting with \\\"List\\\". It helps SREs monitor enumeration activity on CloudWatch resources, which can indicate normal operational queries or potential reconnaissance by unauthorized users.\\n\\n**Purpose:**  \\nTo track and analyze the frequency of CloudWatch resource listing actions, enabling detection of unusual spikes that may signal automated scanning, misconfigurations, or security incidents.\\n\\n**Threshold Guidance:**  \\nSet alert thresholds based on baseline activity for your environment. For example, trigger an alert if the number of List* events exceeds 3 standard deviations above the daily average or if more than 100 list operations occur within a 5-minute window, indicating abnormal enumeration.\\n\\n**Impact of Values:**  \\n- **High values:** May indicate excessive or automated querying of CloudWatch resources, potentially revealing reconnaissance attempts or inefficient scripts causing performance overhead.  \\n- **Low values:** Typically normal, but a sudden drop could suggest issues with monitoring tools or API access problems.\\n\\n**Example Alert Rule:**  \\nTrigger an alert when the count of CloudWatch List* events in CloudTrail exceeds 100 within 5 minutes, signaling potential unauthorized or excessive enumeration activity.\\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of CloudWatch List* events per 5-minute interval, overlaid with the alert threshold line, to visualize normal versus anomalous listing activity.\", \" - This pattern captures all Amazon EKS \\\"Describe\\\" API operations logged in CloudTrail, which occur when cluster metadata, node group configurations, or add-on details are queried. It helps SREs monitor how often EKS cluster information is accessed, providing visibility into potential reconnaissance or troubleshooting activities. A sudden spike in Describe calls\\u2014such as exceeding 100 requests within 5 minutes\\u2014may indicate unusual or automated querying that could precede configuration changes or security incidents, warranting an alert. Conversely, consistently low or zero Describe activity might suggest lack of monitoring or insufficient operational visibility. For example, an alert rule could trigger when Describe API calls surpass 100 in a 5-minute window, and a dashboard widget might display a time series graph of Describe call counts to track trends and detect anomalies in cluster information access patterns.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": true,
                        "score": 0.9,
                        "reason": "The retrieval context is highly relevant and directly addresses the question about spikes in List* API calls by explaining what these calls measure, providing alert thresholds, impacts of high and low values, and example alert rules. The language is clear and aligns well with the input terminology. Coverage is comprehensive, including measurement details, units (event counts over time), contextual background, and implications for potential issues. The description offers sufficient information for a user to confidently monitor and interpret spikes in List* API calls, though it could be slightly more concise.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Compare the Input (monitoring question) with the Retrieval Context (metric description) to assess if the description is relevant and directly addresses the question.\",\n    \"Evaluate Clarity by ensuring the description uses understandable language and concise phrasing that aligns with the terminology in the input question.\",\n    \"Assess Coverage by checking if the retrieval context explains what is measured, includes units, provides contextual background, and describes the implications relevant to the input question.\",\n    \"Determine Utility by verifying if the description provides sufficient information for a user to confidently answer the monitoring question posed in the input.\"\n] \n \nRubric:\nNone \n \nScore: 0.9"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Compare the Input (monitoring question) with the Retrieval Context (metric description) to assess if the description is relevant and directly addresses the question.",
                            "Evaluate Clarity by ensuring the description uses understandable language and concise phrasing that aligns with the terminology in the input question.",
                            "Assess Coverage by checking if the retrieval context explains what is measured, includes units, provides contextual background, and describes the implications relevant to the input question.",
                            "Determine Utility by verifying if the description provides sufficient information for a user to confidently answer the monitoring question posed in the input."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"cloudwatch.amazonaws.com\\\", \\\"EventName\\\": \\\"Create*\\\"}\", \"hyperparameters\": null, \"input\": \"Does the number of CloudTrail events for creating new CloudWatch resources exceed five?\", \"retrieval_context\": [\" - **{\\\"EventName\\\": \\\"Start*\\\"}** events in CloudTrail indicate the initiation of resource start operations across various AWS services, such as starting EC2 instances, RDS databases, or other managed resources. These events help SREs track when resources transition from a stopped or inactive state to an active state, which is critical for service availability, cost management, and operational recovery.\\n\\n**Purpose:**  \\nTo monitor and audit the activation of cloud resources, ensuring that start operations align with expected usage patterns and do not indicate unauthorized or unexpected activity.\\n\\n**Alert Thresholds:**  \\n- Trigger an alert if the number of **Start*** events exceeds a predefined threshold within a short time window (e.g., more than 10 start operations within 5 minutes), which may indicate an automated scaling event, a potential misconfiguration, or a security incident.  \\n- Conversely, alert if expected start operations do not occur during scheduled maintenance windows, indicating possible failures in recovery or deployment processes.\\n\\n**Impact of Values:**  \\n- **High volume of Start* events:** Could lead to increased costs due to resource activation, potential service disruptions if resources are started unexpectedly, or indicate automated scaling or recovery actions.  \\n- **Low or zero Start* events during expected periods:** May signal failed recovery attempts, stalled deployments, or issues in operational workflows, potentially impacting service availability.\\n\\n**Example Usage:**  \\nIn a CloudWatch dashboard, plot the count of **Start*** events over time to visualize spikes or drops. An alert rule can be configured as:  \\n```\\nIF count(Start* events) > 10 within 5 minutes THEN trigger alert \\\"Unusual spike in resource start operations\\\"\\n```\\nThis enables proactive investigation into unexpected resource activations or failures to start critical services.\", \" - This pattern captures CloudWatch API operations that list resources, such as metrics, log groups, and alarms, as recorded in CloudTrail under EventSource \\\"cloudwatch.amazonaws.com\\\" with EventNames starting with \\\"List\\\". It helps SREs monitor enumeration activity on CloudWatch resources, which can indicate normal operational queries or potential reconnaissance by unauthorized users.\\n\\n**Purpose:**  \\nTo track and analyze the frequency of CloudWatch resource listing actions, enabling detection of unusual spikes that may signal automated scanning, misconfigurations, or security incidents.\\n\\n**Threshold Guidance:**  \\nSet alert thresholds based on baseline activity for your environment. For example, trigger an alert if the number of List* events exceeds 3 standard deviations above the daily average or if more than 100 list operations occur within a 5-minute window, indicating abnormal enumeration.\\n\\n**Impact of Values:**  \\n- **High values:** May indicate excessive or automated querying of CloudWatch resources, potentially revealing reconnaissance attempts or inefficient scripts causing performance overhead.  \\n- **Low values:** Typically normal, but a sudden drop could suggest issues with monitoring tools or API access problems.\\n\\n**Example Alert Rule:**  \\nTrigger an alert when the count of CloudWatch List* events in CloudTrail exceeds 100 within 5 minutes, signaling potential unauthorized or excessive enumeration activity.\\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of CloudWatch List* events per 5-minute interval, overlaid with the alert threshold line, to visualize normal versus anomalous listing activity.\", \" - This pattern captures all CloudWatch API operations that begin with \\\"Put\\\", such as PutMetricData, PutLogEvents, and PutAlarm, indicating when CloudWatch resources or configurations are created, updated, or modified. In CloudTrail, monitoring these events helps SREs detect changes to monitoring metrics, log ingestion, and alarm settings that could impact observability or alerting behavior.\\n\\n**Threshold guidance:**  \\nAn alert should trigger if the rate of Put* events exceeds a baseline threshold (e.g., a sudden spike beyond normal operational patterns, such as a 3x increase within 5 minutes), which may indicate automated scripts or unauthorized changes modifying monitoring configurations. Conversely, an unusually low rate over an extended period might suggest disruptions in metric or log ingestion.\\n\\n**Impact:**  \\n- High volumes of Put* events can lead to configuration drift, unexpected alert noise, or resource misconfigurations affecting system reliability.  \\n- Low volumes may result in missing critical metrics or logs, reducing visibility into system health.\\n\\n**Example alert rule:**  \\nTrigger an alert when the count of CloudTrail events with EventSource = \\\"cloudwatch.amazonaws.com\\\" and EventName starting with \\\"Put\\\" exceeds 100 events within 5 minutes, signaling potential bulk updates to monitoring configurations that require investigation. This can be visualized in a dashboard showing Put* event counts over time alongside key system metrics to correlate changes with system behavior.\", \" - This pattern detects CloudTrail events where CloudWatch resources are created, such as alarms, dashboards, and log groups. Its purpose is to monitor the provisioning of new CloudWatch components, which can indicate changes in monitoring coverage or potential configuration drift. An alert should be triggered when the number of creation events exceeds a defined threshold within a short time window (e.g., more than 5 Create* events in 10 minutes), as a sudden spike may signal automated deployments, misconfigurations, or unauthorized activity. Conversely, a prolonged absence of creation events might suggest stagnation in monitoring updates or missed deployments. For example, in a monitoring dashboard, you can visualize the count of CloudWatch Create* events over time and set an alert rule to notify the SRE team if the event count surpasses the threshold, enabling timely investigation and response to unexpected changes in monitoring infrastructure.\", \" - This pattern detects SNS topic creation events recorded in CloudTrail, specifically any API calls starting with \\\"Create\\\" from the SNS service (e.g., CreateTopic). It helps SREs monitor when new SNS topics are provisioned, which can indicate changes in messaging architecture or potential unauthorized resource creation. An alert threshold could be set on the number of Create* events within a given time window (e.g., more than 5 topic creations in 10 minutes), as a sudden spike may signal automation errors or security issues. Low or expected values typically indicate normal operations, while high values may impact system stability by increasing resource usage or indicate potential misuse. For example, an alert rule could trigger if the count of {\\\"EventSource\\\": \\\"sns.amazonaws.com\\\", \\\"EventName\\\": \\\"Create*\\\"} events exceeds 5 in 10 minutes, and a dashboard widget could display a time series graph of topic creation events to track trends and detect anomalies.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": true,
                        "score": 0.8970687771633548,
                        "reason": "The description clearly aligns with the monitoring question by focusing on CloudTrail events for creating CloudWatch resources and specifies the threshold of more than 5 creation events within a short time window. It is detailed, understandable, and explains what is measured, including examples of resource types, alert conditions, and implications of spikes or absence of events. The only minor shortcoming is the lack of explicit units for the event count (though implied), but overall it provides sufficient information to effectively answer the question.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Compare the Input (monitoring question) with the Retrieval Context (metric description) to assess if the description clearly aligns with and addresses the question's focus.\",\n    \"Evaluate Clarity by determining if the metric description is understandable and concise in relation to the question's terminology and intent.\",\n    \"Assess Coverage by verifying that the description explains what is measured, including units, context, and implications relevant to the monitoring question.\",\n    \"Judge Utility by confirming if the description provides sufficient information to effectively answer the monitoring question; if not, identify specific gaps linking the description to the question.\"\n] \n \nRubric:\nNone \n \nScore: 0.8970687771633548"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Compare the Input (monitoring question) with the Retrieval Context (metric description) to assess if the description clearly aligns with and addresses the question's focus.",
                            "Evaluate Clarity by determining if the metric description is understandable and concise in relation to the question's terminology and intent.",
                            "Assess Coverage by verifying that the description explains what is measured, including units, context, and implications relevant to the monitoring question.",
                            "Judge Utility by confirming if the description provides sufficient information to effectively answer the monitoring question; if not, identify specific gaps linking the description to the question."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"route53.amazonaws.com\\\", \\\"EventName\\\": \\\"Get*\\\"}\", \"hyperparameters\": null, \"input\": \"Does a sudden spike in Route 53 \\\"Get\\\" API operations exceed 100 requests per hour?\", \"retrieval_context\": [\" - This pattern captures all Amazon EKS \\\"Describe\\\" API operations logged in CloudTrail, which occur when cluster metadata, node group configurations, or add-on details are queried. It helps SREs monitor how often EKS cluster information is accessed, providing visibility into potential reconnaissance or troubleshooting activities. A sudden spike in Describe calls\\u2014such as exceeding 100 requests within 5 minutes\\u2014may indicate unusual or automated querying that could precede configuration changes or security incidents, warranting an alert. Conversely, consistently low or zero Describe activity might suggest lack of monitoring or insufficient operational visibility. For example, an alert rule could trigger when Describe API calls surpass 100 in a 5-minute window, and a dashboard widget might display a time series graph of Describe call counts to track trends and detect anomalies in cluster information access patterns.\", \" - This pattern captures all Route 53 \\\"Get\\\" API operations logged in CloudTrail, such as retrieving hosted zone details, record sets, and health check statuses. It helps SREs monitor read access to DNS configurations and health data, which can indicate normal operational queries or potential reconnaissance activity. A sudden spike in these \\\"Get\\\" requests\\u2014exceeding a baseline threshold (e.g., 3 standard deviations above the average hourly rate)\\u2014may signal unusual interest in DNS infrastructure, warranting investigation. Conversely, a significant drop could indicate issues with monitoring or automation systems relying on these queries. For example, an alert rule could trigger when the count of **{\\\"EventSource\\\": \\\"route53.amazonaws.com\\\", \\\"EventName\\\": \\\"Get*\\\"}** events exceeds 100 requests per hour, and a dashboard widget might display a time series graph of these events to track trends and detect anomalies in DNS query activity.\", \" - This pattern captures all Route 53 deletion events recorded in CloudTrail, such as deleting hosted zones, record sets, or health checks. It helps SREs monitor when DNS configurations are removed, which could be part of routine cleanup or signal accidental or malicious disruptions to DNS resolution.\\n\\n**Purpose:**  \\nTrack and alert on Route 53 resource deletions to quickly detect potential service impact caused by DNS changes.\\n\\n**Alert Threshold:**  \\nTrigger an alert if more than 3 deletion events occur within a 10-minute window, as multiple deletions in a short period may indicate an ongoing incident or misconfiguration.\\n\\n**Impact:**  \\n- **High volume:** May cause widespread DNS outages or service disruptions, requiring immediate investigation.  \\n- **Low volume (single event):** Could be routine maintenance but should still be reviewed to confirm legitimacy.\\n\\n**Example Alert Rule:**  \\n\\u201cAlert when count of events matching {EventSource: route53.amazonaws.com, EventName: Delete*} exceeds 3 within 10 minutes.\\u201d\\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of Route 53 deletion events over time, with a threshold line at 3 events per 10 minutes to highlight potential issues.\", \" - This pattern captures all Route 53 resource creation events recorded in CloudTrail, such as the creation of hosted zones, DNS record sets, and health checks. Monitoring these events helps SREs detect configuration changes that could impact DNS resolution and application availability. \\n\\n**Purpose:** Track when new Route 53 resources are created to identify potential unauthorized changes or misconfigurations early.\\n\\n**Alert Threshold:** Trigger an alert if the number of creation events exceeds a baseline threshold (e.g., more than 5 creation events within 10 minutes), which may indicate automated misconfigurations, security breaches, or unintended mass changes.\\n\\n**Impact:**  \\n- **High values:** A spike in creation events could lead to DNS inconsistencies, increased attack surface, or service disruptions if malicious or erroneous resources are introduced.  \\n- **Low or zero values:** Normal operation, assuming no planned infrastructure changes.\\n\\n**Example Alert Rule:**  \\nAlert when `count({\\\"EventSource\\\": \\\"route53.amazonaws.com\\\", \\\"EventName\\\": \\\"Create*\\\"})` > 5 within 10 minutes.\\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of Route 53 creation events over time, enabling quick identification of unusual spikes in resource creation activity.\", \" - This pattern detects API calls made to Amazon Route 53 that begin with \\\"List,\\\" such as ListHostedZones, ListResourceRecordSets, and ListHealthChecks. It measures the count of these list operations performed within a given time frame. Each event corresponds to a single request to retrieve a collection of Route 53 resources. The unit of measurement is the number of list API calls executed.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": true,
                        "score": 0.9,
                        "reason": "The Retrieval Context clearly and concisely explains what is measured (Route 53 'Get' API operations), the units (requests per hour), and the operational context (monitoring read access to DNS configurations and detecting unusual spikes). It directly addresses the Input question by providing an example alert rule triggering when 'Get' requests exceed 100 per hour, enabling accurate interpretation and decision-making. Minor improvements could include explicitly defining the baseline threshold concept more clearly for users unfamiliar with statistical terms like '3 standard deviations above average.'",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Compare the Input (monitoring question) and Retrieval Context (metric description) to ensure the description is clearly understandable and concise relative to the question posed.\",\n    \"Evaluate whether the Retrieval Context sufficiently covers key aspects (what is measured, units, operational context, and implications), in a way that corresponds directly to the information needed to answer the Input question.\",\n    \"Assess the practical utility of the Retrieval Context for answering the Input question by verifying if the description enables accurate interpretation and decision-making relevant to the question.\",\n    \"If any of clarity, coverage, or utility is lacking when comparing Input and Retrieval Context, identify specific gaps or ambiguities and suggest targeted improvements to enhance alignment and informativeness.\"\n] \n \nRubric:\nNone \n \nScore: 0.9"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Compare the Input (monitoring question) and Retrieval Context (metric description) to ensure the description is clearly understandable and concise relative to the question posed.",
                            "Evaluate whether the Retrieval Context sufficiently covers key aspects (what is measured, units, operational context, and implications), in a way that corresponds directly to the information needed to answer the Input question.",
                            "Assess the practical utility of the Retrieval Context for answering the Input question by verifying if the description enables accurate interpretation and decision-making relevant to the question.",
                            "If any of clarity, coverage, or utility is lacking when comparing Input and Retrieval Context, identify specific gaps or ambiguities and suggest targeted improvements to enhance alignment and informativeness."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"cloudwatch.amazonaws.com\\\", \\\"EventName\\\": \\\"Delete*\\\"}\", \"hyperparameters\": null, \"input\": \"Are the Delete* events indicating a removal of CloudWatch resources that could impact monitoring?\", \"retrieval_context\": [\" - API Gateway deletion events captured by CloudTrail indicate when APIs, stages, or related resources are removed. These events are critical for tracking decommissioning activities, ensuring that endpoint removals are intentional and authorized, and preventing accidental service disruptions.  \\n\\n**Purpose:**  \\nMonitor all delete operations initiated via API Gateway (e.g., DeleteRestApi, DeleteStage) to maintain visibility into changes that reduce API surface area or remove critical endpoints.\\n\\n**Alert Threshold:**  \\nTrigger an alert if the number of Delete* events exceeds a predefined baseline within a short time window (e.g., more than 3 deletions within 10 minutes), as this may indicate accidental mass deletions, unauthorized activity, or a misconfigured automation script.\\n\\n**Impact:**  \\n- **High frequency:** Could lead to service outages, broken integrations, or data loss if APIs or stages are removed unexpectedly. Immediate investigation is required.  \\n- **Low or zero frequency:** Normal operation; deletion events are infrequent and typically planned.\\n\\n**Example Usage:**  \\nIn a monitoring dashboard, display a time series graph of Delete* events from apigateway.amazonaws.com. Set an alert rule such as:  \\n`IF count(Delete* events) > 3 within 10 minutes THEN trigger high-severity alert \\\"Potential API Gateway mass deletion detected\\\"`  \\nThis enables rapid response to potentially disruptive changes in the API infrastructure.\", \" - CloudFormation Delete* events in CloudTrail indicate the initiation or completion of stack deletion operations, signaling infrastructure teardown and resource decommissioning activities. These events help SREs monitor environment lifecycle changes and ensure that deletions are intentional and controlled. \\n\\n**Alert Threshold:** Trigger an alert if the number of Delete* events exceeds a predefined baseline (e.g., more than 3 deletions within 1 hour) or occurs unexpectedly outside of scheduled maintenance windows, as this may indicate accidental or malicious infrastructure removal.\\n\\n**Impact of Values:**  \\n- **High frequency:** May lead to unintended service disruptions, data loss, or compliance risks due to rapid or bulk resource deletions. Requires immediate investigation.  \\n- **Low or zero frequency:** Normal in stable environments; indicates no recent stack deletions and stable infrastructure.\\n\\n**Example Usage:**  \\nCreate a dashboard widget tracking the count of CloudFormation Delete* events over time. Set an alert rule to notify the SRE team if Delete* events spike above the threshold within a rolling 1-hour window, enabling prompt response to potential infrastructure teardown incidents.\", \" - IAM deletion events (e.g., DeleteUser, DeleteRole) recorded by CloudTrail indicate removal of IAM identities or permissions. These events are critical for detecting unauthorized or accidental deletions that can disrupt access or signal a security breach. An alert threshold should be set to trigger on any unexpected deletion event or a sudden spike above normal baseline activity (e.g., more than 1 deletion event within 5 minutes), as even a single deletion can have significant impact. High volumes may indicate automated attacks or misconfigurations causing mass access removal, while low or zero values typically indicate normal operation.  \\nExample alert rule: trigger when count of iam.amazonaws.com Delete* events > 1 in 5 minutes.  \\nExample dashboard widget: a time series graph showing Delete* event counts over time, annotated with alert thresholds to quickly identify unusual deletion activity.\", \" - This event pattern captures all CloudTrail events where CloudWatch Logs resources\\u2014such as log groups or log streams\\u2014are deleted (e.g., DeleteLogGroup, DeleteLogStream). Its purpose is to monitor and audit log deletion activities, which can be legitimate cleanup or indicate potential loss of critical log data needed for troubleshooting and compliance.\\n\\n**Alert Threshold:**  \\nTrigger an alert if the number of delete events exceeds a baseline threshold within a defined time window (e.g., more than 3 deletions within 1 hour), or if deletions occur unexpectedly outside of scheduled maintenance windows.\\n\\n**Impact:**  \\n- **High frequency of deletions:** May indicate accidental or malicious removal of logs, risking loss of observability and forensic data. Immediate investigation is recommended.  \\n- **Low or zero deletions:** Normal operation, indicating logs are retained as expected.\\n\\n**Example Alert Rule:**  \\n\\u201cAlert if DeleteLogGroup or DeleteLogStream events from logs.amazonaws.com exceed 3 occurrences in 60 minutes.\\u201d  \\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of Delete* events over time, annotated with alert thresholds and maintenance windows, enabling quick identification of unusual spikes in log deletions.\", \" - This pattern captures CloudWatch deletion events. It identifies when CloudWatch resources are removed, which can indicate cleanup operations or potential monitoring loss incidents.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": true,
                        "score": 0.9,
                        "reason": "The retrieval context directly addresses the input question by explaining that Delete* events capture CloudWatch resource deletions, indicating potential monitoring loss. It clearly defines what is measured (deletion events), provides examples (DeleteLogGroup, DeleteLogStream), explains the impact (risk of losing observability and forensic data), and includes alert thresholds and usage examples. The description is detailed, clear, and concise, offering sufficient information to understand the implications of these events on monitoring. The only minor shortcoming is the slight complexity due to multiple event types, but overall it effectively supports the input question.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Compare the Input (monitoring question) with the Retrieval Context (metric description) to ensure the description directly addresses the question.\",\n    \"Evaluate Clarity by checking if the Retrieval Context is understandable and concise in relation to the terminology and concepts used in the Input.\",\n    \"Assess Coverage by verifying the description explains what is measured, units, context, and implications explicitly enough to support the Input question.\",\n    \"Judge Utility by determining if the Retrieval Context provides sufficient relevant information to effectively answer the Input question.\"\n] \n \nRubric:\nNone \n \nScore: 0.9"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Compare the Input (monitoring question) with the Retrieval Context (metric description) to ensure the description directly addresses the question.",
                            "Evaluate Clarity by checking if the Retrieval Context is understandable and concise in relation to the terminology and concepts used in the Input.",
                            "Assess Coverage by verifying the description explains what is measured, units, context, and implications explicitly enough to support the Input question.",
                            "Judge Utility by determining if the Retrieval Context provides sufficient relevant information to effectively answer the Input question."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"cloudwatch.amazonaws.com\\\", \\\"EventName\\\": \\\"Get*\\\"}\", \"hyperparameters\": null, \"input\": \"Are there spikes in Get* API calls to CloudWatch services indicating excessive data retrieval?\", \"retrieval_context\": [\" - S3 Get* events in CloudTrail capture all read operations on S3 objects, such as GetObject, GetObjectAcl, and GetObjectVersion. These events indicate when data is accessed or downloaded from your buckets, providing critical visibility into data retrieval patterns and potential unauthorized access.  \\n\\n**Purpose:** Monitor and audit object read activity to detect unusual access spikes, potential data exfiltration, or performance bottlenecks caused by excessive reads.\\n\\n**Alert Threshold:** Trigger an alert if the number of Get* events exceeds a baseline threshold (e.g., a 3x increase over the average hourly rate) or if access occurs from unexpected IP addresses or principals.\\n\\n**Impact:**  \\n- **High values:** May indicate heavy data consumption, possible data leakage, or abuse of resources leading to increased costs and degraded application performance.  \\n- **Low values:** Could suggest reduced usage, potential application issues, or misconfigured permissions blocking legitimate access.\\n\\n**Example Alert Rule:**  \\nAlert when the count of s3.amazonaws.com Get* events in CloudTrail exceeds 5000 within 1 hour, or when access originates from an IP address outside your trusted network range.\\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing hourly counts of Get* events per bucket, combined with a heatmap of source IP addresses, enabling quick identification of unusual access patterns or spikes in data retrieval.\", \" - This pattern captures CloudWatch API operations that list resources, such as metrics, log groups, and alarms, as recorded in CloudTrail under EventSource \\\"cloudwatch.amazonaws.com\\\" with EventNames starting with \\\"List\\\". It helps SREs monitor enumeration activity on CloudWatch resources, which can indicate normal operational queries or potential reconnaissance by unauthorized users.\\n\\n**Purpose:**  \\nTo track and analyze the frequency of CloudWatch resource listing actions, enabling detection of unusual spikes that may signal automated scanning, misconfigurations, or security incidents.\\n\\n**Threshold Guidance:**  \\nSet alert thresholds based on baseline activity for your environment. For example, trigger an alert if the number of List* events exceeds 3 standard deviations above the daily average or if more than 100 list operations occur within a 5-minute window, indicating abnormal enumeration.\\n\\n**Impact of Values:**  \\n- **High values:** May indicate excessive or automated querying of CloudWatch resources, potentially revealing reconnaissance attempts or inefficient scripts causing performance overhead.  \\n- **Low values:** Typically normal, but a sudden drop could suggest issues with monitoring tools or API access problems.\\n\\n**Example Alert Rule:**  \\nTrigger an alert when the count of CloudWatch List* events in CloudTrail exceeds 100 within 5 minutes, signaling potential unauthorized or excessive enumeration activity.\\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of CloudWatch List* events per 5-minute interval, overlaid with the alert threshold line, to visualize normal versus anomalous listing activity.\", \" - This pattern captures CloudWatch Logs retrieval operations (any API call starting with \\\"Get\\\") recorded in CloudTrail, such as GetLogEvents and GetQueryResults. Its purpose is to monitor access to log data, helping SREs detect unusual or excessive log reads that may indicate troubleshooting activity, data exfiltration, or unauthorized access.\\n\\n**Threshold guidance:**  \\n- Trigger an alert if the number of Get* events exceeds a baseline by 3x within a 5-minute window, or if there is a sudden spike compared to historical averages.  \\n- Low or normal values typically indicate routine log access during debugging or monitoring.\\n\\n**Impact:**  \\n- High values may signal active investigation, potential security incidents, or misuse of log data.  \\n- Low values generally reflect normal operations with minimal log retrieval.\\n\\n**Example alert rule:**  \\n\\u201cAlert when logs.amazonaws.com Get* events exceed 100 calls in 5 minutes.\\u201d  \\n\\n**Example dashboard usage:**  \\nVisualize the count of Get* events over time to identify spikes in log access, correlating with incident response or suspicious activity. This helps ensure log data is accessed appropriately and supports timely detection of anomalies.\", \" - This pattern captures all Route 53 \\\"Get\\\" API operations logged in CloudTrail, such as retrieving hosted zone details, record sets, and health check statuses. It helps SREs monitor read access to DNS configurations and health data, which can indicate normal operational queries or potential reconnaissance activity. A sudden spike in these \\\"Get\\\" requests\\u2014exceeding a baseline threshold (e.g., 3 standard deviations above the average hourly rate)\\u2014may signal unusual interest in DNS infrastructure, warranting investigation. Conversely, a significant drop could indicate issues with monitoring or automation systems relying on these queries. For example, an alert rule could trigger when the count of **{\\\"EventSource\\\": \\\"route53.amazonaws.com\\\", \\\"EventName\\\": \\\"Get*\\\"}** events exceeds 100 requests per hour, and a dashboard widget might display a time series graph of these events to track trends and detect anomalies in DNS query activity.\", \" - This pattern captures all Systems Manager (SSM) \\\"Get\\\" operations recorded in CloudTrail, such as retrieving parameters from Parameter Store, downloading SSM documents, or requesting instance information. It helps SREs monitor read access to SSM resources, which can indicate normal operational queries or potential reconnaissance activity by unauthorized users.\\n\\n**Purpose:**  \\nTrack and analyze the frequency of SSM \\\"Get\\\" API calls to detect unusual spikes or drops in read operations that may impact system performance or signal security concerns.\\n\\n**Alert Threshold Guidance:**  \\nSet alert thresholds based on baseline usage patterns. For example, trigger an alert if the number of \\\"Get\\\" operations exceeds 2-3 times the average hourly rate within a short time window (e.g., 5-15 minutes), or if there is a sudden drop to near zero, which might indicate service disruption or misconfiguration.\\n\\n**Impact of Values:**  \\n- **High values:** May indicate automated scripts, bulk data retrieval, or potential reconnaissance by attackers trying to gather system details. Excessive reads can also increase API costs or cause throttling.  \\n- **Low values:** Could suggest issues with monitoring tools, broken automation, or loss of visibility into SSM-managed resources.\\n\\n**Example Usage:**  \\nIn a CloudWatch dashboard or alert rule, aggregate CloudTrail events filtered by `{\\\"EventSource\\\": \\\"ssm.amazonaws.com\\\", \\\"EventName\\\": \\\"Get*\\\"}` and plot the count over time. Configure an alarm to notify the SRE team if the count spikes above the defined threshold within a 15-minute window, enabling rapid investigation of unusual access patterns.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": true,
                        "score": 0.8999999999999998,
                        "reason": "The retrieval context thoroughly addresses the input question by describing multiple CloudWatch Get* API call patterns, including their purpose, threshold guidance, impact, and example alert rules. It clearly explains what is measured (Get* API calls), the units (counts over time windows), and the implications of spikes, enabling confident detection of excessive data retrieval. The description is detailed and mostly clear, though the inclusion of multiple service patterns (SSM, Route 53, S3) alongside CloudWatch slightly reduces conciseness and focus on the specific CloudWatch Get* calls mentioned in the input.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Compare the Input (monitoring question) and Retrieval Context (metric description) to ensure the description clearly addresses the question.\",\n    \"Evaluate the clarity of the Retrieval Context by checking if it is concise and easily understandable in relation to the terminology and intent of the Input.\",\n    \"Assess the coverage by confirming the description explains what is measured, the units involved, and the metric\u2019s context and implications relevant to the Input.\",\n    \"Determine the utility by verifying whether the Retrieval Context provides enough information to confidently answer the Input question; if not, identify missing details.\"\n] \n \nRubric:\nNone \n \nScore: 0.8999999999999998"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Compare the Input (monitoring question) and Retrieval Context (metric description) to ensure the description clearly addresses the question.",
                            "Evaluate the clarity of the Retrieval Context by checking if it is concise and easily understandable in relation to the terminology and intent of the Input.",
                            "Assess the coverage by confirming the description explains what is measured, the units involved, and the metric\u2019s context and implications relevant to the Input.",
                            "Determine the utility by verifying whether the Retrieval Context provides enough information to confidently answer the Input question; if not, identify missing details."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"logs.amazonaws.com\\\", \\\"EventName\\\": \\\"Create*\\\"}\", \"hyperparameters\": null, \"input\": \"Are there spikes in Create* API calls to AWS CloudWatch Logs indicating potential resource overprovisioning?\", \"retrieval_context\": [\" - CloudFormation stack creation events (**EventSource: cloudformation.amazonaws.com**, **EventName: Create\\\\*** ) represent API calls initiating the provisioning of AWS infrastructure and resources via CloudFormation templates. These events in CloudTrail help SREs monitor the start of environment setups and infrastructure deployments as part of Infrastructure as Code workflows.\\n\\n**Purpose:** Track and audit when new CloudFormation stacks or stack components are being created, enabling visibility into changes in infrastructure state and deployment activities.\\n\\n**Alert Thresholds:**  \\n- Trigger an alert if the number of Create* events exceeds a baseline threshold within a short time window (e.g., >10 stack creation attempts in 5 minutes), which may indicate automated deployment loops, misconfigurations, or potential security incidents.  \\n- Alert if Create* events spike unexpectedly outside of scheduled deployment windows or change management periods.\\n\\n**Impact of Values:**  \\n- **High volume:** May signal rapid infrastructure changes that could lead to instability, resource contention, or deployment failures. It could also indicate unauthorized or accidental mass provisioning.  \\n- **Low or zero volume:** Normal during steady-state operations; however, a sudden drop during expected deployment windows might indicate pipeline failures or blocked deployments.\\n\\n**Example Usage:**  \\n- **Dashboard:** Visualize the count of CloudFormation Create* events over time, segmented by stack name or user identity, to correlate deployments with system performance or incidents.  \\n- **Alert Rule:**  \\n  ```  \\n  WHEN count(events where EventSource=\\\"cloudformation.amazonaws.com\\\" AND EventName LIKE \\\"Create%\\\") > 10 within 5 minutes  \\n  THEN trigger alert \\\"High rate of CloudFormation stack creation events detected\\\"  \\n  ```  \\nThis enables proactive detection of abnormal infrastructure provisioning activity and supports rapid investigation and response.\", \" - Redshift cluster creation events in CloudTrail capture all API calls initiating the provisioning of new Redshift clusters (e.g., CreateCluster). These events indicate when new data warehouse resources are being deployed or configured, impacting capacity and cost.  \\n**Purpose:** Enables SREs to monitor and audit cluster provisioning activities for operational control and security compliance.  \\n**Alert Threshold:** Trigger alerts on an unusually high number of cluster creation events within a short time window (e.g., >3 creates in 1 hour), which may indicate automation errors, misconfigurations, or unauthorized resource provisioning.  \\n**Impact:**  \\n- **High values:** May lead to resource sprawl, increased costs, and potential performance degradation due to over-provisioning. Could also signal security risks if unexpected clusters are created.  \\n- **Low or zero values:** Normal in stable environments; no new clusters being created means stable infrastructure.  \\n**Example Alert Rule:**  \\n\\u201cAlert if count of events with EventSource='redshift.amazonaws.com' and EventName starting with 'Create' exceeds 3 within 60 minutes.\\u201d  \\n**Dashboard Use:** Visualize the frequency of Redshift cluster creation events over time to detect spikes or anomalies, correlating with deployment activities or security incidents.\", \" - S3 bucket creation events captured by CloudTrail under **{\\\"EventSource\\\": \\\"s3.amazonaws.com\\\", \\\"EventName\\\": \\\"Create*\\\"}** indicate when new buckets or related resources (e.g., bucket policies, access points) are provisioned. These events help SREs monitor infrastructure changes that affect data storage, security posture, and compliance.\\n\\n**Purpose:**  \\nTrack and audit the creation of S3 buckets and associated configurations to ensure proper governance, prevent unauthorized resource sprawl, and maintain compliance with organizational policies.\\n\\n**Alert Threshold:**  \\nTrigger an alert if the number of S3 bucket creation events exceeds a defined threshold within a short time window (e.g., more than 5 bucket creations within 10 minutes), which may indicate automated provisioning errors, misconfigurations, or potential security incidents such as unauthorized resource creation.\\n\\n**Impact of Values:**  \\n- **High frequency:** May signal abnormal activity, such as a compromised credential or runaway automation scripts creating excessive buckets, leading to increased costs, security risks, or compliance violations.  \\n- **Low or zero frequency:** Normal in stable environments; however, sudden spikes should be investigated promptly.\\n\\n**Example Alert Rule:**  \\n\\u201cAlert when count of events with EventSource = 's3.amazonaws.com' and EventName starting with 'Create' exceeds 5 within 10 minutes.\\u201d\\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of S3 Create* events over time, with thresholds marked to highlight unusual spikes, enabling quick identification of abnormal bucket creation activity.\", \" - This pattern captures all Route 53 resource creation events recorded in CloudTrail, such as the creation of hosted zones, DNS record sets, and health checks. Monitoring these events helps SREs detect configuration changes that could impact DNS resolution and application availability. \\n\\n**Purpose:** Track when new Route 53 resources are created to identify potential unauthorized changes or misconfigurations early.\\n\\n**Alert Threshold:** Trigger an alert if the number of creation events exceeds a baseline threshold (e.g., more than 5 creation events within 10 minutes), which may indicate automated misconfigurations, security breaches, or unintended mass changes.\\n\\n**Impact:**  \\n- **High values:** A spike in creation events could lead to DNS inconsistencies, increased attack surface, or service disruptions if malicious or erroneous resources are introduced.  \\n- **Low or zero values:** Normal operation, assuming no planned infrastructure changes.\\n\\n**Example Alert Rule:**  \\nAlert when `count({\\\"EventSource\\\": \\\"route53.amazonaws.com\\\", \\\"EventName\\\": \\\"Create*\\\"})` > 5 within 10 minutes.\\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of Route 53 creation events over time, enabling quick identification of unusual spikes in resource creation activity.\", \" - This pattern detects CloudTrail events where CloudWatch resources are created, such as alarms, dashboards, and log groups. Its purpose is to monitor the provisioning of new CloudWatch components, which can indicate changes in monitoring coverage or potential configuration drift. An alert should be triggered when the number of creation events exceeds a defined threshold within a short time window (e.g., more than 5 Create* events in 10 minutes), as a sudden spike may signal automated deployments, misconfigurations, or unauthorized activity. Conversely, a prolonged absence of creation events might suggest stagnation in monitoring updates or missed deployments. For example, in a monitoring dashboard, you can visualize the count of CloudWatch Create* events over time and set an alert rule to notify the SRE team if the event count surpasses the threshold, enabling timely investigation and response to unexpected changes in monitoring infrastructure.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": true,
                        "score": 0.873105859034899,
                        "reason": "The retrieval context directly addresses the question by describing Create* API calls in CloudWatch Logs and related AWS services, explaining how spikes indicate potential resource overprovisioning. It is clear and detailed, providing alert thresholds, impacts, and example alert rules. The context covers what is measured, units (event counts over time), and implications relevant to the input question. Minor deduction is due to the context being somewhat broad across multiple AWS services rather than focused solely on CloudWatch Logs, but it still provides sufficient detail for confident user interpretation.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Compare the Input (monitoring question) with the Retrieval Context (metric description) to ensure the description directly addresses the question.\",\n    \"Evaluate Clarity by checking if the Retrieval Context is understandable and concise relative to the terminology and complexity of the Input question.\",\n    \"Assess Coverage by verifying if the Retrieval Context explains what is measured, including units, context, and the implications relevant to the Input question.\",\n    \"Determine Utility by confirming if the Retrieval Context provides sufficient detail to help a user confidently answer the Input question.\"\n] \n \nRubric:\nNone \n \nScore: 0.873105859034899"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Compare the Input (monitoring question) with the Retrieval Context (metric description) to ensure the description directly addresses the question.",
                            "Evaluate Clarity by checking if the Retrieval Context is understandable and concise relative to the terminology and complexity of the Input question.",
                            "Assess Coverage by verifying if the Retrieval Context explains what is measured, including units, context, and the implications relevant to the Input question.",
                            "Determine Utility by confirming if the Retrieval Context provides sufficient detail to help a user confidently answer the Input question."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"route53.amazonaws.com\\\", \\\"EventName\\\": \\\"Delete*\\\"}\", \"hyperparameters\": null, \"input\": \"Are there more than three Route 53 deletion events occurring in a short period, indicating a potential service impact?\", \"retrieval_context\": [\" - This pattern captures ECS deletion events recorded in CloudTrail, specifically any API calls starting with \\\"Delete\\\" from the ECS service (e.g., DeleteCluster, DeleteService, DeleteTaskSet). Its purpose is to monitor when ECS resources are removed, which can signal intentional cleanup or unintended disruptions affecting service availability.\\n\\n**Threshold guidance:**  \\n- Trigger an alert if the number of ECS deletion events exceeds a baseline threshold within a short time window (e.g., more than 3 Delete* events in 5 minutes), as this may indicate accidental mass deletion or a security incident.  \\n- Low or expected deletion rates typically reflect routine maintenance or scaling down of resources and generally have minimal impact.\\n\\n**Impact:**  \\n- High deletion event counts can lead to service downtime, loss of running tasks, or cluster instability, requiring immediate investigation.  \\n- Low or zero deletion events usually indicate stable ECS resource management.\\n\\n**Example alert rule:**  \\n- Alert when `count(events where EventSource=\\\"ecs.amazonaws.com\\\" and EventName starts with \\\"Delete\\\") > 3` within 5 minutes.  \\n- This alert can be visualized on a dashboard showing ECS Delete* event counts over time, helping SREs quickly identify unusual spikes and correlate with service health metrics.\", \" - This pattern captures Route 53 change events. It identifies when Route 53 resources are modified, including record set changes, health check updates, and routing policy modifications.\", \" - This pattern captures all Route 53 \\\"Get\\\" API operations logged in CloudTrail, such as retrieving hosted zone details, record sets, and health check statuses. It helps SREs monitor read access to DNS configurations and health data, which can indicate normal operational queries or potential reconnaissance activity. A sudden spike in these \\\"Get\\\" requests\\u2014exceeding a baseline threshold (e.g., 3 standard deviations above the average hourly rate)\\u2014may signal unusual interest in DNS infrastructure, warranting investigation. Conversely, a significant drop could indicate issues with monitoring or automation systems relying on these queries. For example, an alert rule could trigger when the count of **{\\\"EventSource\\\": \\\"route53.amazonaws.com\\\", \\\"EventName\\\": \\\"Get*\\\"}** events exceeds 100 requests per hour, and a dashboard widget might display a time series graph of these events to track trends and detect anomalies in DNS query activity.\", \" - This pattern captures all Route 53 deletion events recorded in CloudTrail, such as deleting hosted zones, record sets, or health checks. It helps SREs monitor when DNS configurations are removed, which could be part of routine cleanup or signal accidental or malicious disruptions to DNS resolution.\\n\\n**Purpose:**  \\nTrack and alert on Route 53 resource deletions to quickly detect potential service impact caused by DNS changes.\\n\\n**Alert Threshold:**  \\nTrigger an alert if more than 3 deletion events occur within a 10-minute window, as multiple deletions in a short period may indicate an ongoing incident or misconfiguration.\\n\\n**Impact:**  \\n- **High volume:** May cause widespread DNS outages or service disruptions, requiring immediate investigation.  \\n- **Low volume (single event):** Could be routine maintenance but should still be reviewed to confirm legitimacy.\\n\\n**Example Alert Rule:**  \\n\\u201cAlert when count of events matching {EventSource: route53.amazonaws.com, EventName: Delete*} exceeds 3 within 10 minutes.\\u201d\\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of Route 53 deletion events over time, with a threshold line at 3 events per 10 minutes to highlight potential issues.\", \" - This pattern captures all Route 53 resource creation events recorded in CloudTrail, such as the creation of hosted zones, DNS record sets, and health checks. Monitoring these events helps SREs detect configuration changes that could impact DNS resolution and application availability. \\n\\n**Purpose:** Track when new Route 53 resources are created to identify potential unauthorized changes or misconfigurations early.\\n\\n**Alert Threshold:** Trigger an alert if the number of creation events exceeds a baseline threshold (e.g., more than 5 creation events within 10 minutes), which may indicate automated misconfigurations, security breaches, or unintended mass changes.\\n\\n**Impact:**  \\n- **High values:** A spike in creation events could lead to DNS inconsistencies, increased attack surface, or service disruptions if malicious or erroneous resources are introduced.  \\n- **Low or zero values:** Normal operation, assuming no planned infrastructure changes.\\n\\n**Example Alert Rule:**  \\nAlert when `count({\\\"EventSource\\\": \\\"route53.amazonaws.com\\\", \\\"EventName\\\": \\\"Create*\\\"})` > 5 within 10 minutes.\\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of Route 53 creation events over time, enabling quick identification of unusual spikes in resource creation activity.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": true,
                        "score": 0.9148047203670104,
                        "reason": "The retrieval context directly addresses the input question by describing Route 53 deletion events, including the alert threshold of more than 3 deletions within 10 minutes, which matches the input's concern about multiple deletions in a short period. The language is clear and concise, explaining what is measured (deletion events), the units (count within 10 minutes), context (potential service impact), and implications (possible DNS outages). The context provides sufficient detail to answer the question effectively, though it could slightly improve by explicitly defining 'short period' as 10 minutes upfront for absolute clarity.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Compare the Input (monitoring question) with the Retrieval Context (metric description) to assess if the description directly addresses the question.\",\n    \"Evaluate the Clarity of the Retrieval Context in relation to the Input by checking if the description uses understandable and concise language pertinent to the question.\",\n    \"Assess the Coverage of the Retrieval Context by verifying if it explains what is measured, units, context, and implications relevant to the Input question.\",\n    \"Judge the Utility by determining if the Retrieval Context provides enough information to answer the Input question effectively, suggesting improvements if gaps exist.\"\n] \n \nRubric:\nNone \n \nScore: 0.9148047203670104"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Compare the Input (monitoring question) with the Retrieval Context (metric description) to assess if the description directly addresses the question.",
                            "Evaluate the Clarity of the Retrieval Context in relation to the Input by checking if the description uses understandable and concise language pertinent to the question.",
                            "Assess the Coverage of the Retrieval Context by verifying if it explains what is measured, units, context, and implications relevant to the Input question.",
                            "Judge the Utility by determining if the Retrieval Context provides enough information to answer the Input question effectively, suggesting improvements if gaps exist."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"cloudwatch.amazonaws.com\\\", \\\"EventName\\\": \\\"List*\\\"}\", \"hyperparameters\": null, \"input\": \"Do spikes in CloudWatch resource listing actions exceed baseline thresholds, indicating potential reconnaissance or misconfiguration?\", \"retrieval_context\": [\" - **{\\\"EventName\\\": \\\"Start*\\\"}** events in CloudTrail indicate the initiation of resource start operations across various AWS services, such as starting EC2 instances, RDS databases, or other managed resources. These events help SREs track when resources transition from a stopped or inactive state to an active state, which is critical for service availability, cost management, and operational recovery.\\n\\n**Purpose:**  \\nTo monitor and audit the activation of cloud resources, ensuring that start operations align with expected usage patterns and do not indicate unauthorized or unexpected activity.\\n\\n**Alert Thresholds:**  \\n- Trigger an alert if the number of **Start*** events exceeds a predefined threshold within a short time window (e.g., more than 10 start operations within 5 minutes), which may indicate an automated scaling event, a potential misconfiguration, or a security incident.  \\n- Conversely, alert if expected start operations do not occur during scheduled maintenance windows, indicating possible failures in recovery or deployment processes.\\n\\n**Impact of Values:**  \\n- **High volume of Start* events:** Could lead to increased costs due to resource activation, potential service disruptions if resources are started unexpectedly, or indicate automated scaling or recovery actions.  \\n- **Low or zero Start* events during expected periods:** May signal failed recovery attempts, stalled deployments, or issues in operational workflows, potentially impacting service availability.\\n\\n**Example Usage:**  \\nIn a CloudWatch dashboard, plot the count of **Start*** events over time to visualize spikes or drops. An alert rule can be configured as:  \\n```\\nIF count(Start* events) > 10 within 5 minutes THEN trigger alert \\\"Unusual spike in resource start operations\\\"\\n```\\nThis enables proactive investigation into unexpected resource activations or failures to start critical services.\", \" - Resource listing operations (events with names starting with \\\"List\\\") in CloudTrail capture API calls that enumerate or retrieve metadata about cloud resources across services (e.g., ListBuckets, ListInstances). These events help SREs monitor inventory changes, detect unusual enumeration activity, and maintain infrastructure visibility. \\n\\n**Purpose:** Track and audit resource discovery actions to identify potential reconnaissance or automation behaviors.\\n\\n**Alert Threshold:** Trigger alerts when the rate of List* events exceeds a baseline by 3x within a 5-minute window, indicating possible automated scanning or misconfigured scripts.\\n\\n**Impact:**  \\n- **High values:** May signal excessive resource enumeration, potentially due to unauthorized scanning, automation loops, or misconfigured monitoring tools, increasing API costs and risk exposure.  \\n- **Low values:** Could indicate loss of visibility or failures in inventory processes, risking outdated infrastructure awareness.\\n\\n**Example Alert Rule:**  \\n`IF count(List*) > 300 events in 5 minutes THEN alert \\\"High resource enumeration activity detected\\\"`  \\n\\n**Dashboard Use:** Visualize List* event counts over time alongside other API calls to correlate spikes with deployments or incidents, aiding in capacity planning and anomaly detection.\", \" - S3 List operations (EventName starting with \\\"List\\\") in CloudTrail capture requests to enumerate buckets, list objects, or browse directories within S3. These events help track data discovery activities, such as inventory management or security reconnaissance attempts by identifying who is accessing or exploring bucket contents.  \\n\\n**Purpose:**  \\n- Monitor access patterns to detect unusual or excessive listing activity that may indicate unauthorized data exploration or reconnaissance.  \\n- Support auditing and compliance by providing visibility into how and when bucket contents are being queried.\\n\\n**Alert Threshold Guidance:**  \\n- Trigger alerts when the number of List operations exceeds a baseline threshold (e.g., a sudden spike above normal daily averages or a sustained high rate over a short period).  \\n- Thresholds should be customized per environment but a common starting point is alerting on a 3x increase over the average hourly count or more than 100 List requests per minute from a single principal or IP.\\n\\n**Impact of Values:**  \\n- **High values:** May indicate automated scanning, data scraping, or reconnaissance by malicious actors, potentially preceding data exfiltration attempts. Could also reflect legitimate bulk inventory or analytics jobs\\u2014context matters.  \\n- **Low values:** Normal or expected in environments with limited or infrequent bucket browsing; very low values typically pose no risk.\\n\\n**Example Usage:**  \\n- **Dashboard:** Visualize the count of List* events over time, segmented by user or source IP, to identify unusual spikes or patterns.  \\n- **Alert Rule (pseudo-code):**  \\n  ```  \\n  IF count(EventName LIKE \\\"List*\\\") BY user OVER 15 minutes > 3x baseline THEN alert(\\\"Unusual S3 List activity detected for user\\\")  \\n  ```  \\nThis enables proactive detection of suspicious enumeration behavior while minimizing false positives from routine operations.\", \" - This pattern captures CloudWatch API operations that list resources, such as metrics, log groups, and alarms, as recorded in CloudTrail under EventSource \\\"cloudwatch.amazonaws.com\\\" with EventNames starting with \\\"List\\\". It helps SREs monitor enumeration activity on CloudWatch resources, which can indicate normal operational queries or potential reconnaissance by unauthorized users.\\n\\n**Purpose:**  \\nTo track and analyze the frequency of CloudWatch resource listing actions, enabling detection of unusual spikes that may signal automated scanning, misconfigurations, or security incidents.\\n\\n**Threshold Guidance:**  \\nSet alert thresholds based on baseline activity for your environment. For example, trigger an alert if the number of List* events exceeds 3 standard deviations above the daily average or if more than 100 list operations occur within a 5-minute window, indicating abnormal enumeration.\\n\\n**Impact of Values:**  \\n- **High values:** May indicate excessive or automated querying of CloudWatch resources, potentially revealing reconnaissance attempts or inefficient scripts causing performance overhead.  \\n- **Low values:** Typically normal, but a sudden drop could suggest issues with monitoring tools or API access problems.\\n\\n**Example Alert Rule:**  \\nTrigger an alert when the count of CloudWatch List* events in CloudTrail exceeds 100 within 5 minutes, signaling potential unauthorized or excessive enumeration activity.\\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of CloudWatch List* events per 5-minute interval, overlaid with the alert threshold line, to visualize normal versus anomalous listing activity.\", \" - This pattern captures all Systems Manager (SSM) \\\"Get\\\" operations recorded in CloudTrail, such as retrieving parameters from Parameter Store, downloading SSM documents, or requesting instance information. It helps SREs monitor read access to SSM resources, which can indicate normal operational queries or potential reconnaissance activity by unauthorized users.\\n\\n**Purpose:**  \\nTrack and analyze the frequency of SSM \\\"Get\\\" API calls to detect unusual spikes or drops in read operations that may impact system performance or signal security concerns.\\n\\n**Alert Threshold Guidance:**  \\nSet alert thresholds based on baseline usage patterns. For example, trigger an alert if the number of \\\"Get\\\" operations exceeds 2-3 times the average hourly rate within a short time window (e.g., 5-15 minutes), or if there is a sudden drop to near zero, which might indicate service disruption or misconfiguration.\\n\\n**Impact of Values:**  \\n- **High values:** May indicate automated scripts, bulk data retrieval, or potential reconnaissance by attackers trying to gather system details. Excessive reads can also increase API costs or cause throttling.  \\n- **Low values:** Could suggest issues with monitoring tools, broken automation, or loss of visibility into SSM-managed resources.\\n\\n**Example Usage:**  \\nIn a CloudWatch dashboard or alert rule, aggregate CloudTrail events filtered by `{\\\"EventSource\\\": \\\"ssm.amazonaws.com\\\", \\\"EventName\\\": \\\"Get*\\\"}` and plot the count over time. Configure an alarm to notify the SRE team if the count spikes above the defined threshold within a 15-minute window, enabling rapid investigation of unusual access patterns.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": true,
                        "score": 0.9,
                        "reason": "The Retrieval Context is clear and concise, directly addressing CloudWatch resource listing actions with detailed explanations of what is measured, including event sources, event names, and the significance of spikes. It provides threshold guidance with specific numeric examples and implications of high and low values, fully relevant to the Input question about spikes exceeding baseline thresholds indicating reconnaissance or misconfiguration. The context offers sufficient information to assist in answering the question, including example alert rules and dashboard visualizations. Minor improvements could include explicitly stating units for baseline thresholds (e.g., daily average) more consistently and clarifying the exact metric units, but overall coverage and utility are strong.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Assess Clarity by checking if the Input (monitoring question) and Retrieval Context (metric description) are both understandable and concise when examined together.\",\n    \"Evaluate Coverage by verifying that the Retrieval Context fully explains what is measured, including units and implications, and is relevant to the Input question.\",\n    \"Determine Utility by confirming the Retrieval Context provides sufficient information to directly answer or assist with the Input question.\",\n    \"If any criterion scores below 8, identify specific areas where the Retrieval Context lacks detail or clarity relative to the Input and suggest improvements accordingly.\"\n] \n \nRubric:\nNone \n \nScore: 0.9"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Assess Clarity by checking if the Input (monitoring question) and Retrieval Context (metric description) are both understandable and concise when examined together.",
                            "Evaluate Coverage by verifying that the Retrieval Context fully explains what is measured, including units and implications, and is relevant to the Input question.",
                            "Determine Utility by confirming the Retrieval Context provides sufficient information to directly answer or assist with the Input question.",
                            "If any criterion scores below 8, identify specific areas where the Retrieval Context lacks detail or clarity relative to the Input and suggest improvements accordingly."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"elasticache.amazonaws.com\\\", \\\"EventName\\\": \\\"Failover*\\\"}\", \"hyperparameters\": null, \"input\": \"Does the number of ElastiCache failover events exceed one within an hour, indicating potential hardware problems or misconfiguration?\", \"retrieval_context\": [\" - This pattern captures CloudTrail events where ElastiCache clusters are modified, including scaling operations (e.g., changing node count or instance types), parameter group updates, and configuration changes. It helps SREs monitor critical changes that can impact cache performance, availability, or cost.\\n\\n**Purpose:**  \\nDetect when ElastiCache resources are altered to ensure changes are intentional, authorized, and do not degrade system stability.\\n\\n**Alert Threshold:**  \\nTrigger an alert on any **Modify\\\\*** event to catch all configuration changes. For noisy environments, consider alerting only on modifications that increase or decrease node count by more than 1, or changes to parameter groups affecting performance-critical settings.\\n\\n**Impact of Values:**  \\n- **High frequency of Modify events:** May indicate repeated scaling or configuration changes, potentially causing instability or unexpected behavior.  \\n- **Low or zero Modify events:** Suggests stable cache configuration, but lack of changes during scaling needs may indicate missed updates.\\n\\n**Example Alert Rule:**  \\nAlert when an event with `EventSource = \\\"elasticache.amazonaws.com\\\"` and `EventName` matching `Modify*` occurs, optionally filtering for changes in node count or parameter group names. This can be visualized in a dashboard showing a timeline of modification events alongside cluster performance metrics to correlate changes with impact.\", \" - This pattern captures ElastiCache reboot events recorded in CloudTrail, specifically any API calls starting with \\\"Reboot\\\" (e.g., RebootCacheCluster). It helps SREs monitor when ElastiCache nodes undergo reboots, which typically occur during maintenance, configuration changes, or troubleshooting. Frequent or unexpected reboots may indicate instability or underlying issues affecting cache availability and performance.\\n\\n**Alert Threshold:**  \\nTrigger an alert if the number of reboot events exceeds a defined threshold within a short time window (e.g., more than 3 reboots per node within 1 hour), as this may signal recurring failures or misconfigurations.\\n\\n**Impact:**  \\n- **High reboot frequency:** Can cause increased latency, cache misses, and potential downtime for applications relying on ElastiCache, impacting user experience and system reliability.  \\n- **Low or expected reboot frequency:** Indicates normal maintenance or controlled troubleshooting with minimal impact.\\n\\n**Example Alert Rule (CloudWatch or SIEM):**  \\nMonitor CloudTrail logs for events matching `{\\\"EventSource\\\": \\\"elasticache.amazonaws.com\\\", \\\"EventName\\\": \\\"Reboot*\\\"}` and trigger an alert if the count of such events per cache cluster exceeds 3 within 60 minutes. This helps proactively detect and respond to abnormal reboot patterns before they affect service stability.\", \" - This pattern captures all ElastiCache deletion events recorded in CloudTrail, specifically any API calls starting with \\\"Delete\\\" (e.g., DeleteCacheCluster, DeleteReplicationGroup). Its primary purpose is to monitor when ElastiCache resources are removed, which can signal intentional cleanup or unintended cache loss that may impact application performance or availability.\\n\\n**Alert Threshold:**  \\nTrigger an alert if more than 1 deletion event occurs within a 5-minute window, as multiple deletions in a short period may indicate a misconfiguration, automation error, or potential security incident.\\n\\n**Impact:**  \\n- **High frequency:** Multiple deletions can lead to significant cache data loss, increased latency due to cache warm-up, or service disruption. Immediate investigation is required.  \\n- **Low frequency (single event):** Usually expected during planned maintenance or scaling down, but should still be reviewed to confirm authorization.\\n\\n**Example Alert Rule:**  \\n- **Condition:** Count of events matching {\\\"EventSource\\\": \\\"elasticache.amazonaws.com\\\", \\\"EventName\\\": \\\"Delete*\\\"} > 1 in 5 minutes  \\n- **Action:** Send notification to SRE team and trigger incident response workflow.\\n\\n**Dashboard Use Case:**  \\nVisualize the count of ElastiCache deletion events over time to quickly identify spikes or unusual patterns, correlating with deployment or incident timelines for root cause analysis.\", \" - This pattern captures all update-related events from Amazon EKS recorded in CloudTrail, such as cluster version upgrades, managed node group modifications, and add-on updates. Its purpose is to monitor changes that can affect cluster stability, security, or performance. An SRE should set alert thresholds based on the frequency and timing of these update events\\u2014for example, triggering an alert if more than 3 update events occur within a 1-hour window, which may indicate unexpected or automated changes that require investigation. High volumes of update events in a short period could signal potential configuration drift, deployment issues, or unauthorized modifications, increasing risk to cluster availability and security. Conversely, low or no update events over extended periods may suggest stagnation in maintenance or missed critical updates. An example alert rule could be: \\u201cAlert if count of events matching {EventSource: 'eks.amazonaws.com', EventName: 'Update*'} exceeds 3 within 60 minutes.\\u201d In a dashboard, this pattern can be visualized as a time series graph showing update event counts per hour, helping SREs quickly identify unusual spikes or trends in cluster modifications.\", \" - This pattern detects ElastiCache failover events recorded in CloudTrail, indicating when a primary node in a cluster is replaced due to failure or maintenance to maintain high availability. Monitoring these events helps SREs quickly identify potential service disruptions or instability in cache performance.\\n\\n**Purpose:**  \\nTrack failover occurrences to ensure cluster resilience and detect abnormal failover frequency that may signal underlying issues.\\n\\n**Alert Threshold:**  \\nTrigger an alert if the number of failover events exceeds a defined threshold within a given time window (e.g., more than 1 failover per hour or 3 failovers within 24 hours), as frequent failovers can degrade application performance and availability.\\n\\n**Impact:**  \\n- **High failover frequency:** May indicate hardware problems, network instability, or misconfiguration, potentially causing increased latency or downtime. Immediate investigation and remediation are required.  \\n- **Low or zero failovers:** Reflects stable cluster operation and healthy failover mechanisms.\\n\\n**Example Alert Rule:**  \\nAlert when `count({\\\"EventSource\\\": \\\"elasticache.amazonaws.com\\\", \\\"EventName\\\": \\\"Failover*\\\"}) > 1` within 1 hour.\\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of ElastiCache failover events per hour, enabling trend analysis and rapid detection of spikes in failovers.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": true,
                        "score": 0.901798621308753,
                        "reason": "The description clearly addresses the monitoring question by focusing on ElastiCache failover events and their implications, including alert thresholds (e.g., more than 1 failover per hour) that directly relate to the question. It uses clear, concise language and covers what is measured (failover events), the units (count per hour), context (CloudTrail events indicating primary node replacement), and impact (potential hardware problems or misconfiguration). The inclusion of example alert rules and dashboard widgets enhances utility, enabling accurate response to the question. The only minor shortcoming is the lack of explicit mention of the exact one-hour window in the initial explanation, though it is implied and detailed in the alert threshold and example rule.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Compare the metric description (Retrieval Context) with the monitoring question (Input) to assess if the description clearly addresses the question's focus.\",\n    \"Evaluate the description for clarity by checking if it uses understandable language and is concise in explaining the metric relevant to the question.\",\n    \"Assess coverage by verifying if the description includes what is measured, the units, the context, and the implications necessary to answer the question.\",\n    \"Determine utility by judging whether the description enables the user to accurately respond to the monitoring question; if not, identify specific missing elements.\"\n] \n \nRubric:\nNone \n \nScore: 0.901798621308753"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Compare the metric description (Retrieval Context) with the monitoring question (Input) to assess if the description clearly addresses the question's focus.",
                            "Evaluate the description for clarity by checking if it uses understandable language and is concise in explaining the metric relevant to the question.",
                            "Assess coverage by verifying if the description includes what is measured, the units, the context, and the implications necessary to answer the question.",
                            "Determine utility by judging whether the description enables the user to accurately respond to the monitoring question; if not, identify specific missing elements."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"logs.amazonaws.com\\\", \\\"EventName\\\": \\\"Delete*\\\"}\", \"hyperparameters\": null, \"input\": \"Are there more than three DeleteLogGroup or DeleteLogStream events from logs.amazonaws.com, indicating potential loss of critical log data?\", \"retrieval_context\": [\" - This event pattern captures all CloudTrail events where CloudWatch Logs resources\\u2014such as log groups or log streams\\u2014are deleted (e.g., DeleteLogGroup, DeleteLogStream). Its purpose is to monitor and audit log deletion activities, which can be legitimate cleanup or indicate potential loss of critical log data needed for troubleshooting and compliance.\\n\\n**Alert Threshold:**  \\nTrigger an alert if the number of delete events exceeds a baseline threshold within a defined time window (e.g., more than 3 deletions within 1 hour), or if deletions occur unexpectedly outside of scheduled maintenance windows.\\n\\n**Impact:**  \\n- **High frequency of deletions:** May indicate accidental or malicious removal of logs, risking loss of observability and forensic data. Immediate investigation is recommended.  \\n- **Low or zero deletions:** Normal operation, indicating logs are retained as expected.\\n\\n**Example Alert Rule:**  \\n\\u201cAlert if DeleteLogGroup or DeleteLogStream events from logs.amazonaws.com exceed 3 occurrences in 60 minutes.\\u201d  \\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of Delete* events over time, annotated with alert thresholds and maintenance windows, enabling quick identification of unusual spikes in log deletions.\", \" - This pattern captures CloudWatch deletion events. It identifies when CloudWatch resources are removed, which can indicate cleanup operations or potential monitoring loss incidents.\", \" - This pattern captures DynamoDB deletion events. It identifies when DynamoDB tables are removed, which can indicate cleanup operations or potential data loss incidents.\", \" - This pattern captures ECS deletion events recorded in CloudTrail, specifically any API calls starting with \\\"Delete\\\" from the ECS service (e.g., DeleteCluster, DeleteService, DeleteTaskSet). Its purpose is to monitor when ECS resources are removed, which can signal intentional cleanup or unintended disruptions affecting service availability.\\n\\n**Threshold guidance:**  \\n- Trigger an alert if the number of ECS deletion events exceeds a baseline threshold within a short time window (e.g., more than 3 Delete* events in 5 minutes), as this may indicate accidental mass deletion or a security incident.  \\n- Low or expected deletion rates typically reflect routine maintenance or scaling down of resources and generally have minimal impact.\\n\\n**Impact:**  \\n- High deletion event counts can lead to service downtime, loss of running tasks, or cluster instability, requiring immediate investigation.  \\n- Low or zero deletion events usually indicate stable ECS resource management.\\n\\n**Example alert rule:**  \\n- Alert when `count(events where EventSource=\\\"ecs.amazonaws.com\\\" and EventName starts with \\\"Delete\\\") > 3` within 5 minutes.  \\n- This alert can be visualized on a dashboard showing ECS Delete* event counts over time, helping SREs quickly identify unusual spikes and correlate with service health metrics.\", \" - This pattern captures all Route 53 deletion events recorded in CloudTrail, such as deleting hosted zones, record sets, or health checks. It helps SREs monitor when DNS configurations are removed, which could be part of routine cleanup or signal accidental or malicious disruptions to DNS resolution.\\n\\n**Purpose:**  \\nTrack and alert on Route 53 resource deletions to quickly detect potential service impact caused by DNS changes.\\n\\n**Alert Threshold:**  \\nTrigger an alert if more than 3 deletion events occur within a 10-minute window, as multiple deletions in a short period may indicate an ongoing incident or misconfiguration.\\n\\n**Impact:**  \\n- **High volume:** May cause widespread DNS outages or service disruptions, requiring immediate investigation.  \\n- **Low volume (single event):** Could be routine maintenance but should still be reviewed to confirm legitimacy.\\n\\n**Example Alert Rule:**  \\n\\u201cAlert when count of events matching {EventSource: route53.amazonaws.com, EventName: Delete*} exceeds 3 within 10 minutes.\\u201d\\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of Route 53 deletion events over time, with a threshold line at 3 events per 10 minutes to highlight potential issues.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": true,
                        "score": 0.9,
                        "reason": "The input clearly asks if there are more than three DeleteLogGroup or DeleteLogStream events from logs.amazonaws.com indicating potential log data loss. The retrieval context provides a detailed, clear, and concise description of these events, including what is measured (delete events of CloudWatch Logs resources), the relevant units (number of events within a time window), and the implications (potential loss of critical log data). It also includes an explicit alert threshold matching the input's query (more than 3 deletions within 1 hour) and explains the impact and example alert rules, enabling confident answering of the input question. Minor deduction is due to the retrieval context being part of a larger list with some unrelated entries, which slightly reduces focus but does not impair clarity or utility.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Evaluate the Input (monitoring question) for clarity and specificity to determine if it sets a clear requirement for the metric description.\",\n    \"Assess the Retrieval Context (metric description) for clarity, ensuring it is understandable and concise in relation to the question.\",\n    \"Check Coverage by verifying if the Retrieval Context explains what is measured, including units, context, and implications that relate directly to the Input.\",\n    \"Determine Utility by confirming that the Retrieval Context provides sufficient information to confidently answer the Input question, linking the description's details to the question's needs.\"\n] \n \nRubric:\nNone \n \nScore: 0.9"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Evaluate the Input (monitoring question) for clarity and specificity to determine if it sets a clear requirement for the metric description.",
                            "Assess the Retrieval Context (metric description) for clarity, ensuring it is understandable and concise in relation to the question.",
                            "Check Coverage by verifying if the Retrieval Context explains what is measured, including units, context, and implications that relate directly to the Input.",
                            "Determine Utility by confirming that the Retrieval Context provides sufficient information to confidently answer the Input question, linking the description's details to the question's needs."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"logs.amazonaws.com\\\", \\\"EventName\\\": \\\"Put*\\\"}\", \"hyperparameters\": null, \"input\": \"Does a sustained drop in Put operations below 50% of average daily events indicate possible logging disruptions?\", \"retrieval_context\": [\" - **{\\\"EventName\\\": \\\"Stop*\\\"}**  \\nThis event captures all resource stop operations across cloud services, such as stopping virtual machines, containers, or other compute resources. It signals intentional halting of resources for cost optimization, maintenance, or deactivation purposes.  \\n\\n**Purpose:**  \\nTo monitor when resources are stopped, enabling tracking of operational changes that affect availability and cost.  \\n\\n**Alert Threshold:**  \\nTrigger an alert if the number of Stop* events exceeds a defined baseline (e.g., a 50% increase over the average daily stop events) within a short time window (e.g., 15 minutes), which may indicate unexpected or mass shutdowns.  \\n\\n**Impact:**  \\n- **High values:** May indicate large-scale maintenance, potential outages, or unauthorized shutdowns impacting service availability and user experience.  \\n- **Low values:** Normal or no stop activity, indicating stable resource operation or potential lack of expected maintenance.  \\n\\n**Example Usage:**  \\nIn a dashboard, plot the count of Stop* events over time to visualize stop operation trends. An alert rule could be:  \\n`WHEN count(Stop* events) > baseline * 1.5 FOR 15 minutes THEN trigger alert`  \\nThis helps SREs quickly detect abnormal stop activity and respond accordingly.\", \" - Lambda function \\\"Put*\\\" events in CloudTrail capture changes to function configurations, concurrency settings, event source mappings, and resource provisioning. These events indicate updates or deployments that can affect function behavior and performance. An SRE should monitor the frequency and success of these operations; unusually high rates of \\\"Put*\\\" events may signal automation errors or configuration churn, while absence of expected updates could indicate deployment issues. Alert thresholds might include more than 5 \\\"Put*\\\" events within 5 minutes or failed update attempts exceeding 10% of total \\\"Put*\\\" events. High volumes can lead to inconsistent function states or throttling, impacting availability and latency; low update activity during active development phases may delay critical fixes or optimizations. For example, a dashboard widget can track the count of \\\"Put*\\\" events per hour alongside error rates, and an alert rule could trigger when the number of failed \\\"Put*\\\" events surpasses a set threshold, prompting investigation into deployment or configuration problems.\", \" - This pattern captures CloudWatch Logs Put operations, which occur when log events are written to log streams from applications, systems, or custom sources. In CloudTrail, these events indicate active ingestion of log data into CloudWatch Logs, essential for monitoring application health and troubleshooting.\\n\\n**Purpose:**  \\nMonitor the frequency and volume of log ingestion to detect anomalies such as sudden drops (potentially indicating logging failures or agent issues) or spikes (which may signal increased application activity or potential log flooding).\\n\\n**Alert Threshold Guidance:**  \\n- Trigger an alert if the number of Put operations drops below a baseline threshold for a sustained period (e.g., less than 50% of average daily Put events over 15 minutes), indicating possible logging disruptions.  \\n- Trigger an alert if Put operations spike above a defined upper threshold (e.g., 2x the average rate), which could indicate abnormal application behavior or excessive logging that may impact costs and performance.\\n\\n**Impact:**  \\n- **High values:** May lead to increased CloudWatch Logs ingestion costs and potential performance degradation; could also indicate abnormal application behavior or security events generating excessive logs.  \\n- **Low values:** May result in loss of critical log data, hindering troubleshooting and incident response.\\n\\n**Example Usage:**  \\nIn a monitoring dashboard or alert rule, track the count of CloudTrail events where `EventSource` is `logs.amazonaws.com` and `EventName` matches `Put*` over rolling 5-minute intervals. Set alerts to notify the SRE team if counts fall below or exceed defined thresholds, enabling timely investigation into logging pipeline health.\", \" - This pattern captures SNS unsubscription events recorded in CloudTrail, indicating when endpoints or subscribers are removed from SNS topics. For an SRE, monitoring these events helps track changes in notification delivery and detect potential disruptions or configuration changes.\\n\\n**Purpose:**  \\n- Identify when subscribers unsubscribe from SNS topics, which may reflect endpoint decommissioning, application changes, or user-initiated opt-outs.  \\n- Detect unusual spikes that could indicate mass unsubscriptions due to misconfigurations, security incidents, or service issues.\\n\\n**Alert Threshold:**  \\n- Trigger an alert if the number of Unsubscribe events exceeds a baseline threshold (e.g., more than 5 unsubscriptions within 5 minutes) or shows a sudden increase compared to historical averages. Thresholds should be tuned based on normal subscription churn rates.\\n\\n**Impact:**  \\n- **High values:** May signal widespread endpoint removals causing notification delivery failures, potential service degradation, or security concerns (e.g., unauthorized unsubscriptions). Immediate investigation is warranted.  \\n- **Low or zero values:** Typically expected during stable operations; a sudden drop to zero after a period of regular unsubscriptions might indicate logging issues or CloudTrail misconfigurations.\\n\\n**Example Usage:**  \\n- **Dashboard:** Display a time series graph of Unsubscribe event counts per minute to visualize trends and detect anomalies.  \\n- **Alert Rule (pseudo-code):**  \\n  ```\\n  WHEN count(Events where EventSource=\\\"sns.amazonaws.com\\\" AND EventName LIKE \\\"Unsubscribe%\\\") \\n  OVER last 5 minutes > 5 \\n  THEN trigger alert \\\"High SNS Unsubscription Rate\\\"\\n  ```\", \" - This pattern captures all CloudWatch API operations that begin with \\\"Put\\\", such as PutMetricData, PutLogEvents, and PutAlarm, indicating when CloudWatch resources or configurations are created, updated, or modified. In CloudTrail, monitoring these events helps SREs detect changes to monitoring metrics, log ingestion, and alarm settings that could impact observability or alerting behavior.\\n\\n**Threshold guidance:**  \\nAn alert should trigger if the rate of Put* events exceeds a baseline threshold (e.g., a sudden spike beyond normal operational patterns, such as a 3x increase within 5 minutes), which may indicate automated scripts or unauthorized changes modifying monitoring configurations. Conversely, an unusually low rate over an extended period might suggest disruptions in metric or log ingestion.\\n\\n**Impact:**  \\n- High volumes of Put* events can lead to configuration drift, unexpected alert noise, or resource misconfigurations affecting system reliability.  \\n- Low volumes may result in missing critical metrics or logs, reducing visibility into system health.\\n\\n**Example alert rule:**  \\nTrigger an alert when the count of CloudTrail events with EventSource = \\\"cloudwatch.amazonaws.com\\\" and EventName starting with \\\"Put\\\" exceeds 100 events within 5 minutes, signaling potential bulk updates to monitoring configurations that require investigation. This can be visualized in a dashboard showing Put* event counts over time alongside key system metrics to correlate changes with system behavior.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": true,
                        "score": 0.8962673110112472,
                        "reason": "The description is clear, concise, and directly addresses the monitoring question about sustained drops in Put operations below 50% of average daily events indicating logging disruptions. It covers what is measured (CloudWatch Logs Put operations), units (counts over time intervals), context (log ingestion health), and implications (loss of critical log data). The detailed alert threshold guidance and example usage enable practical application, effectively supporting the monitoring question. Minor improvements could include explicitly stating the exact measurement interval and clarifying the duration defining 'sustained' drops for full precision.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Compare the Input (metric description) against the Retrieval Context (monitoring question) to assess if the description is clear, concise, and free of ambiguity.\",\n    \"Evaluate whether the metric description covers all essential aspects (what is measured, units, context, implications) and aligns with the specific needs posed by the monitoring question.\",\n    \"Determine if the description\u2019s content enables a user to effectively answer the monitoring question, ensuring practical utility and relevance.\",\n    \"If any criteria are not sufficiently met (score < 8), identify specific areas where the description lacks clarity, coverage, or utility, and suggest targeted improvements.\"\n] \n \nRubric:\nNone \n \nScore: 0.8962673110112472"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Compare the Input (metric description) against the Retrieval Context (monitoring question) to assess if the description is clear, concise, and free of ambiguity.",
                            "Evaluate whether the metric description covers all essential aspects (what is measured, units, context, implications) and aligns with the specific needs posed by the monitoring question.",
                            "Determine if the description\u2019s content enables a user to effectively answer the monitoring question, ensuring practical utility and relevance.",
                            "If any criteria are not sufficiently met (score < 8), identify specific areas where the description lacks clarity, coverage, or utility, and suggest targeted improvements."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"logs.amazonaws.com\\\", \\\"EventName\\\": \\\"Filter*\\\"}\", \"hyperparameters\": null, \"input\": \"Does the number of Filter* events exceed ten, indicating potential automated or anomalous activity?\", \"retrieval_context\": [\" - This pattern captures CloudFront tagging events recorded in CloudTrail, specifically when CloudFront distributions are tagged or untagged. Tagging actions are critical for resource organization, cost allocation, and access management. Monitoring these events helps SREs detect unauthorized or unexpected changes to distribution metadata that could affect billing, security policies, or operational workflows.\\n\\n**Alert Threshold:**  \\nTrigger an alert if the number of CloudFront Tag* events exceeds a baseline threshold within a short time window (e.g., more than 5 tagging operations in 10 minutes), as this may indicate automated misconfigurations, potential security breaches, or bulk updates requiring review.\\n\\n**Impact of Values:**  \\n- **High frequency:** Could signal mass tagging/untagging possibly due to automation errors, policy violations, or malicious activity, potentially leading to misallocated costs or broken access controls.  \\n- **Low or zero frequency:** Normal state; tagging changes are typically infrequent and deliberate.\\n\\n**Example Usage:**  \\nIn a monitoring dashboard, plot the count of CloudFront Tag* events over time to visualize tagging activity spikes. An alert rule might be:  \\n`WHEN count(events where EventSource=\\\"cloudfront.amazonaws.com\\\" AND EventName LIKE \\\"Tag%\\\") > 5 within 10 minutes THEN trigger alert \\\"Unusual CloudFront tagging activity detected\\\"`  \\nThis enables proactive investigation and mitigation of tagging anomalies impacting resource governance.\", \" - This pattern captures CloudWatch Logs filter operations recorded in CloudTrail, including metric filter creations, updates, deletions, and CloudWatch Logs Insights queries. It helps SREs monitor how log data is being queried or transformed into metrics, which is critical for detecting unusual or unauthorized access to log data and ensuring the integrity of monitoring configurations.\\n\\n**Purpose:**  \\nTrack and audit all filter-related activities on CloudWatch Logs to detect potential misuse, configuration drift, or performance issues caused by excessive or complex log queries and metric filters.\\n\\n**Alert Threshold Guidance:**  \\n- Trigger an alert if the number of Filter* events exceeds a baseline threshold (e.g., more than 10 filter operations or queries within 5 minutes), indicating potential automated or anomalous activity.  \\n- Alternatively, alert on sudden spikes compared to historical averages or on unauthorized users performing filter operations.\\n\\n**Impact of Values:**  \\n- **High values:** May indicate heavy querying or frequent changes to metric filters, which can increase CloudWatch costs, degrade log ingestion performance, or signal suspicious activity such as data exfiltration attempts.  \\n- **Low or zero values:** Normal in stable environments but could also mean lack of monitoring updates or insufficient log analysis, potentially missing critical insights.\\n\\n**Example Usage in Dashboard/Alert Rule:**  \\n- Create a CloudWatch metric filter on CloudTrail logs for events where EventSource = \\\"logs.amazonaws.com\\\" and EventName starts with \\\"Filter\\\".  \\n- Visualize the count of these events over time in a dashboard to identify trends or spikes.  \\n- Set an alert rule to notify the SRE team if the count exceeds 10 events in a 5-minute window, prompting investigation into recent log filter activity.\", \" - This pattern captures all Amazon EKS \\\"Describe\\\" API operations logged in CloudTrail, which occur when cluster metadata, node group configurations, or add-on details are queried. It helps SREs monitor how often EKS cluster information is accessed, providing visibility into potential reconnaissance or troubleshooting activities. A sudden spike in Describe calls\\u2014such as exceeding 100 requests within 5 minutes\\u2014may indicate unusual or automated querying that could precede configuration changes or security incidents, warranting an alert. Conversely, consistently low or zero Describe activity might suggest lack of monitoring or insufficient operational visibility. For example, an alert rule could trigger when Describe API calls surpass 100 in a 5-minute window, and a dashboard widget might display a time series graph of Describe call counts to track trends and detect anomalies in cluster information access patterns.\", \" - This pattern captures all modification events related to EC2 resources in AWS CloudTrail, triggered by any API calls starting with \\\"Modify\\\" (e.g., ModifyInstanceAttribute, ModifyNetworkInterfaceAttribute). Its purpose is to monitor changes to critical EC2 configurations such as instance attributes, security group rules, and network settings, which can directly impact system security, availability, and performance.\\n\\n**Threshold guidance:**  \\n- Alert when the number of Modify* events exceeds a baseline threshold (e.g., more than 5 modifications within 10 minutes), indicating unusual or potentially unauthorized changes.  \\n- A sudden spike in modification events may signal misconfigurations, automation errors, or security incidents like privilege escalation or lateral movement.\\n\\n**Impact of values:**  \\n- **High frequency:** Could indicate active troubleshooting, automated scaling/configuration changes, or suspicious activity requiring immediate investigation.  \\n- **Low or zero frequency:** Normal steady state; no unexpected modifications detected.\\n\\n**Example alert rule:**  \\nTrigger an alert if the count of events matching {\\\"EventSource\\\": \\\"ec2.amazonaws.com\\\", \\\"EventName\\\": \\\"Modify*\\\"} exceeds 5 within a rolling 10-minute window.\\n\\n**Example dashboard widget:**  \\nA time-series graph showing the count of EC2 Modify* events per 5-minute interval, overlaid with a threshold line at 5 events, enabling quick identification of abnormal modification activity.\", \" - This pattern detects SNS topic creation events recorded in CloudTrail, specifically any API calls starting with \\\"Create\\\" from the SNS service (e.g., CreateTopic). It helps SREs monitor when new SNS topics are provisioned, which can indicate changes in messaging architecture or potential unauthorized resource creation. An alert threshold could be set on the number of Create* events within a given time window (e.g., more than 5 topic creations in 10 minutes), as a sudden spike may signal automation errors or security issues. Low or expected values typically indicate normal operations, while high values may impact system stability by increasing resource usage or indicate potential misuse. For example, an alert rule could trigger if the count of {\\\"EventSource\\\": \\\"sns.amazonaws.com\\\", \\\"EventName\\\": \\\"Create*\\\"} events exceeds 5 in 10 minutes, and a dashboard widget could display a time series graph of topic creation events to track trends and detect anomalies.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": true,
                        "score": 0.9148047201790632,
                        "reason": "The Retrieval Context aligns well with the Input question by directly addressing Filter* events and their monitoring in CloudWatch Logs via CloudTrail. It clearly explains what is measured (filter operations and queries), includes measurement units (e.g., more than 10 events within 5 minutes), and provides alert threshold guidance relevant to detecting automated or anomalous activity. The language is concise and understandable, covering monitoring context, impact of values, and example alert rules, enabling a confident answer. Minor improvement could be made by explicitly defining the exact metric name or event count aggregation method.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Evaluate if the Input (monitoring question) and Retrieval Context (metric description) are aligned in terms of terminology and scope, ensuring the description directly addresses the question asked.\",\n    \"Assess the clarity of the Retrieval Context in explaining what is measured and how, verifying it uses concise and understandable language relevant to the Input question.\",\n    \"Check the coverage of the Retrieval Context to confirm it includes measurement units, monitoring context, and implications necessary to answer the Input question effectively.\",\n    \"Determine the utility by verifying that the Retrieval Context provides sufficient information to enable a confident answer to the Input question, suggesting improvements if gaps exist.\"\n] \n \nRubric:\nNone \n \nScore: 0.9148047201790632"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Evaluate if the Input (monitoring question) and Retrieval Context (metric description) are aligned in terms of terminology and scope, ensuring the description directly addresses the question asked.",
                            "Assess the clarity of the Retrieval Context in explaining what is measured and how, verifying it uses concise and understandable language relevant to the Input question.",
                            "Check the coverage of the Retrieval Context to confirm it includes measurement units, monitoring context, and implications necessary to answer the Input question effectively.",
                            "Determine the utility by verifying that the Retrieval Context provides sufficient information to enable a confident answer to the Input question, suggesting improvements if gaps exist."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"logs.amazonaws.com\\\", \\\"EventName\\\": \\\"Get*\\\"}\", \"hyperparameters\": null, \"input\": \"Does the number of Get* events exceed 100 calls in a short period, indicating potential investigation or misuse of log data?\", \"retrieval_context\": [\" - This pattern captures AWS KMS Decrypt API calls recorded in CloudTrail, indicating when encrypted data is accessed and decrypted using KMS keys. It helps SREs monitor data access events for security auditing and anomaly detection. A sudden spike in Decrypt events may signal unusual or unauthorized data access, while consistently low or expected volumes suggest normal operation. As a threshold, alerting on a sustained increase exceeding 3 standard deviations above the historical average or a sudden burst of Decrypt calls within a short time window (e.g., 5 minutes) is recommended. For example, an alert rule could trigger when the count of Decrypt events exceeds 100 in 5 minutes, indicating potential data exfiltration or misuse. In dashboards, tracking the rate of Decrypt events over time alongside user identities and key IDs can help quickly identify suspicious patterns or compromised credentials.\", \" - This pattern captures CloudWatch Logs retrieval operations (any API call starting with \\\"Get\\\") recorded in CloudTrail, such as GetLogEvents and GetQueryResults. Its purpose is to monitor access to log data, helping SREs detect unusual or excessive log reads that may indicate troubleshooting activity, data exfiltration, or unauthorized access.\\n\\n**Threshold guidance:**  \\n- Trigger an alert if the number of Get* events exceeds a baseline by 3x within a 5-minute window, or if there is a sudden spike compared to historical averages.  \\n- Low or normal values typically indicate routine log access during debugging or monitoring.\\n\\n**Impact:**  \\n- High values may signal active investigation, potential security incidents, or misuse of log data.  \\n- Low values generally reflect normal operations with minimal log retrieval.\\n\\n**Example alert rule:**  \\n\\u201cAlert when logs.amazonaws.com Get* events exceed 100 calls in 5 minutes.\\u201d  \\n\\n**Example dashboard usage:**  \\nVisualize the count of Get* events over time to identify spikes in log access, correlating with incident response or suspicious activity. This helps ensure log data is accessed appropriately and supports timely detection of anomalies.\", \" - This pattern captures all AWS Security Token Service (STS) \\\"Get\\\" operations, such as `GetSessionToken`, `GetCallerIdentity`, and similar API calls that issue or validate temporary security credentials. In CloudTrail, these events indicate when users or services request short-lived credentials to access AWS resources.\\n\\n**Purpose:**  \\nMonitor STS Get* events to detect unusual or excessive requests for temporary credentials, which can signal automation activity, credential misuse, or potential security incidents like privilege escalation or compromised identities.\\n\\n**Alert Threshold:**  \\nTrigger an alert when the count of STS Get* events exceeds a baseline threshold established from normal activity patterns\\u2014commonly, a sudden spike above 3-5 times the average hourly rate or an absolute count exceeding 100 requests per hour, depending on your environment size and usage.\\n\\n**Impact of Values:**  \\n- **High values:** May indicate automated processes requesting many temporary credentials, potential credential abuse, or an attacker attempting to escalate privileges or move laterally. Prompt investigation is warranted.  \\n- **Low or expected values:** Reflect normal operation with routine credential issuance and validation.\\n\\n**Example Usage:**  \\nIn a monitoring dashboard, plot the count of `sts.amazonaws.com` events with `EventName` matching `Get*` over time. Set an alert rule such as:  \\n`WHEN count(events where EventSource=\\\"sts.amazonaws.com\\\" AND EventName LIKE \\\"Get*\\\") > 100 within 1 hour THEN alert \\\"High STS Get* activity detected\\\"`  \\nThis helps SREs quickly identify abnormal credential request patterns and respond accordingly.\", \" - This pattern captures all Amazon EKS \\\"Describe\\\" API operations logged in CloudTrail, which occur when cluster metadata, node group configurations, or add-on details are queried. It helps SREs monitor how often EKS cluster information is accessed, providing visibility into potential reconnaissance or troubleshooting activities. A sudden spike in Describe calls\\u2014such as exceeding 100 requests within 5 minutes\\u2014may indicate unusual or automated querying that could precede configuration changes or security incidents, warranting an alert. Conversely, consistently low or zero Describe activity might suggest lack of monitoring or insufficient operational visibility. For example, an alert rule could trigger when Describe API calls surpass 100 in a 5-minute window, and a dashboard widget might display a time series graph of Describe call counts to track trends and detect anomalies in cluster information access patterns.\", \" - This pattern captures all Route 53 \\\"Get\\\" API operations logged in CloudTrail, such as retrieving hosted zone details, record sets, and health check statuses. It helps SREs monitor read access to DNS configurations and health data, which can indicate normal operational queries or potential reconnaissance activity. A sudden spike in these \\\"Get\\\" requests\\u2014exceeding a baseline threshold (e.g., 3 standard deviations above the average hourly rate)\\u2014may signal unusual interest in DNS infrastructure, warranting investigation. Conversely, a significant drop could indicate issues with monitoring or automation systems relying on these queries. For example, an alert rule could trigger when the count of **{\\\"EventSource\\\": \\\"route53.amazonaws.com\\\", \\\"EventName\\\": \\\"Get*\\\"}** events exceeds 100 requests per hour, and a dashboard widget might display a time series graph of these events to track trends and detect anomalies in DNS query activity.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": true,
                        "score": 0.9,
                        "reason": "The Retrieval Context directly addresses the Input by explaining the monitoring of Get* events in CloudWatch Logs, including what is measured (Get* API calls), the units (number of calls within a 5-minute window), context (potential investigation or misuse), and implications (alerts on spikes or exceeding 100 calls). It provides clear threshold guidance, impact descriptions, and actionable alert examples, making it highly useful and understandable. The only minor shortcoming is that the exact phrase 'exceed 100 calls in a short period' is exemplified as 5 minutes, which aligns well but could be explicitly emphasized as 'short period' to fully match the Input wording.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Compare the Input (monitoring question) and Retrieval Context (metric description) to ensure the description addresses the specific question asked.\",\n    \"Evaluate the clarity of the Retrieval Context by checking if it is understandable and concise relative to the terminology and scope implied by the Input.\",\n    \"Assess the coverage in the Retrieval Context by verifying it explains what is measured, units, context, and implications sufficiently to answer the Input.\",\n    \"Determine the utility by confirming that the Retrieval Context provides actionable information that directly helps answer the Input question.\"\n] \n \nRubric:\nNone \n \nScore: 0.9"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Compare the Input (monitoring question) and Retrieval Context (metric description) to ensure the description addresses the specific question asked.",
                            "Evaluate the clarity of the Retrieval Context by checking if it is understandable and concise relative to the terminology and scope implied by the Input.",
                            "Assess the coverage in the Retrieval Context by verifying it explains what is measured, units, context, and implications sufficiently to answer the Input.",
                            "Determine the utility by confirming that the Retrieval Context provides actionable information that directly helps answer the Input question."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"sts.amazonaws.com\\\", \\\"EventName\\\": \\\"Decode*\\\"}\", \"hyperparameters\": null, \"input\": \"Do Decode* API calls in AWS Security Token Service (STS) exceed ten, indicating a potential authentication issue?\", \"retrieval_context\": [\" - S3 bucket creation events captured by CloudTrail under **{\\\"EventSource\\\": \\\"s3.amazonaws.com\\\", \\\"EventName\\\": \\\"Create*\\\"}** indicate when new buckets or related resources (e.g., bucket policies, access points) are provisioned. These events help SREs monitor infrastructure changes that affect data storage, security posture, and compliance.\\n\\n**Purpose:**  \\nTrack and audit the creation of S3 buckets and associated configurations to ensure proper governance, prevent unauthorized resource sprawl, and maintain compliance with organizational policies.\\n\\n**Alert Threshold:**  \\nTrigger an alert if the number of S3 bucket creation events exceeds a defined threshold within a short time window (e.g., more than 5 bucket creations within 10 minutes), which may indicate automated provisioning errors, misconfigurations, or potential security incidents such as unauthorized resource creation.\\n\\n**Impact of Values:**  \\n- **High frequency:** May signal abnormal activity, such as a compromised credential or runaway automation scripts creating excessive buckets, leading to increased costs, security risks, or compliance violations.  \\n- **Low or zero frequency:** Normal in stable environments; however, sudden spikes should be investigated promptly.\\n\\n**Example Alert Rule:**  \\n\\u201cAlert when count of events with EventSource = 's3.amazonaws.com' and EventName starting with 'Create' exceeds 5 within 10 minutes.\\u201d\\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of S3 Create* events over time, with thresholds marked to highlight unusual spikes, enabling quick identification of abnormal bucket creation activity.\", \" - This pattern captures AWS Security Token Service (STS) AssumeRole API calls, which occur when an identity assumes a role to obtain temporary security credentials. In CloudTrail, these events indicate role assumption activities such as cross-account access, privilege escalation, or session switching within the same account. Monitoring these events helps detect unusual or unauthorized access patterns.\\n\\n**Purpose:**  \\n- Track when and how often roles are assumed to identify potential security risks or operational anomalies.  \\n- Detect spikes in assume role activity that may indicate compromised credentials or misuse of permissions.\\n\\n**Alert Threshold Guidance:**  \\n- Set alert thresholds based on baseline activity for your environment. For example, trigger an alert if the number of AssumeRole events exceeds the daily average by 3x or if assume role events occur from unexpected source IPs or accounts.  \\n- Low or zero assume role activity may indicate service disruptions or misconfigurations if role assumption is expected regularly.\\n\\n**Impact of Values:**  \\n- **High values:** Could signal automated processes, legitimate scaling activities, or potential security incidents such as credential compromise or privilege escalation attempts.  \\n- **Low values:** May indicate reduced operational activity or potential failures in systems relying on role assumption.\\n\\n**Example Alert Rule:**  \\nTrigger an alert if the count of **{\\\"EventSource\\\": \\\"sts.amazonaws.com\\\", \\\"EventName\\\": \\\"AssumeRole\\\"}** events in a 1-hour window exceeds 100 or deviates by more than 3 standard deviations from the 7-day rolling average.\\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of AssumeRole events per hour, annotated with alerts when thresholds are breached, alongside a table listing top source IPs and assumed roles to aid investigation.\", \" - This pattern captures all AWS Security Token Service (STS) \\\"Get\\\" operations, such as `GetSessionToken`, `GetCallerIdentity`, and similar API calls that issue or validate temporary security credentials. In CloudTrail, these events indicate when users or services request short-lived credentials to access AWS resources.\\n\\n**Purpose:**  \\nMonitor STS Get* events to detect unusual or excessive requests for temporary credentials, which can signal automation activity, credential misuse, or potential security incidents like privilege escalation or compromised identities.\\n\\n**Alert Threshold:**  \\nTrigger an alert when the count of STS Get* events exceeds a baseline threshold established from normal activity patterns\\u2014commonly, a sudden spike above 3-5 times the average hourly rate or an absolute count exceeding 100 requests per hour, depending on your environment size and usage.\\n\\n**Impact of Values:**  \\n- **High values:** May indicate automated processes requesting many temporary credentials, potential credential abuse, or an attacker attempting to escalate privileges or move laterally. Prompt investigation is warranted.  \\n- **Low or expected values:** Reflect normal operation with routine credential issuance and validation.\\n\\n**Example Usage:**  \\nIn a monitoring dashboard, plot the count of `sts.amazonaws.com` events with `EventName` matching `Get*` over time. Set an alert rule such as:  \\n`WHEN count(events where EventSource=\\\"sts.amazonaws.com\\\" AND EventName LIKE \\\"Get*\\\") > 100 within 1 hour THEN alert \\\"High STS Get* activity detected\\\"`  \\nThis helps SREs quickly identify abnormal credential request patterns and respond accordingly.\", \" - This pattern detects Secrets Manager creation events in CloudTrail, specifically any API calls starting with \\\"Create\\\" (e.g., CreateSecret). It helps SREs monitor when new secrets, secret versions, or related configurations are added, which could indicate deployment changes or potential security risks.  \\n**Alert threshold:** Trigger an alert if the number of create events exceeds a baseline (e.g., more than 5 creates within 10 minutes), as a sudden spike may signal unauthorized secret creation or misconfiguration. Conversely, zero create events over an extended period in an active environment might indicate issues with deployment pipelines or automation failures.  \\n**Impact:**  \\n- High values: Could indicate potential security breaches, unauthorized secret provisioning, or rapid environment changes requiring immediate investigation.  \\n- Low values: May suggest stalled deployments or automation problems, potentially delaying application updates or secret rotations.  \\n**Example usage:**  \\nIn a dashboard, plot the count of Secrets Manager Create* events over time to visualize spikes. An alert rule could be:  \\n`WHEN count(secretsmanager.amazonaws.com Create* events) > 5 within 10 minutes THEN trigger alert \\\"Unusual Secrets Creation Activity\\\"`  \\nThis enables proactive detection of abnormal secret creation activity, helping maintain security and operational stability.\", \" - This pattern matches AWS Security Token Service (STS) API calls that begin with \\\"Decode,\\\" such as DecodeAuthorizationMessage. It captures events where encoded authorization messages are decoded to reveal detailed error or permission information. These events help diagnose authentication and authorization failures by providing decoded message content. The measurement is event occurrence, counted per API call matching the pattern.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": false,
                        "score": 0.22227001336663843,
                        "reason": "The Retrieval Context does not address the specific Input question about 'Decode*' API calls exceeding ten in AWS STS. While it explains the DecodeAuthorizationMessage pattern and its diagnostic purpose, it lacks explicit measurement units, alert thresholds, or guidance on interpreting counts exceeding ten, limiting clarity, coverage, and utility for answering the question.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Compare the Input (monitoring question) and Retrieval Context (metric description) to ensure the description clearly addresses the specific question posed.\",\n    \"Evaluate the clarity of the Retrieval Context by checking if it is concise, easily understandable, and free of ambiguous terms relative to the Input.\",\n    \"Assess the coverage of the Retrieval Context to verify that it explains what is measured, the units involved, and relevant context and implications that align with the Input question.\",\n    \"Determine the utility by judging whether the description provides sufficient information for a user to effectively answer the Input question, ensuring coherence between the Input and Retrieval Context.\"\n] \n \nRubric:\nNone \n \nScore: 0.22227001336663843"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Compare the Input (monitoring question) and Retrieval Context (metric description) to ensure the description clearly addresses the specific question posed.",
                            "Evaluate the clarity of the Retrieval Context by checking if it is concise, easily understandable, and free of ambiguous terms relative to the Input.",
                            "Assess the coverage of the Retrieval Context to verify that it explains what is measured, the units involved, and relevant context and implications that align with the Input question.",
                            "Determine the utility by judging whether the description provides sufficient information for a user to effectively answer the Input question, ensuring coherence between the Input and Retrieval Context."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"sts.amazonaws.com\\\", \\\"EventName\\\": \\\"Assume*\\\"}\", \"hyperparameters\": null, \"input\": \"Does the number of AssumeRole API calls exceed the daily average by 3x, indicating potential security risks or operational anomalies?\", \"retrieval_context\": [\" - Redshift cluster creation events in CloudTrail capture all API calls initiating the provisioning of new Redshift clusters (e.g., CreateCluster). These events indicate when new data warehouse resources are being deployed or configured, impacting capacity and cost.  \\n**Purpose:** Enables SREs to monitor and audit cluster provisioning activities for operational control and security compliance.  \\n**Alert Threshold:** Trigger alerts on an unusually high number of cluster creation events within a short time window (e.g., >3 creates in 1 hour), which may indicate automation errors, misconfigurations, or unauthorized resource provisioning.  \\n**Impact:**  \\n- **High values:** May lead to resource sprawl, increased costs, and potential performance degradation due to over-provisioning. Could also signal security risks if unexpected clusters are created.  \\n- **Low or zero values:** Normal in stable environments; no new clusters being created means stable infrastructure.  \\n**Example Alert Rule:**  \\n\\u201cAlert if count of events with EventSource='redshift.amazonaws.com' and EventName starting with 'Create' exceeds 3 within 60 minutes.\\u201d  \\n**Dashboard Use:** Visualize the frequency of Redshift cluster creation events over time to detect spikes or anomalies, correlating with deployment activities or security incidents.\", \" - This pattern captures AWS KMS Decrypt API calls recorded in CloudTrail, indicating when encrypted data is accessed and decrypted using KMS keys. It helps SREs monitor data access events for security auditing and anomaly detection. A sudden spike in Decrypt events may signal unusual or unauthorized data access, while consistently low or expected volumes suggest normal operation. As a threshold, alerting on a sustained increase exceeding 3 standard deviations above the historical average or a sudden burst of Decrypt calls within a short time window (e.g., 5 minutes) is recommended. For example, an alert rule could trigger when the count of Decrypt events exceeds 100 in 5 minutes, indicating potential data exfiltration or misuse. In dashboards, tracking the rate of Decrypt events over time alongside user identities and key IDs can help quickly identify suspicious patterns or compromised credentials.\", \" - This pattern captures AWS Security Token Service (STS) AssumeRole API calls, which occur when an identity assumes a role to obtain temporary security credentials. In CloudTrail, these events indicate role assumption activities such as cross-account access, privilege escalation, or session switching within the same account. Monitoring these events helps detect unusual or unauthorized access patterns.\\n\\n**Purpose:**  \\n- Track when and how often roles are assumed to identify potential security risks or operational anomalies.  \\n- Detect spikes in assume role activity that may indicate compromised credentials or misuse of permissions.\\n\\n**Alert Threshold Guidance:**  \\n- Set alert thresholds based on baseline activity for your environment. For example, trigger an alert if the number of AssumeRole events exceeds the daily average by 3x or if assume role events occur from unexpected source IPs or accounts.  \\n- Low or zero assume role activity may indicate service disruptions or misconfigurations if role assumption is expected regularly.\\n\\n**Impact of Values:**  \\n- **High values:** Could signal automated processes, legitimate scaling activities, or potential security incidents such as credential compromise or privilege escalation attempts.  \\n- **Low values:** May indicate reduced operational activity or potential failures in systems relying on role assumption.\\n\\n**Example Alert Rule:**  \\nTrigger an alert if the count of **{\\\"EventSource\\\": \\\"sts.amazonaws.com\\\", \\\"EventName\\\": \\\"AssumeRole\\\"}** events in a 1-hour window exceeds 100 or deviates by more than 3 standard deviations from the 7-day rolling average.\\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of AssumeRole events per hour, annotated with alerts when thresholds are breached, alongside a table listing top source IPs and assumed roles to aid investigation.\", \" - This pattern captures CloudWatch API operations that list resources, such as metrics, log groups, and alarms, as recorded in CloudTrail under EventSource \\\"cloudwatch.amazonaws.com\\\" with EventNames starting with \\\"List\\\". It helps SREs monitor enumeration activity on CloudWatch resources, which can indicate normal operational queries or potential reconnaissance by unauthorized users.\\n\\n**Purpose:**  \\nTo track and analyze the frequency of CloudWatch resource listing actions, enabling detection of unusual spikes that may signal automated scanning, misconfigurations, or security incidents.\\n\\n**Threshold Guidance:**  \\nSet alert thresholds based on baseline activity for your environment. For example, trigger an alert if the number of List* events exceeds 3 standard deviations above the daily average or if more than 100 list operations occur within a 5-minute window, indicating abnormal enumeration.\\n\\n**Impact of Values:**  \\n- **High values:** May indicate excessive or automated querying of CloudWatch resources, potentially revealing reconnaissance attempts or inefficient scripts causing performance overhead.  \\n- **Low values:** Typically normal, but a sudden drop could suggest issues with monitoring tools or API access problems.\\n\\n**Example Alert Rule:**  \\nTrigger an alert when the count of CloudWatch List* events in CloudTrail exceeds 100 within 5 minutes, signaling potential unauthorized or excessive enumeration activity.\\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of CloudWatch List* events per 5-minute interval, overlaid with the alert threshold line, to visualize normal versus anomalous listing activity.\", \" - This pattern detects Secrets Manager creation events in CloudTrail, specifically any API calls starting with \\\"Create\\\" (e.g., CreateSecret). It helps SREs monitor when new secrets, secret versions, or related configurations are added, which could indicate deployment changes or potential security risks.  \\n**Alert threshold:** Trigger an alert if the number of create events exceeds a baseline (e.g., more than 5 creates within 10 minutes), as a sudden spike may signal unauthorized secret creation or misconfiguration. Conversely, zero create events over an extended period in an active environment might indicate issues with deployment pipelines or automation failures.  \\n**Impact:**  \\n- High values: Could indicate potential security breaches, unauthorized secret provisioning, or rapid environment changes requiring immediate investigation.  \\n- Low values: May suggest stalled deployments or automation problems, potentially delaying application updates or secret rotations.  \\n**Example usage:**  \\nIn a dashboard, plot the count of Secrets Manager Create* events over time to visualize spikes. An alert rule could be:  \\n`WHEN count(secretsmanager.amazonaws.com Create* events) > 5 within 10 minutes THEN trigger alert \\\"Unusual Secrets Creation Activity\\\"`  \\nThis enables proactive detection of abnormal secret creation activity, helping maintain security and operational stability.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": true,
                        "score": 0.9182425526028812,
                        "reason": "The retrieval context directly addresses the monitoring question by explaining AssumeRole API calls, their security implications, and how to detect spikes exceeding the daily average by 3x. It is clear, concise, and provides detailed coverage including what is measured, alert thresholds, impact of values, and example alert rules. The description offers sufficient information to accurately answer the question about potential security risks or anomalies related to AssumeRole call volume. The only minor shortcoming is the lack of explicit units for the daily average, but the context implies time windows clearly.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Compare the Input (question) with the Retrieval Context (description) to assess if the description directly addresses the monitoring question.\",\n    \"Evaluate Clarity by checking if the description is understandable and concise within the context of the specific question asked.\",\n    \"Assess Coverage by verifying if the description explains what is measured, the units used, relevant context, and the implications necessary to answer the question.\",\n    \"Determine Utility by confirming whether the description, in relation to the question, provides sufficient information to accurately answer the monitoring question.\"\n] \n \nRubric:\nNone \n \nScore: 0.9182425526028812"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Compare the Input (question) with the Retrieval Context (description) to assess if the description directly addresses the monitoring question.",
                            "Evaluate Clarity by checking if the description is understandable and concise within the context of the specific question asked.",
                            "Assess Coverage by verifying if the description explains what is measured, the units used, relevant context, and the implications necessary to answer the question.",
                            "Determine Utility by confirming whether the description, in relation to the question, provides sufficient information to accurately answer the monitoring question."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"secretsmanager.amazonaws.com\\\", \\\"EventName\\\": \\\"Delete*\\\"}\", \"hyperparameters\": null, \"input\": \"Are the Delete* events in Secrets Manager indicative of a deliberate cleanup operation or an unexpected credential loss incident?\", \"retrieval_context\": [\" - IAM deletion events (e.g., DeleteUser, DeleteRole) recorded by CloudTrail indicate removal of IAM identities or permissions. These events are critical for detecting unauthorized or accidental deletions that can disrupt access or signal a security breach. An alert threshold should be set to trigger on any unexpected deletion event or a sudden spike above normal baseline activity (e.g., more than 1 deletion event within 5 minutes), as even a single deletion can have significant impact. High volumes may indicate automated attacks or misconfigurations causing mass access removal, while low or zero values typically indicate normal operation.  \\nExample alert rule: trigger when count of iam.amazonaws.com Delete* events > 1 in 5 minutes.  \\nExample dashboard widget: a time series graph showing Delete* event counts over time, annotated with alert thresholds to quickly identify unusual deletion activity.\", \" - This event pattern captures all CloudTrail events where CloudWatch Logs resources\\u2014such as log groups or log streams\\u2014are deleted (e.g., DeleteLogGroup, DeleteLogStream). Its purpose is to monitor and audit log deletion activities, which can be legitimate cleanup or indicate potential loss of critical log data needed for troubleshooting and compliance.\\n\\n**Alert Threshold:**  \\nTrigger an alert if the number of delete events exceeds a baseline threshold within a defined time window (e.g., more than 3 deletions within 1 hour), or if deletions occur unexpectedly outside of scheduled maintenance windows.\\n\\n**Impact:**  \\n- **High frequency of deletions:** May indicate accidental or malicious removal of logs, risking loss of observability and forensic data. Immediate investigation is recommended.  \\n- **Low or zero deletions:** Normal operation, indicating logs are retained as expected.\\n\\n**Example Alert Rule:**  \\n\\u201cAlert if DeleteLogGroup or DeleteLogStream events from logs.amazonaws.com exceed 3 occurrences in 60 minutes.\\u201d  \\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of Delete* events over time, annotated with alert thresholds and maintenance windows, enabling quick identification of unusual spikes in log deletions.\", \" - This pattern captures CloudWatch deletion events. It identifies when CloudWatch resources are removed, which can indicate cleanup operations or potential monitoring loss incidents.\", \" - This pattern captures Secrets Manager deletion events. It identifies when secrets are removed, which can indicate cleanup operations or potential credential loss incidents.\", \" - This pattern captures all update-related events from AWS Secrets Manager, such as modifications to secret values, rotation configurations, and access policy changes, as recorded in CloudTrail. Its purpose is to monitor changes that could affect the confidentiality, integrity, or availability of secrets critical to application security and operations.\\n\\n**Threshold guidance:**  \\n- Trigger an alert if the number of update events exceeds a baseline threshold within a short time window (e.g., more than 5 update events in 10 minutes), as this may indicate unusual or potentially unauthorized activity.  \\n- Conversely, an absence of expected rotation updates over a longer period (e.g., no rotation updates in 30 days) could signal stale secrets and increased security risk.\\n\\n**Impact of values:**  \\n- **High frequency of update events:** May indicate automated rotation, bulk secret changes, or suspicious activity such as credential compromise or insider threat. Immediate investigation is recommended.  \\n- **Low or zero update events:** Could mean secrets are not being rotated as per policy, increasing the risk of secret leakage or misuse.\\n\\n**Example alert rule:**  \\nAlert when `count(secretsmanager.amazonaws.com Update* events) > 5` within 10 minutes, excluding known maintenance windows.  \\n**Example dashboard widget:**  \\nA time-series graph showing the count of Secrets Manager update events over time, annotated with alerts triggered when thresholds are breached, helping SREs quickly identify abnormal secret modification patterns.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": true,
                        "score": 0.8053452266950419,
                        "reason": "The Retrieval Context directly relates to the Input question by describing Secrets Manager deletion events and their potential implications for cleanup or credential loss. It is generally clear and concise, explaining what is measured (deletion events), the context (Secrets Manager), and the implications (cleanup vs. credential loss). However, the coverage is somewhat limited as it does not provide detailed units, thresholds, or explicit guidance on distinguishing deliberate cleanup from unexpected incidents, which slightly reduces its utility for fully answering the question.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Compare the Input question with the Retrieval Context description to check if the description directly relates to the question.\",\n    \"Evaluate the clarity of the Retrieval Context by determining if it is concise and easy to understand in relation to the terms used in the Input question.\",\n    \"Assess the coverage of the Retrieval Context by verifying if it explains what is measured, the units, context, and implications relevant to the Input question.\",\n    \"Judge the utility of the Retrieval Context by determining if it provides sufficient information to accurately answer the Input question.\"\n] \n \nRubric:\nNone \n \nScore: 0.8053452266950419"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Compare the Input question with the Retrieval Context description to check if the description directly relates to the question.",
                            "Evaluate the clarity of the Retrieval Context by determining if it is concise and easy to understand in relation to the terms used in the Input question.",
                            "Assess the coverage of the Retrieval Context by verifying if it explains what is measured, the units, context, and implications relevant to the Input question.",
                            "Judge the utility of the Retrieval Context by determining if it provides sufficient information to accurately answer the Input question."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"sts.amazonaws.com\\\", \\\"EventName\\\": \\\"Get*\\\"}\", \"hyperparameters\": null, \"input\": \"Does the count of STS Get* events exceed 3-5 times the average hourly rate or an absolute count exceeding 100 requests per hour?\", \"retrieval_context\": [\" - EKS List* events in CloudTrail capture API calls that enumerate EKS resources such as clusters, node groups, add-ons, and other related components. These operations are primarily read-only and used for infrastructure discovery, capacity planning, and operational visibility. Monitoring the frequency of List* calls helps detect unusual activity patterns: a sudden spike may indicate automated scanning, reconnaissance, or potential misuse, while an abnormally low rate could suggest monitoring gaps or service disruptions. A practical alert threshold might be set at a rate exceeding the baseline average by 3x within a 5-minute window. For example, a dashboard widget could track the count of eks.amazonaws.com List* events per minute, with an alert rule triggering when this count surpasses the defined threshold, enabling timely investigation of unexpected enumeration activity.\", \" - This pattern captures AWS KMS Decrypt API calls recorded in CloudTrail, indicating when encrypted data is accessed and decrypted using KMS keys. It helps SREs monitor data access events for security auditing and anomaly detection. A sudden spike in Decrypt events may signal unusual or unauthorized data access, while consistently low or expected volumes suggest normal operation. As a threshold, alerting on a sustained increase exceeding 3 standard deviations above the historical average or a sudden burst of Decrypt calls within a short time window (e.g., 5 minutes) is recommended. For example, an alert rule could trigger when the count of Decrypt events exceeds 100 in 5 minutes, indicating potential data exfiltration or misuse. In dashboards, tracking the rate of Decrypt events over time alongside user identities and key IDs can help quickly identify suspicious patterns or compromised credentials.\", \" - This pattern captures all AWS Security Token Service (STS) \\\"Get\\\" operations, such as `GetSessionToken`, `GetCallerIdentity`, and similar API calls that issue or validate temporary security credentials. In CloudTrail, these events indicate when users or services request short-lived credentials to access AWS resources.\\n\\n**Purpose:**  \\nMonitor STS Get* events to detect unusual or excessive requests for temporary credentials, which can signal automation activity, credential misuse, or potential security incidents like privilege escalation or compromised identities.\\n\\n**Alert Threshold:**  \\nTrigger an alert when the count of STS Get* events exceeds a baseline threshold established from normal activity patterns\\u2014commonly, a sudden spike above 3-5 times the average hourly rate or an absolute count exceeding 100 requests per hour, depending on your environment size and usage.\\n\\n**Impact of Values:**  \\n- **High values:** May indicate automated processes requesting many temporary credentials, potential credential abuse, or an attacker attempting to escalate privileges or move laterally. Prompt investigation is warranted.  \\n- **Low or expected values:** Reflect normal operation with routine credential issuance and validation.\\n\\n**Example Usage:**  \\nIn a monitoring dashboard, plot the count of `sts.amazonaws.com` events with `EventName` matching `Get*` over time. Set an alert rule such as:  \\n`WHEN count(events where EventSource=\\\"sts.amazonaws.com\\\" AND EventName LIKE \\\"Get*\\\") > 100 within 1 hour THEN alert \\\"High STS Get* activity detected\\\"`  \\nThis helps SREs quickly identify abnormal credential request patterns and respond accordingly.\", \" - This pattern captures all Amazon EKS \\\"Describe\\\" API operations logged in CloudTrail, which occur when cluster metadata, node group configurations, or add-on details are queried. It helps SREs monitor how often EKS cluster information is accessed, providing visibility into potential reconnaissance or troubleshooting activities. A sudden spike in Describe calls\\u2014such as exceeding 100 requests within 5 minutes\\u2014may indicate unusual or automated querying that could precede configuration changes or security incidents, warranting an alert. Conversely, consistently low or zero Describe activity might suggest lack of monitoring or insufficient operational visibility. For example, an alert rule could trigger when Describe API calls surpass 100 in a 5-minute window, and a dashboard widget might display a time series graph of Describe call counts to track trends and detect anomalies in cluster information access patterns.\", \" - This pattern captures all Route 53 \\\"Get\\\" API operations logged in CloudTrail, such as retrieving hosted zone details, record sets, and health check statuses. It helps SREs monitor read access to DNS configurations and health data, which can indicate normal operational queries or potential reconnaissance activity. A sudden spike in these \\\"Get\\\" requests\\u2014exceeding a baseline threshold (e.g., 3 standard deviations above the average hourly rate)\\u2014may signal unusual interest in DNS infrastructure, warranting investigation. Conversely, a significant drop could indicate issues with monitoring or automation systems relying on these queries. For example, an alert rule could trigger when the count of **{\\\"EventSource\\\": \\\"route53.amazonaws.com\\\", \\\"EventName\\\": \\\"Get*\\\"}** events exceeds 100 requests per hour, and a dashboard widget might display a time series graph of these events to track trends and detect anomalies in DNS query activity.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": true,
                        "score": 0.9437823499114201,
                        "reason": "The description clearly and concisely explains the metric relevant to the question by defining STS Get* events, their purpose, and the alert thresholds including the exact criteria of exceeding 3-5 times the average hourly rate or an absolute count over 100 requests per hour. It covers what is measured, the units (requests per hour), context (monitoring for unusual credential requests), and implications (potential security incidents). The clarity and coverage provide strong utility for confidently addressing the question. Minor improvement could be made by explicitly stating the units earlier, but overall the description is comprehensive and well-aligned.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Compare the input (question) with the retrieval context (description) to assess if the description clearly and concisely explains the metric relevant to the question.\",\n    \"Check if the description covers all necessary aspects (what is measured, units, context, and implications) to fully support answering the question.\",\n    \"Evaluate whether the description\u2019s clarity and coverage provide enough utility for a user to confidently address the question based on the provided context.\",\n    \"If any of clarity, coverage, or utility are insufficient relative to the question, identify specific missing or unclear components to suggest targeted improvements.\"\n] \n \nRubric:\nNone \n \nScore: 0.9437823499114201"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Compare the input (question) with the retrieval context (description) to assess if the description clearly and concisely explains the metric relevant to the question.",
                            "Check if the description covers all necessary aspects (what is measured, units, context, and implications) to fully support answering the question.",
                            "Evaluate whether the description\u2019s clarity and coverage provide enough utility for a user to confidently address the question based on the provided context.",
                            "If any of clarity, coverage, or utility are insufficient relative to the question, identify specific missing or unclear components to suggest targeted improvements."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"secretsmanager.amazonaws.com\\\", \\\"EventName\\\": \\\"Create*\\\"}\", \"hyperparameters\": null, \"input\": \"Does the number of Secrets Manager create events exceed five, indicating potential unauthorized secret provisioning or misconfiguration?\", \"retrieval_context\": [\" - This pattern captures Secrets Manager deletion events. It identifies when secrets are removed, which can indicate cleanup operations or potential credential loss incidents.\", \" - This pattern captures all AWS Systems Manager (SSM) resource creation events logged in CloudTrail, such as the creation of parameters, documents, and maintenance windows. It helps SREs monitor the provisioning of new SSM assets, which can indicate configuration changes or automation deployments.\\n\\n**Purpose:**  \\nTo detect when new SSM resources are created, enabling timely awareness of infrastructure changes that may affect system behavior or security posture.\\n\\n**Alert Threshold Guidance:**  \\nSet an alert threshold based on your environment\\u2019s baseline creation activity. For example, trigger an alert if more than 5 creation events occur within 10 minutes, which may indicate unexpected or unauthorized provisioning.\\n\\n**Impact of Values:**  \\n- **High values:** A spike in creation events could signal automated deployments, configuration drift, or potential security incidents such as unauthorized resource creation.  \\n- **Low or zero values:** Normal in stable environments; however, a sudden drop might indicate issues with deployment pipelines or monitoring gaps.\\n\\n**Example Alert Rule:**  \\nTrigger an alert when the count of events matching `{\\\"EventSource\\\": \\\"ssm.amazonaws.com\\\", \\\"EventName\\\": \\\"Create*\\\"}` exceeds 5 within a 10-minute window.\\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of SSM creation events over time, with thresholds marked to highlight unusual spikes, helping SREs quickly identify and investigate abnormal provisioning activity.\", \" - This pattern captures all update-related events from AWS Secrets Manager, such as modifications to secret values, rotation configurations, and access policy changes, as recorded in CloudTrail. Its purpose is to monitor changes that could affect the confidentiality, integrity, or availability of secrets critical to application security and operations.\\n\\n**Threshold guidance:**  \\n- Trigger an alert if the number of update events exceeds a baseline threshold within a short time window (e.g., more than 5 update events in 10 minutes), as this may indicate unusual or potentially unauthorized activity.  \\n- Conversely, an absence of expected rotation updates over a longer period (e.g., no rotation updates in 30 days) could signal stale secrets and increased security risk.\\n\\n**Impact of values:**  \\n- **High frequency of update events:** May indicate automated rotation, bulk secret changes, or suspicious activity such as credential compromise or insider threat. Immediate investigation is recommended.  \\n- **Low or zero update events:** Could mean secrets are not being rotated as per policy, increasing the risk of secret leakage or misuse.\\n\\n**Example alert rule:**  \\nAlert when `count(secretsmanager.amazonaws.com Update* events) > 5` within 10 minutes, excluding known maintenance windows.  \\n**Example dashboard widget:**  \\nA time-series graph showing the count of Secrets Manager update events over time, annotated with alerts triggered when thresholds are breached, helping SREs quickly identify abnormal secret modification patterns.\", \" - This pattern detects SNS topic creation events recorded in CloudTrail, specifically any API calls starting with \\\"Create\\\" from the SNS service (e.g., CreateTopic). It helps SREs monitor when new SNS topics are provisioned, which can indicate changes in messaging architecture or potential unauthorized resource creation. An alert threshold could be set on the number of Create* events within a given time window (e.g., more than 5 topic creations in 10 minutes), as a sudden spike may signal automation errors or security issues. Low or expected values typically indicate normal operations, while high values may impact system stability by increasing resource usage or indicate potential misuse. For example, an alert rule could trigger if the count of {\\\"EventSource\\\": \\\"sns.amazonaws.com\\\", \\\"EventName\\\": \\\"Create*\\\"} events exceeds 5 in 10 minutes, and a dashboard widget could display a time series graph of topic creation events to track trends and detect anomalies.\", \" - This pattern detects Secrets Manager creation events in CloudTrail, specifically any API calls starting with \\\"Create\\\" (e.g., CreateSecret). It helps SREs monitor when new secrets, secret versions, or related configurations are added, which could indicate deployment changes or potential security risks.  \\n**Alert threshold:** Trigger an alert if the number of create events exceeds a baseline (e.g., more than 5 creates within 10 minutes), as a sudden spike may signal unauthorized secret creation or misconfiguration. Conversely, zero create events over an extended period in an active environment might indicate issues with deployment pipelines or automation failures.  \\n**Impact:**  \\n- High values: Could indicate potential security breaches, unauthorized secret provisioning, or rapid environment changes requiring immediate investigation.  \\n- Low values: May suggest stalled deployments or automation problems, potentially delaying application updates or secret rotations.  \\n**Example usage:**  \\nIn a dashboard, plot the count of Secrets Manager Create* events over time to visualize spikes. An alert rule could be:  \\n`WHEN count(secretsmanager.amazonaws.com Create* events) > 5 within 10 minutes THEN trigger alert \\\"Unusual Secrets Creation Activity\\\"`  \\nThis enables proactive detection of abnormal secret creation activity, helping maintain security and operational stability.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": true,
                        "score": 0.8413822085851292,
                        "reason": "The input clearly states the metric being measured (Secrets Manager create events) and the threshold (>5) indicating potential unauthorized provisioning or misconfiguration, aligning well with the retrieval context. The retrieval provides detailed context on event types, alert thresholds, impacts, and example alert rules, supporting the input's monitoring question. However, the input could improve clarity by specifying the time window (e.g., within 10 minutes) as given in the retrieval, enhancing precision and utility for effective monitoring.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Compare the input metric description against the retrieval context to ensure the description is clear and concise, verifying that technical terms and measurements are easily understandable.\",\n    \"Check that the description covers essential aspects including what is measured, the units used, relevant context from the retrieval, and the implications, confirming alignment between the input and retrieval context.\",\n    \"Evaluate the utility of the description by assessing if the information collectively provided by the input and retrieval context can help answer the monitoring question effectively.\",\n    \"If any gaps or ambiguities exist between the input and retrieval context that reduce clarity, coverage, or utility, identify specific improvements to make the description more informative and reliable.\"\n] \n \nRubric:\nNone \n \nScore: 0.8413822085851292"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Compare the input metric description against the retrieval context to ensure the description is clear and concise, verifying that technical terms and measurements are easily understandable.",
                            "Check that the description covers essential aspects including what is measured, the units used, relevant context from the retrieval, and the implications, confirming alignment between the input and retrieval context.",
                            "Evaluate the utility of the description by assessing if the information collectively provided by the input and retrieval context can help answer the monitoring question effectively.",
                            "If any gaps or ambiguities exist between the input and retrieval context that reduce clarity, coverage, or utility, identify specific improvements to make the description more informative and reliable."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"kms.amazonaws.com\\\", \\\"EventName\\\": \\\"Create*\\\"}\", \"hyperparameters\": null, \"input\": \"Are the CreateKey events related to a specific KMS configuration or policy change?\", \"retrieval_context\": [\" - This pattern captures AWS KMS Decrypt API calls recorded in CloudTrail, indicating when encrypted data is accessed and decrypted using KMS keys. It helps SREs monitor data access events for security auditing and anomaly detection. A sudden spike in Decrypt events may signal unusual or unauthorized data access, while consistently low or expected volumes suggest normal operation. As a threshold, alerting on a sustained increase exceeding 3 standard deviations above the historical average or a sudden burst of Decrypt calls within a short time window (e.g., 5 minutes) is recommended. For example, an alert rule could trigger when the count of Decrypt events exceeds 100 in 5 minutes, indicating potential data exfiltration or misuse. In dashboards, tracking the rate of Decrypt events over time alongside user identities and key IDs can help quickly identify suspicious patterns or compromised credentials.\", \" - This pattern captures AWS KMS encryption API calls (e.g., Encrypt, EncryptData) recorded in CloudTrail, indicating when data is being encrypted using customer-managed or AWS-managed KMS keys. It helps SREs monitor cryptographic operations to ensure data protection policies are enforced and to detect unusual encryption activity that could signal misuse or security incidents.\\n\\n**Purpose:** Track the frequency and context of encryption operations to verify normal application behavior and compliance with data security standards.\\n\\n**Alert Threshold:** Trigger an alert if the number of Encrypt* events exceeds a baseline threshold (e.g., a sudden spike beyond 3 standard deviations from the average hourly rate) or if encryption requests originate from unexpected principals or regions.\\n\\n**Impact of Values:**  \\n- **High volume:** May indicate increased data processing, potential automated encryption loops, or unauthorized bulk encryption attempts, which could impact performance or signal a security breach.  \\n- **Low or zero volume:** Could suggest application issues, disabled encryption, or misconfigured services failing to encrypt data as required, risking data exposure.\\n\\n**Example Alert Rule:**  \\nAlert when Encrypt* events exceed 500 per hour or when encryption requests come from an unrecognized IAM role, triggering an investigation into possible misuse or operational anomalies.\\n\\n**Dashboard Use:**  \\nVisualize Encrypt* event counts over time alongside related Decrypt* events and key usage metrics to correlate encryption activity with application workloads and detect deviations from normal patterns.\", \" - This pattern captures KMS creation events. It identifies when KMS keys are created, including key configurations, key material generation, and key policy settings.\", \" - This pattern detects AWS KMS API calls that begin with \\\"Generate,\\\" such as GenerateDataKey and GenerateRandom. It captures events where cryptographic keys, data keys, or random byte sequences are created. The measurement is event occurrence count, indicating how many such generation requests were made. This helps monitor key material creation activities within AWS KMS.\", \" - This pattern detects AWS KMS key deletion events captured in CloudTrail, specifically any API calls starting with \\\"Delete\\\" (e.g., DeleteKey). Its purpose is to monitor the removal of cryptographic keys, which are critical for data encryption and access control. Frequent or unexpected deletions may indicate potential security risks, accidental data loss, or cleanup activities.\\n\\n**Alert Threshold:**  \\nTrigger an alert if more than 1 Delete* event occurs within a short time window (e.g., 1 hour), as multiple deletions could signify malicious activity or misconfiguration.\\n\\n**Impact:**  \\n- **High values:** Multiple key deletions in a brief period can lead to irreversible data access loss, service disruptions, or security breaches. Immediate investigation is required.  \\n- **Low values:** Occasional single deletions may be part of routine key rotation or cleanup but should still be reviewed for authorization.\\n\\n**Example Alert Rule:**  \\n```\\nWHEN count of events WHERE EventSource = \\\"kms.amazonaws.com\\\" AND EventName LIKE \\\"Delete%\\\" OVER last 1 hour > 1  \\nTHEN trigger alert \\\"Multiple KMS key deletions detected\\\"\\n```\\n\\n**Dashboard Use Case:**  \\nVisualize the count of Delete* events over time to identify spikes or unusual patterns, correlating with operational changes or security incidents. This helps SREs proactively manage key lifecycle and maintain data protection integrity.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": false,
                        "score": 0.33361129392064826,
                        "reason": "The retrieval context describes various KMS event patterns including key creation, key material generation, and key policy settings, which relate to CreateKey events. However, it does not explicitly address whether these events are linked to specific KMS configurations or policy changes, leaving ambiguity about the relationship to the monitoring question. The description is detailed and clear about what is measured and includes examples and implications, but it lacks direct coverage of the question's focus on configuration or policy change correlation, limiting its utility for confidently answering the question.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Compare the Input (the monitoring question) with the Retrieval Context (metric description) to check if the description clearly addresses the question's focus and key concepts.\",\n    \"Evaluate the clarity of the metric description by assessing whether it is concise, uses understandable language, and avoids ambiguity in relation to the question.\",\n    \"Assess coverage by verifying that the description explains what is measured, including units, context, and potential implications that support answering the question.\",\n    \"Determine utility by judging if the description provides sufficient and relevant information enabling the user to confidently answer the monitoring question.\"\n] \n \nRubric:\nNone \n \nScore: 0.33361129392064826"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Compare the Input (the monitoring question) with the Retrieval Context (metric description) to check if the description clearly addresses the question's focus and key concepts.",
                            "Evaluate the clarity of the metric description by assessing whether it is concise, uses understandable language, and avoids ambiguity in relation to the question.",
                            "Assess coverage by verifying that the description explains what is measured, including units, context, and potential implications that support answering the question.",
                            "Determine utility by judging if the description provides sufficient and relevant information enabling the user to confidently answer the monitoring question."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"kms.amazonaws.com\\\", \\\"EventName\\\": \\\"Generate*\\\"}\", \"hyperparameters\": null, \"input\": \"Are there spikes in Generate* API calls that could indicate an unusual key material creation activity?\", \"retrieval_context\": [\" - Redshift cluster creation events in CloudTrail capture all API calls initiating the provisioning of new Redshift clusters (e.g., CreateCluster). These events indicate when new data warehouse resources are being deployed or configured, impacting capacity and cost.  \\n**Purpose:** Enables SREs to monitor and audit cluster provisioning activities for operational control and security compliance.  \\n**Alert Threshold:** Trigger alerts on an unusually high number of cluster creation events within a short time window (e.g., >3 creates in 1 hour), which may indicate automation errors, misconfigurations, or unauthorized resource provisioning.  \\n**Impact:**  \\n- **High values:** May lead to resource sprawl, increased costs, and potential performance degradation due to over-provisioning. Could also signal security risks if unexpected clusters are created.  \\n- **Low or zero values:** Normal in stable environments; no new clusters being created means stable infrastructure.  \\n**Example Alert Rule:**  \\n\\u201cAlert if count of events with EventSource='redshift.amazonaws.com' and EventName starting with 'Create' exceeds 3 within 60 minutes.\\u201d  \\n**Dashboard Use:** Visualize the frequency of Redshift cluster creation events over time to detect spikes or anomalies, correlating with deployment activities or security incidents.\", \" - S3 bucket creation events captured by CloudTrail under **{\\\"EventSource\\\": \\\"s3.amazonaws.com\\\", \\\"EventName\\\": \\\"Create*\\\"}** indicate when new buckets or related resources (e.g., bucket policies, access points) are provisioned. These events help SREs monitor infrastructure changes that affect data storage, security posture, and compliance.\\n\\n**Purpose:**  \\nTrack and audit the creation of S3 buckets and associated configurations to ensure proper governance, prevent unauthorized resource sprawl, and maintain compliance with organizational policies.\\n\\n**Alert Threshold:**  \\nTrigger an alert if the number of S3 bucket creation events exceeds a defined threshold within a short time window (e.g., more than 5 bucket creations within 10 minutes), which may indicate automated provisioning errors, misconfigurations, or potential security incidents such as unauthorized resource creation.\\n\\n**Impact of Values:**  \\n- **High frequency:** May signal abnormal activity, such as a compromised credential or runaway automation scripts creating excessive buckets, leading to increased costs, security risks, or compliance violations.  \\n- **Low or zero frequency:** Normal in stable environments; however, sudden spikes should be investigated promptly.\\n\\n**Example Alert Rule:**  \\n\\u201cAlert when count of events with EventSource = 's3.amazonaws.com' and EventName starting with 'Create' exceeds 5 within 10 minutes.\\u201d\\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of S3 Create* events over time, with thresholds marked to highlight unusual spikes, enabling quick identification of abnormal bucket creation activity.\", \" - This pattern captures all Amazon EKS \\\"Describe\\\" API operations logged in CloudTrail, which occur when cluster metadata, node group configurations, or add-on details are queried. It helps SREs monitor how often EKS cluster information is accessed, providing visibility into potential reconnaissance or troubleshooting activities. A sudden spike in Describe calls\\u2014such as exceeding 100 requests within 5 minutes\\u2014may indicate unusual or automated querying that could precede configuration changes or security incidents, warranting an alert. Conversely, consistently low or zero Describe activity might suggest lack of monitoring or insufficient operational visibility. For example, an alert rule could trigger when Describe API calls surpass 100 in a 5-minute window, and a dashboard widget might display a time series graph of Describe call counts to track trends and detect anomalies in cluster information access patterns.\", \" - This pattern detects AWS KMS API calls that begin with \\\"Generate,\\\" such as GenerateDataKey and GenerateRandom. It captures events where cryptographic keys, data keys, or random byte sequences are created. The measurement is event occurrence count, indicating how many such generation requests were made. This helps monitor key material creation activities within AWS KMS.\", \" - This pattern detects Secrets Manager creation events in CloudTrail, specifically any API calls starting with \\\"Create\\\" (e.g., CreateSecret). It helps SREs monitor when new secrets, secret versions, or related configurations are added, which could indicate deployment changes or potential security risks.  \\n**Alert threshold:** Trigger an alert if the number of create events exceeds a baseline (e.g., more than 5 creates within 10 minutes), as a sudden spike may signal unauthorized secret creation or misconfiguration. Conversely, zero create events over an extended period in an active environment might indicate issues with deployment pipelines or automation failures.  \\n**Impact:**  \\n- High values: Could indicate potential security breaches, unauthorized secret provisioning, or rapid environment changes requiring immediate investigation.  \\n- Low values: May suggest stalled deployments or automation problems, potentially delaying application updates or secret rotations.  \\n**Example usage:**  \\nIn a dashboard, plot the count of Secrets Manager Create* events over time to visualize spikes. An alert rule could be:  \\n`WHEN count(secretsmanager.amazonaws.com Create* events) > 5 within 10 minutes THEN trigger alert \\\"Unusual Secrets Creation Activity\\\"`  \\nThis enables proactive detection of abnormal secret creation activity, helping maintain security and operational stability.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": false,
                        "score": 0.7881166978881253,
                        "reason": "The retrieval context clearly addresses the input question by describing detection of AWS KMS API calls starting with 'Generate,' including examples like GenerateDataKey and GenerateRandom, which relate directly to key material creation. It explains the measurement as event occurrence count and its relevance to monitoring key creation activities. The description is understandable and concise, using terminology consistent with the input. However, it lacks explicit mention of alert thresholds or examples of spikes, which would enhance utility by providing actionable insights for identifying unusual activity.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Compare the Input (monitoring question) with the Retrieval Context (metric description) to ensure the description clearly addresses the question.\",\n    \"Evaluate the clarity of the Retrieval Context in terms of understandability and conciseness, considering the terminology used in the Input.\",\n    \"Assess coverage by verifying the description explains what is measured, including units, context, and implications, ensuring relevance to the Input question.\",\n    \"Determine the utility of the description by checking if it provides actionable or insightful information that directly helps answer the Input question.\"\n] \n \nRubric:\nNone \n \nScore: 0.7881166978881253"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Compare the Input (monitoring question) with the Retrieval Context (metric description) to ensure the description clearly addresses the question.",
                            "Evaluate the clarity of the Retrieval Context in terms of understandability and conciseness, considering the terminology used in the Input.",
                            "Assess coverage by verifying the description explains what is measured, including units, context, and implications, ensuring relevance to the Input question.",
                            "Determine the utility of the description by checking if it provides actionable or insightful information that directly helps answer the Input question."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"kms.amazonaws.com\\\", \\\"EventName\\\": \\\"Decrypt*\\\"}\", \"hyperparameters\": null, \"input\": \"Does a sudden spike in Decrypt events exceed 100 within a short period, indicating potential unauthorized access to encrypted data?\", \"retrieval_context\": [\" - This pattern captures AWS KMS Decrypt API calls recorded in CloudTrail, indicating when encrypted data is accessed and decrypted using KMS keys. It helps SREs monitor data access events for security auditing and anomaly detection. A sudden spike in Decrypt events may signal unusual or unauthorized data access, while consistently low or expected volumes suggest normal operation. As a threshold, alerting on a sustained increase exceeding 3 standard deviations above the historical average or a sudden burst of Decrypt calls within a short time window (e.g., 5 minutes) is recommended. For example, an alert rule could trigger when the count of Decrypt events exceeds 100 in 5 minutes, indicating potential data exfiltration or misuse. In dashboards, tracking the rate of Decrypt events over time alongside user identities and key IDs can help quickly identify suspicious patterns or compromised credentials.\", \" - This pattern captures AWS KMS encryption API calls (e.g., Encrypt, EncryptData) recorded in CloudTrail, indicating when data is being encrypted using customer-managed or AWS-managed KMS keys. It helps SREs monitor cryptographic operations to ensure data protection policies are enforced and to detect unusual encryption activity that could signal misuse or security incidents.\\n\\n**Purpose:** Track the frequency and context of encryption operations to verify normal application behavior and compliance with data security standards.\\n\\n**Alert Threshold:** Trigger an alert if the number of Encrypt* events exceeds a baseline threshold (e.g., a sudden spike beyond 3 standard deviations from the average hourly rate) or if encryption requests originate from unexpected principals or regions.\\n\\n**Impact of Values:**  \\n- **High volume:** May indicate increased data processing, potential automated encryption loops, or unauthorized bulk encryption attempts, which could impact performance or signal a security breach.  \\n- **Low or zero volume:** Could suggest application issues, disabled encryption, or misconfigured services failing to encrypt data as required, risking data exposure.\\n\\n**Example Alert Rule:**  \\nAlert when Encrypt* events exceed 500 per hour or when encryption requests come from an unrecognized IAM role, triggering an investigation into possible misuse or operational anomalies.\\n\\n**Dashboard Use:**  \\nVisualize Encrypt* event counts over time alongside related Decrypt* events and key usage metrics to correlate encryption activity with application workloads and detect deviations from normal patterns.\", \" - This pattern captures CloudWatch API operations that list resources, such as metrics, log groups, and alarms, as recorded in CloudTrail under EventSource \\\"cloudwatch.amazonaws.com\\\" with EventNames starting with \\\"List\\\". It helps SREs monitor enumeration activity on CloudWatch resources, which can indicate normal operational queries or potential reconnaissance by unauthorized users.\\n\\n**Purpose:**  \\nTo track and analyze the frequency of CloudWatch resource listing actions, enabling detection of unusual spikes that may signal automated scanning, misconfigurations, or security incidents.\\n\\n**Threshold Guidance:**  \\nSet alert thresholds based on baseline activity for your environment. For example, trigger an alert if the number of List* events exceeds 3 standard deviations above the daily average or if more than 100 list operations occur within a 5-minute window, indicating abnormal enumeration.\\n\\n**Impact of Values:**  \\n- **High values:** May indicate excessive or automated querying of CloudWatch resources, potentially revealing reconnaissance attempts or inefficient scripts causing performance overhead.  \\n- **Low values:** Typically normal, but a sudden drop could suggest issues with monitoring tools or API access problems.\\n\\n**Example Alert Rule:**  \\nTrigger an alert when the count of CloudWatch List* events in CloudTrail exceeds 100 within 5 minutes, signaling potential unauthorized or excessive enumeration activity.\\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of CloudWatch List* events per 5-minute interval, overlaid with the alert threshold line, to visualize normal versus anomalous listing activity.\", \" - This pattern captures all AWS Security Token Service (STS) \\\"Get\\\" operations, such as `GetSessionToken`, `GetCallerIdentity`, and similar API calls that issue or validate temporary security credentials. In CloudTrail, these events indicate when users or services request short-lived credentials to access AWS resources.\\n\\n**Purpose:**  \\nMonitor STS Get* events to detect unusual or excessive requests for temporary credentials, which can signal automation activity, credential misuse, or potential security incidents like privilege escalation or compromised identities.\\n\\n**Alert Threshold:**  \\nTrigger an alert when the count of STS Get* events exceeds a baseline threshold established from normal activity patterns\\u2014commonly, a sudden spike above 3-5 times the average hourly rate or an absolute count exceeding 100 requests per hour, depending on your environment size and usage.\\n\\n**Impact of Values:**  \\n- **High values:** May indicate automated processes requesting many temporary credentials, potential credential abuse, or an attacker attempting to escalate privileges or move laterally. Prompt investigation is warranted.  \\n- **Low or expected values:** Reflect normal operation with routine credential issuance and validation.\\n\\n**Example Usage:**  \\nIn a monitoring dashboard, plot the count of `sts.amazonaws.com` events with `EventName` matching `Get*` over time. Set an alert rule such as:  \\n`WHEN count(events where EventSource=\\\"sts.amazonaws.com\\\" AND EventName LIKE \\\"Get*\\\") > 100 within 1 hour THEN alert \\\"High STS Get* activity detected\\\"`  \\nThis helps SREs quickly identify abnormal credential request patterns and respond accordingly.\", \" - This pattern captures all Amazon EKS \\\"Describe\\\" API operations logged in CloudTrail, which occur when cluster metadata, node group configurations, or add-on details are queried. It helps SREs monitor how often EKS cluster information is accessed, providing visibility into potential reconnaissance or troubleshooting activities. A sudden spike in Describe calls\\u2014such as exceeding 100 requests within 5 minutes\\u2014may indicate unusual or automated querying that could precede configuration changes or security incidents, warranting an alert. Conversely, consistently low or zero Describe activity might suggest lack of monitoring or insufficient operational visibility. For example, an alert rule could trigger when Describe API calls surpass 100 in a 5-minute window, and a dashboard widget might display a time series graph of Describe call counts to track trends and detect anomalies in cluster information access patterns.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": true,
                        "score": 0.909534946104308,
                        "reason": "The Retrieval Context directly addresses the Input question by explaining the monitoring of AWS KMS Decrypt events, including what is measured (Decrypt API calls), relevant units (count within 5 minutes), and the significance of a sudden spike exceeding 100 events as a potential indicator of unauthorized access. The description is clear, concise, and provides actionable alert thresholds and dashboard usage, enabling confident and accurate responses to the question. Minor deduction is due to the context being part of a larger multi-pattern list, which slightly reduces focus but does not impair understanding.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Compare the Input (monitoring question) with the Retrieval Context (metric description) to assess if the description directly addresses the question's focus.\",\n    \"Evaluate clarity by checking if the Retrieval Context is concise and understandable in relation to the terminology and intent presented in the Input.\",\n    \"Assess coverage by verifying that the Retrieval Context explains what is measured, in what units, provides relevant context, and potential implications pertinent to the Input question.\",\n    \"Determine utility by confirming the Retrieval Context enables a user to confidently and accurately answer the Input question based on the information provided.\"\n] \n \nRubric:\nNone \n \nScore: 0.909534946104308"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Compare the Input (monitoring question) with the Retrieval Context (metric description) to assess if the description directly addresses the question's focus.",
                            "Evaluate clarity by checking if the Retrieval Context is concise and understandable in relation to the terminology and intent presented in the Input.",
                            "Assess coverage by verifying that the Retrieval Context explains what is measured, in what units, provides relevant context, and potential implications pertinent to the Input question.",
                            "Determine utility by confirming the Retrieval Context enables a user to confidently and accurately answer the Input question based on the information provided."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"kms.amazonaws.com\\\", \\\"EventName\\\": \\\"Delete*\\\"}\", \"hyperparameters\": null, \"input\": \"Are multiple AWS KMS key deletions occurring within a short period, indicating potential malicious activity or misconfiguration?\", \"retrieval_context\": [\" - This pattern captures AWS KMS encryption API calls (e.g., Encrypt, EncryptData) recorded in CloudTrail, indicating when data is being encrypted using customer-managed or AWS-managed KMS keys. It helps SREs monitor cryptographic operations to ensure data protection policies are enforced and to detect unusual encryption activity that could signal misuse or security incidents.\\n\\n**Purpose:** Track the frequency and context of encryption operations to verify normal application behavior and compliance with data security standards.\\n\\n**Alert Threshold:** Trigger an alert if the number of Encrypt* events exceeds a baseline threshold (e.g., a sudden spike beyond 3 standard deviations from the average hourly rate) or if encryption requests originate from unexpected principals or regions.\\n\\n**Impact of Values:**  \\n- **High volume:** May indicate increased data processing, potential automated encryption loops, or unauthorized bulk encryption attempts, which could impact performance or signal a security breach.  \\n- **Low or zero volume:** Could suggest application issues, disabled encryption, or misconfigured services failing to encrypt data as required, risking data exposure.\\n\\n**Example Alert Rule:**  \\nAlert when Encrypt* events exceed 500 per hour or when encryption requests come from an unrecognized IAM role, triggering an investigation into possible misuse or operational anomalies.\\n\\n**Dashboard Use:**  \\nVisualize Encrypt* event counts over time alongside related Decrypt* events and key usage metrics to correlate encryption activity with application workloads and detect deviations from normal patterns.\", \" - This pattern captures ECS deletion events recorded in CloudTrail, specifically any API calls starting with \\\"Delete\\\" from the ECS service (e.g., DeleteCluster, DeleteService, DeleteTaskSet). Its purpose is to monitor when ECS resources are removed, which can signal intentional cleanup or unintended disruptions affecting service availability.\\n\\n**Threshold guidance:**  \\n- Trigger an alert if the number of ECS deletion events exceeds a baseline threshold within a short time window (e.g., more than 3 Delete* events in 5 minutes), as this may indicate accidental mass deletion or a security incident.  \\n- Low or expected deletion rates typically reflect routine maintenance or scaling down of resources and generally have minimal impact.\\n\\n**Impact:**  \\n- High deletion event counts can lead to service downtime, loss of running tasks, or cluster instability, requiring immediate investigation.  \\n- Low or zero deletion events usually indicate stable ECS resource management.\\n\\n**Example alert rule:**  \\n- Alert when `count(events where EventSource=\\\"ecs.amazonaws.com\\\" and EventName starts with \\\"Delete\\\") > 3` within 5 minutes.  \\n- This alert can be visualized on a dashboard showing ECS Delete* event counts over time, helping SREs quickly identify unusual spikes and correlate with service health metrics.\", \" - This pattern captures all EC2 resource deletion events recorded in CloudTrail, triggered by any API calls starting with \\\"Delete\\\" from the EC2 service (e.g., DeleteSecurityGroup, DeleteNetworkInterface). Its purpose is to monitor and alert on the removal of critical EC2 components, which can impact infrastructure stability and security.\\n\\n**Threshold guidance:**  \\n- Set an alert if the number of deletion events exceeds a baseline threshold within a short time window (e.g., more than 5 deletions in 10 minutes), as this may indicate accidental mass deletions or malicious activity.  \\n- A low or zero count is typical during normal operations, while sudden spikes warrant immediate investigation.\\n\\n**Impact:**  \\n- High deletion event counts can lead to service disruptions, loss of network connectivity, or security vulnerabilities if key resources like security groups or network interfaces are removed unexpectedly.  \\n- Low or no deletion activity generally indicates stable infrastructure management.\\n\\n**Example alert rule:**  \\nTrigger an alert when the count of events matching {\\\"EventSource\\\": \\\"ec2.amazonaws.com\\\", \\\"EventName\\\": \\\"Delete*\\\"} exceeds 5 within 10 minutes.\\n\\n**Example dashboard usage:**  \\nVisualize the count of EC2 deletion events over time to identify unusual spikes, correlating with other operational metrics to assess potential impact on system availability or security posture.\", \" - This pattern detects AWS KMS key deletion events captured in CloudTrail, specifically any API calls starting with \\\"Delete\\\" (e.g., DeleteKey). Its purpose is to monitor the removal of cryptographic keys, which are critical for data encryption and access control. Frequent or unexpected deletions may indicate potential security risks, accidental data loss, or cleanup activities.\\n\\n**Alert Threshold:**  \\nTrigger an alert if more than 1 Delete* event occurs within a short time window (e.g., 1 hour), as multiple deletions could signify malicious activity or misconfiguration.\\n\\n**Impact:**  \\n- **High values:** Multiple key deletions in a brief period can lead to irreversible data access loss, service disruptions, or security breaches. Immediate investigation is required.  \\n- **Low values:** Occasional single deletions may be part of routine key rotation or cleanup but should still be reviewed for authorization.\\n\\n**Example Alert Rule:**  \\n```\\nWHEN count of events WHERE EventSource = \\\"kms.amazonaws.com\\\" AND EventName LIKE \\\"Delete%\\\" OVER last 1 hour > 1  \\nTHEN trigger alert \\\"Multiple KMS key deletions detected\\\"\\n```\\n\\n**Dashboard Use Case:**  \\nVisualize the count of Delete* events over time to identify spikes or unusual patterns, correlating with operational changes or security incidents. This helps SREs proactively manage key lifecycle and maintain data protection integrity.\", \" - Tracks all AWS Lambda function deletion events captured in CloudTrail. Monitoring **{\\\"EventSource\\\": \\\"lambda.amazonaws.com\\\", \\\"EventName\\\": \\\"Delete*\\\"}** helps SREs detect when Lambda functions are removed, which is critical for maintaining application stability, ensuring proper resource cleanup, and preventing accidental or unauthorized deletions.  \\n\\n**Alert Threshold:** Trigger an alert if more than 3 Lambda function deletions occur within a 1-hour window, as this may indicate a misconfiguration, automated script error, or potential security breach.  \\n\\n**Impact:**  \\n- **High values:** A spike in deletions can lead to service disruptions, loss of critical functionality, or security incidents if unauthorized deletions occur. Immediate investigation is required.  \\n- **Low or zero values:** Normal operation; infrequent deletions are expected during routine maintenance or deployments.  \\n\\n**Example Alert Rule:**  \\n`WHEN count(events where EventSource=\\\"lambda.amazonaws.com\\\" AND EventName LIKE \\\"Delete%\\\") > 3 WITHIN 1 hour THEN alert \\\"Unusual number of Lambda deletions detected\\\"`  \\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of Lambda deletion events per hour, annotated with alert thresholds, enabling quick identification of abnormal deletion activity.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": true,
                        "score": 0.9320821287837052,
                        "reason": "The retrieval context clearly addresses the input question by describing a pattern that detects multiple AWS KMS key deletion events within a short time window, including alert thresholds, impact, and example alert rules. The description is concise, easy to understand, and covers what is measured (Delete* events), relevant units (e.g., within 1 hour), operational context (CloudTrail events), and implications related to potential malicious activity or misconfiguration. It provides sufficient information for a user to accurately monitor and respond to the question. The only minor shortcoming is the lack of explicit mention of the exact time window definition beyond 'e.g., 1 hour,' which slightly limits precision.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Compare the Input (monitoring question) and the Retrieval Context (metric description) to ensure the description clearly addresses the question's focus.\",\n    \"Evaluate Clarity by checking if the metric description is concise and easy to understand in relation to the question asked.\",\n    \"Assess Coverage by verifying whether the description includes what is measured, relevant units, the operational context, and implications that relate directly to the input question.\",\n    \"Determine Utility by judging if the description provides sufficient information to enable a user to answer the monitoring question accurately.\"\n] \n \nRubric:\nNone \n \nScore: 0.9320821287837052"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Compare the Input (monitoring question) and the Retrieval Context (metric description) to ensure the description clearly addresses the question's focus.",
                            "Evaluate Clarity by checking if the metric description is concise and easy to understand in relation to the question asked.",
                            "Assess Coverage by verifying whether the description includes what is measured, relevant units, the operational context, and implications that relate directly to the input question.",
                            "Determine Utility by judging if the description provides sufficient information to enable a user to answer the monitoring question accurately."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"kms.amazonaws.com\\\", \\\"EventName\\\": \\\"Encrypt*\\\"}\", \"hyperparameters\": null, \"input\": \"Does the number of Encrypt* events exceed 500 per hour, indicating a potential security breach or operational anomaly?\", \"retrieval_context\": [\" - This pattern captures AWS KMS Decrypt API calls recorded in CloudTrail, indicating when encrypted data is accessed and decrypted using KMS keys. It helps SREs monitor data access events for security auditing and anomaly detection. A sudden spike in Decrypt events may signal unusual or unauthorized data access, while consistently low or expected volumes suggest normal operation. As a threshold, alerting on a sustained increase exceeding 3 standard deviations above the historical average or a sudden burst of Decrypt calls within a short time window (e.g., 5 minutes) is recommended. For example, an alert rule could trigger when the count of Decrypt events exceeds 100 in 5 minutes, indicating potential data exfiltration or misuse. In dashboards, tracking the rate of Decrypt events over time alongside user identities and key IDs can help quickly identify suspicious patterns or compromised credentials.\", \" - This pattern captures AWS KMS encryption API calls (e.g., Encrypt, EncryptData) recorded in CloudTrail, indicating when data is being encrypted using customer-managed or AWS-managed KMS keys. It helps SREs monitor cryptographic operations to ensure data protection policies are enforced and to detect unusual encryption activity that could signal misuse or security incidents.\\n\\n**Purpose:** Track the frequency and context of encryption operations to verify normal application behavior and compliance with data security standards.\\n\\n**Alert Threshold:** Trigger an alert if the number of Encrypt* events exceeds a baseline threshold (e.g., a sudden spike beyond 3 standard deviations from the average hourly rate) or if encryption requests originate from unexpected principals or regions.\\n\\n**Impact of Values:**  \\n- **High volume:** May indicate increased data processing, potential automated encryption loops, or unauthorized bulk encryption attempts, which could impact performance or signal a security breach.  \\n- **Low or zero volume:** Could suggest application issues, disabled encryption, or misconfigured services failing to encrypt data as required, risking data exposure.\\n\\n**Example Alert Rule:**  \\nAlert when Encrypt* events exceed 500 per hour or when encryption requests come from an unrecognized IAM role, triggering an investigation into possible misuse or operational anomalies.\\n\\n**Dashboard Use:**  \\nVisualize Encrypt* event counts over time alongside related Decrypt* events and key usage metrics to correlate encryption activity with application workloads and detect deviations from normal patterns.\", \" - This pattern captures all AWS Security Token Service (STS) \\\"Get\\\" operations, such as `GetSessionToken`, `GetCallerIdentity`, and similar API calls that issue or validate temporary security credentials. In CloudTrail, these events indicate when users or services request short-lived credentials to access AWS resources.\\n\\n**Purpose:**  \\nMonitor STS Get* events to detect unusual or excessive requests for temporary credentials, which can signal automation activity, credential misuse, or potential security incidents like privilege escalation or compromised identities.\\n\\n**Alert Threshold:**  \\nTrigger an alert when the count of STS Get* events exceeds a baseline threshold established from normal activity patterns\\u2014commonly, a sudden spike above 3-5 times the average hourly rate or an absolute count exceeding 100 requests per hour, depending on your environment size and usage.\\n\\n**Impact of Values:**  \\n- **High values:** May indicate automated processes requesting many temporary credentials, potential credential abuse, or an attacker attempting to escalate privileges or move laterally. Prompt investigation is warranted.  \\n- **Low or expected values:** Reflect normal operation with routine credential issuance and validation.\\n\\n**Example Usage:**  \\nIn a monitoring dashboard, plot the count of `sts.amazonaws.com` events with `EventName` matching `Get*` over time. Set an alert rule such as:  \\n`WHEN count(events where EventSource=\\\"sts.amazonaws.com\\\" AND EventName LIKE \\\"Get*\\\") > 100 within 1 hour THEN alert \\\"High STS Get* activity detected\\\"`  \\nThis helps SREs quickly identify abnormal credential request patterns and respond accordingly.\", \" - This pattern captures all update-related events from AWS Secrets Manager, such as modifications to secret values, rotation configurations, and access policy changes, as recorded in CloudTrail. Its purpose is to monitor changes that could affect the confidentiality, integrity, or availability of secrets critical to application security and operations.\\n\\n**Threshold guidance:**  \\n- Trigger an alert if the number of update events exceeds a baseline threshold within a short time window (e.g., more than 5 update events in 10 minutes), as this may indicate unusual or potentially unauthorized activity.  \\n- Conversely, an absence of expected rotation updates over a longer period (e.g., no rotation updates in 30 days) could signal stale secrets and increased security risk.\\n\\n**Impact of values:**  \\n- **High frequency of update events:** May indicate automated rotation, bulk secret changes, or suspicious activity such as credential compromise or insider threat. Immediate investigation is recommended.  \\n- **Low or zero update events:** Could mean secrets are not being rotated as per policy, increasing the risk of secret leakage or misuse.\\n\\n**Example alert rule:**  \\nAlert when `count(secretsmanager.amazonaws.com Update* events) > 5` within 10 minutes, excluding known maintenance windows.  \\n**Example dashboard widget:**  \\nA time-series graph showing the count of Secrets Manager update events over time, annotated with alerts triggered when thresholds are breached, helping SREs quickly identify abnormal secret modification patterns.\", \" - This pattern detects Secrets Manager creation events in CloudTrail, specifically any API calls starting with \\\"Create\\\" (e.g., CreateSecret). It helps SREs monitor when new secrets, secret versions, or related configurations are added, which could indicate deployment changes or potential security risks.  \\n**Alert threshold:** Trigger an alert if the number of create events exceeds a baseline (e.g., more than 5 creates within 10 minutes), as a sudden spike may signal unauthorized secret creation or misconfiguration. Conversely, zero create events over an extended period in an active environment might indicate issues with deployment pipelines or automation failures.  \\n**Impact:**  \\n- High values: Could indicate potential security breaches, unauthorized secret provisioning, or rapid environment changes requiring immediate investigation.  \\n- Low values: May suggest stalled deployments or automation problems, potentially delaying application updates or secret rotations.  \\n**Example usage:**  \\nIn a dashboard, plot the count of Secrets Manager Create* events over time to visualize spikes. An alert rule could be:  \\n`WHEN count(secretsmanager.amazonaws.com Create* events) > 5 within 10 minutes THEN trigger alert \\\"Unusual Secrets Creation Activity\\\"`  \\nThis enables proactive detection of abnormal secret creation activity, helping maintain security and operational stability.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": true,
                        "score": 0.9,
                        "reason": "The description directly addresses the question about Encrypt* events exceeding 500 per hour and potential security or operational anomalies. It clearly explains what is measured (AWS KMS encryption API calls), provides relevant units (events per hour), and contextualizes the impact of high volumes, including security breaches and operational issues. The inclusion of an example alert rule matching the threshold in the question enhances clarity and utility, enabling confident user interpretation. Minor deduction is due to some complexity in phrasing that could be slightly more concise.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Compare the Input (monitoring question) and Retrieval Context (metric description) to ensure the description directly addresses the question's intent.\",\n    \"Evaluate the clarity of the description by checking if it is understandable and concise relative to the specific terms and concepts used in the question.\",\n    \"Assess coverage by verifying whether the description explains what is measured, includes relevant units, provides context, and highlights implications that relate to the question.\",\n    \"Judge utility by determining if the description enables a user to confidently answer the question based on the provided information.\"\n] \n \nRubric:\nNone \n \nScore: 0.9"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Compare the Input (monitoring question) and Retrieval Context (metric description) to ensure the description directly addresses the question's intent.",
                            "Evaluate the clarity of the description by checking if it is understandable and concise relative to the specific terms and concepts used in the question.",
                            "Assess coverage by verifying whether the description explains what is measured, includes relevant units, provides context, and highlights implications that relate to the question.",
                            "Judge utility by determining if the description enables a user to confidently answer the question based on the provided information."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"secretsmanager.amazonaws.com\\\", \\\"EventName\\\": \\\"Update*\\\"}\", \"hyperparameters\": null, \"input\": \"Does a high frequency of update events from AWS Secrets Manager indicate automated rotation or potentially suspicious activity?\", \"retrieval_context\": [\" - IAM update events capture all modifications made to IAM resources such as users, roles, groups, policies, and credentials. These events indicate changes to permissions, access controls, and security configurations, which are critical for maintaining the principle of least privilege and preventing unauthorized privilege escalation. In CloudTrail, **{\\\"EventSource\\\": \\\"iam.amazonaws.com\\\", \\\"EventName\\\": \\\"Update*\\\"}** helps track who made changes, what was changed, and when, enabling audit and compliance verification.\\n\\n**Alert Threshold:** Trigger an alert when the number of IAM update events exceeds a baseline threshold within a short time window (e.g., more than 5 update events in 10 minutes), or when specific sensitive updates occur, such as policy changes granting administrative privileges or credential rotations outside of scheduled maintenance.\\n\\n**Impact of Values:**  \\n- **High values:** A spike in update events may indicate automated scripts, bulk permission changes, or potential malicious activity like privilege escalation attempts. Immediate investigation is warranted to confirm legitimacy.  \\n- **Low values:** Normal or zero update events typically indicate stable IAM configurations with no recent permission changes, which is expected in steady-state operations.\\n\\n**Example Usage:**  \\nIn a dashboard, display a time series graph of IAM update events filtered by event name pattern \\\"Update*\\\". Set an alert rule to notify the SRE team if the count of these events exceeds 5 within any rolling 10-minute window, or if any update event modifies policies granting \\\"AdministratorAccess\\\". This enables rapid detection of potentially risky permission changes and supports proactive security posture management.\", \" - S3 Get* events in CloudTrail capture all read operations on S3 objects, such as GetObject, GetObjectAcl, and GetObjectVersion. These events indicate when data is accessed or downloaded from your buckets, providing critical visibility into data retrieval patterns and potential unauthorized access.  \\n\\n**Purpose:** Monitor and audit object read activity to detect unusual access spikes, potential data exfiltration, or performance bottlenecks caused by excessive reads.\\n\\n**Alert Threshold:** Trigger an alert if the number of Get* events exceeds a baseline threshold (e.g., a 3x increase over the average hourly rate) or if access occurs from unexpected IP addresses or principals.\\n\\n**Impact:**  \\n- **High values:** May indicate heavy data consumption, possible data leakage, or abuse of resources leading to increased costs and degraded application performance.  \\n- **Low values:** Could suggest reduced usage, potential application issues, or misconfigured permissions blocking legitimate access.\\n\\n**Example Alert Rule:**  \\nAlert when the count of s3.amazonaws.com Get* events in CloudTrail exceeds 5000 within 1 hour, or when access originates from an IP address outside your trusted network range.\\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing hourly counts of Get* events per bucket, combined with a heatmap of source IP addresses, enabling quick identification of unusual access patterns or spikes in data retrieval.\", \" - This pattern captures AWS KMS encryption API calls (e.g., Encrypt, EncryptData) recorded in CloudTrail, indicating when data is being encrypted using customer-managed or AWS-managed KMS keys. It helps SREs monitor cryptographic operations to ensure data protection policies are enforced and to detect unusual encryption activity that could signal misuse or security incidents.\\n\\n**Purpose:** Track the frequency and context of encryption operations to verify normal application behavior and compliance with data security standards.\\n\\n**Alert Threshold:** Trigger an alert if the number of Encrypt* events exceeds a baseline threshold (e.g., a sudden spike beyond 3 standard deviations from the average hourly rate) or if encryption requests originate from unexpected principals or regions.\\n\\n**Impact of Values:**  \\n- **High volume:** May indicate increased data processing, potential automated encryption loops, or unauthorized bulk encryption attempts, which could impact performance or signal a security breach.  \\n- **Low or zero volume:** Could suggest application issues, disabled encryption, or misconfigured services failing to encrypt data as required, risking data exposure.\\n\\n**Example Alert Rule:**  \\nAlert when Encrypt* events exceed 500 per hour or when encryption requests come from an unrecognized IAM role, triggering an investigation into possible misuse or operational anomalies.\\n\\n**Dashboard Use:**  \\nVisualize Encrypt* event counts over time alongside related Decrypt* events and key usage metrics to correlate encryption activity with application workloads and detect deviations from normal patterns.\", \" - This pattern captures all update-related events from AWS Secrets Manager, such as modifications to secret values, rotation configurations, and access policy changes, as recorded in CloudTrail. Its purpose is to monitor changes that could affect the confidentiality, integrity, or availability of secrets critical to application security and operations.\\n\\n**Threshold guidance:**  \\n- Trigger an alert if the number of update events exceeds a baseline threshold within a short time window (e.g., more than 5 update events in 10 minutes), as this may indicate unusual or potentially unauthorized activity.  \\n- Conversely, an absence of expected rotation updates over a longer period (e.g., no rotation updates in 30 days) could signal stale secrets and increased security risk.\\n\\n**Impact of values:**  \\n- **High frequency of update events:** May indicate automated rotation, bulk secret changes, or suspicious activity such as credential compromise or insider threat. Immediate investigation is recommended.  \\n- **Low or zero update events:** Could mean secrets are not being rotated as per policy, increasing the risk of secret leakage or misuse.\\n\\n**Example alert rule:**  \\nAlert when `count(secretsmanager.amazonaws.com Update* events) > 5` within 10 minutes, excluding known maintenance windows.  \\n**Example dashboard widget:**  \\nA time-series graph showing the count of Secrets Manager update events over time, annotated with alerts triggered when thresholds are breached, helping SREs quickly identify abnormal secret modification patterns.\", \" - This pattern detects Secrets Manager creation events in CloudTrail, specifically any API calls starting with \\\"Create\\\" (e.g., CreateSecret). It helps SREs monitor when new secrets, secret versions, or related configurations are added, which could indicate deployment changes or potential security risks.  \\n**Alert threshold:** Trigger an alert if the number of create events exceeds a baseline (e.g., more than 5 creates within 10 minutes), as a sudden spike may signal unauthorized secret creation or misconfiguration. Conversely, zero create events over an extended period in an active environment might indicate issues with deployment pipelines or automation failures.  \\n**Impact:**  \\n- High values: Could indicate potential security breaches, unauthorized secret provisioning, or rapid environment changes requiring immediate investigation.  \\n- Low values: May suggest stalled deployments or automation problems, potentially delaying application updates or secret rotations.  \\n**Example usage:**  \\nIn a dashboard, plot the count of Secrets Manager Create* events over time to visualize spikes. An alert rule could be:  \\n`WHEN count(secretsmanager.amazonaws.com Create* events) > 5 within 10 minutes THEN trigger alert \\\"Unusual Secrets Creation Activity\\\"`  \\nThis enables proactive detection of abnormal secret creation activity, helping maintain security and operational stability.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": true,
                        "score": 0.9,
                        "reason": "The retrieval context directly addresses the question by explaining that a high frequency of AWS Secrets Manager update events may indicate automated rotation or suspicious activity, including potential credential compromise or insider threat. It provides clear threshold guidance, impact of values, and example alert rules, making the description concise, understandable, and comprehensive. The context includes what is measured (update events), units (e.g., more than 5 events in 10 minutes), relevant security implications, and practical monitoring advice, enabling effective user interpretation. The only minor shortcoming is the lack of explicit differentiation between automated rotation and suspicious activity beyond the general recommendation for investigation.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Compare the Input question and the Retrieval Context description to ensure the description clearly addresses the question's focus.\",\n    \"Evaluate the clarity of the description by checking if it is concise and easily understandable in relation to the Input question.\",\n    \"Assess coverage by verifying that the description includes what is measured, units, relevant context, and potential implications needed to answer the Input question.\",\n    \"Determine the utility by measuring how effectively the description enables the user to answer the Input question; identify gaps where the description may fall short.\"\n] \n \nRubric:\nNone \n \nScore: 0.9"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Compare the Input question and the Retrieval Context description to ensure the description clearly addresses the question's focus.",
                            "Evaluate the clarity of the description by checking if it is concise and easily understandable in relation to the Input question.",
                            "Assess coverage by verifying that the description includes what is measured, units, relevant context, and potential implications needed to answer the Input question.",
                            "Determine the utility by measuring how effectively the description enables the user to answer the Input question; identify gaps where the description may fall short."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"secretsmanager.amazonaws.com\\\", \\\"EventName\\\": \\\"Put*\\\"}\", \"hyperparameters\": null, \"input\": \"Are there any Put* events in Secrets Manager that could indicate a misconfigured secret?\", \"retrieval_context\": [\" - Lambda function \\\"Put*\\\" events in CloudTrail capture changes to function configurations, concurrency settings, event source mappings, and resource provisioning. These events indicate updates or deployments that can affect function behavior and performance. An SRE should monitor the frequency and success of these operations; unusually high rates of \\\"Put*\\\" events may signal automation errors or configuration churn, while absence of expected updates could indicate deployment issues. Alert thresholds might include more than 5 \\\"Put*\\\" events within 5 minutes or failed update attempts exceeding 10% of total \\\"Put*\\\" events. High volumes can lead to inconsistent function states or throttling, impacting availability and latency; low update activity during active development phases may delay critical fixes or optimizations. For example, a dashboard widget can track the count of \\\"Put*\\\" events per hour alongside error rates, and an alert rule could trigger when the number of failed \\\"Put*\\\" events surpasses a set threshold, prompting investigation into deployment or configuration problems.\", \" - This pattern captures Secrets Manager deletion events. It identifies when secrets are removed, which can indicate cleanup operations or potential credential loss incidents.\", \" - This pattern captures Secrets Manager put operations. It identifies when secrets are stored or updated, including secret value changes and configuration modifications.\", \" - This pattern captures all update-related events from AWS Secrets Manager, such as modifications to secret values, rotation configurations, and access policy changes, as recorded in CloudTrail. Its purpose is to monitor changes that could affect the confidentiality, integrity, or availability of secrets critical to application security and operations.\\n\\n**Threshold guidance:**  \\n- Trigger an alert if the number of update events exceeds a baseline threshold within a short time window (e.g., more than 5 update events in 10 minutes), as this may indicate unusual or potentially unauthorized activity.  \\n- Conversely, an absence of expected rotation updates over a longer period (e.g., no rotation updates in 30 days) could signal stale secrets and increased security risk.\\n\\n**Impact of values:**  \\n- **High frequency of update events:** May indicate automated rotation, bulk secret changes, or suspicious activity such as credential compromise or insider threat. Immediate investigation is recommended.  \\n- **Low or zero update events:** Could mean secrets are not being rotated as per policy, increasing the risk of secret leakage or misuse.\\n\\n**Example alert rule:**  \\nAlert when `count(secretsmanager.amazonaws.com Update* events) > 5` within 10 minutes, excluding known maintenance windows.  \\n**Example dashboard widget:**  \\nA time-series graph showing the count of Secrets Manager update events over time, annotated with alerts triggered when thresholds are breached, helping SREs quickly identify abnormal secret modification patterns.\", \" - This pattern detects Secrets Manager creation events in CloudTrail, specifically any API calls starting with \\\"Create\\\" (e.g., CreateSecret). It helps SREs monitor when new secrets, secret versions, or related configurations are added, which could indicate deployment changes or potential security risks.  \\n**Alert threshold:** Trigger an alert if the number of create events exceeds a baseline (e.g., more than 5 creates within 10 minutes), as a sudden spike may signal unauthorized secret creation or misconfiguration. Conversely, zero create events over an extended period in an active environment might indicate issues with deployment pipelines or automation failures.  \\n**Impact:**  \\n- High values: Could indicate potential security breaches, unauthorized secret provisioning, or rapid environment changes requiring immediate investigation.  \\n- Low values: May suggest stalled deployments or automation problems, potentially delaying application updates or secret rotations.  \\n**Example usage:**  \\nIn a dashboard, plot the count of Secrets Manager Create* events over time to visualize spikes. An alert rule could be:  \\n`WHEN count(secretsmanager.amazonaws.com Create* events) > 5 within 10 minutes THEN trigger alert \\\"Unusual Secrets Creation Activity\\\"`  \\nThis enables proactive detection of abnormal secret creation activity, helping maintain security and operational stability.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": false,
                        "score": 0.7619374977269315,
                        "reason": "The Retrieval Context is relevant and aligned with the Input question about Put* events in Secrets Manager, clearly describing what these events capture (updates to secrets and configurations) and their security implications. It provides detailed threshold guidance, impact explanations, and example alert rules, enabling confident monitoring for misconfigurations. However, the context mixes Put* events for Secrets Manager with unrelated Lambda Put* events at the end, which could cause some confusion and slightly reduces clarity and focus.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Compare the Input (monitoring question) with the Retrieval Context (metric description) to check for alignment and relevance.\",\n    \"Evaluate the clarity of the Retrieval Context to ensure it is understandable and concise in relation to the clarity needed by the Input question.\",\n    \"Assess whether the Retrieval Context provides sufficient coverage (what is measured, units, context, implications) to address the Input effectively.\",\n    \"Determine the utility of the Retrieval Context by judging if it enables a user to confidently answer the Input question; highlight any gaps or ambiguities that reduce usefulness.\"\n] \n \nRubric:\nNone \n \nScore: 0.7619374977269315"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Compare the Input (monitoring question) with the Retrieval Context (metric description) to check for alignment and relevance.",
                            "Evaluate the clarity of the Retrieval Context to ensure it is understandable and concise in relation to the clarity needed by the Input question.",
                            "Assess whether the Retrieval Context provides sufficient coverage (what is measured, units, context, implications) to address the Input effectively.",
                            "Determine the utility of the Retrieval Context by judging if it enables a user to confidently answer the Input question; highlight any gaps or ambiguities that reduce usefulness."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"secretsmanager.amazonaws.com\\\", \\\"EventName\\\": \\\"Get*\\\"}\", \"hyperparameters\": null, \"input\": \"Are there spikes in Secret retrieval operations, indicating potential security issues?\", \"retrieval_context\": [\" - S3 Get* events in CloudTrail capture all read operations on S3 objects, such as GetObject, GetObjectAcl, and GetObjectVersion. These events indicate when data is accessed or downloaded from your buckets, providing critical visibility into data retrieval patterns and potential unauthorized access.  \\n\\n**Purpose:** Monitor and audit object read activity to detect unusual access spikes, potential data exfiltration, or performance bottlenecks caused by excessive reads.\\n\\n**Alert Threshold:** Trigger an alert if the number of Get* events exceeds a baseline threshold (e.g., a 3x increase over the average hourly rate) or if access occurs from unexpected IP addresses or principals.\\n\\n**Impact:**  \\n- **High values:** May indicate heavy data consumption, possible data leakage, or abuse of resources leading to increased costs and degraded application performance.  \\n- **Low values:** Could suggest reduced usage, potential application issues, or misconfigured permissions blocking legitimate access.\\n\\n**Example Alert Rule:**  \\nAlert when the count of s3.amazonaws.com Get* events in CloudTrail exceeds 5000 within 1 hour, or when access originates from an IP address outside your trusted network range.\\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing hourly counts of Get* events per bucket, combined with a heatmap of source IP addresses, enabling quick identification of unusual access patterns or spikes in data retrieval.\", \" - S3 List operations (EventName starting with \\\"List\\\") in CloudTrail capture requests to enumerate buckets, list objects, or browse directories within S3. These events help track data discovery activities, such as inventory management or security reconnaissance attempts by identifying who is accessing or exploring bucket contents.  \\n\\n**Purpose:**  \\n- Monitor access patterns to detect unusual or excessive listing activity that may indicate unauthorized data exploration or reconnaissance.  \\n- Support auditing and compliance by providing visibility into how and when bucket contents are being queried.\\n\\n**Alert Threshold Guidance:**  \\n- Trigger alerts when the number of List operations exceeds a baseline threshold (e.g., a sudden spike above normal daily averages or a sustained high rate over a short period).  \\n- Thresholds should be customized per environment but a common starting point is alerting on a 3x increase over the average hourly count or more than 100 List requests per minute from a single principal or IP.\\n\\n**Impact of Values:**  \\n- **High values:** May indicate automated scanning, data scraping, or reconnaissance by malicious actors, potentially preceding data exfiltration attempts. Could also reflect legitimate bulk inventory or analytics jobs\\u2014context matters.  \\n- **Low values:** Normal or expected in environments with limited or infrequent bucket browsing; very low values typically pose no risk.\\n\\n**Example Usage:**  \\n- **Dashboard:** Visualize the count of List* events over time, segmented by user or source IP, to identify unusual spikes or patterns.  \\n- **Alert Rule (pseudo-code):**  \\n  ```  \\n  IF count(EventName LIKE \\\"List*\\\") BY user OVER 15 minutes > 3x baseline THEN alert(\\\"Unusual S3 List activity detected for user\\\")  \\n  ```  \\nThis enables proactive detection of suspicious enumeration behavior while minimizing false positives from routine operations.\", \" - This pattern captures AWS KMS Decrypt API calls recorded in CloudTrail, indicating when encrypted data is accessed and decrypted using KMS keys. It helps SREs monitor data access events for security auditing and anomaly detection. A sudden spike in Decrypt events may signal unusual or unauthorized data access, while consistently low or expected volumes suggest normal operation. As a threshold, alerting on a sustained increase exceeding 3 standard deviations above the historical average or a sudden burst of Decrypt calls within a short time window (e.g., 5 minutes) is recommended. For example, an alert rule could trigger when the count of Decrypt events exceeds 100 in 5 minutes, indicating potential data exfiltration or misuse. In dashboards, tracking the rate of Decrypt events over time alongside user identities and key IDs can help quickly identify suspicious patterns or compromised credentials.\", \" - This pattern captures all update-related events from AWS Secrets Manager, such as modifications to secret values, rotation configurations, and access policy changes, as recorded in CloudTrail. Its purpose is to monitor changes that could affect the confidentiality, integrity, or availability of secrets critical to application security and operations.\\n\\n**Threshold guidance:**  \\n- Trigger an alert if the number of update events exceeds a baseline threshold within a short time window (e.g., more than 5 update events in 10 minutes), as this may indicate unusual or potentially unauthorized activity.  \\n- Conversely, an absence of expected rotation updates over a longer period (e.g., no rotation updates in 30 days) could signal stale secrets and increased security risk.\\n\\n**Impact of values:**  \\n- **High frequency of update events:** May indicate automated rotation, bulk secret changes, or suspicious activity such as credential compromise or insider threat. Immediate investigation is recommended.  \\n- **Low or zero update events:** Could mean secrets are not being rotated as per policy, increasing the risk of secret leakage or misuse.\\n\\n**Example alert rule:**  \\nAlert when `count(secretsmanager.amazonaws.com Update* events) > 5` within 10 minutes, excluding known maintenance windows.  \\n**Example dashboard widget:**  \\nA time-series graph showing the count of Secrets Manager update events over time, annotated with alerts triggered when thresholds are breached, helping SREs quickly identify abnormal secret modification patterns.\", \" - This pattern detects Secrets Manager creation events in CloudTrail, specifically any API calls starting with \\\"Create\\\" (e.g., CreateSecret). It helps SREs monitor when new secrets, secret versions, or related configurations are added, which could indicate deployment changes or potential security risks.  \\n**Alert threshold:** Trigger an alert if the number of create events exceeds a baseline (e.g., more than 5 creates within 10 minutes), as a sudden spike may signal unauthorized secret creation or misconfiguration. Conversely, zero create events over an extended period in an active environment might indicate issues with deployment pipelines or automation failures.  \\n**Impact:**  \\n- High values: Could indicate potential security breaches, unauthorized secret provisioning, or rapid environment changes requiring immediate investigation.  \\n- Low values: May suggest stalled deployments or automation problems, potentially delaying application updates or secret rotations.  \\n**Example usage:**  \\nIn a dashboard, plot the count of Secrets Manager Create* events over time to visualize spikes. An alert rule could be:  \\n`WHEN count(secretsmanager.amazonaws.com Create* events) > 5 within 10 minutes THEN trigger alert \\\"Unusual Secrets Creation Activity\\\"`  \\nThis enables proactive detection of abnormal secret creation activity, helping maintain security and operational stability.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": false,
                        "score": 0.31746461812351645,
                        "reason": "The retrieval context does not directly address spikes in Secret retrieval operations; it focuses on creation, update, decrypt, and S3 events rather than retrieval of secrets. While some patterns mention security implications and alert thresholds for related events, none clearly explain what is measured, units, or how to detect spikes in secret retrievals specifically. This limits clarity, coverage, and utility in answering the monitoring question about secret retrieval spikes and potential security issues.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Compare the Input (monitoring question) with the Retrieval Context (metric description) to ensure the description clearly addresses the question.\",\n    \"Evaluate Clarity of the description by checking if it explains the metric in an understandable and concise manner in relation to the question asked.\",\n    \"Assess Coverage by verifying the description includes what is measured, units, relevant context, and implications necessary to answer the question.\",\n    \"Judge Utility by determining if the description provides enough information to effectively respond to the monitoring question, suggesting improvements if it falls short.\"\n] \n \nRubric:\nNone \n \nScore: 0.31746461812351645"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Compare the Input (monitoring question) with the Retrieval Context (metric description) to ensure the description clearly addresses the question.",
                            "Evaluate Clarity of the description by checking if it explains the metric in an understandable and concise manner in relation to the question asked.",
                            "Assess Coverage by verifying the description includes what is measured, units, relevant context, and implications necessary to answer the question.",
                            "Judge Utility by determining if the description provides enough information to effectively respond to the monitoring question, suggesting improvements if it falls short."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"ssm.amazonaws.com\\\", \\\"EventName\\\": \\\"Create*\\\"}\", \"hyperparameters\": null, \"input\": \"Does the count of SSM resource creation events exceed five within a short period, indicating potential automated deployments or security incidents?\", \"retrieval_context\": [\" - Redshift cluster creation events in CloudTrail capture all API calls initiating the provisioning of new Redshift clusters (e.g., CreateCluster). These events indicate when new data warehouse resources are being deployed or configured, impacting capacity and cost.  \\n**Purpose:** Enables SREs to monitor and audit cluster provisioning activities for operational control and security compliance.  \\n**Alert Threshold:** Trigger alerts on an unusually high number of cluster creation events within a short time window (e.g., >3 creates in 1 hour), which may indicate automation errors, misconfigurations, or unauthorized resource provisioning.  \\n**Impact:**  \\n- **High values:** May lead to resource sprawl, increased costs, and potential performance degradation due to over-provisioning. Could also signal security risks if unexpected clusters are created.  \\n- **Low or zero values:** Normal in stable environments; no new clusters being created means stable infrastructure.  \\n**Example Alert Rule:**  \\n\\u201cAlert if count of events with EventSource='redshift.amazonaws.com' and EventName starting with 'Create' exceeds 3 within 60 minutes.\\u201d  \\n**Dashboard Use:** Visualize the frequency of Redshift cluster creation events over time to detect spikes or anomalies, correlating with deployment activities or security incidents.\", \" - This pattern captures all AWS Systems Manager (SSM) resource creation events logged in CloudTrail, such as the creation of parameters, documents, and maintenance windows. It helps SREs monitor the provisioning of new SSM assets, which can indicate configuration changes or automation deployments.\\n\\n**Purpose:**  \\nTo detect when new SSM resources are created, enabling timely awareness of infrastructure changes that may affect system behavior or security posture.\\n\\n**Alert Threshold Guidance:**  \\nSet an alert threshold based on your environment\\u2019s baseline creation activity. For example, trigger an alert if more than 5 creation events occur within 10 minutes, which may indicate unexpected or unauthorized provisioning.\\n\\n**Impact of Values:**  \\n- **High values:** A spike in creation events could signal automated deployments, configuration drift, or potential security incidents such as unauthorized resource creation.  \\n- **Low or zero values:** Normal in stable environments; however, a sudden drop might indicate issues with deployment pipelines or monitoring gaps.\\n\\n**Example Alert Rule:**  \\nTrigger an alert when the count of events matching `{\\\"EventSource\\\": \\\"ssm.amazonaws.com\\\", \\\"EventName\\\": \\\"Create*\\\"}` exceeds 5 within a 10-minute window.\\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of SSM creation events over time, with thresholds marked to highlight unusual spikes, helping SREs quickly identify and investigate abnormal provisioning activity.\", \" - This pattern detects CloudTrail events where CloudWatch resources are created, such as alarms, dashboards, and log groups. Its purpose is to monitor the provisioning of new CloudWatch components, which can indicate changes in monitoring coverage or potential configuration drift. An alert should be triggered when the number of creation events exceeds a defined threshold within a short time window (e.g., more than 5 Create* events in 10 minutes), as a sudden spike may signal automated deployments, misconfigurations, or unauthorized activity. Conversely, a prolonged absence of creation events might suggest stagnation in monitoring updates or missed deployments. For example, in a monitoring dashboard, you can visualize the count of CloudWatch Create* events over time and set an alert rule to notify the SRE team if the event count surpasses the threshold, enabling timely investigation and response to unexpected changes in monitoring infrastructure.\", \" - This pattern detects SNS topic creation events recorded in CloudTrail, specifically any API calls starting with \\\"Create\\\" from the SNS service (e.g., CreateTopic). It helps SREs monitor when new SNS topics are provisioned, which can indicate changes in messaging architecture or potential unauthorized resource creation. An alert threshold could be set on the number of Create* events within a given time window (e.g., more than 5 topic creations in 10 minutes), as a sudden spike may signal automation errors or security issues. Low or expected values typically indicate normal operations, while high values may impact system stability by increasing resource usage or indicate potential misuse. For example, an alert rule could trigger if the count of {\\\"EventSource\\\": \\\"sns.amazonaws.com\\\", \\\"EventName\\\": \\\"Create*\\\"} events exceeds 5 in 10 minutes, and a dashboard widget could display a time series graph of topic creation events to track trends and detect anomalies.\", \" - This pattern detects Secrets Manager creation events in CloudTrail, specifically any API calls starting with \\\"Create\\\" (e.g., CreateSecret). It helps SREs monitor when new secrets, secret versions, or related configurations are added, which could indicate deployment changes or potential security risks.  \\n**Alert threshold:** Trigger an alert if the number of create events exceeds a baseline (e.g., more than 5 creates within 10 minutes), as a sudden spike may signal unauthorized secret creation or misconfiguration. Conversely, zero create events over an extended period in an active environment might indicate issues with deployment pipelines or automation failures.  \\n**Impact:**  \\n- High values: Could indicate potential security breaches, unauthorized secret provisioning, or rapid environment changes requiring immediate investigation.  \\n- Low values: May suggest stalled deployments or automation problems, potentially delaying application updates or secret rotations.  \\n**Example usage:**  \\nIn a dashboard, plot the count of Secrets Manager Create* events over time to visualize spikes. An alert rule could be:  \\n`WHEN count(secretsmanager.amazonaws.com Create* events) > 5 within 10 minutes THEN trigger alert \\\"Unusual Secrets Creation Activity\\\"`  \\nThis enables proactive detection of abnormal secret creation activity, helping maintain security and operational stability.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": true,
                        "score": 0.8474406384436601,
                        "reason": "The input question directly aligns with the retrieval context focused on monitoring SSM resource creation events and their implications for automated deployments or security incidents. The retrieval context provides detailed explanations of what is measured (SSM creation events), measurement units (count within a time window), relevant context (CloudTrail logs, event types), and implications (automation, security risks). The input is clear and concise, and the retrieval context offers sufficient information to answer the question effectively. The only minor shortcoming is that the input does not specify the exact time window, which is clarified in the retrieval context.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Compare the Input (metric description) and Retrieval Context (monitoring question) to assess if the description clearly aligns with the question's focus and intent.\",\n    \"Evaluate the clarity of the Input by checking if the description is concise and understandable, considering how it supports interpretation within the Retrieval Context.\",\n    \"Assess coverage by verifying whether the Input explains what is measured, the measurement units, relevant context, and implications directly relating to the question in the Retrieval Context.\",\n    \"Determine the utility by judging if the Input provides sufficient information to effectively answer the Retrieval Context\u2019s question; if not, identify gaps or ambiguities.\"\n] \n \nRubric:\nNone \n \nScore: 0.8474406384436601"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Compare the Input (metric description) and Retrieval Context (monitoring question) to assess if the description clearly aligns with the question's focus and intent.",
                            "Evaluate the clarity of the Input by checking if the description is concise and understandable, considering how it supports interpretation within the Retrieval Context.",
                            "Assess coverage by verifying whether the Input explains what is measured, the measurement units, relevant context, and implications directly relating to the question in the Retrieval Context.",
                            "Determine the utility by judging if the Input provides sufficient information to effectively answer the Retrieval Context\u2019s question; if not, identify gaps or ambiguities."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"ssm.amazonaws.com\\\", \\\"EventName\\\": \\\"Delete*\\\"}\", \"hyperparameters\": null, \"input\": \"Are there any Delete* AWS Systems Manager API calls indicating potential removal of critical resources?\", \"retrieval_context\": [\" - API Gateway deletion events captured by CloudTrail indicate when APIs, stages, or related resources are removed. These events are critical for tracking decommissioning activities, ensuring that endpoint removals are intentional and authorized, and preventing accidental service disruptions.  \\n\\n**Purpose:**  \\nMonitor all delete operations initiated via API Gateway (e.g., DeleteRestApi, DeleteStage) to maintain visibility into changes that reduce API surface area or remove critical endpoints.\\n\\n**Alert Threshold:**  \\nTrigger an alert if the number of Delete* events exceeds a predefined baseline within a short time window (e.g., more than 3 deletions within 10 minutes), as this may indicate accidental mass deletions, unauthorized activity, or a misconfigured automation script.\\n\\n**Impact:**  \\n- **High frequency:** Could lead to service outages, broken integrations, or data loss if APIs or stages are removed unexpectedly. Immediate investigation is required.  \\n- **Low or zero frequency:** Normal operation; deletion events are infrequent and typically planned.\\n\\n**Example Usage:**  \\nIn a monitoring dashboard, display a time series graph of Delete* events from apigateway.amazonaws.com. Set an alert rule such as:  \\n`IF count(Delete* events) > 3 within 10 minutes THEN trigger high-severity alert \\\"Potential API Gateway mass deletion detected\\\"`  \\nThis enables rapid response to potentially disruptive changes in the API infrastructure.\", \" - This pattern captures ECS deletion events recorded in CloudTrail, specifically any API calls starting with \\\"Delete\\\" from the ECS service (e.g., DeleteCluster, DeleteService, DeleteTaskSet). Its purpose is to monitor when ECS resources are removed, which can signal intentional cleanup or unintended disruptions affecting service availability.\\n\\n**Threshold guidance:**  \\n- Trigger an alert if the number of ECS deletion events exceeds a baseline threshold within a short time window (e.g., more than 3 Delete* events in 5 minutes), as this may indicate accidental mass deletion or a security incident.  \\n- Low or expected deletion rates typically reflect routine maintenance or scaling down of resources and generally have minimal impact.\\n\\n**Impact:**  \\n- High deletion event counts can lead to service downtime, loss of running tasks, or cluster instability, requiring immediate investigation.  \\n- Low or zero deletion events usually indicate stable ECS resource management.\\n\\n**Example alert rule:**  \\n- Alert when `count(events where EventSource=\\\"ecs.amazonaws.com\\\" and EventName starts with \\\"Delete\\\") > 3` within 5 minutes.  \\n- This alert can be visualized on a dashboard showing ECS Delete* event counts over time, helping SREs quickly identify unusual spikes and correlate with service health metrics.\", \" - This pattern captures Secrets Manager deletion events. It identifies when secrets are removed, which can indicate cleanup operations or potential credential loss incidents.\", \" - This pattern captures all EC2 resource deletion events recorded in CloudTrail, triggered by any API calls starting with \\\"Delete\\\" from the EC2 service (e.g., DeleteSecurityGroup, DeleteNetworkInterface). Its purpose is to monitor and alert on the removal of critical EC2 components, which can impact infrastructure stability and security.\\n\\n**Threshold guidance:**  \\n- Set an alert if the number of deletion events exceeds a baseline threshold within a short time window (e.g., more than 5 deletions in 10 minutes), as this may indicate accidental mass deletions or malicious activity.  \\n- A low or zero count is typical during normal operations, while sudden spikes warrant immediate investigation.\\n\\n**Impact:**  \\n- High deletion event counts can lead to service disruptions, loss of network connectivity, or security vulnerabilities if key resources like security groups or network interfaces are removed unexpectedly.  \\n- Low or no deletion activity generally indicates stable infrastructure management.\\n\\n**Example alert rule:**  \\nTrigger an alert when the count of events matching {\\\"EventSource\\\": \\\"ec2.amazonaws.com\\\", \\\"EventName\\\": \\\"Delete*\\\"} exceeds 5 within 10 minutes.\\n\\n**Example dashboard usage:**  \\nVisualize the count of EC2 deletion events over time to identify unusual spikes, correlating with other operational metrics to assess potential impact on system availability or security posture.\", \" - This pattern matches AWS Systems Manager API calls where the event name begins with \\\"Delete\\\". It captures actions that remove or delete SSM resources such as documents, parameters, or associations. The pattern measures the occurrence of these deletion events as discrete API call records. Each matched event represents one instance of a resource deletion operation within Systems Manager.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": false,
                        "score": 0.6632244887207881,
                        "reason": "The description directly addresses the input question by explaining that the pattern matches AWS Systems Manager API calls starting with 'Delete', capturing deletion of SSM resources like documents and parameters. It is clear and succinct without extraneous information. However, it lacks details on units, threshold guidance, impact, or alerting implications, which limits coverage and utility for assessing potential removal of critical resources or enabling actionable monitoring.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Compare the Input (monitoring question) and Retrieval Context (metric description) to assess if the description addresses the question directly and clearly.\",\n    \"Evaluate Clarity by determining if the description is understandable without extraneous information, ensuring it succinctly relates to the question.\",\n    \"Assess Coverage by verifying if the description explains what is measured, includes units, context, and implications relevant to the input question.\",\n    \"Judge Utility by confirming the description\u2019s ability to enable a user to answer the question using the provided metrics and context.\"\n] \n \nRubric:\nNone \n \nScore: 0.6632244887207881"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Compare the Input (monitoring question) and Retrieval Context (metric description) to assess if the description addresses the question directly and clearly.",
                            "Evaluate Clarity by determining if the description is understandable without extraneous information, ensuring it succinctly relates to the question.",
                            "Assess Coverage by verifying if the description explains what is measured, includes units, context, and implications relevant to the input question.",
                            "Judge Utility by confirming the description\u2019s ability to enable a user to answer the question using the provided metrics and context."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"ssm.amazonaws.com\\\", \\\"EventName\\\": \\\"Send*\\\"}\", \"hyperparameters\": null, \"input\": \"Are there spikes in Send* events indicating potential misuse or abuse of AWS Systems Manager?\", \"retrieval_context\": [\" - S3 bucket creation events captured by CloudTrail under **{\\\"EventSource\\\": \\\"s3.amazonaws.com\\\", \\\"EventName\\\": \\\"Create*\\\"}** indicate when new buckets or related resources (e.g., bucket policies, access points) are provisioned. These events help SREs monitor infrastructure changes that affect data storage, security posture, and compliance.\\n\\n**Purpose:**  \\nTrack and audit the creation of S3 buckets and associated configurations to ensure proper governance, prevent unauthorized resource sprawl, and maintain compliance with organizational policies.\\n\\n**Alert Threshold:**  \\nTrigger an alert if the number of S3 bucket creation events exceeds a defined threshold within a short time window (e.g., more than 5 bucket creations within 10 minutes), which may indicate automated provisioning errors, misconfigurations, or potential security incidents such as unauthorized resource creation.\\n\\n**Impact of Values:**  \\n- **High frequency:** May signal abnormal activity, such as a compromised credential or runaway automation scripts creating excessive buckets, leading to increased costs, security risks, or compliance violations.  \\n- **Low or zero frequency:** Normal in stable environments; however, sudden spikes should be investigated promptly.\\n\\n**Example Alert Rule:**  \\n\\u201cAlert when count of events with EventSource = 's3.amazonaws.com' and EventName starting with 'Create' exceeds 5 within 10 minutes.\\u201d\\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of S3 Create* events over time, with thresholds marked to highlight unusual spikes, enabling quick identification of abnormal bucket creation activity.\", \" - This pattern captures CloudFront cache invalidation events recorded in CloudTrail, which occur when cached content is explicitly removed or refreshed to ensure users receive the latest versions of assets. For an SRE, monitoring these events helps track content deployment activities and detect potential operational issues such as excessive invalidations that may indicate misconfigurations or abuse.\\n\\n**Purpose:**  \\n- Identify when CloudFront distributions are updated via cache invalidations.  \\n- Correlate invalidation frequency with deployment cycles or troubleshooting efforts.\\n\\n**Alert Threshold Guidance:**  \\n- Trigger an alert if the number of invalidation requests exceeds a defined threshold within a short time window (e.g., more than 10 invalidations in 5 minutes), as this may signal abnormal activity or inefficient cache management.  \\n- Conversely, unusually low invalidation activity during expected deployment periods might indicate deployment failures or monitoring gaps.\\n\\n**Impact:**  \\n- **High invalidation rates:** Can increase latency and cost, as CloudFront must fetch fresh content from origin servers more frequently, potentially degrading user experience.  \\n- **Low invalidation rates:** May cause users to receive stale content, impacting application correctness and user satisfaction.\\n\\n**Example Usage:**  \\n- **Dashboard:** Display a time-series graph of invalidation event counts per minute to visualize spikes or drops in cache refresh activity.  \\n- **Alert Rule (pseudo-code):**  \\n  ```  \\n  WHEN count(EventName LIKE \\\"Invalidate*\\\") FROM cloudtrail  \\n  OVER last 5 minutes > 10  \\n  THEN alert \\\"High CloudFront invalidation rate detected\\\"  \\n  ```\", \" - This pattern captures all AWS Security Token Service (STS) \\\"Get\\\" operations, such as `GetSessionToken`, `GetCallerIdentity`, and similar API calls that issue or validate temporary security credentials. In CloudTrail, these events indicate when users or services request short-lived credentials to access AWS resources.\\n\\n**Purpose:**  \\nMonitor STS Get* events to detect unusual or excessive requests for temporary credentials, which can signal automation activity, credential misuse, or potential security incidents like privilege escalation or compromised identities.\\n\\n**Alert Threshold:**  \\nTrigger an alert when the count of STS Get* events exceeds a baseline threshold established from normal activity patterns\\u2014commonly, a sudden spike above 3-5 times the average hourly rate or an absolute count exceeding 100 requests per hour, depending on your environment size and usage.\\n\\n**Impact of Values:**  \\n- **High values:** May indicate automated processes requesting many temporary credentials, potential credential abuse, or an attacker attempting to escalate privileges or move laterally. Prompt investigation is warranted.  \\n- **Low or expected values:** Reflect normal operation with routine credential issuance and validation.\\n\\n**Example Usage:**  \\nIn a monitoring dashboard, plot the count of `sts.amazonaws.com` events with `EventName` matching `Get*` over time. Set an alert rule such as:  \\n`WHEN count(events where EventSource=\\\"sts.amazonaws.com\\\" AND EventName LIKE \\\"Get*\\\") > 100 within 1 hour THEN alert \\\"High STS Get* activity detected\\\"`  \\nThis helps SREs quickly identify abnormal credential request patterns and respond accordingly.\", \" - This pattern captures all Amazon SQS message send events recorded in CloudTrail, identifying when messages are sent to SQS queues by applications or services. It helps SREs monitor the volume and frequency of messages entering the queue, which is critical for understanding application throughput and detecting anomalies in message flow.\\n\\n**Threshold guidance:**  \\n- Set alert thresholds based on baseline message send rates for your application. For example, trigger an alert if the number of Send* events drops below 50% of the normal rate over a 5-minute window, indicating potential upstream issues or message loss.  \\n- Conversely, alert if the send rate spikes above 150% of the baseline, which may signal unexpected load, misbehaving producers, or potential flooding that could overwhelm downstream consumers.\\n\\n**Impact of values:**  \\n- **High send event volume:** May indicate increased application activity or a surge in workload; sustained spikes can lead to queue congestion, increased processing latency, or throttling.  \\n- **Low send event volume:** Could suggest upstream failures, application downtime, or message generation issues, potentially causing downstream starvation and impacting system responsiveness.\\n\\n**Example usage:**  \\nIn a monitoring dashboard, plot the count of **{\\\"EventSource\\\": \\\"sqs.amazonaws.com\\\", \\\"EventName\\\": \\\"Send*\\\"}** events per minute to visualize message inflow trends. Configure an alert rule to notify the SRE team if the send event count deviates by more than \\u00b150% from the established baseline over a rolling 5-minute period, enabling rapid detection and response to abnormal message flow patterns.\", \" - This pattern captures all Systems Manager (SSM) \\\"Get\\\" operations recorded in CloudTrail, such as retrieving parameters from Parameter Store, downloading SSM documents, or requesting instance information. It helps SREs monitor read access to SSM resources, which can indicate normal operational queries or potential reconnaissance activity by unauthorized users.\\n\\n**Purpose:**  \\nTrack and analyze the frequency of SSM \\\"Get\\\" API calls to detect unusual spikes or drops in read operations that may impact system performance or signal security concerns.\\n\\n**Alert Threshold Guidance:**  \\nSet alert thresholds based on baseline usage patterns. For example, trigger an alert if the number of \\\"Get\\\" operations exceeds 2-3 times the average hourly rate within a short time window (e.g., 5-15 minutes), or if there is a sudden drop to near zero, which might indicate service disruption or misconfiguration.\\n\\n**Impact of Values:**  \\n- **High values:** May indicate automated scripts, bulk data retrieval, or potential reconnaissance by attackers trying to gather system details. Excessive reads can also increase API costs or cause throttling.  \\n- **Low values:** Could suggest issues with monitoring tools, broken automation, or loss of visibility into SSM-managed resources.\\n\\n**Example Usage:**  \\nIn a CloudWatch dashboard or alert rule, aggregate CloudTrail events filtered by `{\\\"EventSource\\\": \\\"ssm.amazonaws.com\\\", \\\"EventName\\\": \\\"Get*\\\"}` and plot the count over time. Configure an alarm to notify the SRE team if the count spikes above the defined threshold within a 15-minute window, enabling rapid investigation of unusual access patterns.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": true,
                        "score": 0.832562334716483,
                        "reason": "The description directly addresses the monitoring question about spikes in Send* events by explaining what is measured (SQS Send events), the units (event counts over time), relevant context (baseline rates, potential causes of spikes), and implications (impact on queue congestion and system responsiveness). It is clear, concise, and provides alert threshold guidance and example usage, enabling effective monitoring and response. Minor deduction is due to the lack of explicit mention of potential misuse or abuse beyond general anomaly detection.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Compare the Input (monitoring question) and Retrieval Context (metric description) to ensure the description directly addresses the question.\",\n    \"Evaluate the description's Clarity by checking if it is easy to understand and concise in relation to the question asked.\",\n    \"Assess Coverage by verifying if the description explains what is measured, the units, relevant context, and potential implications relevant to the question.\",\n    \"Determine Utility by confirming that the description provides sufficient information to effectively answer the monitoring question.\"\n] \n \nRubric:\nNone \n \nScore: 0.832562334716483"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Compare the Input (monitoring question) and Retrieval Context (metric description) to ensure the description directly addresses the question.",
                            "Evaluate the description's Clarity by checking if it is easy to understand and concise in relation to the question asked.",
                            "Assess Coverage by verifying if the description explains what is measured, the units, relevant context, and potential implications relevant to the question.",
                            "Determine Utility by confirming that the description provides sufficient information to effectively answer the monitoring question."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"ssm.amazonaws.com\\\", \\\"EventName\\\": \\\"Update*\\\"}\", \"hyperparameters\": null, \"input\": \"Are there more than five Update* events from AWS Systems Manager (SSM) in a short period?\", \"retrieval_context\": [\" - CloudFormation stack update events (**EventSource**: \\\"cloudformation.amazonaws.com\\\", **EventName**: \\\"Update*\\\") capture all modifications to AWS CloudFormation stacks, including infrastructure changes, resource additions/removals, and configuration updates. These events are critical for tracking infrastructure evolution and ensuring change management compliance.\\n\\n**Purpose:**  \\nThey provide visibility into when and how infrastructure is altered via CloudFormation, enabling SREs to audit changes, detect unauthorized or unexpected updates, and correlate incidents with recent deployments.\\n\\n**Alert Threshold Guidance:**  \\n- Trigger alerts on unusually high frequencies of update events within a short time window (e.g., >5 updates in 10 minutes), which may indicate automation loops, deployment failures, or misconfigurations.  \\n- Alert on failed or rollback update events to quickly identify deployment issues impacting system stability.\\n\\n**Impact of Values:**  \\n- **High volume of updates:** May signal instability, rapid iterative deployments, or potential automation errors, increasing risk of outages or configuration drift.  \\n- **Low or zero updates:** Normal during stable periods but prolonged absence of updates might indicate stalled deployments or lack of infrastructure changes.\\n\\n**Example Usage:**  \\n- **Dashboard:** Display a time-series graph of CloudFormation Update* events per hour, highlighting failed updates in red.  \\n- **Alert Rule:** Trigger an alert if the count of UpdateStack events exceeds 5 within 10 minutes or if any update event has a status of FAILED or ROLLBACK_COMPLETE, enabling rapid response to deployment issues.\", \" - IAM update events capture all modifications made to IAM resources such as users, roles, groups, policies, and credentials. These events indicate changes to permissions, access controls, and security configurations, which are critical for maintaining the principle of least privilege and preventing unauthorized privilege escalation. In CloudTrail, **{\\\"EventSource\\\": \\\"iam.amazonaws.com\\\", \\\"EventName\\\": \\\"Update*\\\"}** helps track who made changes, what was changed, and when, enabling audit and compliance verification.\\n\\n**Alert Threshold:** Trigger an alert when the number of IAM update events exceeds a baseline threshold within a short time window (e.g., more than 5 update events in 10 minutes), or when specific sensitive updates occur, such as policy changes granting administrative privileges or credential rotations outside of scheduled maintenance.\\n\\n**Impact of Values:**  \\n- **High values:** A spike in update events may indicate automated scripts, bulk permission changes, or potential malicious activity like privilege escalation attempts. Immediate investigation is warranted to confirm legitimacy.  \\n- **Low values:** Normal or zero update events typically indicate stable IAM configurations with no recent permission changes, which is expected in steady-state operations.\\n\\n**Example Usage:**  \\nIn a dashboard, display a time series graph of IAM update events filtered by event name pattern \\\"Update*\\\". Set an alert rule to notify the SRE team if the count of these events exceeds 5 within any rolling 10-minute window, or if any update event modifies policies granting \\\"AdministratorAccess\\\". This enables rapid detection of potentially risky permission changes and supports proactive security posture management.\", \" - This pattern captures all AWS Systems Manager (SSM) resource creation events logged in CloudTrail, such as the creation of parameters, documents, and maintenance windows. It helps SREs monitor the provisioning of new SSM assets, which can indicate configuration changes or automation deployments.\\n\\n**Purpose:**  \\nTo detect when new SSM resources are created, enabling timely awareness of infrastructure changes that may affect system behavior or security posture.\\n\\n**Alert Threshold Guidance:**  \\nSet an alert threshold based on your environment\\u2019s baseline creation activity. For example, trigger an alert if more than 5 creation events occur within 10 minutes, which may indicate unexpected or unauthorized provisioning.\\n\\n**Impact of Values:**  \\n- **High values:** A spike in creation events could signal automated deployments, configuration drift, or potential security incidents such as unauthorized resource creation.  \\n- **Low or zero values:** Normal in stable environments; however, a sudden drop might indicate issues with deployment pipelines or monitoring gaps.\\n\\n**Example Alert Rule:**  \\nTrigger an alert when the count of events matching `{\\\"EventSource\\\": \\\"ssm.amazonaws.com\\\", \\\"EventName\\\": \\\"Create*\\\"}` exceeds 5 within a 10-minute window.\\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of SSM creation events over time, with thresholds marked to highlight unusual spikes, helping SREs quickly identify and investigate abnormal provisioning activity.\", \" - This pattern captures all update-related events from AWS Secrets Manager, such as modifications to secret values, rotation configurations, and access policy changes, as recorded in CloudTrail. Its purpose is to monitor changes that could affect the confidentiality, integrity, or availability of secrets critical to application security and operations.\\n\\n**Threshold guidance:**  \\n- Trigger an alert if the number of update events exceeds a baseline threshold within a short time window (e.g., more than 5 update events in 10 minutes), as this may indicate unusual or potentially unauthorized activity.  \\n- Conversely, an absence of expected rotation updates over a longer period (e.g., no rotation updates in 30 days) could signal stale secrets and increased security risk.\\n\\n**Impact of values:**  \\n- **High frequency of update events:** May indicate automated rotation, bulk secret changes, or suspicious activity such as credential compromise or insider threat. Immediate investigation is recommended.  \\n- **Low or zero update events:** Could mean secrets are not being rotated as per policy, increasing the risk of secret leakage or misuse.\\n\\n**Example alert rule:**  \\nAlert when `count(secretsmanager.amazonaws.com Update* events) > 5` within 10 minutes, excluding known maintenance windows.  \\n**Example dashboard widget:**  \\nA time-series graph showing the count of Secrets Manager update events over time, annotated with alerts triggered when thresholds are breached, helping SREs quickly identify abnormal secret modification patterns.\", \" - This pattern captures all update-related events from AWS Systems Manager (SSM) recorded in CloudTrail, such as modifications to parameters, documents, and maintenance windows. It helps SREs monitor changes to critical SSM resources that could affect system configuration, automation workflows, or maintenance schedules.  \\n\\n**Purpose:** Detect when SSM resources are altered to ensure changes are authorized and to quickly identify unexpected or potentially disruptive updates.\\n\\n**Alert Threshold:** Trigger an alert if the number of update events exceeds a baseline threshold within a short time window (e.g., more than 5 update events in 10 minutes), indicating possible misconfiguration, automation errors, or unauthorized changes.\\n\\n**Impact:**  \\n- **High values:** A spike in update events may signal bulk or automated changes that could introduce instability or security risks if unplanned. Immediate investigation is warranted.  \\n- **Low or zero values:** Normal operation if no updates are expected; however, if updates are regularly scheduled, a sudden drop might indicate monitoring gaps or failures in deployment pipelines.\\n\\n**Example Usage:**  \\nIn a monitoring dashboard, display a time series graph of the count of **{\\\"EventSource\\\": \\\"ssm.amazonaws.com\\\", \\\"EventName\\\": \\\"Update*\\\"}** events over time. Configure an alert rule to notify the SRE team when update events exceed 5 within any rolling 10-minute window, enabling rapid response to unexpected configuration changes.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": true,
                        "score": 0.9060086656906503,
                        "reason": "The Retrieval Context directly addresses the Input question by clearly describing the monitoring of AWS Systems Manager (SSM) Update* events, including the threshold of more than 5 events in a short period (10 minutes). It is clear, concise, and uses terminology consistent with the Input. The context fully explains what is measured (update events), the units (count within a time window), relevant context (impact and purpose), and implications, enabling confident user understanding. Minor deduction is due to the presence of additional unrelated patterns that could slightly reduce focus.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Compare the Input (monitoring question) and Retrieval Context (metric description) to check if the description clearly addresses the question's focus.\",\n    \"Evaluate Clarity by assessing if the Retrieval Context is understandable and concise in relation to the terminology and intent expressed in the Input.\",\n    \"Assess Coverage by verifying that the Retrieval Context fully explains what is measured, units, relevant context, and implications to effectively inform the Input question.\",\n    \"Determine Utility by judging whether the Retrieval Context provides sufficient and relevant information that enables a user to confidently answer the Input question.\"\n] \n \nRubric:\nNone \n \nScore: 0.9060086656906503"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Compare the Input (monitoring question) and Retrieval Context (metric description) to check if the description clearly addresses the question's focus.",
                            "Evaluate Clarity by assessing if the Retrieval Context is understandable and concise in relation to the terminology and intent expressed in the Input.",
                            "Assess Coverage by verifying that the Retrieval Context fully explains what is measured, units, relevant context, and implications to effectively inform the Input question.",
                            "Determine Utility by judging whether the Retrieval Context provides sufficient and relevant information that enables a user to confidently answer the Input question."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"ssm.amazonaws.com\\\", \\\"EventName\\\": \\\"Get*\\\"}\", \"hyperparameters\": null, \"input\": \"Does the frequency of SSM \\\"Get\\\" API calls exceed 2-3 times the average hourly rate, indicating potential automated scripts or security concerns?\", \"retrieval_context\": [\" - Redshift cluster creation events in CloudTrail capture all API calls initiating the provisioning of new Redshift clusters (e.g., CreateCluster). These events indicate when new data warehouse resources are being deployed or configured, impacting capacity and cost.  \\n**Purpose:** Enables SREs to monitor and audit cluster provisioning activities for operational control and security compliance.  \\n**Alert Threshold:** Trigger alerts on an unusually high number of cluster creation events within a short time window (e.g., >3 creates in 1 hour), which may indicate automation errors, misconfigurations, or unauthorized resource provisioning.  \\n**Impact:**  \\n- **High values:** May lead to resource sprawl, increased costs, and potential performance degradation due to over-provisioning. Could also signal security risks if unexpected clusters are created.  \\n- **Low or zero values:** Normal in stable environments; no new clusters being created means stable infrastructure.  \\n**Example Alert Rule:**  \\n\\u201cAlert if count of events with EventSource='redshift.amazonaws.com' and EventName starting with 'Create' exceeds 3 within 60 minutes.\\u201d  \\n**Dashboard Use:** Visualize the frequency of Redshift cluster creation events over time to detect spikes or anomalies, correlating with deployment activities or security incidents.\", \" - This pattern captures AWS KMS encryption API calls (e.g., Encrypt, EncryptData) recorded in CloudTrail, indicating when data is being encrypted using customer-managed or AWS-managed KMS keys. It helps SREs monitor cryptographic operations to ensure data protection policies are enforced and to detect unusual encryption activity that could signal misuse or security incidents.\\n\\n**Purpose:** Track the frequency and context of encryption operations to verify normal application behavior and compliance with data security standards.\\n\\n**Alert Threshold:** Trigger an alert if the number of Encrypt* events exceeds a baseline threshold (e.g., a sudden spike beyond 3 standard deviations from the average hourly rate) or if encryption requests originate from unexpected principals or regions.\\n\\n**Impact of Values:**  \\n- **High volume:** May indicate increased data processing, potential automated encryption loops, or unauthorized bulk encryption attempts, which could impact performance or signal a security breach.  \\n- **Low or zero volume:** Could suggest application issues, disabled encryption, or misconfigured services failing to encrypt data as required, risking data exposure.\\n\\n**Example Alert Rule:**  \\nAlert when Encrypt* events exceed 500 per hour or when encryption requests come from an unrecognized IAM role, triggering an investigation into possible misuse or operational anomalies.\\n\\n**Dashboard Use:**  \\nVisualize Encrypt* event counts over time alongside related Decrypt* events and key usage metrics to correlate encryption activity with application workloads and detect deviations from normal patterns.\", \" - This pattern captures all AWS Security Token Service (STS) \\\"Get\\\" operations, such as `GetSessionToken`, `GetCallerIdentity`, and similar API calls that issue or validate temporary security credentials. In CloudTrail, these events indicate when users or services request short-lived credentials to access AWS resources.\\n\\n**Purpose:**  \\nMonitor STS Get* events to detect unusual or excessive requests for temporary credentials, which can signal automation activity, credential misuse, or potential security incidents like privilege escalation or compromised identities.\\n\\n**Alert Threshold:**  \\nTrigger an alert when the count of STS Get* events exceeds a baseline threshold established from normal activity patterns\\u2014commonly, a sudden spike above 3-5 times the average hourly rate or an absolute count exceeding 100 requests per hour, depending on your environment size and usage.\\n\\n**Impact of Values:**  \\n- **High values:** May indicate automated processes requesting many temporary credentials, potential credential abuse, or an attacker attempting to escalate privileges or move laterally. Prompt investigation is warranted.  \\n- **Low or expected values:** Reflect normal operation with routine credential issuance and validation.\\n\\n**Example Usage:**  \\nIn a monitoring dashboard, plot the count of `sts.amazonaws.com` events with `EventName` matching `Get*` over time. Set an alert rule such as:  \\n`WHEN count(events where EventSource=\\\"sts.amazonaws.com\\\" AND EventName LIKE \\\"Get*\\\") > 100 within 1 hour THEN alert \\\"High STS Get* activity detected\\\"`  \\nThis helps SREs quickly identify abnormal credential request patterns and respond accordingly.\", \" - This pattern captures all Route 53 \\\"Get\\\" API operations logged in CloudTrail, such as retrieving hosted zone details, record sets, and health check statuses. It helps SREs monitor read access to DNS configurations and health data, which can indicate normal operational queries or potential reconnaissance activity. A sudden spike in these \\\"Get\\\" requests\\u2014exceeding a baseline threshold (e.g., 3 standard deviations above the average hourly rate)\\u2014may signal unusual interest in DNS infrastructure, warranting investigation. Conversely, a significant drop could indicate issues with monitoring or automation systems relying on these queries. For example, an alert rule could trigger when the count of **{\\\"EventSource\\\": \\\"route53.amazonaws.com\\\", \\\"EventName\\\": \\\"Get*\\\"}** events exceeds 100 requests per hour, and a dashboard widget might display a time series graph of these events to track trends and detect anomalies in DNS query activity.\", \" - This pattern captures all Systems Manager (SSM) \\\"Get\\\" operations recorded in CloudTrail, such as retrieving parameters from Parameter Store, downloading SSM documents, or requesting instance information. It helps SREs monitor read access to SSM resources, which can indicate normal operational queries or potential reconnaissance activity by unauthorized users.\\n\\n**Purpose:**  \\nTrack and analyze the frequency of SSM \\\"Get\\\" API calls to detect unusual spikes or drops in read operations that may impact system performance or signal security concerns.\\n\\n**Alert Threshold Guidance:**  \\nSet alert thresholds based on baseline usage patterns. For example, trigger an alert if the number of \\\"Get\\\" operations exceeds 2-3 times the average hourly rate within a short time window (e.g., 5-15 minutes), or if there is a sudden drop to near zero, which might indicate service disruption or misconfiguration.\\n\\n**Impact of Values:**  \\n- **High values:** May indicate automated scripts, bulk data retrieval, or potential reconnaissance by attackers trying to gather system details. Excessive reads can also increase API costs or cause throttling.  \\n- **Low values:** Could suggest issues with monitoring tools, broken automation, or loss of visibility into SSM-managed resources.\\n\\n**Example Usage:**  \\nIn a CloudWatch dashboard or alert rule, aggregate CloudTrail events filtered by `{\\\"EventSource\\\": \\\"ssm.amazonaws.com\\\", \\\"EventName\\\": \\\"Get*\\\"}` and plot the count over time. Configure an alarm to notify the SRE team if the count spikes above the defined threshold within a 15-minute window, enabling rapid investigation of unusual access patterns.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": true,
                        "score": 0.8562176500885798,
                        "reason": "The description clearly addresses the monitoring question by specifying the threshold of 2-3 times the average hourly rate for SSM 'Get' API calls, aligning well with the Retrieval Context. It concisely explains what is measured (frequency of SSM 'Get' operations), includes relevant units (times the average hourly rate), and highlights implications such as potential automated scripts or security concerns. The description enables effective utility for monitoring and alerting, though it could be slightly improved by explicitly mentioning the short time window (e.g., 5-15 minutes) for threshold evaluation as noted in the Retrieval Context.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Compare the description (Input) with the Retrieval Context to ensure the description clearly addresses the monitoring question by being concise and understandable.\",\n    \"Evaluate if the description comprehensively covers what is measured, including relevant units, context, and implications that align with the Retrieval Context.\",\n    \"Assess whether the description's clarity and coverage enable effective utility in answering the monitoring question given in the Retrieval Context.\",\n    \"If the description lacks sufficient alignment or detail compared to the Retrieval Context, identify specific missing elements and suggest improvements to enhance clarity, coverage, or utility.\"\n] \n \nRubric:\nNone \n \nScore: 0.8562176500885798"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Compare the description (Input) with the Retrieval Context to ensure the description clearly addresses the monitoring question by being concise and understandable.",
                            "Evaluate if the description comprehensively covers what is measured, including relevant units, context, and implications that align with the Retrieval Context.",
                            "Assess whether the description's clarity and coverage enable effective utility in answering the monitoring question given in the Retrieval Context.",
                            "If the description lacks sufficient alignment or detail compared to the Retrieval Context, identify specific missing elements and suggest improvements to enhance clarity, coverage, or utility."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"ecs.amazonaws.com\\\", \\\"EventName\\\": \\\"Update*\\\"}\", \"hyperparameters\": null, \"input\": \"Are there any unexpected or frequent ECS update events that could indicate configuration drift, deployment issues, or unauthorized changes?\", \"retrieval_context\": [\" - Lambda function \\\"Put*\\\" events in CloudTrail capture changes to function configurations, concurrency settings, event source mappings, and resource provisioning. These events indicate updates or deployments that can affect function behavior and performance. An SRE should monitor the frequency and success of these operations; unusually high rates of \\\"Put*\\\" events may signal automation errors or configuration churn, while absence of expected updates could indicate deployment issues. Alert thresholds might include more than 5 \\\"Put*\\\" events within 5 minutes or failed update attempts exceeding 10% of total \\\"Put*\\\" events. High volumes can lead to inconsistent function states or throttling, impacting availability and latency; low update activity during active development phases may delay critical fixes or optimizations. For example, a dashboard widget can track the count of \\\"Put*\\\" events per hour alongside error rates, and an alert rule could trigger when the number of failed \\\"Put*\\\" events surpasses a set threshold, prompting investigation into deployment or configuration problems.\", \" - This pattern captures all ECS update events recorded in CloudTrail, such as modifications to ECS services, task definitions, and cluster configurations. Its purpose is to monitor changes that could affect the stability, performance, or security of ECS workloads. An SRE should use this pattern to detect unexpected or frequent updates that may indicate configuration drift, deployment issues, or unauthorized changes.\\n\\n**Threshold guidance:**  \\n- Trigger an alert if the number of ECS update events exceeds a baseline threshold (e.g., more than 5 updates within 10 minutes), as this may signal rapid or unintended changes.  \\n- A low or zero count over a long period is typically normal but should be reviewed if updates are expected during deployments.\\n\\n**Impact:**  \\n- High frequency of update events can lead to service instability, deployment failures, or security risks if changes are unplanned or unauthorized.  \\n- Low frequency indicates stable ECS configurations but may also suggest stalled deployments or lack of necessary updates.\\n\\n**Example alert rule:**  \\n\\u201cAlert when the count of CloudTrail events with EventSource = 'ecs.amazonaws.com' and EventName starting with 'Update' exceeds 5 within a 10-minute window.\\u201d  \\n\\n**Example dashboard widget:**  \\nA time-series graph showing the count of ECS update events per 5-minute interval, annotated with deployment windows to correlate updates with expected changes.\", \" - This pattern captures all modification events related to EC2 resources in AWS CloudTrail, triggered by any API calls starting with \\\"Modify\\\" (e.g., ModifyInstanceAttribute, ModifyNetworkInterfaceAttribute). Its purpose is to monitor changes to critical EC2 configurations such as instance attributes, security group rules, and network settings, which can directly impact system security, availability, and performance.\\n\\n**Threshold guidance:**  \\n- Alert when the number of Modify* events exceeds a baseline threshold (e.g., more than 5 modifications within 10 minutes), indicating unusual or potentially unauthorized changes.  \\n- A sudden spike in modification events may signal misconfigurations, automation errors, or security incidents like privilege escalation or lateral movement.\\n\\n**Impact of values:**  \\n- **High frequency:** Could indicate active troubleshooting, automated scaling/configuration changes, or suspicious activity requiring immediate investigation.  \\n- **Low or zero frequency:** Normal steady state; no unexpected modifications detected.\\n\\n**Example alert rule:**  \\nTrigger an alert if the count of events matching {\\\"EventSource\\\": \\\"ec2.amazonaws.com\\\", \\\"EventName\\\": \\\"Modify*\\\"} exceeds 5 within a rolling 10-minute window.\\n\\n**Example dashboard widget:**  \\nA time-series graph showing the count of EC2 Modify* events per 5-minute interval, overlaid with a threshold line at 5 events, enabling quick identification of abnormal modification activity.\", \" - This pattern captures all modification events related to Elastic Load Balancing (ELB) resources in AWS, such as changes to load balancer configurations, target groups, and listeners. In CloudTrail, these events indicate when an ELB\\u2019s setup is altered, which can affect traffic routing, availability, and security posture.\\n\\n**Purpose:**  \\nTo monitor and audit any configuration changes to ELB components that could impact application availability or security.\\n\\n**Alert Threshold:**  \\nTrigger an alert if the number of ELB modification events exceeds a defined threshold within a short time window (e.g., more than 3 Modify* events within 10 minutes), as this may indicate unintended or unauthorized changes.\\n\\n**Impact of Values:**  \\n- **High frequency of Modify* events:** Could signal potential misconfigurations, automated deployment issues, or malicious activity altering load balancer behavior, risking downtime or security breaches.  \\n- **Low or no Modify* events:** Typically expected during stable operation; absence of changes suggests configuration stability.\\n\\n**Example Usage:**  \\nIn a monitoring dashboard or alert rule, track the count of **{\\\"EventSource\\\": \\\"elasticloadbalancing.amazonaws.com\\\", \\\"EventName\\\": \\\"Modify*\\\"}** events over rolling 10-minute intervals. Configure alerts to notify the SRE team when this count spikes above the threshold, enabling prompt investigation and rollback if necessary.\", \" - This pattern captures all update-related events from AWS Secrets Manager, such as modifications to secret values, rotation configurations, and access policy changes, as recorded in CloudTrail. Its purpose is to monitor changes that could affect the confidentiality, integrity, or availability of secrets critical to application security and operations.\\n\\n**Threshold guidance:**  \\n- Trigger an alert if the number of update events exceeds a baseline threshold within a short time window (e.g., more than 5 update events in 10 minutes), as this may indicate unusual or potentially unauthorized activity.  \\n- Conversely, an absence of expected rotation updates over a longer period (e.g., no rotation updates in 30 days) could signal stale secrets and increased security risk.\\n\\n**Impact of values:**  \\n- **High frequency of update events:** May indicate automated rotation, bulk secret changes, or suspicious activity such as credential compromise or insider threat. Immediate investigation is recommended.  \\n- **Low or zero update events:** Could mean secrets are not being rotated as per policy, increasing the risk of secret leakage or misuse.\\n\\n**Example alert rule:**  \\nAlert when `count(secretsmanager.amazonaws.com Update* events) > 5` within 10 minutes, excluding known maintenance windows.  \\n**Example dashboard widget:**  \\nA time-series graph showing the count of Secrets Manager update events over time, annotated with alerts triggered when thresholds are breached, helping SREs quickly identify abnormal secret modification patterns.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": true,
                        "score": 0.9119202922022117,
                        "reason": "The retrieval context clearly addresses the monitoring question by describing ECS update events in CloudTrail, including what is measured (ECS service, task definition, and cluster configuration updates), relevant thresholds, and impacts related to configuration drift, deployment issues, and unauthorized changes. The description is concise, uses terminology aligned with the question, and provides actionable guidance such as alert rules and dashboard examples, enabling effective user response. Minor deduction is due to the lack of explicit units for event counts, though the time windows and thresholds are well specified.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Compare the Input (monitoring question) with the Retrieval Context (metric description) to assess if the description clearly addresses the question's focus.\",\n    \"Evaluate Clarity by checking if the metric description is concise and easy to understand in relation to the question's terminology and scope.\",\n    \"Assess Coverage by verifying whether the description explains what is measured, including units, relevant context, and potential implications that connect directly to the question.\",\n    \"Determine Utility by judging if the description provides sufficient information to enable the user to answer the monitoring question effectively.\"\n] \n \nRubric:\nNone \n \nScore: 0.9119202922022117"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Compare the Input (monitoring question) with the Retrieval Context (metric description) to assess if the description clearly addresses the question's focus.",
                            "Evaluate Clarity by checking if the metric description is concise and easy to understand in relation to the question's terminology and scope.",
                            "Assess Coverage by verifying whether the description explains what is measured, including units, relevant context, and potential implications that connect directly to the question.",
                            "Determine Utility by judging if the description provides sufficient information to enable the user to answer the monitoring question effectively."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"ecs.amazonaws.com\\\", \\\"EventName\\\": \\\"Create*\\\"}\", \"hyperparameters\": null, \"input\": \"Are there spikes in Create* events indicating an abnormal rate of resource creation?\", \"retrieval_context\": [\" - Redshift cluster creation events in CloudTrail capture all API calls initiating the provisioning of new Redshift clusters (e.g., CreateCluster). These events indicate when new data warehouse resources are being deployed or configured, impacting capacity and cost.  \\n**Purpose:** Enables SREs to monitor and audit cluster provisioning activities for operational control and security compliance.  \\n**Alert Threshold:** Trigger alerts on an unusually high number of cluster creation events within a short time window (e.g., >3 creates in 1 hour), which may indicate automation errors, misconfigurations, or unauthorized resource provisioning.  \\n**Impact:**  \\n- **High values:** May lead to resource sprawl, increased costs, and potential performance degradation due to over-provisioning. Could also signal security risks if unexpected clusters are created.  \\n- **Low or zero values:** Normal in stable environments; no new clusters being created means stable infrastructure.  \\n**Example Alert Rule:**  \\n\\u201cAlert if count of events with EventSource='redshift.amazonaws.com' and EventName starting with 'Create' exceeds 3 within 60 minutes.\\u201d  \\n**Dashboard Use:** Visualize the frequency of Redshift cluster creation events over time to detect spikes or anomalies, correlating with deployment activities or security incidents.\", \" - S3 bucket creation events captured by CloudTrail under **{\\\"EventSource\\\": \\\"s3.amazonaws.com\\\", \\\"EventName\\\": \\\"Create*\\\"}** indicate when new buckets or related resources (e.g., bucket policies, access points) are provisioned. These events help SREs monitor infrastructure changes that affect data storage, security posture, and compliance.\\n\\n**Purpose:**  \\nTrack and audit the creation of S3 buckets and associated configurations to ensure proper governance, prevent unauthorized resource sprawl, and maintain compliance with organizational policies.\\n\\n**Alert Threshold:**  \\nTrigger an alert if the number of S3 bucket creation events exceeds a defined threshold within a short time window (e.g., more than 5 bucket creations within 10 minutes), which may indicate automated provisioning errors, misconfigurations, or potential security incidents such as unauthorized resource creation.\\n\\n**Impact of Values:**  \\n- **High frequency:** May signal abnormal activity, such as a compromised credential or runaway automation scripts creating excessive buckets, leading to increased costs, security risks, or compliance violations.  \\n- **Low or zero frequency:** Normal in stable environments; however, sudden spikes should be investigated promptly.\\n\\n**Example Alert Rule:**  \\n\\u201cAlert when count of events with EventSource = 's3.amazonaws.com' and EventName starting with 'Create' exceeds 5 within 10 minutes.\\u201d\\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of S3 Create* events over time, with thresholds marked to highlight unusual spikes, enabling quick identification of abnormal bucket creation activity.\", \" - This pattern captures all AWS Systems Manager (SSM) resource creation events logged in CloudTrail, such as the creation of parameters, documents, and maintenance windows. It helps SREs monitor the provisioning of new SSM assets, which can indicate configuration changes or automation deployments.\\n\\n**Purpose:**  \\nTo detect when new SSM resources are created, enabling timely awareness of infrastructure changes that may affect system behavior or security posture.\\n\\n**Alert Threshold Guidance:**  \\nSet an alert threshold based on your environment\\u2019s baseline creation activity. For example, trigger an alert if more than 5 creation events occur within 10 minutes, which may indicate unexpected or unauthorized provisioning.\\n\\n**Impact of Values:**  \\n- **High values:** A spike in creation events could signal automated deployments, configuration drift, or potential security incidents such as unauthorized resource creation.  \\n- **Low or zero values:** Normal in stable environments; however, a sudden drop might indicate issues with deployment pipelines or monitoring gaps.\\n\\n**Example Alert Rule:**  \\nTrigger an alert when the count of events matching `{\\\"EventSource\\\": \\\"ssm.amazonaws.com\\\", \\\"EventName\\\": \\\"Create*\\\"}` exceeds 5 within a 10-minute window.\\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of SSM creation events over time, with thresholds marked to highlight unusual spikes, helping SREs quickly identify and investigate abnormal provisioning activity.\", \" - This pattern captures all Route 53 resource creation events recorded in CloudTrail, such as the creation of hosted zones, DNS record sets, and health checks. Monitoring these events helps SREs detect configuration changes that could impact DNS resolution and application availability. \\n\\n**Purpose:** Track when new Route 53 resources are created to identify potential unauthorized changes or misconfigurations early.\\n\\n**Alert Threshold:** Trigger an alert if the number of creation events exceeds a baseline threshold (e.g., more than 5 creation events within 10 minutes), which may indicate automated misconfigurations, security breaches, or unintended mass changes.\\n\\n**Impact:**  \\n- **High values:** A spike in creation events could lead to DNS inconsistencies, increased attack surface, or service disruptions if malicious or erroneous resources are introduced.  \\n- **Low or zero values:** Normal operation, assuming no planned infrastructure changes.\\n\\n**Example Alert Rule:**  \\nAlert when `count({\\\"EventSource\\\": \\\"route53.amazonaws.com\\\", \\\"EventName\\\": \\\"Create*\\\"})` > 5 within 10 minutes.\\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of Route 53 creation events over time, enabling quick identification of unusual spikes in resource creation activity.\", \" - This pattern detects Secrets Manager creation events in CloudTrail, specifically any API calls starting with \\\"Create\\\" (e.g., CreateSecret). It helps SREs monitor when new secrets, secret versions, or related configurations are added, which could indicate deployment changes or potential security risks.  \\n**Alert threshold:** Trigger an alert if the number of create events exceeds a baseline (e.g., more than 5 creates within 10 minutes), as a sudden spike may signal unauthorized secret creation or misconfiguration. Conversely, zero create events over an extended period in an active environment might indicate issues with deployment pipelines or automation failures.  \\n**Impact:**  \\n- High values: Could indicate potential security breaches, unauthorized secret provisioning, or rapid environment changes requiring immediate investigation.  \\n- Low values: May suggest stalled deployments or automation problems, potentially delaying application updates or secret rotations.  \\n**Example usage:**  \\nIn a dashboard, plot the count of Secrets Manager Create* events over time to visualize spikes. An alert rule could be:  \\n`WHEN count(secretsmanager.amazonaws.com Create* events) > 5 within 10 minutes THEN trigger alert \\\"Unusual Secrets Creation Activity\\\"`  \\nThis enables proactive detection of abnormal secret creation activity, helping maintain security and operational stability.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": true,
                        "score": 0.9,
                        "reason": "The description clearly relates to the question by detailing Create* events across multiple AWS services, explaining what is measured (creation events), units (event counts over time windows), context (impact on cost, security, and operations), and implications of spikes. The language is clear and concise, aiding interpretation of abnormal spikes. It provides sufficient information for users to set alert thresholds and understand the significance of spikes, enabling confident answers to the monitoring question. Minor deduction for slight complexity due to multiple service patterns, but overall highly aligned.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Compare the Input (monitoring question) and the Retrieval Context (metric description) to ensure the description clearly relates to and addresses the question.\",\n    \"Evaluate the clarity of the description in terms of its language simplicity and conciseness, confirming it helps interpret the Input effectively.\",\n    \"Check coverage by verifying the description includes what is measured, units, relevant context, and implications to adequately support the question.\",\n    \"Assess utility by determining if the description provides sufficient information for a user to confidently answer the monitoring question based on the Input and Retrieval Context alignment.\"\n] \n \nRubric:\nNone \n \nScore: 0.9"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Compare the Input (monitoring question) and the Retrieval Context (metric description) to ensure the description clearly relates to and addresses the question.",
                            "Evaluate the clarity of the description in terms of its language simplicity and conciseness, confirming it helps interpret the Input effectively.",
                            "Check coverage by verifying the description includes what is measured, units, relevant context, and implications to adequately support the question.",
                            "Assess utility by determining if the description provides sufficient information for a user to confidently answer the monitoring question based on the Input and Retrieval Context alignment."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"ecs.amazonaws.com\\\", \\\"EventName\\\": \\\"Run*\\\"}\", \"hyperparameters\": null, \"input\": \"Does the count of ECS Run* events spike significantly above the baseline, indicating potential runaway task launches or deployment issues?\", \"retrieval_context\": [\" - **{\\\"EventName\\\": \\\"Start*\\\"}** events in CloudTrail indicate the initiation of resource start operations across various AWS services, such as starting EC2 instances, RDS databases, or other managed resources. These events help SREs track when resources transition from a stopped or inactive state to an active state, which is critical for service availability, cost management, and operational recovery.\\n\\n**Purpose:**  \\nTo monitor and audit the activation of cloud resources, ensuring that start operations align with expected usage patterns and do not indicate unauthorized or unexpected activity.\\n\\n**Alert Thresholds:**  \\n- Trigger an alert if the number of **Start*** events exceeds a predefined threshold within a short time window (e.g., more than 10 start operations within 5 minutes), which may indicate an automated scaling event, a potential misconfiguration, or a security incident.  \\n- Conversely, alert if expected start operations do not occur during scheduled maintenance windows, indicating possible failures in recovery or deployment processes.\\n\\n**Impact of Values:**  \\n- **High volume of Start* events:** Could lead to increased costs due to resource activation, potential service disruptions if resources are started unexpectedly, or indicate automated scaling or recovery actions.  \\n- **Low or zero Start* events during expected periods:** May signal failed recovery attempts, stalled deployments, or issues in operational workflows, potentially impacting service availability.\\n\\n**Example Usage:**  \\nIn a CloudWatch dashboard, plot the count of **Start*** events over time to visualize spikes or drops. An alert rule can be configured as:  \\n```\\nIF count(Start* events) > 10 within 5 minutes THEN trigger alert \\\"Unusual spike in resource start operations\\\"\\n```\\nThis enables proactive investigation into unexpected resource activations or failures to start critical services.\", \" - CodeDeploy events in CloudTrail capture API calls made to the AWS CodeDeploy service (EventSource: \\\"codedeploy.amazonaws.com\\\") across all event names (EventName: \\\"*\\\"). These events provide detailed records of deployment lifecycle actions such as creating, updating, starting, stopping, and deleting deployments, deployment groups, and applications. The data source is the AWS CodeDeploy API, and each event includes metadata like timestamps, user identity, deployment IDs, status changes, and error messages. Metrics derived from these events typically count the number of deployment-related API calls or track deployment status transitions over time (units: count of events or status occurrences). Unusual values\\u2014such as a sudden spike in failed deployment events, unexpected deployment cancellations, or unauthorized API calls\\u2014should trigger alerts as they may indicate deployment issues, configuration errors, or potential security incidents requiring immediate investigation.\", \" - This pattern captures ECS deletion events recorded in CloudTrail, specifically any API calls starting with \\\"Delete\\\" from the ECS service (e.g., DeleteCluster, DeleteService, DeleteTaskSet). Its purpose is to monitor when ECS resources are removed, which can signal intentional cleanup or unintended disruptions affecting service availability.\\n\\n**Threshold guidance:**  \\n- Trigger an alert if the number of ECS deletion events exceeds a baseline threshold within a short time window (e.g., more than 3 Delete* events in 5 minutes), as this may indicate accidental mass deletion or a security incident.  \\n- Low or expected deletion rates typically reflect routine maintenance or scaling down of resources and generally have minimal impact.\\n\\n**Impact:**  \\n- High deletion event counts can lead to service downtime, loss of running tasks, or cluster instability, requiring immediate investigation.  \\n- Low or zero deletion events usually indicate stable ECS resource management.\\n\\n**Example alert rule:**  \\n- Alert when `count(events where EventSource=\\\"ecs.amazonaws.com\\\" and EventName starts with \\\"Delete\\\") > 3` within 5 minutes.  \\n- This alert can be visualized on a dashboard showing ECS Delete* event counts over time, helping SREs quickly identify unusual spikes and correlate with service health metrics.\", \" - This pattern captures ECS task run events from CloudTrail, specifically any API calls starting with \\\"Run\\\" (e.g., RunTask, RunTaskSync). It indicates when ECS tasks are initiated, including manual task launches, service deployments, and scheduled executions. Monitoring these events helps SREs track workload activity and detect anomalies in task start rates.\\n\\n**Threshold guidance:**  \\n- Alert if the number of Run* events spikes significantly above the baseline (e.g., a 2x increase within 5 minutes), which may indicate runaway task launches or deployment issues.  \\n- Alert if the count drops to near zero during expected deployment windows, potentially signaling failures in task scheduling or service disruptions.\\n\\n**Impact:**  \\n- High values can lead to resource exhaustion, increased costs, or cascading failures if tasks are repeatedly started without completion.  \\n- Low values may indicate stalled deployments, scheduler failures, or service outages, impacting application availability.\\n\\n**Example alert rule:**  \\nTrigger an alert when the count of ECS Run* events exceeds 100 within 5 minutes or falls below 5 during a scheduled deployment window, prompting investigation into task launch behavior.\\n\\n**Example dashboard widget:**  \\nA time-series graph showing the count of ECS Run* events per minute, overlaid with deployment schedules, enabling correlation between task launches and expected operational activities.\", \" - This pattern captures all ECS update events recorded in CloudTrail, such as modifications to ECS services, task definitions, and cluster configurations. Its purpose is to monitor changes that could affect the stability, performance, or security of ECS workloads. An SRE should use this pattern to detect unexpected or frequent updates that may indicate configuration drift, deployment issues, or unauthorized changes.\\n\\n**Threshold guidance:**  \\n- Trigger an alert if the number of ECS update events exceeds a baseline threshold (e.g., more than 5 updates within 10 minutes), as this may signal rapid or unintended changes.  \\n- A low or zero count over a long period is typically normal but should be reviewed if updates are expected during deployments.\\n\\n**Impact:**  \\n- High frequency of update events can lead to service instability, deployment failures, or security risks if changes are unplanned or unauthorized.  \\n- Low frequency indicates stable ECS configurations but may also suggest stalled deployments or lack of necessary updates.\\n\\n**Example alert rule:**  \\n\\u201cAlert when the count of CloudTrail events with EventSource = 'ecs.amazonaws.com' and EventName starting with 'Update' exceeds 5 within a 10-minute window.\\u201d  \\n\\n**Example dashboard widget:**  \\nA time-series graph showing the count of ECS update events per 5-minute interval, annotated with deployment windows to correlate updates with expected changes.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": true,
                        "score": 0.888079707015525,
                        "reason": "The description is clear and concise, directly addressing the monitoring question about spikes in ECS Run* events. It explains what is measured (count of ECS Run* events), includes units (event counts over time), provides relevant context about the types of events captured and their operational significance, and states potential implications such as runaway task launches or deployment issues. The description aligns well with the retrieval context, incorporating threshold guidance and impact details that enable effective monitoring and alerting. Minor deduction is due to the absence of explicit example alert rules or dashboard widget references that could further enhance utility.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Evaluate the clarity of the metric description by determining if it is understandable and concise in the context of the provided monitoring question.\",\n    \"Assess the coverage by checking if the description explains what is measured, includes units, provides relevant context, and states potential implications, ensuring alignment with the input question.\",\n    \"Judge the utility by verifying whether the description enables a user to effectively answer the monitoring question based on the information given in both the Input and Retrieval Context.\",\n    \"Compare the description against the retrieval context to identify missing or extraneous information that affects its relevance and helpfulness in addressing the input question.\"\n] \n \nRubric:\nNone \n \nScore: 0.888079707015525"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Evaluate the clarity of the metric description by determining if it is understandable and concise in the context of the provided monitoring question.",
                            "Assess the coverage by checking if the description explains what is measured, includes units, provides relevant context, and states potential implications, ensuring alignment with the input question.",
                            "Judge the utility by verifying whether the description enables a user to effectively answer the monitoring question based on the information given in both the Input and Retrieval Context.",
                            "Compare the description against the retrieval context to identify missing or extraneous information that affects its relevance and helpfulness in addressing the input question."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"ecs.amazonaws.com\\\", \\\"EventName\\\": \\\"Delete*\\\"}\", \"hyperparameters\": null, \"input\": \"Does the number of ECS deletion events exceed three, indicating potential accidental mass deletion or a security incident?\", \"retrieval_context\": [\" - API Gateway deletion events captured by CloudTrail indicate when APIs, stages, or related resources are removed. These events are critical for tracking decommissioning activities, ensuring that endpoint removals are intentional and authorized, and preventing accidental service disruptions.  \\n\\n**Purpose:**  \\nMonitor all delete operations initiated via API Gateway (e.g., DeleteRestApi, DeleteStage) to maintain visibility into changes that reduce API surface area or remove critical endpoints.\\n\\n**Alert Threshold:**  \\nTrigger an alert if the number of Delete* events exceeds a predefined baseline within a short time window (e.g., more than 3 deletions within 10 minutes), as this may indicate accidental mass deletions, unauthorized activity, or a misconfigured automation script.\\n\\n**Impact:**  \\n- **High frequency:** Could lead to service outages, broken integrations, or data loss if APIs or stages are removed unexpectedly. Immediate investigation is required.  \\n- **Low or zero frequency:** Normal operation; deletion events are infrequent and typically planned.\\n\\n**Example Usage:**  \\nIn a monitoring dashboard, display a time series graph of Delete* events from apigateway.amazonaws.com. Set an alert rule such as:  \\n`IF count(Delete* events) > 3 within 10 minutes THEN trigger high-severity alert \\\"Potential API Gateway mass deletion detected\\\"`  \\nThis enables rapid response to potentially disruptive changes in the API infrastructure.\", \" - IAM deletion events (e.g., DeleteUser, DeleteRole) recorded by CloudTrail indicate removal of IAM identities or permissions. These events are critical for detecting unauthorized or accidental deletions that can disrupt access or signal a security breach. An alert threshold should be set to trigger on any unexpected deletion event or a sudden spike above normal baseline activity (e.g., more than 1 deletion event within 5 minutes), as even a single deletion can have significant impact. High volumes may indicate automated attacks or misconfigurations causing mass access removal, while low or zero values typically indicate normal operation.  \\nExample alert rule: trigger when count of iam.amazonaws.com Delete* events > 1 in 5 minutes.  \\nExample dashboard widget: a time series graph showing Delete* event counts over time, annotated with alert thresholds to quickly identify unusual deletion activity.\", \" - This event pattern captures all CloudTrail events where CloudWatch Logs resources\\u2014such as log groups or log streams\\u2014are deleted (e.g., DeleteLogGroup, DeleteLogStream). Its purpose is to monitor and audit log deletion activities, which can be legitimate cleanup or indicate potential loss of critical log data needed for troubleshooting and compliance.\\n\\n**Alert Threshold:**  \\nTrigger an alert if the number of delete events exceeds a baseline threshold within a defined time window (e.g., more than 3 deletions within 1 hour), or if deletions occur unexpectedly outside of scheduled maintenance windows.\\n\\n**Impact:**  \\n- **High frequency of deletions:** May indicate accidental or malicious removal of logs, risking loss of observability and forensic data. Immediate investigation is recommended.  \\n- **Low or zero deletions:** Normal operation, indicating logs are retained as expected.\\n\\n**Example Alert Rule:**  \\n\\u201cAlert if DeleteLogGroup or DeleteLogStream events from logs.amazonaws.com exceed 3 occurrences in 60 minutes.\\u201d  \\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of Delete* events over time, annotated with alert thresholds and maintenance windows, enabling quick identification of unusual spikes in log deletions.\", \" - This pattern captures ECS deletion events recorded in CloudTrail, specifically any API calls starting with \\\"Delete\\\" from the ECS service (e.g., DeleteCluster, DeleteService, DeleteTaskSet). Its purpose is to monitor when ECS resources are removed, which can signal intentional cleanup or unintended disruptions affecting service availability.\\n\\n**Threshold guidance:**  \\n- Trigger an alert if the number of ECS deletion events exceeds a baseline threshold within a short time window (e.g., more than 3 Delete* events in 5 minutes), as this may indicate accidental mass deletion or a security incident.  \\n- Low or expected deletion rates typically reflect routine maintenance or scaling down of resources and generally have minimal impact.\\n\\n**Impact:**  \\n- High deletion event counts can lead to service downtime, loss of running tasks, or cluster instability, requiring immediate investigation.  \\n- Low or zero deletion events usually indicate stable ECS resource management.\\n\\n**Example alert rule:**  \\n- Alert when `count(events where EventSource=\\\"ecs.amazonaws.com\\\" and EventName starts with \\\"Delete\\\") > 3` within 5 minutes.  \\n- This alert can be visualized on a dashboard showing ECS Delete* event counts over time, helping SREs quickly identify unusual spikes and correlate with service health metrics.\", \" - Tracks all AWS Lambda function deletion events captured in CloudTrail. Monitoring **{\\\"EventSource\\\": \\\"lambda.amazonaws.com\\\", \\\"EventName\\\": \\\"Delete*\\\"}** helps SREs detect when Lambda functions are removed, which is critical for maintaining application stability, ensuring proper resource cleanup, and preventing accidental or unauthorized deletions.  \\n\\n**Alert Threshold:** Trigger an alert if more than 3 Lambda function deletions occur within a 1-hour window, as this may indicate a misconfiguration, automated script error, or potential security breach.  \\n\\n**Impact:**  \\n- **High values:** A spike in deletions can lead to service disruptions, loss of critical functionality, or security incidents if unauthorized deletions occur. Immediate investigation is required.  \\n- **Low or zero values:** Normal operation; infrequent deletions are expected during routine maintenance or deployments.  \\n\\n**Example Alert Rule:**  \\n`WHEN count(events where EventSource=\\\"lambda.amazonaws.com\\\" AND EventName LIKE \\\"Delete%\\\") > 3 WITHIN 1 hour THEN alert \\\"Unusual number of Lambda deletions detected\\\"`  \\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of Lambda deletion events per hour, annotated with alert thresholds, enabling quick identification of abnormal deletion activity.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": true,
                        "score": 0.9075858176887361,
                        "reason": "The retrieval context directly addresses the input question by describing ECS deletion events, specifying the threshold of more than 3 deletions within 5 minutes as an indicator of potential accidental mass deletion or security incidents. It clearly explains what is measured (ECS deletion API calls), the units (event counts within a time window), context (CloudTrail monitoring), and implications (service downtime, cluster instability). The description is clear, concise, and provides example alert rules and dashboard visualization guidance, enabling effective user response. The only minor shortcoming is the lack of explicit mention of the exact time window in the input question, but the context reasonably infers it.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Compare the Input (monitoring question) and Retrieval Context (metric description) to ensure the description directly addresses the specific question asked.\",\n    \"Evaluate Clarity by checking if the Retrieval Context is understandable and concise in relation to the terminology and complexity of the Input.\",\n    \"Assess Coverage by verifying that the Retrieval Context explains what is measured, the units, context, and implications relevant to the Input question.\",\n    \"Determine Utility by confirming that the Retrieval Context provides sufficient information for a user to effectively answer the Input question based on the description.\"\n] \n \nRubric:\nNone \n \nScore: 0.9075858176887361"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Compare the Input (monitoring question) and Retrieval Context (metric description) to ensure the description directly addresses the specific question asked.",
                            "Evaluate Clarity by checking if the Retrieval Context is understandable and concise in relation to the terminology and complexity of the Input.",
                            "Assess Coverage by verifying that the Retrieval Context explains what is measured, the units, context, and implications relevant to the Input question.",
                            "Determine Utility by confirming that the Retrieval Context provides sufficient information for a user to effectively answer the Input question based on the description."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"ecs.amazonaws.com\\\", \\\"EventName\\\": \\\"Stop*\\\"}\", \"hyperparameters\": null, \"input\": \"Are the Stop* events indicating a scaling operation or task completion, or could they be related to an unexpected issue with ECS tasks?\", \"retrieval_context\": [\" - **{\\\"EventName\\\": \\\"Stop*\\\"}**  \\nThis event captures all resource stop operations across cloud services, such as stopping virtual machines, containers, or other compute resources. It signals intentional halting of resources for cost optimization, maintenance, or deactivation purposes.  \\n\\n**Purpose:**  \\nTo monitor when resources are stopped, enabling tracking of operational changes that affect availability and cost.  \\n\\n**Alert Threshold:**  \\nTrigger an alert if the number of Stop* events exceeds a defined baseline (e.g., a 50% increase over the average daily stop events) within a short time window (e.g., 15 minutes), which may indicate unexpected or mass shutdowns.  \\n\\n**Impact:**  \\n- **High values:** May indicate large-scale maintenance, potential outages, or unauthorized shutdowns impacting service availability and user experience.  \\n- **Low values:** Normal or no stop activity, indicating stable resource operation or potential lack of expected maintenance.  \\n\\n**Example Usage:**  \\nIn a dashboard, plot the count of Stop* events over time to visualize stop operation trends. An alert rule could be:  \\n`WHEN count(Stop* events) > baseline * 1.5 FOR 15 minutes THEN trigger alert`  \\nThis helps SREs quickly detect abnormal stop activity and respond accordingly.\", \" - EMR cluster events captured by CloudTrail provide detailed records of actions and changes within Amazon EMR, including cluster creation, modification, scaling, and termination. These events enable SREs to monitor the health and lifecycle of big data processing jobs and Hadoop ecosystem workflows. \\n\\n**Purpose:** Track operational changes and anomalies in EMR clusters to ensure data processing pipelines run smoothly and to quickly identify failures or misconfigurations.\\n\\n**Alert Thresholds:**  \\n- Alert on unexpected cluster terminations or failures (e.g., `TerminateJobFlows` or `RunJobFlow` failures).  \\n- Alert if cluster scaling events occur too frequently within a short time window, indicating instability.  \\n- Alert on prolonged cluster startup or shutdown times exceeding defined SLAs.\\n\\n**Impact:**  \\n- High frequency of failure or termination events may indicate systemic issues causing job interruptions or data loss.  \\n- Low or no cluster activity during expected processing windows could signal pipeline stalls or misconfigurations.  \\n- Frequent scaling events might degrade performance or increase costs unnecessarily.\\n\\n**Example Alert Rule:**  \\nTrigger an alert if more than 3 `TerminateJobFlows` events occur within 1 hour, or if a cluster remains in `Starting` state for over 15 minutes without transitioning to `Running`.  \\n\\n**Dashboard Use:**  \\nVisualize event counts over time by event name (e.g., `RunJobFlow`, `AddInstanceGroups`, `TerminateJobFlows`) alongside cluster status metrics to correlate operational events with cluster health and job success rates.\", \" - This pattern captures ECS stop events. It identifies when ECS tasks are stopped, which can indicate task completion, scaling operations, or service updates.\", \" - This pattern captures ECS task run events from CloudTrail, specifically any API calls starting with \\\"Run\\\" (e.g., RunTask, RunTaskSync). It indicates when ECS tasks are initiated, including manual task launches, service deployments, and scheduled executions. Monitoring these events helps SREs track workload activity and detect anomalies in task start rates.\\n\\n**Threshold guidance:**  \\n- Alert if the number of Run* events spikes significantly above the baseline (e.g., a 2x increase within 5 minutes), which may indicate runaway task launches or deployment issues.  \\n- Alert if the count drops to near zero during expected deployment windows, potentially signaling failures in task scheduling or service disruptions.\\n\\n**Impact:**  \\n- High values can lead to resource exhaustion, increased costs, or cascading failures if tasks are repeatedly started without completion.  \\n- Low values may indicate stalled deployments, scheduler failures, or service outages, impacting application availability.\\n\\n**Example alert rule:**  \\nTrigger an alert when the count of ECS Run* events exceeds 100 within 5 minutes or falls below 5 during a scheduled deployment window, prompting investigation into task launch behavior.\\n\\n**Example dashboard widget:**  \\nA time-series graph showing the count of ECS Run* events per minute, overlaid with deployment schedules, enabling correlation between task launches and expected operational activities.\", \" - This pattern captures Elastic Load Balancing (ELB) target deregistration events from CloudTrail, indicating when backend targets (such as EC2 instances or IP addresses) are removed from a load balancer. These events typically occur during scaling operations, deployments, or maintenance activities that affect service availability.\\n\\n**Purpose:**  \\nMonitoring deregistration events helps SREs track changes in load balancer target groups, ensuring that scaling or maintenance actions do not inadvertently reduce capacity or cause service disruptions.\\n\\n**Alert Threshold Guidance:**  \\n- Trigger an alert if the number of deregistration events exceeds a defined threshold within a short time window (e.g., more than 5 deregistrations within 5 minutes), which may indicate unexpected or excessive target removals.  \\n- Conversely, a prolonged absence of deregistration events during expected scaling periods might signal issues with autoscaling or deployment processes.\\n\\n**Impact of Values:**  \\n- **High deregistration rate:** Could lead to reduced backend capacity, increased latency, or service outages if targets are removed too quickly or unexpectedly. Immediate investigation is warranted.  \\n- **Low or no deregistration events:** May indicate stable operations or, if scaling is expected, potential failures in scaling mechanisms.\\n\\n**Example Alert Rule:**  \\n```\\nWHEN count of events WHERE EventSource = \\\"elasticloadbalancing.amazonaws.com\\\" AND EventName LIKE \\\"Deregister%\\\"  \\nIN last 5 minutes > 5  \\nTHEN trigger alert \\\"High ELB Target Deregistration Rate\\\"\\n```\\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of deregistration events per minute, overlaid with thresholds, to visualize spikes or drops in deregistration activity aligned with deployment or scaling events.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": true,
                        "score": 0.873105859034899,
                        "reason": "The retrieval context explicitly addresses the monitoring question by describing Stop* events as ECS stop events indicating task completion, scaling operations, or service updates, and also covers unexpected issues through alert thresholds and impact explanations. The description is clear, concise, and uses terminology aligned with the question. It includes what is measured (Stop* events), context (ECS tasks and other resources), units (event counts over time), and implications (maintenance, outages, unauthorized shutdowns). The detailed alert guidance and impact help users confidently interpret whether Stop* events indicate normal operations or unexpected issues, providing strong utility.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Compare the Input (monitoring question) with the Retrieval Context (metric description) to ensure the description explicitly addresses the question's focus.\",\n    \"Evaluate Clarity by checking if the metric description is concise and easy to understand in relation to the monitoring question's terminology and intent.\",\n    \"Assess Coverage to verify that the description includes what is measured, units, context, and implications relevant to the question.\",\n    \"Determine Utility by confirming the description provides sufficient information to help a user confidently answer the monitoring question.\"\n] \n \nRubric:\nNone \n \nScore: 0.873105859034899"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Compare the Input (monitoring question) with the Retrieval Context (metric description) to ensure the description explicitly addresses the question's focus.",
                            "Evaluate Clarity by checking if the metric description is concise and easy to understand in relation to the monitoring question's terminology and intent.",
                            "Assess Coverage to verify that the description includes what is measured, units, context, and implications relevant to the question.",
                            "Determine Utility by confirming the description provides sufficient information to help a user confidently answer the monitoring question."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"eks.amazonaws.com\\\", \\\"EventName\\\": \\\"Delete*\\\"}\", \"hyperparameters\": null, \"input\": \"Are Delete* events initiated by Amazon EKS causing a spike in resource removals?\", \"retrieval_context\": [\" - This pattern captures ECS deletion events recorded in CloudTrail, specifically any API calls starting with \\\"Delete\\\" from the ECS service (e.g., DeleteCluster, DeleteService, DeleteTaskSet). Its purpose is to monitor when ECS resources are removed, which can signal intentional cleanup or unintended disruptions affecting service availability.\\n\\n**Threshold guidance:**  \\n- Trigger an alert if the number of ECS deletion events exceeds a baseline threshold within a short time window (e.g., more than 3 Delete* events in 5 minutes), as this may indicate accidental mass deletion or a security incident.  \\n- Low or expected deletion rates typically reflect routine maintenance or scaling down of resources and generally have minimal impact.\\n\\n**Impact:**  \\n- High deletion event counts can lead to service downtime, loss of running tasks, or cluster instability, requiring immediate investigation.  \\n- Low or zero deletion events usually indicate stable ECS resource management.\\n\\n**Example alert rule:**  \\n- Alert when `count(events where EventSource=\\\"ecs.amazonaws.com\\\" and EventName starts with \\\"Delete\\\") > 3` within 5 minutes.  \\n- This alert can be visualized on a dashboard showing ECS Delete* event counts over time, helping SREs quickly identify unusual spikes and correlate with service health metrics.\", \" - This pattern captures all EC2 resource deletion events recorded in CloudTrail, triggered by any API calls starting with \\\"Delete\\\" from the EC2 service (e.g., DeleteSecurityGroup, DeleteNetworkInterface). Its purpose is to monitor and alert on the removal of critical EC2 components, which can impact infrastructure stability and security.\\n\\n**Threshold guidance:**  \\n- Set an alert if the number of deletion events exceeds a baseline threshold within a short time window (e.g., more than 5 deletions in 10 minutes), as this may indicate accidental mass deletions or malicious activity.  \\n- A low or zero count is typical during normal operations, while sudden spikes warrant immediate investigation.\\n\\n**Impact:**  \\n- High deletion event counts can lead to service disruptions, loss of network connectivity, or security vulnerabilities if key resources like security groups or network interfaces are removed unexpectedly.  \\n- Low or no deletion activity generally indicates stable infrastructure management.\\n\\n**Example alert rule:**  \\nTrigger an alert when the count of events matching {\\\"EventSource\\\": \\\"ec2.amazonaws.com\\\", \\\"EventName\\\": \\\"Delete*\\\"} exceeds 5 within 10 minutes.\\n\\n**Example dashboard usage:**  \\nVisualize the count of EC2 deletion events over time to identify unusual spikes, correlating with other operational metrics to assess potential impact on system availability or security posture.\", \" - This pattern captures all deletion events related to Elastic Load Balancers (ELBs) in AWS, as recorded by CloudTrail under the event source \\\"elasticloadbalancing.amazonaws.com\\\" with event names starting with \\\"Delete\\\". Its primary purpose is to monitor when ELBs are removed, which can be part of routine cleanup or indicate unintended service disruptions due to the loss of load balancing resources.\\n\\n**Purpose:**  \\nSREs use this pattern to track ELB deletions to quickly detect and investigate potential impacts on application availability and traffic routing.\\n\\n**Alert Threshold:**  \\nAn alert should be triggered if the number of ELB deletion events exceeds a predefined threshold within a short time window\\u2014for example, more than 1 deletion event within 5 minutes\\u2014since multiple deletions in quick succession may indicate a misconfiguration, automation error, or malicious activity.\\n\\n**Impact of Values:**  \\n- **High values:** Frequent or bulk ELB deletions can cause significant service disruption, leading to downtime or degraded performance due to loss of traffic distribution. Immediate investigation and remediation are required.  \\n- **Low values:** Occasional single deletions may be expected during normal maintenance or scaling operations and typically do not require urgent action but should still be logged for audit purposes.\\n\\n**Example Usage:**  \\nIn a monitoring dashboard or alert rule, you might configure a query to count ELB deletion events over a rolling 5-minute window and trigger an alert if the count exceeds 1. For example:\\n\\n```\\ncount_over_time({EventSource=\\\"elasticloadbalancing.amazonaws.com\\\", EventName=~\\\"Delete.*\\\"}[5m]) > 1\\n```\\n\\nThis alert helps ensure that unexpected or excessive ELB deletions are promptly detected and addressed to maintain service reliability.\", \" - This pattern detects AWS KMS key deletion events captured in CloudTrail, specifically any API calls starting with \\\"Delete\\\" (e.g., DeleteKey). Its purpose is to monitor the removal of cryptographic keys, which are critical for data encryption and access control. Frequent or unexpected deletions may indicate potential security risks, accidental data loss, or cleanup activities.\\n\\n**Alert Threshold:**  \\nTrigger an alert if more than 1 Delete* event occurs within a short time window (e.g., 1 hour), as multiple deletions could signify malicious activity or misconfiguration.\\n\\n**Impact:**  \\n- **High values:** Multiple key deletions in a brief period can lead to irreversible data access loss, service disruptions, or security breaches. Immediate investigation is required.  \\n- **Low values:** Occasional single deletions may be part of routine key rotation or cleanup but should still be reviewed for authorization.\\n\\n**Example Alert Rule:**  \\n```\\nWHEN count of events WHERE EventSource = \\\"kms.amazonaws.com\\\" AND EventName LIKE \\\"Delete%\\\" OVER last 1 hour > 1  \\nTHEN trigger alert \\\"Multiple KMS key deletions detected\\\"\\n```\\n\\n**Dashboard Use Case:**  \\nVisualize the count of Delete* events over time to identify spikes or unusual patterns, correlating with operational changes or security incidents. This helps SREs proactively manage key lifecycle and maintain data protection integrity.\", \" - This pattern matches all deletion events initiated by the Amazon EKS service. It captures API calls where the event name starts with \\\"Delete,\\\" such as deleting clusters, node groups, or other EKS resources. The measurement is a count of these deletion events occurring within the monitored timeframe. Tracking these events helps identify resource removals that may impact cluster availability or indicate cleanup activities.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": false,
                        "score": 0.4303118071457539,
                        "reason": "The retrieval context provides detailed descriptions of Delete* events for multiple AWS services (ECS, EKS, KMS, EC2, ELB) but does not specifically focus on Amazon EKS Delete* events causing spikes in resource removals, which is the monitoring question's focus. While the EKS pattern is included, it is brief and lacks threshold guidance, impact details, or alert examples, reducing clarity, coverage, and utility for answering the question effectively.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Compare the Input (monitoring question) and the Retrieval Context (metric description) to ensure the description directly addresses the question's focus.\",\n    \"Evaluate clarity by checking if the description is easily understandable and concise, considering how well it complements the question without ambiguity.\",\n    \"Assess coverage by verifying if the description details what is measured, including units, relevant context, and implications as they relate to the question.\",\n    \"Judge utility by determining if the description provides sufficient information to effectively answer the monitoring question; if gaps exist, note specific improvements.\"\n] \n \nRubric:\nNone \n \nScore: 0.4303118071457539"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Compare the Input (monitoring question) and the Retrieval Context (metric description) to ensure the description directly addresses the question's focus.",
                            "Evaluate clarity by checking if the description is easily understandable and concise, considering how well it complements the question without ambiguity.",
                            "Assess coverage by verifying if the description details what is measured, including units, relevant context, and implications as they relate to the question.",
                            "Judge utility by determining if the description provides sufficient information to effectively answer the monitoring question; if gaps exist, note specific improvements."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"eks.amazonaws.com\\\", \\\"EventName\\\": \\\"Create*\\\"}\", \"hyperparameters\": null, \"input\": \"Does the number of EKS creation events exceed two, indicating potential automated or unintended deployments?\", \"retrieval_context\": [\" - EKS List* events in CloudTrail capture API calls that enumerate EKS resources such as clusters, node groups, add-ons, and other related components. These operations are primarily read-only and used for infrastructure discovery, capacity planning, and operational visibility. Monitoring the frequency of List* calls helps detect unusual activity patterns: a sudden spike may indicate automated scanning, reconnaissance, or potential misuse, while an abnormally low rate could suggest monitoring gaps or service disruptions. A practical alert threshold might be set at a rate exceeding the baseline average by 3x within a 5-minute window. For example, a dashboard widget could track the count of eks.amazonaws.com List* events per minute, with an alert rule triggering when this count surpasses the defined threshold, enabling timely investigation of unexpected enumeration activity.\", \" - This pattern captures all Amazon EKS \\\"Describe\\\" API operations logged in CloudTrail, which occur when cluster metadata, node group configurations, or add-on details are queried. It helps SREs monitor how often EKS cluster information is accessed, providing visibility into potential reconnaissance or troubleshooting activities. A sudden spike in Describe calls\\u2014such as exceeding 100 requests within 5 minutes\\u2014may indicate unusual or automated querying that could precede configuration changes or security incidents, warranting an alert. Conversely, consistently low or zero Describe activity might suggest lack of monitoring or insufficient operational visibility. For example, an alert rule could trigger when Describe API calls surpass 100 in a 5-minute window, and a dashboard widget might display a time series graph of Describe call counts to track trends and detect anomalies in cluster information access patterns.\", \" - This pattern captures all creation events initiated through the Amazon EKS service, such as the creation of EKS clusters, node groups, and add-on components, as recorded in CloudTrail. It enables SREs to monitor when new Kubernetes infrastructure is provisioned, which can impact cluster capacity, security posture, and operational costs.\\n\\n**Purpose:**  \\nTo detect and track the provisioning of new EKS resources, helping teams respond promptly to unexpected or unauthorized cluster creations that may indicate misconfigurations or security risks.\\n\\n**Alert Threshold Guidance:**  \\nTrigger an alert if the number of EKS creation events exceeds a defined baseline within a short time window (e.g., more than 2 cluster or node group creations within 1 hour), as this may signal automated or unintended deployments. Conversely, an unusually low number of creation events over a longer period could indicate deployment pipeline issues or stalled infrastructure scaling.\\n\\n**Impact of Values:**  \\n- **High frequency:** May lead to resource sprawl, increased costs, or potential security vulnerabilities if clusters are created without proper governance.  \\n- **Low frequency:** Could reflect deployment failures or delays, impacting application availability or scalability.\\n\\n**Example Usage:**  \\nIn a monitoring dashboard, display a time series graph of EKS creation events filtered by this pattern to visualize provisioning trends. An alert rule might be:  \\n`WHEN count(events matching {\\\"EventSource\\\": \\\"eks.amazonaws.com\\\", \\\"EventName\\\": \\\"Create*\\\"}) > 2 within 1 hour THEN trigger alert \\\"Unusual EKS resource creation activity detected\\\"`  \\nThis helps SREs quickly identify and investigate abnormal cluster provisioning activities.\", \" - This pattern captures all update-related events from Amazon EKS recorded in CloudTrail, such as cluster version upgrades, managed node group modifications, and add-on updates. Its purpose is to monitor changes that can affect cluster stability, security, or performance. An SRE should set alert thresholds based on the frequency and timing of these update events\\u2014for example, triggering an alert if more than 3 update events occur within a 1-hour window, which may indicate unexpected or automated changes that require investigation. High volumes of update events in a short period could signal potential configuration drift, deployment issues, or unauthorized modifications, increasing risk to cluster availability and security. Conversely, low or no update events over extended periods may suggest stagnation in maintenance or missed critical updates. An example alert rule could be: \\u201cAlert if count of events matching {EventSource: 'eks.amazonaws.com', EventName: 'Update*'} exceeds 3 within 60 minutes.\\u201d In a dashboard, this pattern can be visualized as a time series graph showing update event counts per hour, helping SREs quickly identify unusual spikes or trends in cluster modifications.\", \" - This pattern detects AWS KMS API calls that begin with \\\"Generate,\\\" such as GenerateDataKey and GenerateRandom. It captures events where cryptographic keys, data keys, or random byte sequences are created. The measurement is event occurrence count, indicating how many such generation requests were made. This helps monitor key material creation activities within AWS KMS.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": true,
                        "score": 0.909534947261117,
                        "reason": "The retrieval context directly addresses the input question by explaining the monitoring of EKS creation events, including a clear alert threshold of more than 2 creations within 1 hour, which matches the question's intent. It is detailed and clear, describing what is measured (creation events), the units (event counts within time windows), and the implications of high frequency events. The context provides sufficient information for a user to confidently determine if the number of EKS creation events exceeds two, indicating potential automated or unintended deployments. The only minor shortcoming is the length and density of the text, which could be more concise for clarity.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Compare the Input (question) with the Retrieval Context (metric description) to assess if the description directly addresses the question's intent.\",\n    \"Evaluate Clarity by checking if the Retrieval Context is concise and comprehensible without ambiguity when read alongside the Input.\",\n    \"Assess Coverage by verifying the description explains what is measured, including units and implications, relevant to the question in the Input.\",\n    \"Determine Utility by judging if the Retrieval Context equips a user with enough information to confidently answer the Input question.\"\n] \n \nRubric:\nNone \n \nScore: 0.909534947261117"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Compare the Input (question) with the Retrieval Context (metric description) to assess if the description directly addresses the question's intent.",
                            "Evaluate Clarity by checking if the Retrieval Context is concise and comprehensible without ambiguity when read alongside the Input.",
                            "Assess Coverage by verifying the description explains what is measured, including units and implications, relevant to the question in the Input.",
                            "Determine Utility by judging if the Retrieval Context equips a user with enough information to confidently answer the Input question."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"securityhub.amazonaws.com\\\", \\\"EventName\\\": \\\"*\\\"}\", \"hyperparameters\": null, \"input\": \"Do Security Hub events indicate any detected security issues exceeding ten in the past hour?\", \"retrieval_context\": [\" - S3 bucket creation events captured by CloudTrail under **{\\\"EventSource\\\": \\\"s3.amazonaws.com\\\", \\\"EventName\\\": \\\"Create*\\\"}** indicate when new buckets or related resources (e.g., bucket policies, access points) are provisioned. These events help SREs monitor infrastructure changes that affect data storage, security posture, and compliance.\\n\\n**Purpose:**  \\nTrack and audit the creation of S3 buckets and associated configurations to ensure proper governance, prevent unauthorized resource sprawl, and maintain compliance with organizational policies.\\n\\n**Alert Threshold:**  \\nTrigger an alert if the number of S3 bucket creation events exceeds a defined threshold within a short time window (e.g., more than 5 bucket creations within 10 minutes), which may indicate automated provisioning errors, misconfigurations, or potential security incidents such as unauthorized resource creation.\\n\\n**Impact of Values:**  \\n- **High frequency:** May signal abnormal activity, such as a compromised credential or runaway automation scripts creating excessive buckets, leading to increased costs, security risks, or compliance violations.  \\n- **Low or zero frequency:** Normal in stable environments; however, sudden spikes should be investigated promptly.\\n\\n**Example Alert Rule:**  \\n\\u201cAlert when count of events with EventSource = 's3.amazonaws.com' and EventName starting with 'Create' exceeds 5 within 10 minutes.\\u201d\\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of S3 Create* events over time, with thresholds marked to highlight unusual spikes, enabling quick identification of abnormal bucket creation activity.\", \" - Security Hub events capture findings and compliance status related to your AWS environment's security posture. They measure detected security issues, compliance checks, and control evaluations as discrete event records. Each event represents a specific security or compliance occurrence, enabling centralized monitoring and audit reporting. These events are counted individually to track security and compliance activities over time.\", \" - This pattern captures all AWS Security Token Service (STS) \\\"Get\\\" operations, such as `GetSessionToken`, `GetCallerIdentity`, and similar API calls that issue or validate temporary security credentials. In CloudTrail, these events indicate when users or services request short-lived credentials to access AWS resources.\\n\\n**Purpose:**  \\nMonitor STS Get* events to detect unusual or excessive requests for temporary credentials, which can signal automation activity, credential misuse, or potential security incidents like privilege escalation or compromised identities.\\n\\n**Alert Threshold:**  \\nTrigger an alert when the count of STS Get* events exceeds a baseline threshold established from normal activity patterns\\u2014commonly, a sudden spike above 3-5 times the average hourly rate or an absolute count exceeding 100 requests per hour, depending on your environment size and usage.\\n\\n**Impact of Values:**  \\n- **High values:** May indicate automated processes requesting many temporary credentials, potential credential abuse, or an attacker attempting to escalate privileges or move laterally. Prompt investigation is warranted.  \\n- **Low or expected values:** Reflect normal operation with routine credential issuance and validation.\\n\\n**Example Usage:**  \\nIn a monitoring dashboard, plot the count of `sts.amazonaws.com` events with `EventName` matching `Get*` over time. Set an alert rule such as:  \\n`WHEN count(events where EventSource=\\\"sts.amazonaws.com\\\" AND EventName LIKE \\\"Get*\\\") > 100 within 1 hour THEN alert \\\"High STS Get* activity detected\\\"`  \\nThis helps SREs quickly identify abnormal credential request patterns and respond accordingly.\", \" - This pattern captures all ECS update events recorded in CloudTrail, such as modifications to ECS services, task definitions, and cluster configurations. Its purpose is to monitor changes that could affect the stability, performance, or security of ECS workloads. An SRE should use this pattern to detect unexpected or frequent updates that may indicate configuration drift, deployment issues, or unauthorized changes.\\n\\n**Threshold guidance:**  \\n- Trigger an alert if the number of ECS update events exceeds a baseline threshold (e.g., more than 5 updates within 10 minutes), as this may signal rapid or unintended changes.  \\n- A low or zero count over a long period is typically normal but should be reviewed if updates are expected during deployments.\\n\\n**Impact:**  \\n- High frequency of update events can lead to service instability, deployment failures, or security risks if changes are unplanned or unauthorized.  \\n- Low frequency indicates stable ECS configurations but may also suggest stalled deployments or lack of necessary updates.\\n\\n**Example alert rule:**  \\n\\u201cAlert when the count of CloudTrail events with EventSource = 'ecs.amazonaws.com' and EventName starting with 'Update' exceeds 5 within a 10-minute window.\\u201d  \\n\\n**Example dashboard widget:**  \\nA time-series graph showing the count of ECS update events per 5-minute interval, annotated with deployment windows to correlate updates with expected changes.\", \" - This pattern captures all update-related events from AWS Secrets Manager, such as modifications to secret values, rotation configurations, and access policy changes, as recorded in CloudTrail. Its purpose is to monitor changes that could affect the confidentiality, integrity, or availability of secrets critical to application security and operations.\\n\\n**Threshold guidance:**  \\n- Trigger an alert if the number of update events exceeds a baseline threshold within a short time window (e.g., more than 5 update events in 10 minutes), as this may indicate unusual or potentially unauthorized activity.  \\n- Conversely, an absence of expected rotation updates over a longer period (e.g., no rotation updates in 30 days) could signal stale secrets and increased security risk.\\n\\n**Impact of values:**  \\n- **High frequency of update events:** May indicate automated rotation, bulk secret changes, or suspicious activity such as credential compromise or insider threat. Immediate investigation is recommended.  \\n- **Low or zero update events:** Could mean secrets are not being rotated as per policy, increasing the risk of secret leakage or misuse.\\n\\n**Example alert rule:**  \\nAlert when `count(secretsmanager.amazonaws.com Update* events) > 5` within 10 minutes, excluding known maintenance windows.  \\n**Example dashboard widget:**  \\nA time-series graph showing the count of Secrets Manager update events over time, annotated with alerts triggered when thresholds are breached, helping SREs quickly identify abnormal secret modification patterns.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": true,
                        "score": 0.8324822659377598,
                        "reason": "The description clearly addresses the monitoring question by explaining that Security Hub events capture detected security issues as discrete event records, which can be counted over time. It uses clear and relevant language focused on security findings and compliance status, directly supporting the question about detecting security issues exceeding ten in the past hour. However, it lacks explicit mention of units (e.g., per hour) and specific alert thresholds related to the question's numeric threshold, slightly limiting coverage and utility for immediate actionable insights.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Compare the Input (monitoring question) and Retrieval Context (metric description) to check if the description clearly addresses the question's focus.\",\n    \"Evaluate Clarity by ensuring the description uses understandable and concise language relevant to the specific metric and monitoring scenario posed by the question.\",\n    \"Assess Coverage by verifying that the description explains what the metric measures, including units, operational context, and potential implications, directly supporting the monitoring question.\",\n    \"Judge Utility by determining if the description provides sufficient information and insight to enable answering the monitoring question effectively.\"\n] \n \nRubric:\nNone \n \nScore: 0.8324822659377598"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Compare the Input (monitoring question) and Retrieval Context (metric description) to check if the description clearly addresses the question's focus.",
                            "Evaluate Clarity by ensuring the description uses understandable and concise language relevant to the specific metric and monitoring scenario posed by the question.",
                            "Assess Coverage by verifying that the description explains what the metric measures, including units, operational context, and potential implications, directly supporting the monitoring question.",
                            "Judge Utility by determining if the description provides sufficient information and insight to enable answering the monitoring question effectively."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"guardduty.amazonaws.com\\\", \\\"EventName\\\": \\\"*\\\"}\", \"hyperparameters\": null, \"input\": \"Do GuardDuty events indicate a spike in high-severity threats, suggesting potential security breaches?\", \"retrieval_context\": [\" - Detective security investigation events capture detailed activity logs related to threat analysis, security incident investigations, and behavioral analytics within AWS Detective. These events help SREs monitor and correlate security forensics and threat intelligence to identify suspicious or anomalous behavior in the environment.\\n\\n**Purpose in CloudTrail:**  \\nEvents from `detective.amazonaws.com` provide visibility into investigative actions and findings performed by AWS Detective, enabling tracking of security-related activities and potential threat escalations.\\n\\n**Alert Threshold Guidance:**  \\n- Trigger alerts when the volume of Detective investigation events spikes significantly above baseline (e.g., a 3x increase in investigative queries or findings within a short time window), indicating potential active threat hunting or incident response.  \\n- Alert on unusual event types or repeated failed investigation attempts that may suggest misuse or compromised credentials.\\n\\n**Impact of Values:**  \\n- **High event volume:** May indicate active security incidents, ongoing investigations, or potential security breaches requiring immediate attention.  \\n- **Low or no events:** Could suggest normal operation or lack of active investigations; however, a sudden drop after a period of activity might also warrant review.\\n\\n**Example Alert Rule:**  \\n```\\nWHEN count(detective.amazonaws.com EventName=*) OVER 15 minutes > 3 * baseline_average THEN alert \\\"Unusual Detective investigation activity detected\\\"\\n```\\n\\n**Example Dashboard Widget:**  \\n- A time-series graph showing the count of Detective events per minute, annotated with alerts on spikes.  \\n- A table listing top EventNames and their frequencies to identify unusual investigative patterns.\", \" - GuardDuty events capture detailed findings related to potential security threats detected within your AWS environment. These include alerts on suspicious activities such as unauthorized access, compromised credentials, and known malicious behavior. Each event provides metadata and severity scores to quantify the risk level of the detected threat. This data is essential for continuous security monitoring and incident response.\", \" - S3 bucket creation events captured by CloudTrail under **{\\\"EventSource\\\": \\\"s3.amazonaws.com\\\", \\\"EventName\\\": \\\"Create*\\\"}** indicate when new buckets or related resources (e.g., bucket policies, access points) are provisioned. These events help SREs monitor infrastructure changes that affect data storage, security posture, and compliance.\\n\\n**Purpose:**  \\nTrack and audit the creation of S3 buckets and associated configurations to ensure proper governance, prevent unauthorized resource sprawl, and maintain compliance with organizational policies.\\n\\n**Alert Threshold:**  \\nTrigger an alert if the number of S3 bucket creation events exceeds a defined threshold within a short time window (e.g., more than 5 bucket creations within 10 minutes), which may indicate automated provisioning errors, misconfigurations, or potential security incidents such as unauthorized resource creation.\\n\\n**Impact of Values:**  \\n- **High frequency:** May signal abnormal activity, such as a compromised credential or runaway automation scripts creating excessive buckets, leading to increased costs, security risks, or compliance violations.  \\n- **Low or zero frequency:** Normal in stable environments; however, sudden spikes should be investigated promptly.\\n\\n**Example Alert Rule:**  \\n\\u201cAlert when count of events with EventSource = 's3.amazonaws.com' and EventName starting with 'Create' exceeds 5 within 10 minutes.\\u201d\\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of S3 Create* events over time, with thresholds marked to highlight unusual spikes, enabling quick identification of abnormal bucket creation activity.\", \" - This pattern captures AWS KMS Decrypt API calls recorded in CloudTrail, indicating when encrypted data is accessed and decrypted using KMS keys. It helps SREs monitor data access events for security auditing and anomaly detection. A sudden spike in Decrypt events may signal unusual or unauthorized data access, while consistently low or expected volumes suggest normal operation. As a threshold, alerting on a sustained increase exceeding 3 standard deviations above the historical average or a sudden burst of Decrypt calls within a short time window (e.g., 5 minutes) is recommended. For example, an alert rule could trigger when the count of Decrypt events exceeds 100 in 5 minutes, indicating potential data exfiltration or misuse. In dashboards, tracking the rate of Decrypt events over time alongside user identities and key IDs can help quickly identify suspicious patterns or compromised credentials.\", \" - This pattern detects Secrets Manager creation events in CloudTrail, specifically any API calls starting with \\\"Create\\\" (e.g., CreateSecret). It helps SREs monitor when new secrets, secret versions, or related configurations are added, which could indicate deployment changes or potential security risks.  \\n**Alert threshold:** Trigger an alert if the number of create events exceeds a baseline (e.g., more than 5 creates within 10 minutes), as a sudden spike may signal unauthorized secret creation or misconfiguration. Conversely, zero create events over an extended period in an active environment might indicate issues with deployment pipelines or automation failures.  \\n**Impact:**  \\n- High values: Could indicate potential security breaches, unauthorized secret provisioning, or rapid environment changes requiring immediate investigation.  \\n- Low values: May suggest stalled deployments or automation problems, potentially delaying application updates or secret rotations.  \\n**Example usage:**  \\nIn a dashboard, plot the count of Secrets Manager Create* events over time to visualize spikes. An alert rule could be:  \\n`WHEN count(secretsmanager.amazonaws.com Create* events) > 5 within 10 minutes THEN trigger alert \\\"Unusual Secrets Creation Activity\\\"`  \\nThis enables proactive detection of abnormal secret creation activity, helping maintain security and operational stability.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": false,
                        "score": 0.3158452305921696,
                        "reason": "The Retrieval Context does not include any information about GuardDuty events, which are the focus of the Input question regarding spikes in high-severity threats. Instead, it provides detailed descriptions of other AWS event types (Detective, KMS Decrypt, S3 bucket creation, Secrets Manager) without addressing GuardDuty. This results in poor alignment and insufficient coverage to answer the question. While the context is clear and detailed for the included event types, it lacks relevance and utility for the specific monitoring question asked.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Compare the Input (monitoring question) with the Retrieval Context (metric description) to assess if the description clearly addresses what the question is asking.\",\n    \"Evaluate the clarity of the Retrieval Context by checking if it is understandable and concise in relation to the terminology and concepts presented in the Input.\",\n    \"Check the coverage within the Retrieval Context to ensure it explains what is measured, units, context, and implications that are relevant to the Input question.\",\n    \"Determine the utility by verifying if the Retrieval Context provides enough information to effectively answer the Input question, ensuring alignment between both.\"\n] \n \nRubric:\nNone \n \nScore: 0.3158452305921696"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Compare the Input (monitoring question) with the Retrieval Context (metric description) to assess if the description clearly addresses what the question is asking.",
                            "Evaluate the clarity of the Retrieval Context by checking if it is understandable and concise in relation to the terminology and concepts presented in the Input.",
                            "Check the coverage within the Retrieval Context to ensure it explains what is measured, units, context, and implications that are relevant to the Input question.",
                            "Determine the utility by verifying if the Retrieval Context provides enough information to effectively answer the Input question, ensuring alignment between both."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"eks.amazonaws.com\\\", \\\"EventName\\\": \\\"Describe*\\\"}\", \"hyperparameters\": null, \"input\": \"Does the number of EKS \\\"Describe\\\" API operations exceed 100 requests within a short period?\", \"retrieval_context\": [\" - EKS List* events in CloudTrail capture API calls that enumerate EKS resources such as clusters, node groups, add-ons, and other related components. These operations are primarily read-only and used for infrastructure discovery, capacity planning, and operational visibility. Monitoring the frequency of List* calls helps detect unusual activity patterns: a sudden spike may indicate automated scanning, reconnaissance, or potential misuse, while an abnormally low rate could suggest monitoring gaps or service disruptions. A practical alert threshold might be set at a rate exceeding the baseline average by 3x within a 5-minute window. For example, a dashboard widget could track the count of eks.amazonaws.com List* events per minute, with an alert rule triggering when this count surpasses the defined threshold, enabling timely investigation of unexpected enumeration activity.\", \" - Operations that retrieve detailed information about cloud resources across all services. This includes inspecting configurations, discovering resources, and providing operational visibility. It measures the number of API calls made to describe or list resource details. The unit of measurement is the count of these describe or list requests.\", \" - This pattern captures AWS KMS Decrypt API calls recorded in CloudTrail, indicating when encrypted data is accessed and decrypted using KMS keys. It helps SREs monitor data access events for security auditing and anomaly detection. A sudden spike in Decrypt events may signal unusual or unauthorized data access, while consistently low or expected volumes suggest normal operation. As a threshold, alerting on a sustained increase exceeding 3 standard deviations above the historical average or a sudden burst of Decrypt calls within a short time window (e.g., 5 minutes) is recommended. For example, an alert rule could trigger when the count of Decrypt events exceeds 100 in 5 minutes, indicating potential data exfiltration or misuse. In dashboards, tracking the rate of Decrypt events over time alongside user identities and key IDs can help quickly identify suspicious patterns or compromised credentials.\", \" - This pattern captures all Amazon EKS \\\"Describe\\\" API operations logged in CloudTrail, which occur when cluster metadata, node group configurations, or add-on details are queried. It helps SREs monitor how often EKS cluster information is accessed, providing visibility into potential reconnaissance or troubleshooting activities. A sudden spike in Describe calls\\u2014such as exceeding 100 requests within 5 minutes\\u2014may indicate unusual or automated querying that could precede configuration changes or security incidents, warranting an alert. Conversely, consistently low or zero Describe activity might suggest lack of monitoring or insufficient operational visibility. For example, an alert rule could trigger when Describe API calls surpass 100 in a 5-minute window, and a dashboard widget might display a time series graph of Describe call counts to track trends and detect anomalies in cluster information access patterns.\", \" - This pattern captures all creation events initiated through the Amazon EKS service, such as the creation of EKS clusters, node groups, and add-on components, as recorded in CloudTrail. It enables SREs to monitor when new Kubernetes infrastructure is provisioned, which can impact cluster capacity, security posture, and operational costs.\\n\\n**Purpose:**  \\nTo detect and track the provisioning of new EKS resources, helping teams respond promptly to unexpected or unauthorized cluster creations that may indicate misconfigurations or security risks.\\n\\n**Alert Threshold Guidance:**  \\nTrigger an alert if the number of EKS creation events exceeds a defined baseline within a short time window (e.g., more than 2 cluster or node group creations within 1 hour), as this may signal automated or unintended deployments. Conversely, an unusually low number of creation events over a longer period could indicate deployment pipeline issues or stalled infrastructure scaling.\\n\\n**Impact of Values:**  \\n- **High frequency:** May lead to resource sprawl, increased costs, or potential security vulnerabilities if clusters are created without proper governance.  \\n- **Low frequency:** Could reflect deployment failures or delays, impacting application availability or scalability.\\n\\n**Example Usage:**  \\nIn a monitoring dashboard, display a time series graph of EKS creation events filtered by this pattern to visualize provisioning trends. An alert rule might be:  \\n`WHEN count(events matching {\\\"EventSource\\\": \\\"eks.amazonaws.com\\\", \\\"EventName\\\": \\\"Create*\\\"}) > 2 within 1 hour THEN trigger alert \\\"Unusual EKS resource creation activity detected\\\"`  \\nThis helps SREs quickly identify and investigate abnormal cluster provisioning activities.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": true,
                        "score": 0.8962673115734721,
                        "reason": "The description clearly addresses the monitoring question by focusing on EKS \"Describe\" API operations and their frequency, specifically mentioning the threshold of exceeding 100 requests within a short period. It is clear, concise, and explains what is measured (count of Describe calls), the context (EKS cluster metadata queries), and the implications (potential reconnaissance or security incidents). The description also provides practical alerting guidance and dashboard usage, which enhances its utility for answering the monitoring question. The only minor shortcoming is a slight lack of explicit unit definition (e.g., per 5 minutes) in the description itself, though it is implied.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Compare the input metric description and retrieval context to ensure the description clearly addresses the monitoring question provided.\",\n    \"Evaluate clarity by checking if the description is understandable and concise within the retrieval context and how it relates to the input question.\",\n    \"Assess coverage by confirming the description explains what is measured, including units, context, and implications relevant to the input and retrieval scenario.\",\n    \"Determine utility by verifying if the description sufficiently helps a user answer the monitoring question based on the combined information from input and retrieval context.\"\n] \n \nRubric:\nNone \n \nScore: 0.8962673115734721"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Compare the input metric description and retrieval context to ensure the description clearly addresses the monitoring question provided.",
                            "Evaluate clarity by checking if the description is understandable and concise within the retrieval context and how it relates to the input question.",
                            "Assess coverage by confirming the description explains what is measured, including units, context, and implications relevant to the input and retrieval scenario.",
                            "Determine utility by verifying if the description sufficiently helps a user answer the monitoring question based on the combined information from input and retrieval context."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"eks.amazonaws.com\\\", \\\"EventName\\\": \\\"List*\\\"}\", \"hyperparameters\": null, \"input\": \"Does the rate of EKS List* events exceed three times the baseline average, indicating potential automated scanning or misuse?\", \"retrieval_context\": [\" - EKS List* events in CloudTrail capture API calls that enumerate EKS resources such as clusters, node groups, add-ons, and other related components. These operations are primarily read-only and used for infrastructure discovery, capacity planning, and operational visibility. Monitoring the frequency of List* calls helps detect unusual activity patterns: a sudden spike may indicate automated scanning, reconnaissance, or potential misuse, while an abnormally low rate could suggest monitoring gaps or service disruptions. A practical alert threshold might be set at a rate exceeding the baseline average by 3x within a 5-minute window. For example, a dashboard widget could track the count of eks.amazonaws.com List* events per minute, with an alert rule triggering when this count surpasses the defined threshold, enabling timely investigation of unexpected enumeration activity.\", \" - This pattern captures AWS KMS Decrypt API calls recorded in CloudTrail, indicating when encrypted data is accessed and decrypted using KMS keys. It helps SREs monitor data access events for security auditing and anomaly detection. A sudden spike in Decrypt events may signal unusual or unauthorized data access, while consistently low or expected volumes suggest normal operation. As a threshold, alerting on a sustained increase exceeding 3 standard deviations above the historical average or a sudden burst of Decrypt calls within a short time window (e.g., 5 minutes) is recommended. For example, an alert rule could trigger when the count of Decrypt events exceeds 100 in 5 minutes, indicating potential data exfiltration or misuse. In dashboards, tracking the rate of Decrypt events over time alongside user identities and key IDs can help quickly identify suspicious patterns or compromised credentials.\", \" - This pattern captures AWS KMS encryption API calls (e.g., Encrypt, EncryptData) recorded in CloudTrail, indicating when data is being encrypted using customer-managed or AWS-managed KMS keys. It helps SREs monitor cryptographic operations to ensure data protection policies are enforced and to detect unusual encryption activity that could signal misuse or security incidents.\\n\\n**Purpose:** Track the frequency and context of encryption operations to verify normal application behavior and compliance with data security standards.\\n\\n**Alert Threshold:** Trigger an alert if the number of Encrypt* events exceeds a baseline threshold (e.g., a sudden spike beyond 3 standard deviations from the average hourly rate) or if encryption requests originate from unexpected principals or regions.\\n\\n**Impact of Values:**  \\n- **High volume:** May indicate increased data processing, potential automated encryption loops, or unauthorized bulk encryption attempts, which could impact performance or signal a security breach.  \\n- **Low or zero volume:** Could suggest application issues, disabled encryption, or misconfigured services failing to encrypt data as required, risking data exposure.\\n\\n**Example Alert Rule:**  \\nAlert when Encrypt* events exceed 500 per hour or when encryption requests come from an unrecognized IAM role, triggering an investigation into possible misuse or operational anomalies.\\n\\n**Dashboard Use:**  \\nVisualize Encrypt* event counts over time alongside related Decrypt* events and key usage metrics to correlate encryption activity with application workloads and detect deviations from normal patterns.\", \" - This pattern captures all Amazon EKS \\\"Describe\\\" API operations logged in CloudTrail, which occur when cluster metadata, node group configurations, or add-on details are queried. It helps SREs monitor how often EKS cluster information is accessed, providing visibility into potential reconnaissance or troubleshooting activities. A sudden spike in Describe calls\\u2014such as exceeding 100 requests within 5 minutes\\u2014may indicate unusual or automated querying that could precede configuration changes or security incidents, warranting an alert. Conversely, consistently low or zero Describe activity might suggest lack of monitoring or insufficient operational visibility. For example, an alert rule could trigger when Describe API calls surpass 100 in a 5-minute window, and a dashboard widget might display a time series graph of Describe call counts to track trends and detect anomalies in cluster information access patterns.\", \" - This pattern captures all update-related events from Amazon EKS recorded in CloudTrail, such as cluster version upgrades, managed node group modifications, and add-on updates. Its purpose is to monitor changes that can affect cluster stability, security, or performance. An SRE should set alert thresholds based on the frequency and timing of these update events\\u2014for example, triggering an alert if more than 3 update events occur within a 1-hour window, which may indicate unexpected or automated changes that require investigation. High volumes of update events in a short period could signal potential configuration drift, deployment issues, or unauthorized modifications, increasing risk to cluster availability and security. Conversely, low or no update events over extended periods may suggest stagnation in maintenance or missed critical updates. An example alert rule could be: \\u201cAlert if count of events matching {EventSource: 'eks.amazonaws.com', EventName: 'Update*'} exceeds 3 within 60 minutes.\\u201d In a dashboard, this pattern can be visualized as a time series graph showing update event counts per hour, helping SREs quickly identify unusual spikes or trends in cluster modifications.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": true,
                        "score": 0.9,
                        "reason": "The description directly addresses the monitoring question by explaining what EKS List* events are, their purpose, and how monitoring their frequency can detect automated scanning or misuse. It clearly states the measurement context (CloudTrail API calls), the units (event counts per minute), and provides a practical alert threshold of exceeding three times the baseline average within a 5-minute window, matching the question's criteria. The language is clear and concise, with relevant examples and implications for security monitoring. The only minor shortcoming is the lack of explicit mention of the baseline average calculation method, but overall the description provides sufficient information for confident monitoring and alerting.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Compare the Input (monitoring question) and the Retrieval Context (metric description) to ensure the description directly addresses the question's intent.\",\n    \"Assess the Clarity of the description by verifying if the language is clear, concise, and free of ambiguity in relation to the question.\",\n    \"Evaluate Coverage by checking if the description explains what is measured, the units used, the measurement context, and its implications relevant to the question.\",\n    \"Determine Utility by judging whether the description provides sufficient information for a user to confidently answer the monitoring question based on the description.\"\n] \n \nRubric:\nNone \n \nScore: 0.9"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Compare the Input (monitoring question) and the Retrieval Context (metric description) to ensure the description directly addresses the question's intent.",
                            "Assess the Clarity of the description by verifying if the language is clear, concise, and free of ambiguity in relation to the question.",
                            "Evaluate Coverage by checking if the description explains what is measured, the units used, the measurement context, and its implications relevant to the question.",
                            "Determine Utility by judging whether the description provides sufficient information for a user to confidently answer the monitoring question based on the description."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"eks.amazonaws.com\\\", \\\"EventName\\\": \\\"Update*\\\"}\", \"hyperparameters\": null, \"input\": \"Do the Update events from Amazon EKS exceed three within a short period, indicating potential configuration drift or deployment issues?\", \"retrieval_context\": [\" - Lambda function \\\"Put*\\\" events in CloudTrail capture changes to function configurations, concurrency settings, event source mappings, and resource provisioning. These events indicate updates or deployments that can affect function behavior and performance. An SRE should monitor the frequency and success of these operations; unusually high rates of \\\"Put*\\\" events may signal automation errors or configuration churn, while absence of expected updates could indicate deployment issues. Alert thresholds might include more than 5 \\\"Put*\\\" events within 5 minutes or failed update attempts exceeding 10% of total \\\"Put*\\\" events. High volumes can lead to inconsistent function states or throttling, impacting availability and latency; low update activity during active development phases may delay critical fixes or optimizations. For example, a dashboard widget can track the count of \\\"Put*\\\" events per hour alongside error rates, and an alert rule could trigger when the number of failed \\\"Put*\\\" events surpasses a set threshold, prompting investigation into deployment or configuration problems.\", \" - This pattern captures all ECS update events recorded in CloudTrail, such as modifications to ECS services, task definitions, and cluster configurations. Its purpose is to monitor changes that could affect the stability, performance, or security of ECS workloads. An SRE should use this pattern to detect unexpected or frequent updates that may indicate configuration drift, deployment issues, or unauthorized changes.\\n\\n**Threshold guidance:**  \\n- Trigger an alert if the number of ECS update events exceeds a baseline threshold (e.g., more than 5 updates within 10 minutes), as this may signal rapid or unintended changes.  \\n- A low or zero count over a long period is typically normal but should be reviewed if updates are expected during deployments.\\n\\n**Impact:**  \\n- High frequency of update events can lead to service instability, deployment failures, or security risks if changes are unplanned or unauthorized.  \\n- Low frequency indicates stable ECS configurations but may also suggest stalled deployments or lack of necessary updates.\\n\\n**Example alert rule:**  \\n\\u201cAlert when the count of CloudTrail events with EventSource = 'ecs.amazonaws.com' and EventName starting with 'Update' exceeds 5 within a 10-minute window.\\u201d  \\n\\n**Example dashboard widget:**  \\nA time-series graph showing the count of ECS update events per 5-minute interval, annotated with deployment windows to correlate updates with expected changes.\", \" - This pattern captures all creation events initiated through the Amazon EKS service, such as the creation of EKS clusters, node groups, and add-on components, as recorded in CloudTrail. It enables SREs to monitor when new Kubernetes infrastructure is provisioned, which can impact cluster capacity, security posture, and operational costs.\\n\\n**Purpose:**  \\nTo detect and track the provisioning of new EKS resources, helping teams respond promptly to unexpected or unauthorized cluster creations that may indicate misconfigurations or security risks.\\n\\n**Alert Threshold Guidance:**  \\nTrigger an alert if the number of EKS creation events exceeds a defined baseline within a short time window (e.g., more than 2 cluster or node group creations within 1 hour), as this may signal automated or unintended deployments. Conversely, an unusually low number of creation events over a longer period could indicate deployment pipeline issues or stalled infrastructure scaling.\\n\\n**Impact of Values:**  \\n- **High frequency:** May lead to resource sprawl, increased costs, or potential security vulnerabilities if clusters are created without proper governance.  \\n- **Low frequency:** Could reflect deployment failures or delays, impacting application availability or scalability.\\n\\n**Example Usage:**  \\nIn a monitoring dashboard, display a time series graph of EKS creation events filtered by this pattern to visualize provisioning trends. An alert rule might be:  \\n`WHEN count(events matching {\\\"EventSource\\\": \\\"eks.amazonaws.com\\\", \\\"EventName\\\": \\\"Create*\\\"}) > 2 within 1 hour THEN trigger alert \\\"Unusual EKS resource creation activity detected\\\"`  \\nThis helps SREs quickly identify and investigate abnormal cluster provisioning activities.\", \" - This pattern captures all modification events related to Elastic Load Balancing (ELB) resources in AWS, such as changes to load balancer configurations, target groups, and listeners. In CloudTrail, these events indicate when an ELB\\u2019s setup is altered, which can affect traffic routing, availability, and security posture.\\n\\n**Purpose:**  \\nTo monitor and audit any configuration changes to ELB components that could impact application availability or security.\\n\\n**Alert Threshold:**  \\nTrigger an alert if the number of ELB modification events exceeds a defined threshold within a short time window (e.g., more than 3 Modify* events within 10 minutes), as this may indicate unintended or unauthorized changes.\\n\\n**Impact of Values:**  \\n- **High frequency of Modify* events:** Could signal potential misconfigurations, automated deployment issues, or malicious activity altering load balancer behavior, risking downtime or security breaches.  \\n- **Low or no Modify* events:** Typically expected during stable operation; absence of changes suggests configuration stability.\\n\\n**Example Usage:**  \\nIn a monitoring dashboard or alert rule, track the count of **{\\\"EventSource\\\": \\\"elasticloadbalancing.amazonaws.com\\\", \\\"EventName\\\": \\\"Modify*\\\"}** events over rolling 10-minute intervals. Configure alerts to notify the SRE team when this count spikes above the threshold, enabling prompt investigation and rollback if necessary.\", \" - This pattern captures all update-related events from Amazon EKS recorded in CloudTrail, such as cluster version upgrades, managed node group modifications, and add-on updates. Its purpose is to monitor changes that can affect cluster stability, security, or performance. An SRE should set alert thresholds based on the frequency and timing of these update events\\u2014for example, triggering an alert if more than 3 update events occur within a 1-hour window, which may indicate unexpected or automated changes that require investigation. High volumes of update events in a short period could signal potential configuration drift, deployment issues, or unauthorized modifications, increasing risk to cluster availability and security. Conversely, low or no update events over extended periods may suggest stagnation in maintenance or missed critical updates. An example alert rule could be: \\u201cAlert if count of events matching {EventSource: 'eks.amazonaws.com', EventName: 'Update*'} exceeds 3 within 60 minutes.\\u201d In a dashboard, this pattern can be visualized as a time series graph showing update event counts per hour, helping SREs quickly identify unusual spikes or trends in cluster modifications.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": true,
                        "score": 0.9024475176438207,
                        "reason": "The description clearly and concisely addresses the monitoring question by focusing on Amazon EKS update events, specifying what is measured (update-related events in CloudTrail), relevant units (e.g., more than 3 events within 1 hour), and the context of potential configuration drift or deployment issues. It provides threshold guidance, impact implications, and example alert rules directly linked to the question's intent, supporting effective monitoring and investigation. Minor improvements could include explicitly defining 'short period' to avoid ambiguity, but overall the coverage and utility strongly align with the input question.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Compare the Input (monitoring question) and Retrieval Context (metric description) to verify if the description clearly and concisely addresses the specific question asked.\",\n    \"Evaluate the description's coverage to ensure it includes details on what is measured, units, relevant context, and potential implications, all of which should be pertinent to the input question.\",\n    \"Assess the utility by determining whether the description provides sufficient information to directly support answering the monitoring question, linking the measurement details to the question\u2019s intent.\",\n    \"If any aspect of clarity, coverage, or utility is lacking in relation to the input question, identify concrete improvements targeting how the description better aligns with and supports the retrieval context for the given input.\"\n] \n \nRubric:\nNone \n \nScore: 0.9024475176438207"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Compare the Input (monitoring question) and Retrieval Context (metric description) to verify if the description clearly and concisely addresses the specific question asked.",
                            "Evaluate the description's coverage to ensure it includes details on what is measured, units, relevant context, and potential implications, all of which should be pertinent to the input question.",
                            "Assess the utility by determining whether the description provides sufficient information to directly support answering the monitoring question, linking the measurement details to the question\u2019s intent.",
                            "If any aspect of clarity, coverage, or utility is lacking in relation to the input question, identify concrete improvements targeting how the description better aligns with and supports the retrieval context for the given input."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"config.amazonaws.com\\\", \\\"EventName\\\": \\\"*\\\"}\", \"hyperparameters\": null, \"input\": \"Are there any configuration changes or compliance rule violations that could be causing unexpected behavior?\", \"retrieval_context\": [\" - Lambda function \\\"Put*\\\" events in CloudTrail capture changes to function configurations, concurrency settings, event source mappings, and resource provisioning. These events indicate updates or deployments that can affect function behavior and performance. An SRE should monitor the frequency and success of these operations; unusually high rates of \\\"Put*\\\" events may signal automation errors or configuration churn, while absence of expected updates could indicate deployment issues. Alert thresholds might include more than 5 \\\"Put*\\\" events within 5 minutes or failed update attempts exceeding 10% of total \\\"Put*\\\" events. High volumes can lead to inconsistent function states or throttling, impacting availability and latency; low update activity during active development phases may delay critical fixes or optimizations. For example, a dashboard widget can track the count of \\\"Put*\\\" events per hour alongside error rates, and an alert rule could trigger when the number of failed \\\"Put*\\\" events surpasses a set threshold, prompting investigation into deployment or configuration problems.\", \" - This pattern captures SNS unsubscription events recorded in CloudTrail, indicating when endpoints or subscribers are removed from SNS topics. For an SRE, monitoring these events helps track changes in notification delivery and detect potential disruptions or configuration changes.\\n\\n**Purpose:**  \\n- Identify when subscribers unsubscribe from SNS topics, which may reflect endpoint decommissioning, application changes, or user-initiated opt-outs.  \\n- Detect unusual spikes that could indicate mass unsubscriptions due to misconfigurations, security incidents, or service issues.\\n\\n**Alert Threshold:**  \\n- Trigger an alert if the number of Unsubscribe events exceeds a baseline threshold (e.g., more than 5 unsubscriptions within 5 minutes) or shows a sudden increase compared to historical averages. Thresholds should be tuned based on normal subscription churn rates.\\n\\n**Impact:**  \\n- **High values:** May signal widespread endpoint removals causing notification delivery failures, potential service degradation, or security concerns (e.g., unauthorized unsubscriptions). Immediate investigation is warranted.  \\n- **Low or zero values:** Typically expected during stable operations; a sudden drop to zero after a period of regular unsubscriptions might indicate logging issues or CloudTrail misconfigurations.\\n\\n**Example Usage:**  \\n- **Dashboard:** Display a time series graph of Unsubscribe event counts per minute to visualize trends and detect anomalies.  \\n- **Alert Rule (pseudo-code):**  \\n  ```\\n  WHEN count(Events where EventSource=\\\"sns.amazonaws.com\\\" AND EventName LIKE \\\"Unsubscribe%\\\") \\n  OVER last 5 minutes > 5 \\n  THEN trigger alert \\\"High SNS Unsubscription Rate\\\"\\n  ```\", \" - This pattern captures all ECS update events recorded in CloudTrail, such as modifications to ECS services, task definitions, and cluster configurations. Its purpose is to monitor changes that could affect the stability, performance, or security of ECS workloads. An SRE should use this pattern to detect unexpected or frequent updates that may indicate configuration drift, deployment issues, or unauthorized changes.\\n\\n**Threshold guidance:**  \\n- Trigger an alert if the number of ECS update events exceeds a baseline threshold (e.g., more than 5 updates within 10 minutes), as this may signal rapid or unintended changes.  \\n- A low or zero count over a long period is typically normal but should be reviewed if updates are expected during deployments.\\n\\n**Impact:**  \\n- High frequency of update events can lead to service instability, deployment failures, or security risks if changes are unplanned or unauthorized.  \\n- Low frequency indicates stable ECS configurations but may also suggest stalled deployments or lack of necessary updates.\\n\\n**Example alert rule:**  \\n\\u201cAlert when the count of CloudTrail events with EventSource = 'ecs.amazonaws.com' and EventName starting with 'Update' exceeds 5 within a 10-minute window.\\u201d  \\n\\n**Example dashboard widget:**  \\nA time-series graph showing the count of ECS update events per 5-minute interval, annotated with deployment windows to correlate updates with expected changes.\", \" - This pattern captures all modification events related to EC2 resources in AWS CloudTrail, triggered by any API calls starting with \\\"Modify\\\" (e.g., ModifyInstanceAttribute, ModifyNetworkInterfaceAttribute). Its purpose is to monitor changes to critical EC2 configurations such as instance attributes, security group rules, and network settings, which can directly impact system security, availability, and performance.\\n\\n**Threshold guidance:**  \\n- Alert when the number of Modify* events exceeds a baseline threshold (e.g., more than 5 modifications within 10 minutes), indicating unusual or potentially unauthorized changes.  \\n- A sudden spike in modification events may signal misconfigurations, automation errors, or security incidents like privilege escalation or lateral movement.\\n\\n**Impact of values:**  \\n- **High frequency:** Could indicate active troubleshooting, automated scaling/configuration changes, or suspicious activity requiring immediate investigation.  \\n- **Low or zero frequency:** Normal steady state; no unexpected modifications detected.\\n\\n**Example alert rule:**  \\nTrigger an alert if the count of events matching {\\\"EventSource\\\": \\\"ec2.amazonaws.com\\\", \\\"EventName\\\": \\\"Modify*\\\"} exceeds 5 within a rolling 10-minute window.\\n\\n**Example dashboard widget:**  \\nA time-series graph showing the count of EC2 Modify* events per 5-minute interval, overlaid with a threshold line at 5 events, enabling quick identification of abnormal modification activity.\", \" - This pattern captures all modification events related to Elastic Load Balancing (ELB) resources in AWS, such as changes to load balancer configurations, target groups, and listeners. In CloudTrail, these events indicate when an ELB\\u2019s setup is altered, which can affect traffic routing, availability, and security posture.\\n\\n**Purpose:**  \\nTo monitor and audit any configuration changes to ELB components that could impact application availability or security.\\n\\n**Alert Threshold:**  \\nTrigger an alert if the number of ELB modification events exceeds a defined threshold within a short time window (e.g., more than 3 Modify* events within 10 minutes), as this may indicate unintended or unauthorized changes.\\n\\n**Impact of Values:**  \\n- **High frequency of Modify* events:** Could signal potential misconfigurations, automated deployment issues, or malicious activity altering load balancer behavior, risking downtime or security breaches.  \\n- **Low or no Modify* events:** Typically expected during stable operation; absence of changes suggests configuration stability.\\n\\n**Example Usage:**  \\nIn a monitoring dashboard or alert rule, track the count of **{\\\"EventSource\\\": \\\"elasticloadbalancing.amazonaws.com\\\", \\\"EventName\\\": \\\"Modify*\\\"}** events over rolling 10-minute intervals. Configure alerts to notify the SRE team when this count spikes above the threshold, enabling prompt investigation and rollback if necessary.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": false,
                        "score": 0.356863896678097,
                        "reason": "The input question broadly asks about configuration changes or compliance rule violations causing unexpected behavior, but the retrieval context provides detailed monitoring patterns for specific AWS service events without directly addressing compliance violations or explicitly linking configuration changes to unexpected behavior. The input lacks clarity and coverage as it does not specify what is measured, units, or implications, making it less useful for answering the detailed monitoring questions in the context. Therefore, the response has minimal alignment with the evaluation steps.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Compare the Input (metric description) and Retrieval Context (monitoring question) to ensure the description specifically addresses the user\u2019s question.\",\n    \"Evaluate Clarity by checking if the Input is concise and easily understandable in the context of the Retrieval Context.\",\n    \"Assess Coverage by verifying that the Input explains what is measured, units, context, and implications relevant to the Retrieval Context.\",\n    \"Judge Utility by determining if the Input helps a user effectively answer the Retrieval Context\u2019s question, providing actionable information.\"\n] \n \nRubric:\nNone \n \nScore: 0.356863896678097"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Compare the Input (metric description) and Retrieval Context (monitoring question) to ensure the description specifically addresses the user\u2019s question.",
                            "Evaluate Clarity by checking if the Input is concise and easily understandable in the context of the Retrieval Context.",
                            "Assess Coverage by verifying that the Input explains what is measured, units, context, and implications relevant to the Retrieval Context.",
                            "Judge Utility by determining if the Input helps a user effectively answer the Retrieval Context\u2019s question, providing actionable information."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"ce.amazonaws.com\\\", \\\"EventName\\\": \\\"*\\\"}\", \"hyperparameters\": null, \"input\": \"Are there any spikes in UnHealthyHostCount that correlate with increases in CostExceededEvents?\", \"retrieval_context\": [\" - **{\\\"EventName\\\": \\\"Start*\\\"}** events in CloudTrail indicate the initiation of resource start operations across various AWS services, such as starting EC2 instances, RDS databases, or other managed resources. These events help SREs track when resources transition from a stopped or inactive state to an active state, which is critical for service availability, cost management, and operational recovery.\\n\\n**Purpose:**  \\nTo monitor and audit the activation of cloud resources, ensuring that start operations align with expected usage patterns and do not indicate unauthorized or unexpected activity.\\n\\n**Alert Thresholds:**  \\n- Trigger an alert if the number of **Start*** events exceeds a predefined threshold within a short time window (e.g., more than 10 start operations within 5 minutes), which may indicate an automated scaling event, a potential misconfiguration, or a security incident.  \\n- Conversely, alert if expected start operations do not occur during scheduled maintenance windows, indicating possible failures in recovery or deployment processes.\\n\\n**Impact of Values:**  \\n- **High volume of Start* events:** Could lead to increased costs due to resource activation, potential service disruptions if resources are started unexpectedly, or indicate automated scaling or recovery actions.  \\n- **Low or zero Start* events during expected periods:** May signal failed recovery attempts, stalled deployments, or issues in operational workflows, potentially impacting service availability.\\n\\n**Example Usage:**  \\nIn a CloudWatch dashboard, plot the count of **Start*** events over time to visualize spikes or drops. An alert rule can be configured as:  \\n```\\nIF count(Start* events) > 10 within 5 minutes THEN trigger alert \\\"Unusual spike in resource start operations\\\"\\n```\\nThis enables proactive investigation into unexpected resource activations or failures to start critical services.\", \" - Redshift cluster creation events in CloudTrail capture all API calls initiating the provisioning of new Redshift clusters (e.g., CreateCluster). These events indicate when new data warehouse resources are being deployed or configured, impacting capacity and cost.  \\n**Purpose:** Enables SREs to monitor and audit cluster provisioning activities for operational control and security compliance.  \\n**Alert Threshold:** Trigger alerts on an unusually high number of cluster creation events within a short time window (e.g., >3 creates in 1 hour), which may indicate automation errors, misconfigurations, or unauthorized resource provisioning.  \\n**Impact:**  \\n- **High values:** May lead to resource sprawl, increased costs, and potential performance degradation due to over-provisioning. Could also signal security risks if unexpected clusters are created.  \\n- **Low or zero values:** Normal in stable environments; no new clusters being created means stable infrastructure.  \\n**Example Alert Rule:**  \\n\\u201cAlert if count of events with EventSource='redshift.amazonaws.com' and EventName starting with 'Create' exceeds 3 within 60 minutes.\\u201d  \\n**Dashboard Use:** Visualize the frequency of Redshift cluster creation events over time to detect spikes or anomalies, correlating with deployment activities or security incidents.\", \" - S3 bucket creation events captured by CloudTrail under **{\\\"EventSource\\\": \\\"s3.amazonaws.com\\\", \\\"EventName\\\": \\\"Create*\\\"}** indicate when new buckets or related resources (e.g., bucket policies, access points) are provisioned. These events help SREs monitor infrastructure changes that affect data storage, security posture, and compliance.\\n\\n**Purpose:**  \\nTrack and audit the creation of S3 buckets and associated configurations to ensure proper governance, prevent unauthorized resource sprawl, and maintain compliance with organizational policies.\\n\\n**Alert Threshold:**  \\nTrigger an alert if the number of S3 bucket creation events exceeds a defined threshold within a short time window (e.g., more than 5 bucket creations within 10 minutes), which may indicate automated provisioning errors, misconfigurations, or potential security incidents such as unauthorized resource creation.\\n\\n**Impact of Values:**  \\n- **High frequency:** May signal abnormal activity, such as a compromised credential or runaway automation scripts creating excessive buckets, leading to increased costs, security risks, or compliance violations.  \\n- **Low or zero frequency:** Normal in stable environments; however, sudden spikes should be investigated promptly.\\n\\n**Example Alert Rule:**  \\n\\u201cAlert when count of events with EventSource = 's3.amazonaws.com' and EventName starting with 'Create' exceeds 5 within 10 minutes.\\u201d\\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of S3 Create* events over time, with thresholds marked to highlight unusual spikes, enabling quick identification of abnormal bucket creation activity.\", \" - This pattern captures all CloudFront distribution creation events recorded in CloudTrail, identified by event names starting with \\\"Create\\\" from the CloudFront service. Its purpose is to monitor when new CloudFront distributions are provisioned, including their initial configuration details. Tracking these events helps SREs detect unexpected or unauthorized distribution creations that could impact content delivery, security, or cost.\\n\\n**Alert Threshold:**  \\nTrigger an alert if the number of CloudFront distribution creation events exceeds a defined threshold within a short time window (e.g., more than 3 creations within 1 hour), as this may indicate automation errors, misconfigurations, or potential security incidents.\\n\\n**Impact of Values:**  \\n- **High values:** A spike in creation events could signal rapid environment changes, possible misconfigurations, or unauthorized activity, potentially leading to increased costs or service disruptions.  \\n- **Low or zero values:** Normal operation typically involves infrequent distribution creations; zero or low values indicate stable infrastructure without unexpected provisioning.\\n\\n**Example Alert Rule:**  \\n\\\"Alert when count of events matching {EventSource: 'cloudfront.amazonaws.com', EventName: 'Create*'} exceeds 3 within 1 hour.\\\"\\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of CloudFront distribution creation events over time, enabling quick identification of unusual spikes or trends in distribution provisioning activity.\", \" - This pattern captures all Route 53 resource creation events recorded in CloudTrail, such as the creation of hosted zones, DNS record sets, and health checks. Monitoring these events helps SREs detect configuration changes that could impact DNS resolution and application availability. \\n\\n**Purpose:** Track when new Route 53 resources are created to identify potential unauthorized changes or misconfigurations early.\\n\\n**Alert Threshold:** Trigger an alert if the number of creation events exceeds a baseline threshold (e.g., more than 5 creation events within 10 minutes), which may indicate automated misconfigurations, security breaches, or unintended mass changes.\\n\\n**Impact:**  \\n- **High values:** A spike in creation events could lead to DNS inconsistencies, increased attack surface, or service disruptions if malicious or erroneous resources are introduced.  \\n- **Low or zero values:** Normal operation, assuming no planned infrastructure changes.\\n\\n**Example Alert Rule:**  \\nAlert when `count({\\\"EventSource\\\": \\\"route53.amazonaws.com\\\", \\\"EventName\\\": \\\"Create*\\\"})` > 5 within 10 minutes.\\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of Route 53 creation events over time, enabling quick identification of unusual spikes in resource creation activity.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": false,
                        "score": 0.09626731110495138,
                        "reason": "The Retrieval Context does not relate to the Input question about spikes in UnHealthyHostCount and CostExceededEvents; instead, it describes various AWS event creation monitoring unrelated to these metrics. The context lacks clarity and coverage for the specific metrics asked, providing no relevant units, implications, or correlation information, thus offering no utility in answering the question.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Compare the Input (monitoring question) with the Retrieval Context (metric description) to ensure the description directly relates to and supports answering the question.\",\n    \"Evaluate Clarity by checking if the Retrieval Context is understandable and concise, and if the Input is precise enough to match it.\",\n    \"Assess Coverage by verifying that the Retrieval Context explains what is measured, including units, context, and implications relevant to the Input question.\",\n    \"Judge Utility by determining if the Retrieval Context provides sufficient information to confidently answer the Input question, suggesting improvements if it scores below 8.\"\n] \n \nRubric:\nNone \n \nScore: 0.09626731110495138"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Compare the Input (monitoring question) with the Retrieval Context (metric description) to ensure the description directly relates to and supports answering the question.",
                            "Evaluate Clarity by checking if the Retrieval Context is understandable and concise, and if the Input is precise enough to match it.",
                            "Assess Coverage by verifying that the Retrieval Context explains what is measured, including units, context, and implications relevant to the Input question.",
                            "Judge Utility by determining if the Retrieval Context provides sufficient information to confidently answer the Input question, suggesting improvements if it scores below 8."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"apigateway.amazonaws.com\\\", \\\"EventName\\\": \\\"Create*\\\"}\", \"hyperparameters\": null, \"input\": \"Are there spikes in Create* events indicating an abnormal rate of API Gateway resource creations?\", \"retrieval_context\": [\" - CloudFormation stack creation events (**EventSource: cloudformation.amazonaws.com**, **EventName: Create\\\\*** ) represent API calls initiating the provisioning of AWS infrastructure and resources via CloudFormation templates. These events in CloudTrail help SREs monitor the start of environment setups and infrastructure deployments as part of Infrastructure as Code workflows.\\n\\n**Purpose:** Track and audit when new CloudFormation stacks or stack components are being created, enabling visibility into changes in infrastructure state and deployment activities.\\n\\n**Alert Thresholds:**  \\n- Trigger an alert if the number of Create* events exceeds a baseline threshold within a short time window (e.g., >10 stack creation attempts in 5 minutes), which may indicate automated deployment loops, misconfigurations, or potential security incidents.  \\n- Alert if Create* events spike unexpectedly outside of scheduled deployment windows or change management periods.\\n\\n**Impact of Values:**  \\n- **High volume:** May signal rapid infrastructure changes that could lead to instability, resource contention, or deployment failures. It could also indicate unauthorized or accidental mass provisioning.  \\n- **Low or zero volume:** Normal during steady-state operations; however, a sudden drop during expected deployment windows might indicate pipeline failures or blocked deployments.\\n\\n**Example Usage:**  \\n- **Dashboard:** Visualize the count of CloudFormation Create* events over time, segmented by stack name or user identity, to correlate deployments with system performance or incidents.  \\n- **Alert Rule:**  \\n  ```  \\n  WHEN count(events where EventSource=\\\"cloudformation.amazonaws.com\\\" AND EventName LIKE \\\"Create%\\\") > 10 within 5 minutes  \\n  THEN trigger alert \\\"High rate of CloudFormation stack creation events detected\\\"  \\n  ```  \\nThis enables proactive detection of abnormal infrastructure provisioning activity and supports rapid investigation and response.\", \" - S3 bucket creation events captured by CloudTrail under **{\\\"EventSource\\\": \\\"s3.amazonaws.com\\\", \\\"EventName\\\": \\\"Create*\\\"}** indicate when new buckets or related resources (e.g., bucket policies, access points) are provisioned. These events help SREs monitor infrastructure changes that affect data storage, security posture, and compliance.\\n\\n**Purpose:**  \\nTrack and audit the creation of S3 buckets and associated configurations to ensure proper governance, prevent unauthorized resource sprawl, and maintain compliance with organizational policies.\\n\\n**Alert Threshold:**  \\nTrigger an alert if the number of S3 bucket creation events exceeds a defined threshold within a short time window (e.g., more than 5 bucket creations within 10 minutes), which may indicate automated provisioning errors, misconfigurations, or potential security incidents such as unauthorized resource creation.\\n\\n**Impact of Values:**  \\n- **High frequency:** May signal abnormal activity, such as a compromised credential or runaway automation scripts creating excessive buckets, leading to increased costs, security risks, or compliance violations.  \\n- **Low or zero frequency:** Normal in stable environments; however, sudden spikes should be investigated promptly.\\n\\n**Example Alert Rule:**  \\n\\u201cAlert when count of events with EventSource = 's3.amazonaws.com' and EventName starting with 'Create' exceeds 5 within 10 minutes.\\u201d\\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of S3 Create* events over time, with thresholds marked to highlight unusual spikes, enabling quick identification of abnormal bucket creation activity.\", \" - This pattern captures all CloudFront distribution creation events recorded in CloudTrail, identified by event names starting with \\\"Create\\\" from the CloudFront service. Its purpose is to monitor when new CloudFront distributions are provisioned, including their initial configuration details. Tracking these events helps SREs detect unexpected or unauthorized distribution creations that could impact content delivery, security, or cost.\\n\\n**Alert Threshold:**  \\nTrigger an alert if the number of CloudFront distribution creation events exceeds a defined threshold within a short time window (e.g., more than 3 creations within 1 hour), as this may indicate automation errors, misconfigurations, or potential security incidents.\\n\\n**Impact of Values:**  \\n- **High values:** A spike in creation events could signal rapid environment changes, possible misconfigurations, or unauthorized activity, potentially leading to increased costs or service disruptions.  \\n- **Low or zero values:** Normal operation typically involves infrequent distribution creations; zero or low values indicate stable infrastructure without unexpected provisioning.\\n\\n**Example Alert Rule:**  \\n\\\"Alert when count of events matching {EventSource: 'cloudfront.amazonaws.com', EventName: 'Create*'} exceeds 3 within 1 hour.\\\"\\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of CloudFront distribution creation events over time, enabling quick identification of unusual spikes or trends in distribution provisioning activity.\", \" - This pattern captures all Route 53 resource creation events recorded in CloudTrail, such as the creation of hosted zones, DNS record sets, and health checks. Monitoring these events helps SREs detect configuration changes that could impact DNS resolution and application availability. \\n\\n**Purpose:** Track when new Route 53 resources are created to identify potential unauthorized changes or misconfigurations early.\\n\\n**Alert Threshold:** Trigger an alert if the number of creation events exceeds a baseline threshold (e.g., more than 5 creation events within 10 minutes), which may indicate automated misconfigurations, security breaches, or unintended mass changes.\\n\\n**Impact:**  \\n- **High values:** A spike in creation events could lead to DNS inconsistencies, increased attack surface, or service disruptions if malicious or erroneous resources are introduced.  \\n- **Low or zero values:** Normal operation, assuming no planned infrastructure changes.\\n\\n**Example Alert Rule:**  \\nAlert when `count({\\\"EventSource\\\": \\\"route53.amazonaws.com\\\", \\\"EventName\\\": \\\"Create*\\\"})` > 5 within 10 minutes.\\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of Route 53 creation events over time, enabling quick identification of unusual spikes in resource creation activity.\", \" - This pattern detects Secrets Manager creation events in CloudTrail, specifically any API calls starting with \\\"Create\\\" (e.g., CreateSecret). It helps SREs monitor when new secrets, secret versions, or related configurations are added, which could indicate deployment changes or potential security risks.  \\n**Alert threshold:** Trigger an alert if the number of create events exceeds a baseline (e.g., more than 5 creates within 10 minutes), as a sudden spike may signal unauthorized secret creation or misconfiguration. Conversely, zero create events over an extended period in an active environment might indicate issues with deployment pipelines or automation failures.  \\n**Impact:**  \\n- High values: Could indicate potential security breaches, unauthorized secret provisioning, or rapid environment changes requiring immediate investigation.  \\n- Low values: May suggest stalled deployments or automation problems, potentially delaying application updates or secret rotations.  \\n**Example usage:**  \\nIn a dashboard, plot the count of Secrets Manager Create* events over time to visualize spikes. An alert rule could be:  \\n`WHEN count(secretsmanager.amazonaws.com Create* events) > 5 within 10 minutes THEN trigger alert \\\"Unusual Secrets Creation Activity\\\"`  \\nThis enables proactive detection of abnormal secret creation activity, helping maintain security and operational stability.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": true,
                        "score": 0.8914900949772248,
                        "reason": "The retrieval context comprehensively addresses the input question by detailing multiple AWS services' Create* event patterns, alert thresholds, impacts, and example usage, enabling detection of abnormal spikes in API Gateway resource creations. It is clear, well-structured, and provides sufficient coverage of what is measured, units (event counts over time), and implications. However, it does not explicitly mention API Gateway events, which slightly limits direct applicability to the input question.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Compare the Input (monitoring question) against the Retrieval Context (metric description) to assess if the description clearly addresses the question's focus.\",\n    \"Evaluate Clarity by verifying that the Retrieval Context is understandable and concise enough for users to relate directly to the Input.\",\n    \"Check Coverage by ensuring the Retrieval Context explains what is measured, including units, relevant context, and potential implications relevant to the Input.\",\n    \"Assess Utility by determining if the Retrieval Context enables a user to answer the Input question effectively based on the information provided.\"\n] \n \nRubric:\nNone \n \nScore: 0.8914900949772248"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Compare the Input (monitoring question) against the Retrieval Context (metric description) to assess if the description clearly addresses the question's focus.",
                            "Evaluate Clarity by verifying that the Retrieval Context is understandable and concise enough for users to relate directly to the Input.",
                            "Check Coverage by ensuring the Retrieval Context explains what is measured, including units, relevant context, and potential implications relevant to the Input.",
                            "Assess Utility by determining if the Retrieval Context enables a user to answer the Input question effectively based on the information provided."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"macie.amazonaws.com\\\", \\\"EventName\\\": \\\"*\\\"}\", \"hyperparameters\": null, \"input\": \"Does the count of Macie findings exceed ten within a given time window, indicating potential data leaks or misconfiguration?\", \"retrieval_context\": [\" - Macie data discovery events in CloudTrail capture detailed records of sensitive data identification and classification activities performed by Amazon Macie. These events help monitor the discovery of Personally Identifiable Information (PII), data loss risks, and compliance with privacy regulations. An SRE can use these events to track when Macie detects sensitive data or policy violations, enabling proactive data governance and security posture management.\\n\\n**Alert Thresholds:**  \\n- Trigger alerts when the number of sensitive data findings exceeds a predefined threshold within a given time window (e.g., > 10 new PII findings in 1 hour).  \\n- Alert on sudden spikes or unusual patterns in data classification events that may indicate data exfiltration or misconfiguration.\\n\\n**Impact of Values:**  \\n- **High values:** A surge in sensitive data findings may indicate increased exposure of PII or potential data leaks, requiring immediate investigation.  \\n- **Low or zero values:** May indicate normal operation or, conversely, that Macie scanning is not running correctly, potentially missing critical data.\\n\\n**Example Usage:**  \\n- **Dashboard:** Visualize the count of Macie findings over time, segmented by severity or data type, to monitor trends and identify anomalies.  \\n- **Alert Rule:**  \\n  ```\\n  WHEN count(maciedata.findings) > 10 WITHIN 1 hour  \\n  THEN trigger alert \\\"High number of sensitive data findings detected by Macie\\\"\\n  ```\", \" - This pattern captures AWS KMS Decrypt API calls recorded in CloudTrail, indicating when encrypted data is accessed and decrypted using KMS keys. It helps SREs monitor data access events for security auditing and anomaly detection. A sudden spike in Decrypt events may signal unusual or unauthorized data access, while consistently low or expected volumes suggest normal operation. As a threshold, alerting on a sustained increase exceeding 3 standard deviations above the historical average or a sudden burst of Decrypt calls within a short time window (e.g., 5 minutes) is recommended. For example, an alert rule could trigger when the count of Decrypt events exceeds 100 in 5 minutes, indicating potential data exfiltration or misuse. In dashboards, tracking the rate of Decrypt events over time alongside user identities and key IDs can help quickly identify suspicious patterns or compromised credentials.\", \" - This pattern captures CloudFront tagging events recorded in CloudTrail, specifically when CloudFront distributions are tagged or untagged. Tagging actions are critical for resource organization, cost allocation, and access management. Monitoring these events helps SREs detect unauthorized or unexpected changes to distribution metadata that could affect billing, security policies, or operational workflows.\\n\\n**Alert Threshold:**  \\nTrigger an alert if the number of CloudFront Tag* events exceeds a baseline threshold within a short time window (e.g., more than 5 tagging operations in 10 minutes), as this may indicate automated misconfigurations, potential security breaches, or bulk updates requiring review.\\n\\n**Impact of Values:**  \\n- **High frequency:** Could signal mass tagging/untagging possibly due to automation errors, policy violations, or malicious activity, potentially leading to misallocated costs or broken access controls.  \\n- **Low or zero frequency:** Normal state; tagging changes are typically infrequent and deliberate.\\n\\n**Example Usage:**  \\nIn a monitoring dashboard, plot the count of CloudFront Tag* events over time to visualize tagging activity spikes. An alert rule might be:  \\n`WHEN count(events where EventSource=\\\"cloudfront.amazonaws.com\\\" AND EventName LIKE \\\"Tag%\\\") > 5 within 10 minutes THEN trigger alert \\\"Unusual CloudFront tagging activity detected\\\"`  \\nThis enables proactive investigation and mitigation of tagging anomalies impacting resource governance.\", \" - This pattern captures all Amazon EKS \\\"Describe\\\" API operations logged in CloudTrail, which occur when cluster metadata, node group configurations, or add-on details are queried. It helps SREs monitor how often EKS cluster information is accessed, providing visibility into potential reconnaissance or troubleshooting activities. A sudden spike in Describe calls\\u2014such as exceeding 100 requests within 5 minutes\\u2014may indicate unusual or automated querying that could precede configuration changes or security incidents, warranting an alert. Conversely, consistently low or zero Describe activity might suggest lack of monitoring or insufficient operational visibility. For example, an alert rule could trigger when Describe API calls surpass 100 in a 5-minute window, and a dashboard widget might display a time series graph of Describe call counts to track trends and detect anomalies in cluster information access patterns.\", \" - This pattern captures all update-related events from Amazon EKS recorded in CloudTrail, such as cluster version upgrades, managed node group modifications, and add-on updates. Its purpose is to monitor changes that can affect cluster stability, security, or performance. An SRE should set alert thresholds based on the frequency and timing of these update events\\u2014for example, triggering an alert if more than 3 update events occur within a 1-hour window, which may indicate unexpected or automated changes that require investigation. High volumes of update events in a short period could signal potential configuration drift, deployment issues, or unauthorized modifications, increasing risk to cluster availability and security. Conversely, low or no update events over extended periods may suggest stagnation in maintenance or missed critical updates. An example alert rule could be: \\u201cAlert if count of events matching {EventSource: 'eks.amazonaws.com', EventName: 'Update*'} exceeds 3 within 60 minutes.\\u201d In a dashboard, this pattern can be visualized as a time series graph showing update event counts per hour, helping SREs quickly identify unusual spikes or trends in cluster modifications.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": true,
                        "score": 0.9,
                        "reason": "The retrieval context directly addresses the monitoring question by explaining Macie data discovery events and how to alert when findings exceed a threshold within a time window, matching the question's focus on counts exceeding ten. The description is clear, concise, and explains key concepts such as what is measured (sensitive data findings), units (count within time windows), and implications (potential data leaks or misconfiguration). It also provides example alert rules and impact of values, enabling confident use of the metric. The only minor shortcoming is a slight complexity in phrasing that could be simplified further for absolute clarity.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Compare the Input (monitoring question) and Retrieval Context (metric description) to ensure the description directly addresses the question\u2019s focus.\",\n    \"Evaluate Clarity by checking if the metric description explains the key concept in simple and concise language without ambiguity.\",\n    \"Assess Coverage by verifying that the description specifies what is measured, its units, relevant context, and the implications of the metric in relation to the question.\",\n    \"Determine Utility by considering whether the description enables a user to confidently answer the monitoring question; if not, identify specific content gaps or unclear elements that reduce usefulness.\"\n] \n \nRubric:\nNone \n \nScore: 0.9"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Compare the Input (monitoring question) and Retrieval Context (metric description) to ensure the description directly addresses the question\u2019s focus.",
                            "Evaluate Clarity by checking if the metric description explains the key concept in simple and concise language without ambiguity.",
                            "Assess Coverage by verifying that the description specifies what is measured, its units, relevant context, and the implications of the metric in relation to the question.",
                            "Determine Utility by considering whether the description enables a user to confidently answer the monitoring question; if not, identify specific content gaps or unclear elements that reduce usefulness."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"apigateway.amazonaws.com\\\", \\\"EventName\\\": \\\"Update*\\\"}\", \"hyperparameters\": null, \"input\": \"Are there any Update events from apigateway.amazonaws.com that indicate a change to the production environment?\", \"retrieval_context\": [\" - API Gateway deletion events captured by CloudTrail indicate when APIs, stages, or related resources are removed. These events are critical for tracking decommissioning activities, ensuring that endpoint removals are intentional and authorized, and preventing accidental service disruptions.  \\n\\n**Purpose:**  \\nMonitor all delete operations initiated via API Gateway (e.g., DeleteRestApi, DeleteStage) to maintain visibility into changes that reduce API surface area or remove critical endpoints.\\n\\n**Alert Threshold:**  \\nTrigger an alert if the number of Delete* events exceeds a predefined baseline within a short time window (e.g., more than 3 deletions within 10 minutes), as this may indicate accidental mass deletions, unauthorized activity, or a misconfigured automation script.\\n\\n**Impact:**  \\n- **High frequency:** Could lead to service outages, broken integrations, or data loss if APIs or stages are removed unexpectedly. Immediate investigation is required.  \\n- **Low or zero frequency:** Normal operation; deletion events are infrequent and typically planned.\\n\\n**Example Usage:**  \\nIn a monitoring dashboard, display a time series graph of Delete* events from apigateway.amazonaws.com. Set an alert rule such as:  \\n`IF count(Delete* events) > 3 within 10 minutes THEN trigger high-severity alert \\\"Potential API Gateway mass deletion detected\\\"`  \\nThis enables rapid response to potentially disruptive changes in the API infrastructure.\", \" - API Gateway update events. API modifications, configuration changes, and deployment updates. API versioning, performance tuning, and security policy updates.\", \" - CodeDeploy events in CloudTrail capture API calls made to the AWS CodeDeploy service (EventSource: \\\"codedeploy.amazonaws.com\\\") across all event names (EventName: \\\"*\\\"). These events provide detailed records of deployment lifecycle actions such as creating, updating, starting, stopping, and deleting deployments, deployment groups, and applications. The data source is the AWS CodeDeploy API, and each event includes metadata like timestamps, user identity, deployment IDs, status changes, and error messages. Metrics derived from these events typically count the number of deployment-related API calls or track deployment status transitions over time (units: count of events or status occurrences). Unusual values\\u2014such as a sudden spike in failed deployment events, unexpected deployment cancellations, or unauthorized API calls\\u2014should trigger alerts as they may indicate deployment issues, configuration errors, or potential security incidents requiring immediate investigation.\", \" - IAM update events capture all modifications made to IAM resources such as users, roles, groups, policies, and credentials. These events indicate changes to permissions, access controls, and security configurations, which are critical for maintaining the principle of least privilege and preventing unauthorized privilege escalation. In CloudTrail, **{\\\"EventSource\\\": \\\"iam.amazonaws.com\\\", \\\"EventName\\\": \\\"Update*\\\"}** helps track who made changes, what was changed, and when, enabling audit and compliance verification.\\n\\n**Alert Threshold:** Trigger an alert when the number of IAM update events exceeds a baseline threshold within a short time window (e.g., more than 5 update events in 10 minutes), or when specific sensitive updates occur, such as policy changes granting administrative privileges or credential rotations outside of scheduled maintenance.\\n\\n**Impact of Values:**  \\n- **High values:** A spike in update events may indicate automated scripts, bulk permission changes, or potential malicious activity like privilege escalation attempts. Immediate investigation is warranted to confirm legitimacy.  \\n- **Low values:** Normal or zero update events typically indicate stable IAM configurations with no recent permission changes, which is expected in steady-state operations.\\n\\n**Example Usage:**  \\nIn a dashboard, display a time series graph of IAM update events filtered by event name pattern \\\"Update*\\\". Set an alert rule to notify the SRE team if the count of these events exceeds 5 within any rolling 10-minute window, or if any update event modifies policies granting \\\"AdministratorAccess\\\". This enables rapid detection of potentially risky permission changes and supports proactive security posture management.\", \" - Lambda function \\\"Put*\\\" events in CloudTrail capture changes to function configurations, concurrency settings, event source mappings, and resource provisioning. These events indicate updates or deployments that can affect function behavior and performance. An SRE should monitor the frequency and success of these operations; unusually high rates of \\\"Put*\\\" events may signal automation errors or configuration churn, while absence of expected updates could indicate deployment issues. Alert thresholds might include more than 5 \\\"Put*\\\" events within 5 minutes or failed update attempts exceeding 10% of total \\\"Put*\\\" events. High volumes can lead to inconsistent function states or throttling, impacting availability and latency; low update activity during active development phases may delay critical fixes or optimizations. For example, a dashboard widget can track the count of \\\"Put*\\\" events per hour alongside error rates, and an alert rule could trigger when the number of failed \\\"Put*\\\" events surpasses a set threshold, prompting investigation into deployment or configuration problems.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": false,
                        "score": 0.3,
                        "reason": "The retrieval context provides detailed descriptions of update and deletion events for various AWS services but does not specifically address Update events from apigateway.amazonaws.com or their relation to changes in the production environment. It lacks clarity and direct coverage of the requested metric, including units, implications, or alert thresholds for API Gateway Update events. Consequently, it offers limited utility for answering the monitoring question about production environment changes via API Gateway Update events.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Compare the Input (monitoring question) and the Retrieval Context (metric description) to assess clarity: ensure the description is understandable and uses language appropriate for the question's scope.\",\n    \"Evaluate coverage by verifying if the Retrieval Context explains what is measured, includes units, provides relevant context, and implications that relate directly to the Input question.\",\n    \"Assess utility by determining if the metric description aids the user in effectively answering the monitoring question, focusing on the relevance between Input and Retrieval Context.\",\n    \"If the description scores below 8, specify improvements aimed at enhancing clarity, coverage, or utility relative to the monitoring question.\"\n] \n \nRubric:\nNone \n \nScore: 0.3"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Compare the Input (monitoring question) and the Retrieval Context (metric description) to assess clarity: ensure the description is understandable and uses language appropriate for the question's scope.",
                            "Evaluate coverage by verifying if the Retrieval Context explains what is measured, includes units, provides relevant context, and implications that relate directly to the Input question.",
                            "Assess utility by determining if the metric description aids the user in effectively answering the monitoring question, focusing on the relevance between Input and Retrieval Context.",
                            "If the description scores below 8, specify improvements aimed at enhancing clarity, coverage, or utility relative to the monitoring question."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"apigateway.amazonaws.com\\\", \\\"EventName\\\": \\\"Delete*\\\"}\", \"hyperparameters\": null, \"input\": \"Does the number of Delete* events exceed three, indicating a potential accidental mass deletion or unauthorized activity?\", \"retrieval_context\": [\" - API Gateway deletion events captured by CloudTrail indicate when APIs, stages, or related resources are removed. These events are critical for tracking decommissioning activities, ensuring that endpoint removals are intentional and authorized, and preventing accidental service disruptions.  \\n\\n**Purpose:**  \\nMonitor all delete operations initiated via API Gateway (e.g., DeleteRestApi, DeleteStage) to maintain visibility into changes that reduce API surface area or remove critical endpoints.\\n\\n**Alert Threshold:**  \\nTrigger an alert if the number of Delete* events exceeds a predefined baseline within a short time window (e.g., more than 3 deletions within 10 minutes), as this may indicate accidental mass deletions, unauthorized activity, or a misconfigured automation script.\\n\\n**Impact:**  \\n- **High frequency:** Could lead to service outages, broken integrations, or data loss if APIs or stages are removed unexpectedly. Immediate investigation is required.  \\n- **Low or zero frequency:** Normal operation; deletion events are infrequent and typically planned.\\n\\n**Example Usage:**  \\nIn a monitoring dashboard, display a time series graph of Delete* events from apigateway.amazonaws.com. Set an alert rule such as:  \\n`IF count(Delete* events) > 3 within 10 minutes THEN trigger high-severity alert \\\"Potential API Gateway mass deletion detected\\\"`  \\nThis enables rapid response to potentially disruptive changes in the API infrastructure.\", \" - IAM deletion events (e.g., DeleteUser, DeleteRole) recorded by CloudTrail indicate removal of IAM identities or permissions. These events are critical for detecting unauthorized or accidental deletions that can disrupt access or signal a security breach. An alert threshold should be set to trigger on any unexpected deletion event or a sudden spike above normal baseline activity (e.g., more than 1 deletion event within 5 minutes), as even a single deletion can have significant impact. High volumes may indicate automated attacks or misconfigurations causing mass access removal, while low or zero values typically indicate normal operation.  \\nExample alert rule: trigger when count of iam.amazonaws.com Delete* events > 1 in 5 minutes.  \\nExample dashboard widget: a time series graph showing Delete* event counts over time, annotated with alert thresholds to quickly identify unusual deletion activity.\", \" - This event pattern captures all CloudTrail events where CloudWatch Logs resources\\u2014such as log groups or log streams\\u2014are deleted (e.g., DeleteLogGroup, DeleteLogStream). Its purpose is to monitor and audit log deletion activities, which can be legitimate cleanup or indicate potential loss of critical log data needed for troubleshooting and compliance.\\n\\n**Alert Threshold:**  \\nTrigger an alert if the number of delete events exceeds a baseline threshold within a defined time window (e.g., more than 3 deletions within 1 hour), or if deletions occur unexpectedly outside of scheduled maintenance windows.\\n\\n**Impact:**  \\n- **High frequency of deletions:** May indicate accidental or malicious removal of logs, risking loss of observability and forensic data. Immediate investigation is recommended.  \\n- **Low or zero deletions:** Normal operation, indicating logs are retained as expected.\\n\\n**Example Alert Rule:**  \\n\\u201cAlert if DeleteLogGroup or DeleteLogStream events from logs.amazonaws.com exceed 3 occurrences in 60 minutes.\\u201d  \\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of Delete* events over time, annotated with alert thresholds and maintenance windows, enabling quick identification of unusual spikes in log deletions.\", \" - This pattern captures ECS deletion events recorded in CloudTrail, specifically any API calls starting with \\\"Delete\\\" from the ECS service (e.g., DeleteCluster, DeleteService, DeleteTaskSet). Its purpose is to monitor when ECS resources are removed, which can signal intentional cleanup or unintended disruptions affecting service availability.\\n\\n**Threshold guidance:**  \\n- Trigger an alert if the number of ECS deletion events exceeds a baseline threshold within a short time window (e.g., more than 3 Delete* events in 5 minutes), as this may indicate accidental mass deletion or a security incident.  \\n- Low or expected deletion rates typically reflect routine maintenance or scaling down of resources and generally have minimal impact.\\n\\n**Impact:**  \\n- High deletion event counts can lead to service downtime, loss of running tasks, or cluster instability, requiring immediate investigation.  \\n- Low or zero deletion events usually indicate stable ECS resource management.\\n\\n**Example alert rule:**  \\n- Alert when `count(events where EventSource=\\\"ecs.amazonaws.com\\\" and EventName starts with \\\"Delete\\\") > 3` within 5 minutes.  \\n- This alert can be visualized on a dashboard showing ECS Delete* event counts over time, helping SREs quickly identify unusual spikes and correlate with service health metrics.\", \" - Tracks all AWS Lambda function deletion events captured in CloudTrail. Monitoring **{\\\"EventSource\\\": \\\"lambda.amazonaws.com\\\", \\\"EventName\\\": \\\"Delete*\\\"}** helps SREs detect when Lambda functions are removed, which is critical for maintaining application stability, ensuring proper resource cleanup, and preventing accidental or unauthorized deletions.  \\n\\n**Alert Threshold:** Trigger an alert if more than 3 Lambda function deletions occur within a 1-hour window, as this may indicate a misconfiguration, automated script error, or potential security breach.  \\n\\n**Impact:**  \\n- **High values:** A spike in deletions can lead to service disruptions, loss of critical functionality, or security incidents if unauthorized deletions occur. Immediate investigation is required.  \\n- **Low or zero values:** Normal operation; infrequent deletions are expected during routine maintenance or deployments.  \\n\\n**Example Alert Rule:**  \\n`WHEN count(events where EventSource=\\\"lambda.amazonaws.com\\\" AND EventName LIKE \\\"Delete%\\\") > 3 WITHIN 1 hour THEN alert \\\"Unusual number of Lambda deletions detected\\\"`  \\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of Lambda deletion events per hour, annotated with alert thresholds, enabling quick identification of abnormal deletion activity.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": true,
                        "score": 0.8977022630759018,
                        "reason": "The retrieval context comprehensively addresses the input question by detailing the significance of Delete* events, alert thresholds (notably exceeding three deletions), and the implications of such events indicating potential accidental or unauthorized mass deletions. It provides clear, concise explanations with practical alert examples and impact descriptions, enabling effective monitoring aligned with the question's intent. Minor deduction is due to the context being split across multiple service-specific descriptions rather than a single unified explanation.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Compare the Input (monitoring question) with the Retrieval Context (metric description) to check if the description clearly addresses the question\u2019s intent.\",\n    \"Evaluate clarity by assessing if the description is concise and easily understandable within the context of the input question.\",\n    \"Assess coverage by verifying whether the description details what is measured, the units used, relevant context, and practical implications directly related to the input question.\",\n    \"Determine utility by judging if the description provides sufficient information for a user to effectively answer the monitoring question based on the input and retrieval context relationship.\"\n] \n \nRubric:\nNone \n \nScore: 0.8977022630759018"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Compare the Input (monitoring question) with the Retrieval Context (metric description) to check if the description clearly addresses the question\u2019s intent.",
                            "Evaluate clarity by assessing if the description is concise and easily understandable within the context of the input question.",
                            "Assess coverage by verifying whether the description details what is measured, the units used, relevant context, and practical implications directly related to the input question.",
                            "Determine utility by judging if the description provides sufficient information for a user to effectively answer the monitoring question based on the input and retrieval context relationship."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"codepipeline.amazonaws.com\\\", \\\"EventName\\\": \\\"*\\\"}\", \"hyperparameters\": null, \"input\": \"Are there any failed or cancelled CodePipeline events indicating a potential issue with CI/CD workflow?\", \"retrieval_context\": [\" - CloudFormation stack creation events (**EventSource: cloudformation.amazonaws.com**, **EventName: Create\\\\*** ) represent API calls initiating the provisioning of AWS infrastructure and resources via CloudFormation templates. These events in CloudTrail help SREs monitor the start of environment setups and infrastructure deployments as part of Infrastructure as Code workflows.\\n\\n**Purpose:** Track and audit when new CloudFormation stacks or stack components are being created, enabling visibility into changes in infrastructure state and deployment activities.\\n\\n**Alert Thresholds:**  \\n- Trigger an alert if the number of Create* events exceeds a baseline threshold within a short time window (e.g., >10 stack creation attempts in 5 minutes), which may indicate automated deployment loops, misconfigurations, or potential security incidents.  \\n- Alert if Create* events spike unexpectedly outside of scheduled deployment windows or change management periods.\\n\\n**Impact of Values:**  \\n- **High volume:** May signal rapid infrastructure changes that could lead to instability, resource contention, or deployment failures. It could also indicate unauthorized or accidental mass provisioning.  \\n- **Low or zero volume:** Normal during steady-state operations; however, a sudden drop during expected deployment windows might indicate pipeline failures or blocked deployments.\\n\\n**Example Usage:**  \\n- **Dashboard:** Visualize the count of CloudFormation Create* events over time, segmented by stack name or user identity, to correlate deployments with system performance or incidents.  \\n- **Alert Rule:**  \\n  ```  \\n  WHEN count(events where EventSource=\\\"cloudformation.amazonaws.com\\\" AND EventName LIKE \\\"Create%\\\") > 10 within 5 minutes  \\n  THEN trigger alert \\\"High rate of CloudFormation stack creation events detected\\\"  \\n  ```  \\nThis enables proactive detection of abnormal infrastructure provisioning activity and supports rapid investigation and response.\", \" - CodeDeploy events in CloudTrail capture API calls made to the AWS CodeDeploy service (EventSource: \\\"codedeploy.amazonaws.com\\\") across all event names (EventName: \\\"*\\\"). These events provide detailed records of deployment lifecycle actions such as creating, updating, starting, stopping, and deleting deployments, deployment groups, and applications. The data source is the AWS CodeDeploy API, and each event includes metadata like timestamps, user identity, deployment IDs, status changes, and error messages. Metrics derived from these events typically count the number of deployment-related API calls or track deployment status transitions over time (units: count of events or status occurrences). Unusual values\\u2014such as a sudden spike in failed deployment events, unexpected deployment cancellations, or unauthorized API calls\\u2014should trigger alerts as they may indicate deployment issues, configuration errors, or potential security incidents requiring immediate investigation.\", \" - S3 bucket creation events captured by CloudTrail under **{\\\"EventSource\\\": \\\"s3.amazonaws.com\\\", \\\"EventName\\\": \\\"Create*\\\"}** indicate when new buckets or related resources (e.g., bucket policies, access points) are provisioned. These events help SREs monitor infrastructure changes that affect data storage, security posture, and compliance.\\n\\n**Purpose:**  \\nTrack and audit the creation of S3 buckets and associated configurations to ensure proper governance, prevent unauthorized resource sprawl, and maintain compliance with organizational policies.\\n\\n**Alert Threshold:**  \\nTrigger an alert if the number of S3 bucket creation events exceeds a defined threshold within a short time window (e.g., more than 5 bucket creations within 10 minutes), which may indicate automated provisioning errors, misconfigurations, or potential security incidents such as unauthorized resource creation.\\n\\n**Impact of Values:**  \\n- **High frequency:** May signal abnormal activity, such as a compromised credential or runaway automation scripts creating excessive buckets, leading to increased costs, security risks, or compliance violations.  \\n- **Low or zero frequency:** Normal in stable environments; however, sudden spikes should be investigated promptly.\\n\\n**Example Alert Rule:**  \\n\\u201cAlert when count of events with EventSource = 's3.amazonaws.com' and EventName starting with 'Create' exceeds 5 within 10 minutes.\\u201d\\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of S3 Create* events over time, with thresholds marked to highlight unusual spikes, enabling quick identification of abnormal bucket creation activity.\", \" - This pattern captures all CloudFront distribution creation events recorded in CloudTrail, identified by event names starting with \\\"Create\\\" from the CloudFront service. Its purpose is to monitor when new CloudFront distributions are provisioned, including their initial configuration details. Tracking these events helps SREs detect unexpected or unauthorized distribution creations that could impact content delivery, security, or cost.\\n\\n**Alert Threshold:**  \\nTrigger an alert if the number of CloudFront distribution creation events exceeds a defined threshold within a short time window (e.g., more than 3 creations within 1 hour), as this may indicate automation errors, misconfigurations, or potential security incidents.\\n\\n**Impact of Values:**  \\n- **High values:** A spike in creation events could signal rapid environment changes, possible misconfigurations, or unauthorized activity, potentially leading to increased costs or service disruptions.  \\n- **Low or zero values:** Normal operation typically involves infrequent distribution creations; zero or low values indicate stable infrastructure without unexpected provisioning.\\n\\n**Example Alert Rule:**  \\n\\\"Alert when count of events matching {EventSource: 'cloudfront.amazonaws.com', EventName: 'Create*'} exceeds 3 within 1 hour.\\\"\\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of CloudFront distribution creation events over time, enabling quick identification of unusual spikes or trends in distribution provisioning activity.\", \" - Tracks all events generated by AWS CodePipeline, including pipeline executions, stage transitions, and action results. Measures the status and progress of continuous integration and continuous delivery (CI/CD) workflows. Events are recorded as discrete occurrences without quantitative units, capturing state changes and execution details throughout the software release process.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": false,
                        "score": 0.2721816445319273,
                        "reason": "The description does not specifically address failed or cancelled CodePipeline events as asked in the input question. While the retrieval context includes detailed event tracking for CodePipeline and other AWS services, the description focuses broadly on event types and counts without clarifying failure or cancellation statuses. The language is somewhat clear but lacks direct coverage of failure indicators or implications for CI/CD workflow issues, limiting its utility for answering the monitoring question.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Compare the Input (metric description) and Retrieval Context (monitoring question) to ensure the description clearly addresses the question's intent and scope.\",\n    \"Evaluate the description's clarity by assessing if the language is understandable and concise in the context of the question.\",\n    \"Check the coverage by verifying the description includes what is measured, the units, relevant context, and implications related to the Retrieval Context.\",\n    \"Assess the utility by determining if the description effectively enables a user to answer the monitoring question based on the provided context.\"\n] \n \nRubric:\nNone \n \nScore: 0.2721816445319273"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Compare the Input (metric description) and Retrieval Context (monitoring question) to ensure the description clearly addresses the question's intent and scope.",
                            "Evaluate the description's clarity by assessing if the language is understandable and concise in the context of the question.",
                            "Check the coverage by verifying the description includes what is measured, the units, relevant context, and implications related to the Retrieval Context.",
                            "Assess the utility by determining if the description effectively enables a user to answer the monitoring question based on the provided context."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"athena.amazonaws.com\\\", \\\"EventName\\\": \\\"*\\\"}\", \"hyperparameters\": null, \"input\": \"Do sudden spikes in Athena query volume exceed twice the baseline within five minutes?\", \"retrieval_context\": [\" - Athena query execution events captured by CloudTrail track all SQL query operations initiated via Athena (EventSource: \\\"athena.amazonaws.com\\\", EventName: \\\"*\\\"). These events provide visibility into query submissions, completions, failures, and cancellations, enabling SREs to monitor query performance, usage patterns, and potential operational issues. \\n\\n**Purpose:**  \\n- Identify query execution trends and anomalies.  \\n- Detect failed or long-running queries that may indicate resource contention or misconfigurations.  \\n- Correlate query activity with downstream system performance or cost spikes.\\n\\n**Alert Thresholds:**  \\n- Alert if query failure rate exceeds 5% over a 15-minute window.  \\n- Alert if average query execution time surpasses 5 minutes consistently over 30 minutes.  \\n- Alert on sudden spikes in query volume (e.g., 2x baseline within 5 minutes), which may indicate unexpected load or abuse.\\n\\n**Impact:**  \\n- High failure rates can signal syntax errors, permission issues, or service disruptions, potentially delaying data availability.  \\n- Prolonged query durations may degrade user experience and increase Athena costs.  \\n- Low query volume might indicate upstream data pipeline issues or reduced user activity, affecting business insights.\\n\\n**Example Usage:**  \\n- Dashboard widget showing query counts, success vs failure rates, and average execution time over time.  \\n- Alert rule: Trigger when failed queries > 10 in 15 minutes or average execution time > 300 seconds for 30 minutes, notifying the SRE team to investigate query performance or service health.\", \" - Detective security investigation events capture detailed activity logs related to threat analysis, security incident investigations, and behavioral analytics within AWS Detective. These events help SREs monitor and correlate security forensics and threat intelligence to identify suspicious or anomalous behavior in the environment.\\n\\n**Purpose in CloudTrail:**  \\nEvents from `detective.amazonaws.com` provide visibility into investigative actions and findings performed by AWS Detective, enabling tracking of security-related activities and potential threat escalations.\\n\\n**Alert Threshold Guidance:**  \\n- Trigger alerts when the volume of Detective investigation events spikes significantly above baseline (e.g., a 3x increase in investigative queries or findings within a short time window), indicating potential active threat hunting or incident response.  \\n- Alert on unusual event types or repeated failed investigation attempts that may suggest misuse or compromised credentials.\\n\\n**Impact of Values:**  \\n- **High event volume:** May indicate active security incidents, ongoing investigations, or potential security breaches requiring immediate attention.  \\n- **Low or no events:** Could suggest normal operation or lack of active investigations; however, a sudden drop after a period of activity might also warrant review.\\n\\n**Example Alert Rule:**  \\n```\\nWHEN count(detective.amazonaws.com EventName=*) OVER 15 minutes > 3 * baseline_average THEN alert \\\"Unusual Detective investigation activity detected\\\"\\n```\\n\\n**Example Dashboard Widget:**  \\n- A time-series graph showing the count of Detective events per minute, annotated with alerts on spikes.  \\n- A table listing top EventNames and their frequencies to identify unusual investigative patterns.\", \" - IAM deletion events (e.g., DeleteUser, DeleteRole) recorded by CloudTrail indicate removal of IAM identities or permissions. These events are critical for detecting unauthorized or accidental deletions that can disrupt access or signal a security breach. An alert threshold should be set to trigger on any unexpected deletion event or a sudden spike above normal baseline activity (e.g., more than 1 deletion event within 5 minutes), as even a single deletion can have significant impact. High volumes may indicate automated attacks or misconfigurations causing mass access removal, while low or zero values typically indicate normal operation.  \\nExample alert rule: trigger when count of iam.amazonaws.com Delete* events > 1 in 5 minutes.  \\nExample dashboard widget: a time series graph showing Delete* event counts over time, annotated with alert thresholds to quickly identify unusual deletion activity.\", \" - S3 bucket creation events captured by CloudTrail under **{\\\"EventSource\\\": \\\"s3.amazonaws.com\\\", \\\"EventName\\\": \\\"Create*\\\"}** indicate when new buckets or related resources (e.g., bucket policies, access points) are provisioned. These events help SREs monitor infrastructure changes that affect data storage, security posture, and compliance.\\n\\n**Purpose:**  \\nTrack and audit the creation of S3 buckets and associated configurations to ensure proper governance, prevent unauthorized resource sprawl, and maintain compliance with organizational policies.\\n\\n**Alert Threshold:**  \\nTrigger an alert if the number of S3 bucket creation events exceeds a defined threshold within a short time window (e.g., more than 5 bucket creations within 10 minutes), which may indicate automated provisioning errors, misconfigurations, or potential security incidents such as unauthorized resource creation.\\n\\n**Impact of Values:**  \\n- **High frequency:** May signal abnormal activity, such as a compromised credential or runaway automation scripts creating excessive buckets, leading to increased costs, security risks, or compliance violations.  \\n- **Low or zero frequency:** Normal in stable environments; however, sudden spikes should be investigated promptly.\\n\\n**Example Alert Rule:**  \\n\\u201cAlert when count of events with EventSource = 's3.amazonaws.com' and EventName starting with 'Create' exceeds 5 within 10 minutes.\\u201d\\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of S3 Create* events over time, with thresholds marked to highlight unusual spikes, enabling quick identification of abnormal bucket creation activity.\", \" - This pattern captures all Amazon EKS \\\"Describe\\\" API operations logged in CloudTrail, which occur when cluster metadata, node group configurations, or add-on details are queried. It helps SREs monitor how often EKS cluster information is accessed, providing visibility into potential reconnaissance or troubleshooting activities. A sudden spike in Describe calls\\u2014such as exceeding 100 requests within 5 minutes\\u2014may indicate unusual or automated querying that could precede configuration changes or security incidents, warranting an alert. Conversely, consistently low or zero Describe activity might suggest lack of monitoring or insufficient operational visibility. For example, an alert rule could trigger when Describe API calls surpass 100 in a 5-minute window, and a dashboard widget might display a time series graph of Describe call counts to track trends and detect anomalies in cluster information access patterns.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": true,
                        "score": 0.8777299861174692,
                        "reason": "The retrieval context is well aligned with the input question, specifically addressing sudden spikes in Athena query volume exceeding twice the baseline within five minutes. It clearly explains what is measured (Athena query execution events), the units (query counts over time), the context (monitoring query performance and anomalies), and the implications (unexpected load or abuse). The context is clear, concise, and provides alert thresholds directly relevant to the question. Minor improvements could include explicitly defining 'baseline' calculation or providing more detail on how to measure the baseline, but overall it effectively supports answering the input question.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Compare the input question and the retrieval context description to ensure they are aligned in topic and terminology.\",\n    \"Evaluate the clarity of the retrieval context to determine if it is understandable and concise in relation to the input question.\",\n    \"Assess the coverage of the retrieval context by verifying it fully explains what is measured, the units, the context, and implications relevant to the input question.\",\n    \"Judge the utility of the retrieval context by determining if it effectively supports answering the input question; if not, suggest improvements that enhance relevance or detail.\"\n] \n \nRubric:\nNone \n \nScore: 0.8777299861174692"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Compare the input question and the retrieval context description to ensure they are aligned in topic and terminology.",
                            "Evaluate the clarity of the retrieval context to determine if it is understandable and concise in relation to the input question.",
                            "Assess the coverage of the retrieval context by verifying it fully explains what is measured, the units, the context, and implications relevant to the input question.",
                            "Judge the utility of the retrieval context by determining if it effectively supports answering the input question; if not, suggest improvements that enhance relevance or detail."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"cloudformation.amazonaws.com\\\", \\\"EventName\\\": \\\"Delete*\\\"}\", \"hyperparameters\": null, \"input\": \"Does the number of CloudFormation Delete* events exceed three, indicating potential accidental or malicious infrastructure removal?\", \"retrieval_context\": [\" - CloudFormation Delete* events in CloudTrail indicate the initiation or completion of stack deletion operations, signaling infrastructure teardown and resource decommissioning activities. These events help SREs monitor environment lifecycle changes and ensure that deletions are intentional and controlled. \\n\\n**Alert Threshold:** Trigger an alert if the number of Delete* events exceeds a predefined baseline (e.g., more than 3 deletions within 1 hour) or occurs unexpectedly outside of scheduled maintenance windows, as this may indicate accidental or malicious infrastructure removal.\\n\\n**Impact of Values:**  \\n- **High frequency:** May lead to unintended service disruptions, data loss, or compliance risks due to rapid or bulk resource deletions. Requires immediate investigation.  \\n- **Low or zero frequency:** Normal in stable environments; indicates no recent stack deletions and stable infrastructure.\\n\\n**Example Usage:**  \\nCreate a dashboard widget tracking the count of CloudFormation Delete* events over time. Set an alert rule to notify the SRE team if Delete* events spike above the threshold within a rolling 1-hour window, enabling prompt response to potential infrastructure teardown incidents.\", \" - This event pattern captures all CloudTrail events where CloudWatch Logs resources\\u2014such as log groups or log streams\\u2014are deleted (e.g., DeleteLogGroup, DeleteLogStream). Its purpose is to monitor and audit log deletion activities, which can be legitimate cleanup or indicate potential loss of critical log data needed for troubleshooting and compliance.\\n\\n**Alert Threshold:**  \\nTrigger an alert if the number of delete events exceeds a baseline threshold within a defined time window (e.g., more than 3 deletions within 1 hour), or if deletions occur unexpectedly outside of scheduled maintenance windows.\\n\\n**Impact:**  \\n- **High frequency of deletions:** May indicate accidental or malicious removal of logs, risking loss of observability and forensic data. Immediate investigation is recommended.  \\n- **Low or zero deletions:** Normal operation, indicating logs are retained as expected.\\n\\n**Example Alert Rule:**  \\n\\u201cAlert if DeleteLogGroup or DeleteLogStream events from logs.amazonaws.com exceed 3 occurrences in 60 minutes.\\u201d  \\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of Delete* events over time, annotated with alert thresholds and maintenance windows, enabling quick identification of unusual spikes in log deletions.\", \" - This pattern captures ECS deletion events recorded in CloudTrail, specifically any API calls starting with \\\"Delete\\\" from the ECS service (e.g., DeleteCluster, DeleteService, DeleteTaskSet). Its purpose is to monitor when ECS resources are removed, which can signal intentional cleanup or unintended disruptions affecting service availability.\\n\\n**Threshold guidance:**  \\n- Trigger an alert if the number of ECS deletion events exceeds a baseline threshold within a short time window (e.g., more than 3 Delete* events in 5 minutes), as this may indicate accidental mass deletion or a security incident.  \\n- Low or expected deletion rates typically reflect routine maintenance or scaling down of resources and generally have minimal impact.\\n\\n**Impact:**  \\n- High deletion event counts can lead to service downtime, loss of running tasks, or cluster instability, requiring immediate investigation.  \\n- Low or zero deletion events usually indicate stable ECS resource management.\\n\\n**Example alert rule:**  \\n- Alert when `count(events where EventSource=\\\"ecs.amazonaws.com\\\" and EventName starts with \\\"Delete\\\") > 3` within 5 minutes.  \\n- This alert can be visualized on a dashboard showing ECS Delete* event counts over time, helping SREs quickly identify unusual spikes and correlate with service health metrics.\", \" - This pattern captures all EC2 resource deletion events recorded in CloudTrail, triggered by any API calls starting with \\\"Delete\\\" from the EC2 service (e.g., DeleteSecurityGroup, DeleteNetworkInterface). Its purpose is to monitor and alert on the removal of critical EC2 components, which can impact infrastructure stability and security.\\n\\n**Threshold guidance:**  \\n- Set an alert if the number of deletion events exceeds a baseline threshold within a short time window (e.g., more than 5 deletions in 10 minutes), as this may indicate accidental mass deletions or malicious activity.  \\n- A low or zero count is typical during normal operations, while sudden spikes warrant immediate investigation.\\n\\n**Impact:**  \\n- High deletion event counts can lead to service disruptions, loss of network connectivity, or security vulnerabilities if key resources like security groups or network interfaces are removed unexpectedly.  \\n- Low or no deletion activity generally indicates stable infrastructure management.\\n\\n**Example alert rule:**  \\nTrigger an alert when the count of events matching {\\\"EventSource\\\": \\\"ec2.amazonaws.com\\\", \\\"EventName\\\": \\\"Delete*\\\"} exceeds 5 within 10 minutes.\\n\\n**Example dashboard usage:**  \\nVisualize the count of EC2 deletion events over time to identify unusual spikes, correlating with other operational metrics to assess potential impact on system availability or security posture.\", \" - This pattern captures all Route 53 deletion events recorded in CloudTrail, such as deleting hosted zones, record sets, or health checks. It helps SREs monitor when DNS configurations are removed, which could be part of routine cleanup or signal accidental or malicious disruptions to DNS resolution.\\n\\n**Purpose:**  \\nTrack and alert on Route 53 resource deletions to quickly detect potential service impact caused by DNS changes.\\n\\n**Alert Threshold:**  \\nTrigger an alert if more than 3 deletion events occur within a 10-minute window, as multiple deletions in a short period may indicate an ongoing incident or misconfiguration.\\n\\n**Impact:**  \\n- **High volume:** May cause widespread DNS outages or service disruptions, requiring immediate investigation.  \\n- **Low volume (single event):** Could be routine maintenance but should still be reviewed to confirm legitimacy.\\n\\n**Example Alert Rule:**  \\n\\u201cAlert when count of events matching {EventSource: route53.amazonaws.com, EventName: Delete*} exceeds 3 within 10 minutes.\\u201d\\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of Route 53 deletion events over time, with a threshold line at 3 events per 10 minutes to highlight potential issues.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": true,
                        "score": 0.9,
                        "reason": "The Retrieval Context directly addresses the Input question by clearly explaining what CloudFormation Delete* events represent, their significance, and the alert threshold of more than three deletions within one hour. It provides detailed impact information and example alert rules, making it specific, concise, and easy to understand. The context covers what is measured, units (event counts over time), and implications relevant to accidental or malicious infrastructure removal, effectively supporting the user in answering the question. Minor improvement could be made by explicitly linking the threshold to the exact question phrasing, but overall it is highly aligned.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Compare the Input (monitoring question) with the Retrieval Context (metric description) to verify if the description clearly addresses and supports understanding of the question.\",\n    \"Evaluate the Input to ensure the monitoring question is specific and the Retrieval Context provides clarity by being concise and easy to understand.\",\n    \"Assess if the Retrieval Context adequately covers the metric details including what is measured, units, context, and implications relevant to the Input question.\",\n    \"Determine the utility by judging whether the Retrieval Context can effectively help a user answer the Input question, and if not, identify specific areas for improvement.\"\n] \n \nRubric:\nNone \n \nScore: 0.9"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Compare the Input (monitoring question) with the Retrieval Context (metric description) to verify if the description clearly addresses and supports understanding of the question.",
                            "Evaluate the Input to ensure the monitoring question is specific and the Retrieval Context provides clarity by being concise and easy to understand.",
                            "Assess if the Retrieval Context adequately covers the metric details including what is measured, units, context, and implications relevant to the Input question.",
                            "Determine the utility by judging whether the Retrieval Context can effectively help a user answer the Input question, and if not, identify specific areas for improvement."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"cloudformation.amazonaws.com\\\", \\\"EventName\\\": \\\"Create*\\\"}\", \"hyperparameters\": null, \"input\": \"Does the number of Create* events exceed ten, indicating a potential automated deployment loop or misconfiguration?\", \"retrieval_context\": [\" - CloudFormation stack creation events (**EventSource: cloudformation.amazonaws.com**, **EventName: Create\\\\*** ) represent API calls initiating the provisioning of AWS infrastructure and resources via CloudFormation templates. These events in CloudTrail help SREs monitor the start of environment setups and infrastructure deployments as part of Infrastructure as Code workflows.\\n\\n**Purpose:** Track and audit when new CloudFormation stacks or stack components are being created, enabling visibility into changes in infrastructure state and deployment activities.\\n\\n**Alert Thresholds:**  \\n- Trigger an alert if the number of Create* events exceeds a baseline threshold within a short time window (e.g., >10 stack creation attempts in 5 minutes), which may indicate automated deployment loops, misconfigurations, or potential security incidents.  \\n- Alert if Create* events spike unexpectedly outside of scheduled deployment windows or change management periods.\\n\\n**Impact of Values:**  \\n- **High volume:** May signal rapid infrastructure changes that could lead to instability, resource contention, or deployment failures. It could also indicate unauthorized or accidental mass provisioning.  \\n- **Low or zero volume:** Normal during steady-state operations; however, a sudden drop during expected deployment windows might indicate pipeline failures or blocked deployments.\\n\\n**Example Usage:**  \\n- **Dashboard:** Visualize the count of CloudFormation Create* events over time, segmented by stack name or user identity, to correlate deployments with system performance or incidents.  \\n- **Alert Rule:**  \\n  ```  \\n  WHEN count(events where EventSource=\\\"cloudformation.amazonaws.com\\\" AND EventName LIKE \\\"Create%\\\") > 10 within 5 minutes  \\n  THEN trigger alert \\\"High rate of CloudFormation stack creation events detected\\\"  \\n  ```  \\nThis enables proactive detection of abnormal infrastructure provisioning activity and supports rapid investigation and response.\", \" - This pattern captures all AWS Systems Manager (SSM) resource creation events logged in CloudTrail, such as the creation of parameters, documents, and maintenance windows. It helps SREs monitor the provisioning of new SSM assets, which can indicate configuration changes or automation deployments.\\n\\n**Purpose:**  \\nTo detect when new SSM resources are created, enabling timely awareness of infrastructure changes that may affect system behavior or security posture.\\n\\n**Alert Threshold Guidance:**  \\nSet an alert threshold based on your environment\\u2019s baseline creation activity. For example, trigger an alert if more than 5 creation events occur within 10 minutes, which may indicate unexpected or unauthorized provisioning.\\n\\n**Impact of Values:**  \\n- **High values:** A spike in creation events could signal automated deployments, configuration drift, or potential security incidents such as unauthorized resource creation.  \\n- **Low or zero values:** Normal in stable environments; however, a sudden drop might indicate issues with deployment pipelines or monitoring gaps.\\n\\n**Example Alert Rule:**  \\nTrigger an alert when the count of events matching `{\\\"EventSource\\\": \\\"ssm.amazonaws.com\\\", \\\"EventName\\\": \\\"Create*\\\"}` exceeds 5 within a 10-minute window.\\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of SSM creation events over time, with thresholds marked to highlight unusual spikes, helping SREs quickly identify and investigate abnormal provisioning activity.\", \" - This pattern detects CloudTrail events where CloudWatch resources are created, such as alarms, dashboards, and log groups. Its purpose is to monitor the provisioning of new CloudWatch components, which can indicate changes in monitoring coverage or potential configuration drift. An alert should be triggered when the number of creation events exceeds a defined threshold within a short time window (e.g., more than 5 Create* events in 10 minutes), as a sudden spike may signal automated deployments, misconfigurations, or unauthorized activity. Conversely, a prolonged absence of creation events might suggest stagnation in monitoring updates or missed deployments. For example, in a monitoring dashboard, you can visualize the count of CloudWatch Create* events over time and set an alert rule to notify the SRE team if the event count surpasses the threshold, enabling timely investigation and response to unexpected changes in monitoring infrastructure.\", \" - This pattern detects SNS topic creation events recorded in CloudTrail, specifically any API calls starting with \\\"Create\\\" from the SNS service (e.g., CreateTopic). It helps SREs monitor when new SNS topics are provisioned, which can indicate changes in messaging architecture or potential unauthorized resource creation. An alert threshold could be set on the number of Create* events within a given time window (e.g., more than 5 topic creations in 10 minutes), as a sudden spike may signal automation errors or security issues. Low or expected values typically indicate normal operations, while high values may impact system stability by increasing resource usage or indicate potential misuse. For example, an alert rule could trigger if the count of {\\\"EventSource\\\": \\\"sns.amazonaws.com\\\", \\\"EventName\\\": \\\"Create*\\\"} events exceeds 5 in 10 minutes, and a dashboard widget could display a time series graph of topic creation events to track trends and detect anomalies.\", \" - This pattern detects Secrets Manager creation events in CloudTrail, specifically any API calls starting with \\\"Create\\\" (e.g., CreateSecret). It helps SREs monitor when new secrets, secret versions, or related configurations are added, which could indicate deployment changes or potential security risks.  \\n**Alert threshold:** Trigger an alert if the number of create events exceeds a baseline (e.g., more than 5 creates within 10 minutes), as a sudden spike may signal unauthorized secret creation or misconfiguration. Conversely, zero create events over an extended period in an active environment might indicate issues with deployment pipelines or automation failures.  \\n**Impact:**  \\n- High values: Could indicate potential security breaches, unauthorized secret provisioning, or rapid environment changes requiring immediate investigation.  \\n- Low values: May suggest stalled deployments or automation problems, potentially delaying application updates or secret rotations.  \\n**Example usage:**  \\nIn a dashboard, plot the count of Secrets Manager Create* events over time to visualize spikes. An alert rule could be:  \\n`WHEN count(secretsmanager.amazonaws.com Create* events) > 5 within 10 minutes THEN trigger alert \\\"Unusual Secrets Creation Activity\\\"`  \\nThis enables proactive detection of abnormal secret creation activity, helping maintain security and operational stability.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": true,
                        "score": 0.8551764164700968,
                        "reason": "The description is clear and concise, directly addressing whether the number of Create* events exceeds ten, which aligns well with the monitoring question. It covers what is measured (Create* events), the threshold (exceeding ten), and the implications (potential automated deployment loops or misconfigurations). The description provides actionable guidance for alerting and monitoring, making it highly useful. However, slight improvement could be made by explicitly stating the time window for the threshold to fully match the context examples.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Compare the Input (metric description) to the Retrieval Context (monitoring question) to assess clarity: check if the description is understandable and concise enough to address the question clearly.\",\n    \"Evaluate the coverage of the description by verifying if it details what is being measured, the units used, relevant context, and implications, ensuring completeness to answer the question.\",\n    \"Assess utility by determining if the description provides actionable or relevant information that directly helps in answering the monitoring question.\",\n    \"If any of the above criteria score below 8, identify specific aspects (clarity, coverage, or utility) where the description falls short, and suggest concrete improvements focusing on enhancing the relationship between the description and the question.\"\n] \n \nRubric:\nNone \n \nScore: 0.8551764164700968"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Compare the Input (metric description) to the Retrieval Context (monitoring question) to assess clarity: check if the description is understandable and concise enough to address the question clearly.",
                            "Evaluate the coverage of the description by verifying if it details what is being measured, the units used, relevant context, and implications, ensuring completeness to answer the question.",
                            "Assess utility by determining if the description provides actionable or relevant information that directly helps in answering the monitoring question.",
                            "If any of the above criteria score below 8, identify specific aspects (clarity, coverage, or utility) where the description falls short, and suggest concrete improvements focusing on enhancing the relationship between the description and the question."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"codedeploy.amazonaws.com\\\", \\\"EventName\\\": \\\"*\\\"}\", \"hyperparameters\": null, \"input\": \"Are there any CodeDeploy events indicating deployment failures or cancellations?\", \"retrieval_context\": [\" - CloudFormation stack creation events (**EventSource: cloudformation.amazonaws.com**, **EventName: Create\\\\*** ) represent API calls initiating the provisioning of AWS infrastructure and resources via CloudFormation templates. These events in CloudTrail help SREs monitor the start of environment setups and infrastructure deployments as part of Infrastructure as Code workflows.\\n\\n**Purpose:** Track and audit when new CloudFormation stacks or stack components are being created, enabling visibility into changes in infrastructure state and deployment activities.\\n\\n**Alert Thresholds:**  \\n- Trigger an alert if the number of Create* events exceeds a baseline threshold within a short time window (e.g., >10 stack creation attempts in 5 minutes), which may indicate automated deployment loops, misconfigurations, or potential security incidents.  \\n- Alert if Create* events spike unexpectedly outside of scheduled deployment windows or change management periods.\\n\\n**Impact of Values:**  \\n- **High volume:** May signal rapid infrastructure changes that could lead to instability, resource contention, or deployment failures. It could also indicate unauthorized or accidental mass provisioning.  \\n- **Low or zero volume:** Normal during steady-state operations; however, a sudden drop during expected deployment windows might indicate pipeline failures or blocked deployments.\\n\\n**Example Usage:**  \\n- **Dashboard:** Visualize the count of CloudFormation Create* events over time, segmented by stack name or user identity, to correlate deployments with system performance or incidents.  \\n- **Alert Rule:**  \\n  ```  \\n  WHEN count(events where EventSource=\\\"cloudformation.amazonaws.com\\\" AND EventName LIKE \\\"Create%\\\") > 10 within 5 minutes  \\n  THEN trigger alert \\\"High rate of CloudFormation stack creation events detected\\\"  \\n  ```  \\nThis enables proactive detection of abnormal infrastructure provisioning activity and supports rapid investigation and response.\", \" - CodeDeploy events in CloudTrail capture API calls made to the AWS CodeDeploy service (EventSource: \\\"codedeploy.amazonaws.com\\\") across all event names (EventName: \\\"*\\\"). These events provide detailed records of deployment lifecycle actions such as creating, updating, starting, stopping, and deleting deployments, deployment groups, and applications. The data source is the AWS CodeDeploy API, and each event includes metadata like timestamps, user identity, deployment IDs, status changes, and error messages. Metrics derived from these events typically count the number of deployment-related API calls or track deployment status transitions over time (units: count of events or status occurrences). Unusual values\\u2014such as a sudden spike in failed deployment events, unexpected deployment cancellations, or unauthorized API calls\\u2014should trigger alerts as they may indicate deployment issues, configuration errors, or potential security incidents requiring immediate investigation.\", \" - Lambda function \\\"Put*\\\" events in CloudTrail capture changes to function configurations, concurrency settings, event source mappings, and resource provisioning. These events indicate updates or deployments that can affect function behavior and performance. An SRE should monitor the frequency and success of these operations; unusually high rates of \\\"Put*\\\" events may signal automation errors or configuration churn, while absence of expected updates could indicate deployment issues. Alert thresholds might include more than 5 \\\"Put*\\\" events within 5 minutes or failed update attempts exceeding 10% of total \\\"Put*\\\" events. High volumes can lead to inconsistent function states or throttling, impacting availability and latency; low update activity during active development phases may delay critical fixes or optimizations. For example, a dashboard widget can track the count of \\\"Put*\\\" events per hour alongside error rates, and an alert rule could trigger when the number of failed \\\"Put*\\\" events surpasses a set threshold, prompting investigation into deployment or configuration problems.\", \" - This pattern captures ECS stop events. It identifies when ECS tasks are stopped, which can indicate task completion, scaling operations, or service updates.\", \" - This pattern captures ECS task run events from CloudTrail, specifically any API calls starting with \\\"Run\\\" (e.g., RunTask, RunTaskSync). It indicates when ECS tasks are initiated, including manual task launches, service deployments, and scheduled executions. Monitoring these events helps SREs track workload activity and detect anomalies in task start rates.\\n\\n**Threshold guidance:**  \\n- Alert if the number of Run* events spikes significantly above the baseline (e.g., a 2x increase within 5 minutes), which may indicate runaway task launches or deployment issues.  \\n- Alert if the count drops to near zero during expected deployment windows, potentially signaling failures in task scheduling or service disruptions.\\n\\n**Impact:**  \\n- High values can lead to resource exhaustion, increased costs, or cascading failures if tasks are repeatedly started without completion.  \\n- Low values may indicate stalled deployments, scheduler failures, or service outages, impacting application availability.\\n\\n**Example alert rule:**  \\nTrigger an alert when the count of ECS Run* events exceeds 100 within 5 minutes or falls below 5 during a scheduled deployment window, prompting investigation into task launch behavior.\\n\\n**Example dashboard widget:**  \\nA time-series graph showing the count of ECS Run* events per minute, overlaid with deployment schedules, enabling correlation between task launches and expected operational activities.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": true,
                        "score": 0.8194658615575999,
                        "reason": "The retrieval context provides a detailed description of CodeDeploy events in CloudTrail, including event sources, event names, metadata, and the types of deployment lifecycle actions captured. It explains the units (count of events or status occurrences) and highlights the significance of spikes in failed or cancelled deployments, which directly addresses the monitoring question about deployment failures or cancellations. The description is clear and concise, using terminology appropriate for the input. However, it could improve coverage by explicitly defining how to identify failure or cancellation events within the data and providing example alert thresholds or usage scenarios specific to failures or cancellations to enhance utility.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Compare the Input (monitoring question) and the Retrieval Context (metric description) to ensure the description specifically addresses the question asked.\",\n    \"Evaluate Clarity by checking if the metric description is understandable and concise in relation to the terminology and complexity of the Input.\",\n    \"Assess Coverage by verifying the description explains what is measured, units, context, and implications, ensuring it aligns with the needs expressed in the Input.\",\n    \"Judge Utility by determining if the description enables a user to effectively answer the monitoring question presented in the Input, highlighting any gaps or ambiguities.\"\n] \n \nRubric:\nNone \n \nScore: 0.8194658615575999"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Compare the Input (monitoring question) and the Retrieval Context (metric description) to ensure the description specifically addresses the question asked.",
                            "Evaluate Clarity by checking if the metric description is understandable and concise in relation to the terminology and complexity of the Input.",
                            "Assess Coverage by verifying the description explains what is measured, units, context, and implications, ensuring it aligns with the needs expressed in the Input.",
                            "Judge Utility by determining if the description enables a user to effectively answer the monitoring question presented in the Input, highlighting any gaps or ambiguities."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"redshift.amazonaws.com\\\", \\\"EventName\\\": \\\"Delete*\\\"}\", \"hyperparameters\": null, \"input\": \"Are Delete* events in Amazon Redshift exceeding their normal rate?\", \"retrieval_context\": [\" - CloudFormation Delete* events in CloudTrail indicate the initiation or completion of stack deletion operations, signaling infrastructure teardown and resource decommissioning activities. These events help SREs monitor environment lifecycle changes and ensure that deletions are intentional and controlled. \\n\\n**Alert Threshold:** Trigger an alert if the number of Delete* events exceeds a predefined baseline (e.g., more than 3 deletions within 1 hour) or occurs unexpectedly outside of scheduled maintenance windows, as this may indicate accidental or malicious infrastructure removal.\\n\\n**Impact of Values:**  \\n- **High frequency:** May lead to unintended service disruptions, data loss, or compliance risks due to rapid or bulk resource deletions. Requires immediate investigation.  \\n- **Low or zero frequency:** Normal in stable environments; indicates no recent stack deletions and stable infrastructure.\\n\\n**Example Usage:**  \\nCreate a dashboard widget tracking the count of CloudFormation Delete* events over time. Set an alert rule to notify the SRE team if Delete* events spike above the threshold within a rolling 1-hour window, enabling prompt response to potential infrastructure teardown incidents.\", \" - This event pattern captures all CloudTrail events where CloudWatch Logs resources\\u2014such as log groups or log streams\\u2014are deleted (e.g., DeleteLogGroup, DeleteLogStream). Its purpose is to monitor and audit log deletion activities, which can be legitimate cleanup or indicate potential loss of critical log data needed for troubleshooting and compliance.\\n\\n**Alert Threshold:**  \\nTrigger an alert if the number of delete events exceeds a baseline threshold within a defined time window (e.g., more than 3 deletions within 1 hour), or if deletions occur unexpectedly outside of scheduled maintenance windows.\\n\\n**Impact:**  \\n- **High frequency of deletions:** May indicate accidental or malicious removal of logs, risking loss of observability and forensic data. Immediate investigation is recommended.  \\n- **Low or zero deletions:** Normal operation, indicating logs are retained as expected.\\n\\n**Example Alert Rule:**  \\n\\u201cAlert if DeleteLogGroup or DeleteLogStream events from logs.amazonaws.com exceed 3 occurrences in 60 minutes.\\u201d  \\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of Delete* events over time, annotated with alert thresholds and maintenance windows, enabling quick identification of unusual spikes in log deletions.\", \" - This pattern captures ECS deletion events recorded in CloudTrail, specifically any API calls starting with \\\"Delete\\\" from the ECS service (e.g., DeleteCluster, DeleteService, DeleteTaskSet). Its purpose is to monitor when ECS resources are removed, which can signal intentional cleanup or unintended disruptions affecting service availability.\\n\\n**Threshold guidance:**  \\n- Trigger an alert if the number of ECS deletion events exceeds a baseline threshold within a short time window (e.g., more than 3 Delete* events in 5 minutes), as this may indicate accidental mass deletion or a security incident.  \\n- Low or expected deletion rates typically reflect routine maintenance or scaling down of resources and generally have minimal impact.\\n\\n**Impact:**  \\n- High deletion event counts can lead to service downtime, loss of running tasks, or cluster instability, requiring immediate investigation.  \\n- Low or zero deletion events usually indicate stable ECS resource management.\\n\\n**Example alert rule:**  \\n- Alert when `count(events where EventSource=\\\"ecs.amazonaws.com\\\" and EventName starts with \\\"Delete\\\") > 3` within 5 minutes.  \\n- This alert can be visualized on a dashboard showing ECS Delete* event counts over time, helping SREs quickly identify unusual spikes and correlate with service health metrics.\", \" - This pattern captures all AWS CloudTrail events where RDS resources are deleted (e.g., DeleteDBInstance, DeleteDBSnapshot). Its purpose is to monitor and alert on potentially destructive actions affecting RDS databases, which could indicate intentional cleanup, accidental deletions, or malicious activity. \\n\\n**Threshold guidance:**  \\n- Trigger an alert if more than 1 deletion event occurs within a short time window (e.g., 5 minutes), as multiple deletions in quick succession are unusual and may signal a problem.  \\n- A single deletion event should also prompt review, especially if unexpected or outside maintenance windows.\\n\\n**Impact:**  \\n- **High values:** Multiple deletions in a short period can lead to significant data loss or service disruption, requiring immediate investigation and possible recovery actions.  \\n- **Low values:** Occasional single deletions may be normal during maintenance but still warrant confirmation to avoid unnoticed data loss.\\n\\n**Example usage:**  \\nIn a monitoring dashboard, display a time series count of RDS deletion events filtered by this pattern. Configure an alert rule to notify the SRE team if the count exceeds 1 event within any 5-minute interval, enabling rapid response to potential incidents.\", \" - Tracks all AWS Lambda function deletion events captured in CloudTrail. Monitoring **{\\\"EventSource\\\": \\\"lambda.amazonaws.com\\\", \\\"EventName\\\": \\\"Delete*\\\"}** helps SREs detect when Lambda functions are removed, which is critical for maintaining application stability, ensuring proper resource cleanup, and preventing accidental or unauthorized deletions.  \\n\\n**Alert Threshold:** Trigger an alert if more than 3 Lambda function deletions occur within a 1-hour window, as this may indicate a misconfiguration, automated script error, or potential security breach.  \\n\\n**Impact:**  \\n- **High values:** A spike in deletions can lead to service disruptions, loss of critical functionality, or security incidents if unauthorized deletions occur. Immediate investigation is required.  \\n- **Low or zero values:** Normal operation; infrequent deletions are expected during routine maintenance or deployments.  \\n\\n**Example Alert Rule:**  \\n`WHEN count(events where EventSource=\\\"lambda.amazonaws.com\\\" AND EventName LIKE \\\"Delete%\\\") > 3 WITHIN 1 hour THEN alert \\\"Unusual number of Lambda deletions detected\\\"`  \\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of Lambda deletion events per hour, annotated with alert thresholds, enabling quick identification of abnormal deletion activity.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": true,
                        "score": 0.8509455484765939,
                        "reason": "The retrieval context comprehensively covers Delete* events across multiple AWS services, including Amazon Redshift-related services like RDS, with clear alert thresholds, impact explanations, and example usage. It is detailed, clear, and provides sufficient information to assess if Delete* events exceed normal rates. However, it does not explicitly mention Amazon Redshift directly, which slightly reduces direct alignment with the input question.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Compare the Input (monitoring question) and the Retrieval Context (metric description) to ensure the description directly addresses the question asked.\",\n    \"Evaluate the Clarity of the Retrieval Context by checking if it is understandable and concise given the terminology and scope of the Input.\",\n    \"Assess the Coverage of the Retrieval Context by verifying it includes what is measured, units, context, and implications relevant to the Input.\",\n    \"Determine the Utility of the Retrieval Context by confirming if it provides sufficient information to help answer the Input question effectively.\"\n] \n \nRubric:\nNone \n \nScore: 0.8509455484765939"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Compare the Input (monitoring question) and the Retrieval Context (metric description) to ensure the description directly addresses the question asked.",
                            "Evaluate the Clarity of the Retrieval Context by checking if it is understandable and concise given the terminology and scope of the Input.",
                            "Assess the Coverage of the Retrieval Context by verifying it includes what is measured, units, context, and implications relevant to the Input.",
                            "Determine the Utility of the Retrieval Context by confirming if it provides sufficient information to help answer the Input question effectively."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"kinesis.amazonaws.com\\\", \\\"EventName\\\": \\\"*\\\"}\", \"hyperparameters\": null, \"input\": \"Are there spikes in Kinesis PutRecord or PutRecords API operations that could indicate a data ingestion issue?\", \"retrieval_context\": [\" - Lambda function \\\"Put*\\\" events in CloudTrail capture changes to function configurations, concurrency settings, event source mappings, and resource provisioning. These events indicate updates or deployments that can affect function behavior and performance. An SRE should monitor the frequency and success of these operations; unusually high rates of \\\"Put*\\\" events may signal automation errors or configuration churn, while absence of expected updates could indicate deployment issues. Alert thresholds might include more than 5 \\\"Put*\\\" events within 5 minutes or failed update attempts exceeding 10% of total \\\"Put*\\\" events. High volumes can lead to inconsistent function states or throttling, impacting availability and latency; low update activity during active development phases may delay critical fixes or optimizations. For example, a dashboard widget can track the count of \\\"Put*\\\" events per hour alongside error rates, and an alert rule could trigger when the number of failed \\\"Put*\\\" events surpasses a set threshold, prompting investigation into deployment or configuration problems.\", \" - Redshift cluster creation events in CloudTrail capture all API calls initiating the provisioning of new Redshift clusters (e.g., CreateCluster). These events indicate when new data warehouse resources are being deployed or configured, impacting capacity and cost.  \\n**Purpose:** Enables SREs to monitor and audit cluster provisioning activities for operational control and security compliance.  \\n**Alert Threshold:** Trigger alerts on an unusually high number of cluster creation events within a short time window (e.g., >3 creates in 1 hour), which may indicate automation errors, misconfigurations, or unauthorized resource provisioning.  \\n**Impact:**  \\n- **High values:** May lead to resource sprawl, increased costs, and potential performance degradation due to over-provisioning. Could also signal security risks if unexpected clusters are created.  \\n- **Low or zero values:** Normal in stable environments; no new clusters being created means stable infrastructure.  \\n**Example Alert Rule:**  \\n\\u201cAlert if count of events with EventSource='redshift.amazonaws.com' and EventName starting with 'Create' exceeds 3 within 60 minutes.\\u201d  \\n**Dashboard Use:** Visualize the frequency of Redshift cluster creation events over time to detect spikes or anomalies, correlating with deployment activities or security incidents.\", \" - This pattern captures CloudWatch Logs Put operations, which occur when log events are written to log streams from applications, systems, or custom sources. In CloudTrail, these events indicate active ingestion of log data into CloudWatch Logs, essential for monitoring application health and troubleshooting.\\n\\n**Purpose:**  \\nMonitor the frequency and volume of log ingestion to detect anomalies such as sudden drops (potentially indicating logging failures or agent issues) or spikes (which may signal increased application activity or potential log flooding).\\n\\n**Alert Threshold Guidance:**  \\n- Trigger an alert if the number of Put operations drops below a baseline threshold for a sustained period (e.g., less than 50% of average daily Put events over 15 minutes), indicating possible logging disruptions.  \\n- Trigger an alert if Put operations spike above a defined upper threshold (e.g., 2x the average rate), which could indicate abnormal application behavior or excessive logging that may impact costs and performance.\\n\\n**Impact:**  \\n- **High values:** May lead to increased CloudWatch Logs ingestion costs and potential performance degradation; could also indicate abnormal application behavior or security events generating excessive logs.  \\n- **Low values:** May result in loss of critical log data, hindering troubleshooting and incident response.\\n\\n**Example Usage:**  \\nIn a monitoring dashboard or alert rule, track the count of CloudTrail events where `EventSource` is `logs.amazonaws.com` and `EventName` matches `Put*` over rolling 5-minute intervals. Set alerts to notify the SRE team if counts fall below or exceed defined thresholds, enabling timely investigation into logging pipeline health.\", \" - This pattern captures all Amazon EKS \\\"Describe\\\" API operations logged in CloudTrail, which occur when cluster metadata, node group configurations, or add-on details are queried. It helps SREs monitor how often EKS cluster information is accessed, providing visibility into potential reconnaissance or troubleshooting activities. A sudden spike in Describe calls\\u2014such as exceeding 100 requests within 5 minutes\\u2014may indicate unusual or automated querying that could precede configuration changes or security incidents, warranting an alert. Conversely, consistently low or zero Describe activity might suggest lack of monitoring or insufficient operational visibility. For example, an alert rule could trigger when Describe API calls surpass 100 in a 5-minute window, and a dashboard widget might display a time series graph of Describe call counts to track trends and detect anomalies in cluster information access patterns.\", \" - This pattern captures all CloudWatch API operations that begin with \\\"Put\\\", such as PutMetricData, PutLogEvents, and PutAlarm, indicating when CloudWatch resources or configurations are created, updated, or modified. In CloudTrail, monitoring these events helps SREs detect changes to monitoring metrics, log ingestion, and alarm settings that could impact observability or alerting behavior.\\n\\n**Threshold guidance:**  \\nAn alert should trigger if the rate of Put* events exceeds a baseline threshold (e.g., a sudden spike beyond normal operational patterns, such as a 3x increase within 5 minutes), which may indicate automated scripts or unauthorized changes modifying monitoring configurations. Conversely, an unusually low rate over an extended period might suggest disruptions in metric or log ingestion.\\n\\n**Impact:**  \\n- High volumes of Put* events can lead to configuration drift, unexpected alert noise, or resource misconfigurations affecting system reliability.  \\n- Low volumes may result in missing critical metrics or logs, reducing visibility into system health.\\n\\n**Example alert rule:**  \\nTrigger an alert when the count of CloudTrail events with EventSource = \\\"cloudwatch.amazonaws.com\\\" and EventName starting with \\\"Put\\\" exceeds 100 events within 5 minutes, signaling potential bulk updates to monitoring configurations that require investigation. This can be visualized in a dashboard showing Put* event counts over time alongside key system metrics to correlate changes with system behavior.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": false,
                        "score": 0.173105856691102,
                        "reason": "The retrieval context does not address the specific input question about spikes in Kinesis PutRecord or PutRecords API operations; instead, it focuses on unrelated 'Put' operations for CloudWatch, Lambda, Redshift, and CloudWatch Logs. While the descriptions are clear and detailed for their respective metrics, they lack coverage of Kinesis metrics, units, or implications relevant to the question, providing minimal utility for answering the monitoring question.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Compare the Input (monitoring question) and Retrieval Context (metric description) to ensure the description addresses the specific question asked.\",\n    \"Evaluate Clarity by verifying that the description is easily understandable and concise relative to the complexity of the input question.\",\n    \"Assess Coverage by checking if the description includes what the metric measures, units, relevant context, and implications, ensuring it supports answering the input question.\",\n    \"Determine Utility by confirming if the description provides actionable information or insight that enables the user to effectively answer the monitoring question.\"\n] \n \nRubric:\nNone \n \nScore: 0.173105856691102"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Compare the Input (monitoring question) and Retrieval Context (metric description) to ensure the description addresses the specific question asked.",
                            "Evaluate Clarity by verifying that the description is easily understandable and concise relative to the complexity of the input question.",
                            "Assess Coverage by checking if the description includes what the metric measures, units, relevant context, and implications, ensuring it supports answering the input question.",
                            "Determine Utility by confirming if the description provides actionable information or insight that enables the user to effectively answer the monitoring question."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"cloudformation.amazonaws.com\\\", \\\"EventName\\\": \\\"Update*\\\"}\", \"hyperparameters\": null, \"input\": \"Does the high volume of CloudFormation stack updates indicate instability or potential automation errors?\", \"retrieval_context\": [\" - CloudFormation Delete* events in CloudTrail indicate the initiation or completion of stack deletion operations, signaling infrastructure teardown and resource decommissioning activities. These events help SREs monitor environment lifecycle changes and ensure that deletions are intentional and controlled. \\n\\n**Alert Threshold:** Trigger an alert if the number of Delete* events exceeds a predefined baseline (e.g., more than 3 deletions within 1 hour) or occurs unexpectedly outside of scheduled maintenance windows, as this may indicate accidental or malicious infrastructure removal.\\n\\n**Impact of Values:**  \\n- **High frequency:** May lead to unintended service disruptions, data loss, or compliance risks due to rapid or bulk resource deletions. Requires immediate investigation.  \\n- **Low or zero frequency:** Normal in stable environments; indicates no recent stack deletions and stable infrastructure.\\n\\n**Example Usage:**  \\nCreate a dashboard widget tracking the count of CloudFormation Delete* events over time. Set an alert rule to notify the SRE team if Delete* events spike above the threshold within a rolling 1-hour window, enabling prompt response to potential infrastructure teardown incidents.\", \" - CloudFormation stack creation events (**EventSource: cloudformation.amazonaws.com**, **EventName: Create\\\\*** ) represent API calls initiating the provisioning of AWS infrastructure and resources via CloudFormation templates. These events in CloudTrail help SREs monitor the start of environment setups and infrastructure deployments as part of Infrastructure as Code workflows.\\n\\n**Purpose:** Track and audit when new CloudFormation stacks or stack components are being created, enabling visibility into changes in infrastructure state and deployment activities.\\n\\n**Alert Thresholds:**  \\n- Trigger an alert if the number of Create* events exceeds a baseline threshold within a short time window (e.g., >10 stack creation attempts in 5 minutes), which may indicate automated deployment loops, misconfigurations, or potential security incidents.  \\n- Alert if Create* events spike unexpectedly outside of scheduled deployment windows or change management periods.\\n\\n**Impact of Values:**  \\n- **High volume:** May signal rapid infrastructure changes that could lead to instability, resource contention, or deployment failures. It could also indicate unauthorized or accidental mass provisioning.  \\n- **Low or zero volume:** Normal during steady-state operations; however, a sudden drop during expected deployment windows might indicate pipeline failures or blocked deployments.\\n\\n**Example Usage:**  \\n- **Dashboard:** Visualize the count of CloudFormation Create* events over time, segmented by stack name or user identity, to correlate deployments with system performance or incidents.  \\n- **Alert Rule:**  \\n  ```  \\n  WHEN count(events where EventSource=\\\"cloudformation.amazonaws.com\\\" AND EventName LIKE \\\"Create%\\\") > 10 within 5 minutes  \\n  THEN trigger alert \\\"High rate of CloudFormation stack creation events detected\\\"  \\n  ```  \\nThis enables proactive detection of abnormal infrastructure provisioning activity and supports rapid investigation and response.\", \" - CloudFormation stack update events (**EventSource**: \\\"cloudformation.amazonaws.com\\\", **EventName**: \\\"Update*\\\") capture all modifications to AWS CloudFormation stacks, including infrastructure changes, resource additions/removals, and configuration updates. These events are critical for tracking infrastructure evolution and ensuring change management compliance.\\n\\n**Purpose:**  \\nThey provide visibility into when and how infrastructure is altered via CloudFormation, enabling SREs to audit changes, detect unauthorized or unexpected updates, and correlate incidents with recent deployments.\\n\\n**Alert Threshold Guidance:**  \\n- Trigger alerts on unusually high frequencies of update events within a short time window (e.g., >5 updates in 10 minutes), which may indicate automation loops, deployment failures, or misconfigurations.  \\n- Alert on failed or rollback update events to quickly identify deployment issues impacting system stability.\\n\\n**Impact of Values:**  \\n- **High volume of updates:** May signal instability, rapid iterative deployments, or potential automation errors, increasing risk of outages or configuration drift.  \\n- **Low or zero updates:** Normal during stable periods but prolonged absence of updates might indicate stalled deployments or lack of infrastructure changes.\\n\\n**Example Usage:**  \\n- **Dashboard:** Display a time-series graph of CloudFormation Update* events per hour, highlighting failed updates in red.  \\n- **Alert Rule:** Trigger an alert if the count of UpdateStack events exceeds 5 within 10 minutes or if any update event has a status of FAILED or ROLLBACK_COMPLETE, enabling rapid response to deployment issues.\", \" - Lambda function \\\"Put*\\\" events in CloudTrail capture changes to function configurations, concurrency settings, event source mappings, and resource provisioning. These events indicate updates or deployments that can affect function behavior and performance. An SRE should monitor the frequency and success of these operations; unusually high rates of \\\"Put*\\\" events may signal automation errors or configuration churn, while absence of expected updates could indicate deployment issues. Alert thresholds might include more than 5 \\\"Put*\\\" events within 5 minutes or failed update attempts exceeding 10% of total \\\"Put*\\\" events. High volumes can lead to inconsistent function states or throttling, impacting availability and latency; low update activity during active development phases may delay critical fixes or optimizations. For example, a dashboard widget can track the count of \\\"Put*\\\" events per hour alongside error rates, and an alert rule could trigger when the number of failed \\\"Put*\\\" events surpasses a set threshold, prompting investigation into deployment or configuration problems.\", \" - Resource listing operations (events with names starting with \\\"List\\\") in CloudTrail capture API calls that enumerate or retrieve metadata about cloud resources across services (e.g., ListBuckets, ListInstances). These events help SREs monitor inventory changes, detect unusual enumeration activity, and maintain infrastructure visibility. \\n\\n**Purpose:** Track and audit resource discovery actions to identify potential reconnaissance or automation behaviors.\\n\\n**Alert Threshold:** Trigger alerts when the rate of List* events exceeds a baseline by 3x within a 5-minute window, indicating possible automated scanning or misconfigured scripts.\\n\\n**Impact:**  \\n- **High values:** May signal excessive resource enumeration, potentially due to unauthorized scanning, automation loops, or misconfigured monitoring tools, increasing API costs and risk exposure.  \\n- **Low values:** Could indicate loss of visibility or failures in inventory processes, risking outdated infrastructure awareness.\\n\\n**Example Alert Rule:**  \\n`IF count(List*) > 300 events in 5 minutes THEN alert \\\"High resource enumeration activity detected\\\"`  \\n\\n**Dashboard Use:** Visualize List* event counts over time alongside other API calls to correlate spikes with deployments or incidents, aiding in capacity planning and anomaly detection.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": true,
                        "score": 0.9,
                        "reason": "The retrieval context directly addresses the question by explaining that high volumes of CloudFormation stack update events may indicate instability or automation errors, aligning well with the input's focus. The description is clear, detailed, and concise, covering what is measured (update events), relevant units (event counts within time windows), context (infrastructure changes, deployment monitoring), and implications (risk of outages, configuration drift). It also provides alert thresholds and example usage, enhancing utility for answering the monitoring question. The only minor shortcoming is the lack of explicit mention of how to distinguish between normal rapid deployments and problematic automation errors, preventing a perfect score.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Compare the Input (monitoring question) with the Retrieval Context (metric description) to assess if the description directly addresses the question's focus.\",\n    \"Evaluate Clarity by determining if the description is understandable and concise, making it easy to comprehend in relation to the question asked.\",\n    \"Assess Coverage by checking if the description explains what is measured, the measurement units, relevant context, and implications necessary to answer the question.\",\n    \"Judge Utility by verifying if the description provides sufficient information to effectively answer the monitoring question, considering both Input and Retrieval Context together.\"\n] \n \nRubric:\nNone \n \nScore: 0.9"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Compare the Input (monitoring question) with the Retrieval Context (metric description) to assess if the description directly addresses the question's focus.",
                            "Evaluate Clarity by determining if the description is understandable and concise, making it easy to comprehend in relation to the question asked.",
                            "Assess Coverage by checking if the description explains what is measured, the measurement units, relevant context, and implications necessary to answer the question.",
                            "Judge Utility by verifying if the description provides sufficient information to effectively answer the monitoring question, considering both Input and Retrieval Context together."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"glue.amazonaws.com\\\", \\\"EventName\\\": \\\"*\\\"}\", \"hyperparameters\": null, \"input\": \"Are there any failed or cancelled AWS Glue ETL jobs indicating a potential issue with data processing?\", \"retrieval_context\": [\" - EMR cluster events captured by CloudTrail provide detailed records of actions and changes within Amazon EMR, including cluster creation, modification, scaling, and termination. These events enable SREs to monitor the health and lifecycle of big data processing jobs and Hadoop ecosystem workflows. \\n\\n**Purpose:** Track operational changes and anomalies in EMR clusters to ensure data processing pipelines run smoothly and to quickly identify failures or misconfigurations.\\n\\n**Alert Thresholds:**  \\n- Alert on unexpected cluster terminations or failures (e.g., `TerminateJobFlows` or `RunJobFlow` failures).  \\n- Alert if cluster scaling events occur too frequently within a short time window, indicating instability.  \\n- Alert on prolonged cluster startup or shutdown times exceeding defined SLAs.\\n\\n**Impact:**  \\n- High frequency of failure or termination events may indicate systemic issues causing job interruptions or data loss.  \\n- Low or no cluster activity during expected processing windows could signal pipeline stalls or misconfigurations.  \\n- Frequent scaling events might degrade performance or increase costs unnecessarily.\\n\\n**Example Alert Rule:**  \\nTrigger an alert if more than 3 `TerminateJobFlows` events occur within 1 hour, or if a cluster remains in `Starting` state for over 15 minutes without transitioning to `Running`.  \\n\\n**Dashboard Use:**  \\nVisualize event counts over time by event name (e.g., `RunJobFlow`, `AddInstanceGroups`, `TerminateJobFlows`) alongside cluster status metrics to correlate operational events with cluster health and job success rates.\", \" - Redshift cluster creation events in CloudTrail capture all API calls initiating the provisioning of new Redshift clusters (e.g., CreateCluster). These events indicate when new data warehouse resources are being deployed or configured, impacting capacity and cost.  \\n**Purpose:** Enables SREs to monitor and audit cluster provisioning activities for operational control and security compliance.  \\n**Alert Threshold:** Trigger alerts on an unusually high number of cluster creation events within a short time window (e.g., >3 creates in 1 hour), which may indicate automation errors, misconfigurations, or unauthorized resource provisioning.  \\n**Impact:**  \\n- **High values:** May lead to resource sprawl, increased costs, and potential performance degradation due to over-provisioning. Could also signal security risks if unexpected clusters are created.  \\n- **Low or zero values:** Normal in stable environments; no new clusters being created means stable infrastructure.  \\n**Example Alert Rule:**  \\n\\u201cAlert if count of events with EventSource='redshift.amazonaws.com' and EventName starting with 'Create' exceeds 3 within 60 minutes.\\u201d  \\n**Dashboard Use:** Visualize the frequency of Redshift cluster creation events over time to detect spikes or anomalies, correlating with deployment activities or security incidents.\", \" - This pattern captures ECS deletion events recorded in CloudTrail, specifically any API calls starting with \\\"Delete\\\" from the ECS service (e.g., DeleteCluster, DeleteService, DeleteTaskSet). Its purpose is to monitor when ECS resources are removed, which can signal intentional cleanup or unintended disruptions affecting service availability.\\n\\n**Threshold guidance:**  \\n- Trigger an alert if the number of ECS deletion events exceeds a baseline threshold within a short time window (e.g., more than 3 Delete* events in 5 minutes), as this may indicate accidental mass deletion or a security incident.  \\n- Low or expected deletion rates typically reflect routine maintenance or scaling down of resources and generally have minimal impact.\\n\\n**Impact:**  \\n- High deletion event counts can lead to service downtime, loss of running tasks, or cluster instability, requiring immediate investigation.  \\n- Low or zero deletion events usually indicate stable ECS resource management.\\n\\n**Example alert rule:**  \\n- Alert when `count(events where EventSource=\\\"ecs.amazonaws.com\\\" and EventName starts with \\\"Delete\\\") > 3` within 5 minutes.  \\n- This alert can be visualized on a dashboard showing ECS Delete* event counts over time, helping SREs quickly identify unusual spikes and correlate with service health metrics.\", \" - This pattern captures Elastic Load Balancing (ELB) target deregistration events from CloudTrail, indicating when backend targets (such as EC2 instances or IP addresses) are removed from a load balancer. These events typically occur during scaling operations, deployments, or maintenance activities that affect service availability.\\n\\n**Purpose:**  \\nMonitoring deregistration events helps SREs track changes in load balancer target groups, ensuring that scaling or maintenance actions do not inadvertently reduce capacity or cause service disruptions.\\n\\n**Alert Threshold Guidance:**  \\n- Trigger an alert if the number of deregistration events exceeds a defined threshold within a short time window (e.g., more than 5 deregistrations within 5 minutes), which may indicate unexpected or excessive target removals.  \\n- Conversely, a prolonged absence of deregistration events during expected scaling periods might signal issues with autoscaling or deployment processes.\\n\\n**Impact of Values:**  \\n- **High deregistration rate:** Could lead to reduced backend capacity, increased latency, or service outages if targets are removed too quickly or unexpectedly. Immediate investigation is warranted.  \\n- **Low or no deregistration events:** May indicate stable operations or, if scaling is expected, potential failures in scaling mechanisms.\\n\\n**Example Alert Rule:**  \\n```\\nWHEN count of events WHERE EventSource = \\\"elasticloadbalancing.amazonaws.com\\\" AND EventName LIKE \\\"Deregister%\\\"  \\nIN last 5 minutes > 5  \\nTHEN trigger alert \\\"High ELB Target Deregistration Rate\\\"\\n```\\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of deregistration events per minute, overlaid with thresholds, to visualize spikes or drops in deregistration activity aligned with deployment or scaling events.\", \" - Tracks all AWS Glue ETL job events, including job start, success, failure, and state changes. Measures the execution status and lifecycle of data processing and transformation workflows. Events are recorded as discrete state change notifications without quantitative units. Enables monitoring and management of Glue job performance and pipeline execution.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": false,
                        "score": 0.5575557827614613,
                        "reason": "The input question is clear and concise, directly asking about failed or cancelled AWS Glue ETL jobs as indicators of data processing issues. The retrieval context includes a relevant description of AWS Glue ETL job events, covering event types, execution status, and lifecycle, but lacks explicit mention of failure or cancellation metrics or alert thresholds specific to these states. This limits full coverage and utility, as the description does not provide enough detail to confidently answer the monitoring question about failures or cancellations. Additionally, the retrieval context includes unrelated event patterns (EMR, ELB, ECS, Redshift) that do not align with the input question, introducing ambiguity and reducing relevance.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Evaluate the clarity of the Input by checking if both the metric description and the monitoring question are understandable and concise in relation to each other.\",\n    \"Assess the coverage by verifying that the description sufficiently explains what is measured, the units, context, and implications so as to fully address the monitoring question (Retrieval Context).\",\n    \"Determine the utility by confirming that the description provides enough information to directly answer the monitoring question with confidence.\",\n    \"Compare the Input and Retrieval Context to ensure consistency and relevance, noting any gaps or ambiguities that could hinder interpreting the description in the context of the question.\"\n] \n \nRubric:\nNone \n \nScore: 0.5575557827614613"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Evaluate the clarity of the Input by checking if both the metric description and the monitoring question are understandable and concise in relation to each other.",
                            "Assess the coverage by verifying that the description sufficiently explains what is measured, the units, context, and implications so as to fully address the monitoring question (Retrieval Context).",
                            "Determine the utility by confirming that the description provides enough information to directly answer the monitoring question with confidence.",
                            "Compare the Input and Retrieval Context to ensure consistency and relevance, noting any gaps or ambiguities that could hinder interpreting the description in the context of the question."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"detective.amazonaws.com\\\", \\\"EventName\\\": \\\"*\\\"}\", \"hyperparameters\": null, \"input\": \"Does a spike in Detective security investigation events indicate an active threat or potential security breach?\", \"retrieval_context\": [\" - Detective security investigation events capture detailed activity logs related to threat analysis, security incident investigations, and behavioral analytics within AWS Detective. These events help SREs monitor and correlate security forensics and threat intelligence to identify suspicious or anomalous behavior in the environment.\\n\\n**Purpose in CloudTrail:**  \\nEvents from `detective.amazonaws.com` provide visibility into investigative actions and findings performed by AWS Detective, enabling tracking of security-related activities and potential threat escalations.\\n\\n**Alert Threshold Guidance:**  \\n- Trigger alerts when the volume of Detective investigation events spikes significantly above baseline (e.g., a 3x increase in investigative queries or findings within a short time window), indicating potential active threat hunting or incident response.  \\n- Alert on unusual event types or repeated failed investigation attempts that may suggest misuse or compromised credentials.\\n\\n**Impact of Values:**  \\n- **High event volume:** May indicate active security incidents, ongoing investigations, or potential security breaches requiring immediate attention.  \\n- **Low or no events:** Could suggest normal operation or lack of active investigations; however, a sudden drop after a period of activity might also warrant review.\\n\\n**Example Alert Rule:**  \\n```\\nWHEN count(detective.amazonaws.com EventName=*) OVER 15 minutes > 3 * baseline_average THEN alert \\\"Unusual Detective investigation activity detected\\\"\\n```\\n\\n**Example Dashboard Widget:**  \\n- A time-series graph showing the count of Detective events per minute, annotated with alerts on spikes.  \\n- A table listing top EventNames and their frequencies to identify unusual investigative patterns.\", \" - Macie data discovery events in CloudTrail capture detailed records of sensitive data identification and classification activities performed by Amazon Macie. These events help monitor the discovery of Personally Identifiable Information (PII), data loss risks, and compliance with privacy regulations. An SRE can use these events to track when Macie detects sensitive data or policy violations, enabling proactive data governance and security posture management.\\n\\n**Alert Thresholds:**  \\n- Trigger alerts when the number of sensitive data findings exceeds a predefined threshold within a given time window (e.g., > 10 new PII findings in 1 hour).  \\n- Alert on sudden spikes or unusual patterns in data classification events that may indicate data exfiltration or misconfiguration.\\n\\n**Impact of Values:**  \\n- **High values:** A surge in sensitive data findings may indicate increased exposure of PII or potential data leaks, requiring immediate investigation.  \\n- **Low or zero values:** May indicate normal operation or, conversely, that Macie scanning is not running correctly, potentially missing critical data.\\n\\n**Example Usage:**  \\n- **Dashboard:** Visualize the count of Macie findings over time, segmented by severity or data type, to monitor trends and identify anomalies.  \\n- **Alert Rule:**  \\n  ```\\n  WHEN count(maciedata.findings) > 10 WITHIN 1 hour  \\n  THEN trigger alert \\\"High number of sensitive data findings detected by Macie\\\"\\n  ```\", \" - This pattern captures AWS KMS Decrypt API calls recorded in CloudTrail, indicating when encrypted data is accessed and decrypted using KMS keys. It helps SREs monitor data access events for security auditing and anomaly detection. A sudden spike in Decrypt events may signal unusual or unauthorized data access, while consistently low or expected volumes suggest normal operation. As a threshold, alerting on a sustained increase exceeding 3 standard deviations above the historical average or a sudden burst of Decrypt calls within a short time window (e.g., 5 minutes) is recommended. For example, an alert rule could trigger when the count of Decrypt events exceeds 100 in 5 minutes, indicating potential data exfiltration or misuse. In dashboards, tracking the rate of Decrypt events over time alongside user identities and key IDs can help quickly identify suspicious patterns or compromised credentials.\", \" - This pattern captures AWS KMS encryption API calls (e.g., Encrypt, EncryptData) recorded in CloudTrail, indicating when data is being encrypted using customer-managed or AWS-managed KMS keys. It helps SREs monitor cryptographic operations to ensure data protection policies are enforced and to detect unusual encryption activity that could signal misuse or security incidents.\\n\\n**Purpose:** Track the frequency and context of encryption operations to verify normal application behavior and compliance with data security standards.\\n\\n**Alert Threshold:** Trigger an alert if the number of Encrypt* events exceeds a baseline threshold (e.g., a sudden spike beyond 3 standard deviations from the average hourly rate) or if encryption requests originate from unexpected principals or regions.\\n\\n**Impact of Values:**  \\n- **High volume:** May indicate increased data processing, potential automated encryption loops, or unauthorized bulk encryption attempts, which could impact performance or signal a security breach.  \\n- **Low or zero volume:** Could suggest application issues, disabled encryption, or misconfigured services failing to encrypt data as required, risking data exposure.\\n\\n**Example Alert Rule:**  \\nAlert when Encrypt* events exceed 500 per hour or when encryption requests come from an unrecognized IAM role, triggering an investigation into possible misuse or operational anomalies.\\n\\n**Dashboard Use:**  \\nVisualize Encrypt* event counts over time alongside related Decrypt* events and key usage metrics to correlate encryption activity with application workloads and detect deviations from normal patterns.\", \" - This pattern detects Secrets Manager creation events in CloudTrail, specifically any API calls starting with \\\"Create\\\" (e.g., CreateSecret). It helps SREs monitor when new secrets, secret versions, or related configurations are added, which could indicate deployment changes or potential security risks.  \\n**Alert threshold:** Trigger an alert if the number of create events exceeds a baseline (e.g., more than 5 creates within 10 minutes), as a sudden spike may signal unauthorized secret creation or misconfiguration. Conversely, zero create events over an extended period in an active environment might indicate issues with deployment pipelines or automation failures.  \\n**Impact:**  \\n- High values: Could indicate potential security breaches, unauthorized secret provisioning, or rapid environment changes requiring immediate investigation.  \\n- Low values: May suggest stalled deployments or automation problems, potentially delaying application updates or secret rotations.  \\n**Example usage:**  \\nIn a dashboard, plot the count of Secrets Manager Create* events over time to visualize spikes. An alert rule could be:  \\n`WHEN count(secretsmanager.amazonaws.com Create* events) > 5 within 10 minutes THEN trigger alert \\\"Unusual Secrets Creation Activity\\\"`  \\nThis enables proactive detection of abnormal secret creation activity, helping maintain security and operational stability.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": false,
                        "score": 0.7915353379215968,
                        "reason": "The input question effectively targets the key metric of Detective security investigation events and their implication for active threats or breaches, aligning well with the Retrieval Context's detailed explanation of event purpose, alert thresholds, and impact. The description is clear and concise, using terminology consistent with the context, enabling users to understand what is measured and why spikes matter. However, it could be improved by explicitly mentioning alert thresholds or example rules from the context to enhance utility and coverage, ensuring users can directly link spikes to actionable monitoring steps.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Compare the Input metric description against the Retrieval Context to assess if the description covers all necessary details (what is measured, units, context, and implications) relevant to the monitoring question.\",\n    \"Evaluate how clearly the description is written by checking for conciseness and understandability in relation to the specific terminology and data expected from the Retrieval Context.\",\n    \"Determine if the description provides sufficient utility by confirming whether it enables a user to effectively answer the provided monitoring question based on the information present in the Retrieval Context.\",\n    \"If any evaluation aspect (clarity, coverage, utility) is weak when comparing Input with Retrieval Context, note specific gaps and suggest targeted improvements to enhance alignment between the description and the monitoring goal.\"\n] \n \nRubric:\nNone \n \nScore: 0.7915353379215968"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Compare the Input metric description against the Retrieval Context to assess if the description covers all necessary details (what is measured, units, context, and implications) relevant to the monitoring question.",
                            "Evaluate how clearly the description is written by checking for conciseness and understandability in relation to the specific terminology and data expected from the Retrieval Context.",
                            "Determine if the description provides sufficient utility by confirming whether it enables a user to effectively answer the provided monitoring question based on the information present in the Retrieval Context.",
                            "If any evaluation aspect (clarity, coverage, utility) is weak when comparing Input with Retrieval Context, note specific gaps and suggest targeted improvements to enhance alignment between the description and the monitoring goal."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"elasticmapreduce.amazonaws.com\\\", \\\"EventName\\\": \\\"*\\\"}\", \"hyperparameters\": null, \"input\": \"Do unexpected cluster terminations or failures, such as 'TerminateJobFlows' or 'RunJobFlow' failures, exceed the defined alert threshold?\", \"retrieval_context\": [\" - CloudFormation Delete* events in CloudTrail indicate the initiation or completion of stack deletion operations, signaling infrastructure teardown and resource decommissioning activities. These events help SREs monitor environment lifecycle changes and ensure that deletions are intentional and controlled. \\n\\n**Alert Threshold:** Trigger an alert if the number of Delete* events exceeds a predefined baseline (e.g., more than 3 deletions within 1 hour) or occurs unexpectedly outside of scheduled maintenance windows, as this may indicate accidental or malicious infrastructure removal.\\n\\n**Impact of Values:**  \\n- **High frequency:** May lead to unintended service disruptions, data loss, or compliance risks due to rapid or bulk resource deletions. Requires immediate investigation.  \\n- **Low or zero frequency:** Normal in stable environments; indicates no recent stack deletions and stable infrastructure.\\n\\n**Example Usage:**  \\nCreate a dashboard widget tracking the count of CloudFormation Delete* events over time. Set an alert rule to notify the SRE team if Delete* events spike above the threshold within a rolling 1-hour window, enabling prompt response to potential infrastructure teardown incidents.\", \" - EMR cluster events captured by CloudTrail provide detailed records of actions and changes within Amazon EMR, including cluster creation, modification, scaling, and termination. These events enable SREs to monitor the health and lifecycle of big data processing jobs and Hadoop ecosystem workflows. \\n\\n**Purpose:** Track operational changes and anomalies in EMR clusters to ensure data processing pipelines run smoothly and to quickly identify failures or misconfigurations.\\n\\n**Alert Thresholds:**  \\n- Alert on unexpected cluster terminations or failures (e.g., `TerminateJobFlows` or `RunJobFlow` failures).  \\n- Alert if cluster scaling events occur too frequently within a short time window, indicating instability.  \\n- Alert on prolonged cluster startup or shutdown times exceeding defined SLAs.\\n\\n**Impact:**  \\n- High frequency of failure or termination events may indicate systemic issues causing job interruptions or data loss.  \\n- Low or no cluster activity during expected processing windows could signal pipeline stalls or misconfigurations.  \\n- Frequent scaling events might degrade performance or increase costs unnecessarily.\\n\\n**Example Alert Rule:**  \\nTrigger an alert if more than 3 `TerminateJobFlows` events occur within 1 hour, or if a cluster remains in `Starting` state for over 15 minutes without transitioning to `Running`.  \\n\\n**Dashboard Use:**  \\nVisualize event counts over time by event name (e.g., `RunJobFlow`, `AddInstanceGroups`, `TerminateJobFlows`) alongside cluster status metrics to correlate operational events with cluster health and job success rates.\", \" - Redshift cluster creation events in CloudTrail capture all API calls initiating the provisioning of new Redshift clusters (e.g., CreateCluster). These events indicate when new data warehouse resources are being deployed or configured, impacting capacity and cost.  \\n**Purpose:** Enables SREs to monitor and audit cluster provisioning activities for operational control and security compliance.  \\n**Alert Threshold:** Trigger alerts on an unusually high number of cluster creation events within a short time window (e.g., >3 creates in 1 hour), which may indicate automation errors, misconfigurations, or unauthorized resource provisioning.  \\n**Impact:**  \\n- **High values:** May lead to resource sprawl, increased costs, and potential performance degradation due to over-provisioning. Could also signal security risks if unexpected clusters are created.  \\n- **Low or zero values:** Normal in stable environments; no new clusters being created means stable infrastructure.  \\n**Example Alert Rule:**  \\n\\u201cAlert if count of events with EventSource='redshift.amazonaws.com' and EventName starting with 'Create' exceeds 3 within 60 minutes.\\u201d  \\n**Dashboard Use:** Visualize the frequency of Redshift cluster creation events over time to detect spikes or anomalies, correlating with deployment activities or security incidents.\", \" - This pattern captures CloudWatch API operations that list resources, such as metrics, log groups, and alarms, as recorded in CloudTrail under EventSource \\\"cloudwatch.amazonaws.com\\\" with EventNames starting with \\\"List\\\". It helps SREs monitor enumeration activity on CloudWatch resources, which can indicate normal operational queries or potential reconnaissance by unauthorized users.\\n\\n**Purpose:**  \\nTo track and analyze the frequency of CloudWatch resource listing actions, enabling detection of unusual spikes that may signal automated scanning, misconfigurations, or security incidents.\\n\\n**Threshold Guidance:**  \\nSet alert thresholds based on baseline activity for your environment. For example, trigger an alert if the number of List* events exceeds 3 standard deviations above the daily average or if more than 100 list operations occur within a 5-minute window, indicating abnormal enumeration.\\n\\n**Impact of Values:**  \\n- **High values:** May indicate excessive or automated querying of CloudWatch resources, potentially revealing reconnaissance attempts or inefficient scripts causing performance overhead.  \\n- **Low values:** Typically normal, but a sudden drop could suggest issues with monitoring tools or API access problems.\\n\\n**Example Alert Rule:**  \\nTrigger an alert when the count of CloudWatch List* events in CloudTrail exceeds 100 within 5 minutes, signaling potential unauthorized or excessive enumeration activity.\\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of CloudWatch List* events per 5-minute interval, overlaid with the alert threshold line, to visualize normal versus anomalous listing activity.\", \" - This pattern captures all deletion events related to Elastic Load Balancers (ELBs) in AWS, as recorded by CloudTrail under the event source \\\"elasticloadbalancing.amazonaws.com\\\" with event names starting with \\\"Delete\\\". Its primary purpose is to monitor when ELBs are removed, which can be part of routine cleanup or indicate unintended service disruptions due to the loss of load balancing resources.\\n\\n**Purpose:**  \\nSREs use this pattern to track ELB deletions to quickly detect and investigate potential impacts on application availability and traffic routing.\\n\\n**Alert Threshold:**  \\nAn alert should be triggered if the number of ELB deletion events exceeds a predefined threshold within a short time window\\u2014for example, more than 1 deletion event within 5 minutes\\u2014since multiple deletions in quick succession may indicate a misconfiguration, automation error, or malicious activity.\\n\\n**Impact of Values:**  \\n- **High values:** Frequent or bulk ELB deletions can cause significant service disruption, leading to downtime or degraded performance due to loss of traffic distribution. Immediate investigation and remediation are required.  \\n- **Low values:** Occasional single deletions may be expected during normal maintenance or scaling operations and typically do not require urgent action but should still be logged for audit purposes.\\n\\n**Example Usage:**  \\nIn a monitoring dashboard or alert rule, you might configure a query to count ELB deletion events over a rolling 5-minute window and trigger an alert if the count exceeds 1. For example:\\n\\n```\\ncount_over_time({EventSource=\\\"elasticloadbalancing.amazonaws.com\\\", EventName=~\\\"Delete.*\\\"}[5m]) > 1\\n```\\n\\nThis alert helps ensure that unexpected or excessive ELB deletions are promptly detected and addressed to maintain service reliability.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": true,
                        "score": 0.8985936375048753,
                        "reason": "The description directly addresses the monitoring question about unexpected cluster terminations or failures, specifically referencing 'TerminateJobFlows' and 'RunJobFlow' failures. It clearly explains what is measured (EMR cluster events via CloudTrail), includes alert thresholds, impact, and example alert rules, providing sufficient detail and context. The description is clear, concise, and enables confident monitoring of the specified failures. Minor deduction is due to the lack of explicit units for the metrics, though the time windows and event counts are well specified.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Compare the Input (metric description) to the Retrieval Context (monitoring question) to assess if the description directly addresses the question asked.\",\n    \"Evaluate the description's clarity by checking if it is understandable and concise while providing enough detail for the specific question context.\",\n    \"Assess coverage by verifying if the description explains what is measured, including units, context, and potential implications relevant to the retrieval question.\",\n    \"Determine the utility by judging whether the description enables a user to confidently answer the monitoring question, identifying gaps where the input and context do not align.\"\n] \n \nRubric:\nNone \n \nScore: 0.8985936375048753"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Compare the Input (metric description) to the Retrieval Context (monitoring question) to assess if the description directly addresses the question asked.",
                            "Evaluate the description's clarity by checking if it is understandable and concise while providing enough detail for the specific question context.",
                            "Assess coverage by verifying if the description explains what is measured, including units, context, and potential implications relevant to the retrieval question.",
                            "Determine the utility by judging whether the description enables a user to confidently answer the monitoring question, identifying gaps where the input and context do not align."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"states.amazonaws.com\\\", \\\"EventName\\\": \\\"*\\\"}\", \"hyperparameters\": null, \"input\": \"Are there any unusual workflow executions or state transitions being triggered by this API call?\", \"retrieval_context\": [\" - CloudFormation stack creation events (**EventSource: cloudformation.amazonaws.com**, **EventName: Create\\\\*** ) represent API calls initiating the provisioning of AWS infrastructure and resources via CloudFormation templates. These events in CloudTrail help SREs monitor the start of environment setups and infrastructure deployments as part of Infrastructure as Code workflows.\\n\\n**Purpose:** Track and audit when new CloudFormation stacks or stack components are being created, enabling visibility into changes in infrastructure state and deployment activities.\\n\\n**Alert Thresholds:**  \\n- Trigger an alert if the number of Create* events exceeds a baseline threshold within a short time window (e.g., >10 stack creation attempts in 5 minutes), which may indicate automated deployment loops, misconfigurations, or potential security incidents.  \\n- Alert if Create* events spike unexpectedly outside of scheduled deployment windows or change management periods.\\n\\n**Impact of Values:**  \\n- **High volume:** May signal rapid infrastructure changes that could lead to instability, resource contention, or deployment failures. It could also indicate unauthorized or accidental mass provisioning.  \\n- **Low or zero volume:** Normal during steady-state operations; however, a sudden drop during expected deployment windows might indicate pipeline failures or blocked deployments.\\n\\n**Example Usage:**  \\n- **Dashboard:** Visualize the count of CloudFormation Create* events over time, segmented by stack name or user identity, to correlate deployments with system performance or incidents.  \\n- **Alert Rule:**  \\n  ```  \\n  WHEN count(events where EventSource=\\\"cloudformation.amazonaws.com\\\" AND EventName LIKE \\\"Create%\\\") > 10 within 5 minutes  \\n  THEN trigger alert \\\"High rate of CloudFormation stack creation events detected\\\"  \\n  ```  \\nThis enables proactive detection of abnormal infrastructure provisioning activity and supports rapid investigation and response.\", \" - CodeDeploy events in CloudTrail capture API calls made to the AWS CodeDeploy service (EventSource: \\\"codedeploy.amazonaws.com\\\") across all event names (EventName: \\\"*\\\"). These events provide detailed records of deployment lifecycle actions such as creating, updating, starting, stopping, and deleting deployments, deployment groups, and applications. The data source is the AWS CodeDeploy API, and each event includes metadata like timestamps, user identity, deployment IDs, status changes, and error messages. Metrics derived from these events typically count the number of deployment-related API calls or track deployment status transitions over time (units: count of events or status occurrences). Unusual values\\u2014such as a sudden spike in failed deployment events, unexpected deployment cancellations, or unauthorized API calls\\u2014should trigger alerts as they may indicate deployment issues, configuration errors, or potential security incidents requiring immediate investigation.\", \" - This event source captures all API calls made to AWS Step Functions (states.amazonaws.com). It records operations related to state machines, including workflow executions, state transitions, and management actions. Each event measures the occurrence of a specific Step Functions API call, logged as a discrete event without a unit of measurement. This enables monitoring and auditing of workflow orchestration and execution activities.\", \" - This pattern captures all modification events related to EC2 resources in AWS CloudTrail, triggered by any API calls starting with \\\"Modify\\\" (e.g., ModifyInstanceAttribute, ModifyNetworkInterfaceAttribute). Its purpose is to monitor changes to critical EC2 configurations such as instance attributes, security group rules, and network settings, which can directly impact system security, availability, and performance.\\n\\n**Threshold guidance:**  \\n- Alert when the number of Modify* events exceeds a baseline threshold (e.g., more than 5 modifications within 10 minutes), indicating unusual or potentially unauthorized changes.  \\n- A sudden spike in modification events may signal misconfigurations, automation errors, or security incidents like privilege escalation or lateral movement.\\n\\n**Impact of values:**  \\n- **High frequency:** Could indicate active troubleshooting, automated scaling/configuration changes, or suspicious activity requiring immediate investigation.  \\n- **Low or zero frequency:** Normal steady state; no unexpected modifications detected.\\n\\n**Example alert rule:**  \\nTrigger an alert if the count of events matching {\\\"EventSource\\\": \\\"ec2.amazonaws.com\\\", \\\"EventName\\\": \\\"Modify*\\\"} exceeds 5 within a rolling 10-minute window.\\n\\n**Example dashboard widget:**  \\nA time-series graph showing the count of EC2 Modify* events per 5-minute interval, overlaid with a threshold line at 5 events, enabling quick identification of abnormal modification activity.\", \" - This pattern detects Secrets Manager creation events in CloudTrail, specifically any API calls starting with \\\"Create\\\" (e.g., CreateSecret). It helps SREs monitor when new secrets, secret versions, or related configurations are added, which could indicate deployment changes or potential security risks.  \\n**Alert threshold:** Trigger an alert if the number of create events exceeds a baseline (e.g., more than 5 creates within 10 minutes), as a sudden spike may signal unauthorized secret creation or misconfiguration. Conversely, zero create events over an extended period in an active environment might indicate issues with deployment pipelines or automation failures.  \\n**Impact:**  \\n- High values: Could indicate potential security breaches, unauthorized secret provisioning, or rapid environment changes requiring immediate investigation.  \\n- Low values: May suggest stalled deployments or automation problems, potentially delaying application updates or secret rotations.  \\n**Example usage:**  \\nIn a dashboard, plot the count of Secrets Manager Create* events over time to visualize spikes. An alert rule could be:  \\n`WHEN count(secretsmanager.amazonaws.com Create* events) > 5 within 10 minutes THEN trigger alert \\\"Unusual Secrets Creation Activity\\\"`  \\nThis enables proactive detection of abnormal secret creation activity, helping maintain security and operational stability.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": false,
                        "score": 0.7055719077990498,
                        "reason": "The description is generally clear and relates to monitoring API calls triggering workflow executions and state transitions in AWS Step Functions, aligning with the retrieval context. However, it lacks explicit details on units, measurement methods, and specific alert thresholds, which are present in the context for other services. This limits coverage and utility, as it does not fully explain how unusual executions or transitions are quantified or detected, reducing its effectiveness for answering the monitoring question comprehensively.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Compare the Input metric description to the Retrieval Context to assess clarity: verify if the description is understandable, concise, and free of ambiguity in relation to the information available in the context.\",\n    \"Evaluate the coverage by checking if the description fully explains what is measured, including units, context, and implications, and confirm these align or complement the retrieval context provided.\",\n    \"Assess utility by determining if the description, when combined with the retrieval context, provides sufficient and relevant information to accurately answer the given monitoring question.\",\n    \"If any aspect scores below 8, identify specific missing details or unclear elements in the description relative to the retrieval context, and suggest precise improvements to enhance clarity, coverage, or utility.\"\n] \n \nRubric:\nNone \n \nScore: 0.7055719077990498"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Compare the Input metric description to the Retrieval Context to assess clarity: verify if the description is understandable, concise, and free of ambiguity in relation to the information available in the context.",
                            "Evaluate the coverage by checking if the description fully explains what is measured, including units, context, and implications, and confirm these align or complement the retrieval context provided.",
                            "Assess utility by determining if the description, when combined with the retrieval context, provides sufficient and relevant information to accurately answer the given monitoring question.",
                            "If any aspect scores below 8, identify specific missing details or unclear elements in the description relative to the retrieval context, and suggest precise improvements to enhance clarity, coverage, or utility."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"redshift.amazonaws.com\\\", \\\"EventName\\\": \\\"Create*\\\"}\", \"hyperparameters\": null, \"input\": \"Does an unusually high number of Redshift cluster creation events indicate automation errors, misconfigurations, or unauthorized resource provisioning?\", \"retrieval_context\": [\" - CloudFormation stack creation events (**EventSource: cloudformation.amazonaws.com**, **EventName: Create\\\\*** ) represent API calls initiating the provisioning of AWS infrastructure and resources via CloudFormation templates. These events in CloudTrail help SREs monitor the start of environment setups and infrastructure deployments as part of Infrastructure as Code workflows.\\n\\n**Purpose:** Track and audit when new CloudFormation stacks or stack components are being created, enabling visibility into changes in infrastructure state and deployment activities.\\n\\n**Alert Thresholds:**  \\n- Trigger an alert if the number of Create* events exceeds a baseline threshold within a short time window (e.g., >10 stack creation attempts in 5 minutes), which may indicate automated deployment loops, misconfigurations, or potential security incidents.  \\n- Alert if Create* events spike unexpectedly outside of scheduled deployment windows or change management periods.\\n\\n**Impact of Values:**  \\n- **High volume:** May signal rapid infrastructure changes that could lead to instability, resource contention, or deployment failures. It could also indicate unauthorized or accidental mass provisioning.  \\n- **Low or zero volume:** Normal during steady-state operations; however, a sudden drop during expected deployment windows might indicate pipeline failures or blocked deployments.\\n\\n**Example Usage:**  \\n- **Dashboard:** Visualize the count of CloudFormation Create* events over time, segmented by stack name or user identity, to correlate deployments with system performance or incidents.  \\n- **Alert Rule:**  \\n  ```  \\n  WHEN count(events where EventSource=\\\"cloudformation.amazonaws.com\\\" AND EventName LIKE \\\"Create%\\\") > 10 within 5 minutes  \\n  THEN trigger alert \\\"High rate of CloudFormation stack creation events detected\\\"  \\n  ```  \\nThis enables proactive detection of abnormal infrastructure provisioning activity and supports rapid investigation and response.\", \" - Redshift cluster creation events in CloudTrail capture all API calls initiating the provisioning of new Redshift clusters (e.g., CreateCluster). These events indicate when new data warehouse resources are being deployed or configured, impacting capacity and cost.  \\n**Purpose:** Enables SREs to monitor and audit cluster provisioning activities for operational control and security compliance.  \\n**Alert Threshold:** Trigger alerts on an unusually high number of cluster creation events within a short time window (e.g., >3 creates in 1 hour), which may indicate automation errors, misconfigurations, or unauthorized resource provisioning.  \\n**Impact:**  \\n- **High values:** May lead to resource sprawl, increased costs, and potential performance degradation due to over-provisioning. Could also signal security risks if unexpected clusters are created.  \\n- **Low or zero values:** Normal in stable environments; no new clusters being created means stable infrastructure.  \\n**Example Alert Rule:**  \\n\\u201cAlert if count of events with EventSource='redshift.amazonaws.com' and EventName starting with 'Create' exceeds 3 within 60 minutes.\\u201d  \\n**Dashboard Use:** Visualize the frequency of Redshift cluster creation events over time to detect spikes or anomalies, correlating with deployment activities or security incidents.\", \" - S3 bucket creation events captured by CloudTrail under **{\\\"EventSource\\\": \\\"s3.amazonaws.com\\\", \\\"EventName\\\": \\\"Create*\\\"}** indicate when new buckets or related resources (e.g., bucket policies, access points) are provisioned. These events help SREs monitor infrastructure changes that affect data storage, security posture, and compliance.\\n\\n**Purpose:**  \\nTrack and audit the creation of S3 buckets and associated configurations to ensure proper governance, prevent unauthorized resource sprawl, and maintain compliance with organizational policies.\\n\\n**Alert Threshold:**  \\nTrigger an alert if the number of S3 bucket creation events exceeds a defined threshold within a short time window (e.g., more than 5 bucket creations within 10 minutes), which may indicate automated provisioning errors, misconfigurations, or potential security incidents such as unauthorized resource creation.\\n\\n**Impact of Values:**  \\n- **High frequency:** May signal abnormal activity, such as a compromised credential or runaway automation scripts creating excessive buckets, leading to increased costs, security risks, or compliance violations.  \\n- **Low or zero frequency:** Normal in stable environments; however, sudden spikes should be investigated promptly.\\n\\n**Example Alert Rule:**  \\n\\u201cAlert when count of events with EventSource = 's3.amazonaws.com' and EventName starting with 'Create' exceeds 5 within 10 minutes.\\u201d\\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of S3 Create* events over time, with thresholds marked to highlight unusual spikes, enabling quick identification of abnormal bucket creation activity.\", \" - This pattern captures all AWS Systems Manager (SSM) resource creation events logged in CloudTrail, such as the creation of parameters, documents, and maintenance windows. It helps SREs monitor the provisioning of new SSM assets, which can indicate configuration changes or automation deployments.\\n\\n**Purpose:**  \\nTo detect when new SSM resources are created, enabling timely awareness of infrastructure changes that may affect system behavior or security posture.\\n\\n**Alert Threshold Guidance:**  \\nSet an alert threshold based on your environment\\u2019s baseline creation activity. For example, trigger an alert if more than 5 creation events occur within 10 minutes, which may indicate unexpected or unauthorized provisioning.\\n\\n**Impact of Values:**  \\n- **High values:** A spike in creation events could signal automated deployments, configuration drift, or potential security incidents such as unauthorized resource creation.  \\n- **Low or zero values:** Normal in stable environments; however, a sudden drop might indicate issues with deployment pipelines or monitoring gaps.\\n\\n**Example Alert Rule:**  \\nTrigger an alert when the count of events matching `{\\\"EventSource\\\": \\\"ssm.amazonaws.com\\\", \\\"EventName\\\": \\\"Create*\\\"}` exceeds 5 within a 10-minute window.\\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of SSM creation events over time, with thresholds marked to highlight unusual spikes, helping SREs quickly identify and investigate abnormal provisioning activity.\", \" - This pattern captures all creation events initiated through the Amazon EKS service, such as the creation of EKS clusters, node groups, and add-on components, as recorded in CloudTrail. It enables SREs to monitor when new Kubernetes infrastructure is provisioned, which can impact cluster capacity, security posture, and operational costs.\\n\\n**Purpose:**  \\nTo detect and track the provisioning of new EKS resources, helping teams respond promptly to unexpected or unauthorized cluster creations that may indicate misconfigurations or security risks.\\n\\n**Alert Threshold Guidance:**  \\nTrigger an alert if the number of EKS creation events exceeds a defined baseline within a short time window (e.g., more than 2 cluster or node group creations within 1 hour), as this may signal automated or unintended deployments. Conversely, an unusually low number of creation events over a longer period could indicate deployment pipeline issues or stalled infrastructure scaling.\\n\\n**Impact of Values:**  \\n- **High frequency:** May lead to resource sprawl, increased costs, or potential security vulnerabilities if clusters are created without proper governance.  \\n- **Low frequency:** Could reflect deployment failures or delays, impacting application availability or scalability.\\n\\n**Example Usage:**  \\nIn a monitoring dashboard, display a time series graph of EKS creation events filtered by this pattern to visualize provisioning trends. An alert rule might be:  \\n`WHEN count(events matching {\\\"EventSource\\\": \\\"eks.amazonaws.com\\\", \\\"EventName\\\": \\\"Create*\\\"}) > 2 within 1 hour THEN trigger alert \\\"Unusual EKS resource creation activity detected\\\"`  \\nThis helps SREs quickly identify and investigate abnormal cluster provisioning activities.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": true,
                        "score": 0.9,
                        "reason": "The input question clearly asks if an unusually high number of Redshift cluster creation events indicate automation errors, misconfigurations, or unauthorized provisioning. The retrieval context provides a clear, detailed, and concise description of the Redshift cluster creation events, including what is measured (API calls for cluster creation), units (event counts within time windows), relevant context (impact on capacity, cost, security), and implications (resource sprawl, security risks). It also includes alert thresholds and example alert rules directly addressing the question. The only minor shortcoming is the lack of explicit mention of automation errors in the impact section, though it is implied in the alert threshold and purpose. Overall, the description sufficiently covers the input question and provides actionable monitoring guidance.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Evaluate the Input (monitoring question) for clarity, ensuring it clearly defines the information needed to be answered by the metric description.\",\n    \"Assess the Retrieval Context (metric description) for clarity, checking if it is understandable and concise in explaining the metric.\",\n    \"Compare Input and Retrieval Context for coverage: confirm the description explains what is measured, the units used, relevant context, and implications to adequately address the question.\",\n    \"Evaluate utility by determining if the metric description provides sufficient information to directly answer the monitoring question; if not, identify specific missing details.\"\n] \n \nRubric:\nNone \n \nScore: 0.9"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Evaluate the Input (monitoring question) for clarity, ensuring it clearly defines the information needed to be answered by the metric description.",
                            "Assess the Retrieval Context (metric description) for clarity, checking if it is understandable and concise in explaining the metric.",
                            "Compare Input and Retrieval Context for coverage: confirm the description explains what is measured, the units used, relevant context, and implications to adequately address the question.",
                            "Evaluate utility by determining if the metric description provides sufficient information to directly answer the monitoring question; if not, identify specific missing details."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventSource\\\": \\\"apprunner.amazonaws.com\\\", \\\"EventName\\\": \\\"*\\\"}\", \"hyperparameters\": null, \"input\": \"Are there any deployment events indicating an unexpected restart or scaling activity for our containerized applications?\", \"retrieval_context\": [\" - **{\\\"EventName\\\": \\\"Start*\\\"}** events in CloudTrail indicate the initiation of resource start operations across various AWS services, such as starting EC2 instances, RDS databases, or other managed resources. These events help SREs track when resources transition from a stopped or inactive state to an active state, which is critical for service availability, cost management, and operational recovery.\\n\\n**Purpose:**  \\nTo monitor and audit the activation of cloud resources, ensuring that start operations align with expected usage patterns and do not indicate unauthorized or unexpected activity.\\n\\n**Alert Thresholds:**  \\n- Trigger an alert if the number of **Start*** events exceeds a predefined threshold within a short time window (e.g., more than 10 start operations within 5 minutes), which may indicate an automated scaling event, a potential misconfiguration, or a security incident.  \\n- Conversely, alert if expected start operations do not occur during scheduled maintenance windows, indicating possible failures in recovery or deployment processes.\\n\\n**Impact of Values:**  \\n- **High volume of Start* events:** Could lead to increased costs due to resource activation, potential service disruptions if resources are started unexpectedly, or indicate automated scaling or recovery actions.  \\n- **Low or zero Start* events during expected periods:** May signal failed recovery attempts, stalled deployments, or issues in operational workflows, potentially impacting service availability.\\n\\n**Example Usage:**  \\nIn a CloudWatch dashboard, plot the count of **Start*** events over time to visualize spikes or drops. An alert rule can be configured as:  \\n```\\nIF count(Start* events) > 10 within 5 minutes THEN trigger alert \\\"Unusual spike in resource start operations\\\"\\n```\\nThis enables proactive investigation into unexpected resource activations or failures to start critical services.\", \" - App Runner deployment events track actions related to containerized application services managed by AWS App Runner. These events include application deployments, service scaling activities, and lifecycle changes such as start, stop, or update operations. Each event records the occurrence of a specific action with timestamps but does not measure quantitative units. This enables monitoring and auditing of application state changes within the App Runner environment.\", \" - CloudFormation stack creation events (**EventSource: cloudformation.amazonaws.com**, **EventName: Create\\\\*** ) represent API calls initiating the provisioning of AWS infrastructure and resources via CloudFormation templates. These events in CloudTrail help SREs monitor the start of environment setups and infrastructure deployments as part of Infrastructure as Code workflows.\\n\\n**Purpose:** Track and audit when new CloudFormation stacks or stack components are being created, enabling visibility into changes in infrastructure state and deployment activities.\\n\\n**Alert Thresholds:**  \\n- Trigger an alert if the number of Create* events exceeds a baseline threshold within a short time window (e.g., >10 stack creation attempts in 5 minutes), which may indicate automated deployment loops, misconfigurations, or potential security incidents.  \\n- Alert if Create* events spike unexpectedly outside of scheduled deployment windows or change management periods.\\n\\n**Impact of Values:**  \\n- **High volume:** May signal rapid infrastructure changes that could lead to instability, resource contention, or deployment failures. It could also indicate unauthorized or accidental mass provisioning.  \\n- **Low or zero volume:** Normal during steady-state operations; however, a sudden drop during expected deployment windows might indicate pipeline failures or blocked deployments.\\n\\n**Example Usage:**  \\n- **Dashboard:** Visualize the count of CloudFormation Create* events over time, segmented by stack name or user identity, to correlate deployments with system performance or incidents.  \\n- **Alert Rule:**  \\n  ```  \\n  WHEN count(events where EventSource=\\\"cloudformation.amazonaws.com\\\" AND EventName LIKE \\\"Create%\\\") > 10 within 5 minutes  \\n  THEN trigger alert \\\"High rate of CloudFormation stack creation events detected\\\"  \\n  ```  \\nThis enables proactive detection of abnormal infrastructure provisioning activity and supports rapid investigation and response.\", \" - This pattern captures Elastic Load Balancing (ELB) target deregistration events from CloudTrail, indicating when backend targets (such as EC2 instances or IP addresses) are removed from a load balancer. These events typically occur during scaling operations, deployments, or maintenance activities that affect service availability.\\n\\n**Purpose:**  \\nMonitoring deregistration events helps SREs track changes in load balancer target groups, ensuring that scaling or maintenance actions do not inadvertently reduce capacity or cause service disruptions.\\n\\n**Alert Threshold Guidance:**  \\n- Trigger an alert if the number of deregistration events exceeds a defined threshold within a short time window (e.g., more than 5 deregistrations within 5 minutes), which may indicate unexpected or excessive target removals.  \\n- Conversely, a prolonged absence of deregistration events during expected scaling periods might signal issues with autoscaling or deployment processes.\\n\\n**Impact of Values:**  \\n- **High deregistration rate:** Could lead to reduced backend capacity, increased latency, or service outages if targets are removed too quickly or unexpectedly. Immediate investigation is warranted.  \\n- **Low or no deregistration events:** May indicate stable operations or, if scaling is expected, potential failures in scaling mechanisms.\\n\\n**Example Alert Rule:**  \\n```\\nWHEN count of events WHERE EventSource = \\\"elasticloadbalancing.amazonaws.com\\\" AND EventName LIKE \\\"Deregister%\\\"  \\nIN last 5 minutes > 5  \\nTHEN trigger alert \\\"High ELB Target Deregistration Rate\\\"\\n```\\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of deregistration events per minute, overlaid with thresholds, to visualize spikes or drops in deregistration activity aligned with deployment or scaling events.\", \" - This pattern captures all ECS update events recorded in CloudTrail, such as modifications to ECS services, task definitions, and cluster configurations. Its purpose is to monitor changes that could affect the stability, performance, or security of ECS workloads. An SRE should use this pattern to detect unexpected or frequent updates that may indicate configuration drift, deployment issues, or unauthorized changes.\\n\\n**Threshold guidance:**  \\n- Trigger an alert if the number of ECS update events exceeds a baseline threshold (e.g., more than 5 updates within 10 minutes), as this may signal rapid or unintended changes.  \\n- A low or zero count over a long period is typically normal but should be reviewed if updates are expected during deployments.\\n\\n**Impact:**  \\n- High frequency of update events can lead to service instability, deployment failures, or security risks if changes are unplanned or unauthorized.  \\n- Low frequency indicates stable ECS configurations but may also suggest stalled deployments or lack of necessary updates.\\n\\n**Example alert rule:**  \\n\\u201cAlert when the count of CloudTrail events with EventSource = 'ecs.amazonaws.com' and EventName starting with 'Update' exceeds 5 within a 10-minute window.\\u201d  \\n\\n**Example dashboard widget:**  \\nA time-series graph showing the count of ECS update events per 5-minute interval, annotated with deployment windows to correlate updates with expected changes.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": true,
                        "score": 0.8985936370374039,
                        "reason": "The retrieval context explicitly addresses deployment events related to containerized applications, including scaling and lifecycle changes, which directly answer the question about unexpected restarts or scaling. The description is clear, detailed, and includes relevant event types, alert thresholds, and impacts, enabling confident monitoring. However, it could be slightly more concise and explicitly highlight unexpected restarts to fully cover the question.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Compare the Input (question) and the Retrieval Context (description) to ensure the description explicitly addresses the monitoring question posed.\",\n    \"Evaluate Clarity by checking if the description is concise and understandable in the context of the specific question provided.\",\n    \"Assess Coverage by verifying the description includes what is measured, the units involved, relevant context, and implications related to the input question.\",\n    \"Determine Utility by judging if the description provides sufficient information to enable a user to confidently answer the monitoring question; if not, identify gaps between Input and Retrieval Context.\"\n] \n \nRubric:\nNone \n \nScore: 0.8985936370374039"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Compare the Input (question) and the Retrieval Context (description) to ensure the description explicitly addresses the monitoring question posed.",
                            "Evaluate Clarity by checking if the description is concise and understandable in the context of the specific question provided.",
                            "Assess Coverage by verifying the description includes what is measured, the units involved, relevant context, and implications related to the input question.",
                            "Determine Utility by judging if the description provides sufficient information to enable a user to confidently answer the monitoring question; if not, identify gaps between Input and Retrieval Context."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventName\\\": \\\"Tag*\\\"}\", \"hyperparameters\": null, \"input\": \"Are there spikes in TaggingAPICalls that could indicate a resource management issue?\", \"retrieval_context\": [\" - **{\\\"EventName\\\": \\\"Start*\\\"}** events in CloudTrail indicate the initiation of resource start operations across various AWS services, such as starting EC2 instances, RDS databases, or other managed resources. These events help SREs track when resources transition from a stopped or inactive state to an active state, which is critical for service availability, cost management, and operational recovery.\\n\\n**Purpose:**  \\nTo monitor and audit the activation of cloud resources, ensuring that start operations align with expected usage patterns and do not indicate unauthorized or unexpected activity.\\n\\n**Alert Thresholds:**  \\n- Trigger an alert if the number of **Start*** events exceeds a predefined threshold within a short time window (e.g., more than 10 start operations within 5 minutes), which may indicate an automated scaling event, a potential misconfiguration, or a security incident.  \\n- Conversely, alert if expected start operations do not occur during scheduled maintenance windows, indicating possible failures in recovery or deployment processes.\\n\\n**Impact of Values:**  \\n- **High volume of Start* events:** Could lead to increased costs due to resource activation, potential service disruptions if resources are started unexpectedly, or indicate automated scaling or recovery actions.  \\n- **Low or zero Start* events during expected periods:** May signal failed recovery attempts, stalled deployments, or issues in operational workflows, potentially impacting service availability.\\n\\n**Example Usage:**  \\nIn a CloudWatch dashboard, plot the count of **Start*** events over time to visualize spikes or drops. An alert rule can be configured as:  \\n```\\nIF count(Start* events) > 10 within 5 minutes THEN trigger alert \\\"Unusual spike in resource start operations\\\"\\n```\\nThis enables proactive investigation into unexpected resource activations or failures to start critical services.\", \" - Resource listing operations (events with names starting with \\\"List\\\") in CloudTrail capture API calls that enumerate or retrieve metadata about cloud resources across services (e.g., ListBuckets, ListInstances). These events help SREs monitor inventory changes, detect unusual enumeration activity, and maintain infrastructure visibility. \\n\\n**Purpose:** Track and audit resource discovery actions to identify potential reconnaissance or automation behaviors.\\n\\n**Alert Threshold:** Trigger alerts when the rate of List* events exceeds a baseline by 3x within a 5-minute window, indicating possible automated scanning or misconfigured scripts.\\n\\n**Impact:**  \\n- **High values:** May signal excessive resource enumeration, potentially due to unauthorized scanning, automation loops, or misconfigured monitoring tools, increasing API costs and risk exposure.  \\n- **Low values:** Could indicate loss of visibility or failures in inventory processes, risking outdated infrastructure awareness.\\n\\n**Example Alert Rule:**  \\n`IF count(List*) > 300 events in 5 minutes THEN alert \\\"High resource enumeration activity detected\\\"`  \\n\\n**Dashboard Use:** Visualize List* event counts over time alongside other API calls to correlate spikes with deployments or incidents, aiding in capacity planning and anomaly detection.\", \" - This pattern captures CloudFront tagging events recorded in CloudTrail, specifically when CloudFront distributions are tagged or untagged. Tagging actions are critical for resource organization, cost allocation, and access management. Monitoring these events helps SREs detect unauthorized or unexpected changes to distribution metadata that could affect billing, security policies, or operational workflows.\\n\\n**Alert Threshold:**  \\nTrigger an alert if the number of CloudFront Tag* events exceeds a baseline threshold within a short time window (e.g., more than 5 tagging operations in 10 minutes), as this may indicate automated misconfigurations, potential security breaches, or bulk updates requiring review.\\n\\n**Impact of Values:**  \\n- **High frequency:** Could signal mass tagging/untagging possibly due to automation errors, policy violations, or malicious activity, potentially leading to misallocated costs or broken access controls.  \\n- **Low or zero frequency:** Normal state; tagging changes are typically infrequent and deliberate.\\n\\n**Example Usage:**  \\nIn a monitoring dashboard, plot the count of CloudFront Tag* events over time to visualize tagging activity spikes. An alert rule might be:  \\n`WHEN count(events where EventSource=\\\"cloudfront.amazonaws.com\\\" AND EventName LIKE \\\"Tag%\\\") > 5 within 10 minutes THEN trigger alert \\\"Unusual CloudFront tagging activity detected\\\"`  \\nThis enables proactive investigation and mitigation of tagging anomalies impacting resource governance.\", \" - This pattern captures all Amazon EKS \\\"Describe\\\" API operations logged in CloudTrail, which occur when cluster metadata, node group configurations, or add-on details are queried. It helps SREs monitor how often EKS cluster information is accessed, providing visibility into potential reconnaissance or troubleshooting activities. A sudden spike in Describe calls\\u2014such as exceeding 100 requests within 5 minutes\\u2014may indicate unusual or automated querying that could precede configuration changes or security incidents, warranting an alert. Conversely, consistently low or zero Describe activity might suggest lack of monitoring or insufficient operational visibility. For example, an alert rule could trigger when Describe API calls surpass 100 in a 5-minute window, and a dashboard widget might display a time series graph of Describe call counts to track trends and detect anomalies in cluster information access patterns.\", \" - Tracks all resource tagging activities performed across AWS services. Measures the number of tagging API calls made to create, update, or delete tags on resources. Enables monitoring of cost allocation, resource organization, compliance, and governance through tag usage. Recorded as a count of tagging operations.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": true,
                        "score": 0.8125907358399675,
                        "reason": "The retrieval context provides a detailed and clear description of TaggingAPICalls, including what is measured (CloudFront tagging events), relevant units (number of events within time windows), and implications of spikes (potential misconfigurations or security issues). It also includes alert thresholds and example usage, enabling users to detect spikes indicative of resource management issues. However, the description focuses primarily on CloudFront tagging events rather than TaggingAPICalls across all services, which slightly limits coverage relative to the input question's broader scope.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Compare the Input (monitoring question) with the Retrieval Context (metric description) to ensure the description adequately addresses the question.\",\n    \"Evaluate the clarity of the metric description in the context of the input question: is it concise and easy to understand when considering the user's query?\",\n    \"Assess coverage by verifying if the description explains what is measured, including units, context, and implications relevant to the input question.\",\n    \"Determine utility by checking if the description enables a user to confidently answer the input question using the given retrieval context.\"\n] \n \nRubric:\nNone \n \nScore: 0.8125907358399675"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Compare the Input (monitoring question) with the Retrieval Context (metric description) to ensure the description adequately addresses the question.",
                            "Evaluate the clarity of the metric description in the context of the input question: is it concise and easy to understand when considering the user's query?",
                            "Assess coverage by verifying if the description explains what is measured, including units, context, and implications relevant to the input question.",
                            "Determine utility by checking if the description enables a user to confidently answer the input question using the given retrieval context."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventName\\\": \\\"Scale*\\\"}\", \"hyperparameters\": null, \"input\": \"Are there any Scale* events triggered due to high demand, indicating a potential capacity issue?\", \"retrieval_context\": [\" - Auto-scaling events triggered to adjust service capacity based on demand. Measures the number of scaling actions performed, including scale-up and scale-down operations. Units are counted as discrete scaling events per service. This metric helps monitor resource allocation efficiency and cost optimization.\", \" - Redshift cluster creation events in CloudTrail capture all API calls initiating the provisioning of new Redshift clusters (e.g., CreateCluster). These events indicate when new data warehouse resources are being deployed or configured, impacting capacity and cost.  \\n**Purpose:** Enables SREs to monitor and audit cluster provisioning activities for operational control and security compliance.  \\n**Alert Threshold:** Trigger alerts on an unusually high number of cluster creation events within a short time window (e.g., >3 creates in 1 hour), which may indicate automation errors, misconfigurations, or unauthorized resource provisioning.  \\n**Impact:**  \\n- **High values:** May lead to resource sprawl, increased costs, and potential performance degradation due to over-provisioning. Could also signal security risks if unexpected clusters are created.  \\n- **Low or zero values:** Normal in stable environments; no new clusters being created means stable infrastructure.  \\n**Example Alert Rule:**  \\n\\u201cAlert if count of events with EventSource='redshift.amazonaws.com' and EventName starting with 'Create' exceeds 3 within 60 minutes.\\u201d  \\n**Dashboard Use:** Visualize the frequency of Redshift cluster creation events over time to detect spikes or anomalies, correlating with deployment activities or security incidents.\", \" - S3 bucket creation events captured by CloudTrail under **{\\\"EventSource\\\": \\\"s3.amazonaws.com\\\", \\\"EventName\\\": \\\"Create*\\\"}** indicate when new buckets or related resources (e.g., bucket policies, access points) are provisioned. These events help SREs monitor infrastructure changes that affect data storage, security posture, and compliance.\\n\\n**Purpose:**  \\nTrack and audit the creation of S3 buckets and associated configurations to ensure proper governance, prevent unauthorized resource sprawl, and maintain compliance with organizational policies.\\n\\n**Alert Threshold:**  \\nTrigger an alert if the number of S3 bucket creation events exceeds a defined threshold within a short time window (e.g., more than 5 bucket creations within 10 minutes), which may indicate automated provisioning errors, misconfigurations, or potential security incidents such as unauthorized resource creation.\\n\\n**Impact of Values:**  \\n- **High frequency:** May signal abnormal activity, such as a compromised credential or runaway automation scripts creating excessive buckets, leading to increased costs, security risks, or compliance violations.  \\n- **Low or zero frequency:** Normal in stable environments; however, sudden spikes should be investigated promptly.\\n\\n**Example Alert Rule:**  \\n\\u201cAlert when count of events with EventSource = 's3.amazonaws.com' and EventName starting with 'Create' exceeds 5 within 10 minutes.\\u201d\\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of S3 Create* events over time, with thresholds marked to highlight unusual spikes, enabling quick identification of abnormal bucket creation activity.\", \" - This pattern captures Elastic Load Balancing (ELB) target deregistration events from CloudTrail, indicating when backend targets (such as EC2 instances or IP addresses) are removed from a load balancer. These events typically occur during scaling operations, deployments, or maintenance activities that affect service availability.\\n\\n**Purpose:**  \\nMonitoring deregistration events helps SREs track changes in load balancer target groups, ensuring that scaling or maintenance actions do not inadvertently reduce capacity or cause service disruptions.\\n\\n**Alert Threshold Guidance:**  \\n- Trigger an alert if the number of deregistration events exceeds a defined threshold within a short time window (e.g., more than 5 deregistrations within 5 minutes), which may indicate unexpected or excessive target removals.  \\n- Conversely, a prolonged absence of deregistration events during expected scaling periods might signal issues with autoscaling or deployment processes.\\n\\n**Impact of Values:**  \\n- **High deregistration rate:** Could lead to reduced backend capacity, increased latency, or service outages if targets are removed too quickly or unexpectedly. Immediate investigation is warranted.  \\n- **Low or no deregistration events:** May indicate stable operations or, if scaling is expected, potential failures in scaling mechanisms.\\n\\n**Example Alert Rule:**  \\n```\\nWHEN count of events WHERE EventSource = \\\"elasticloadbalancing.amazonaws.com\\\" AND EventName LIKE \\\"Deregister%\\\"  \\nIN last 5 minutes > 5  \\nTHEN trigger alert \\\"High ELB Target Deregistration Rate\\\"\\n```\\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of deregistration events per minute, overlaid with thresholds, to visualize spikes or drops in deregistration activity aligned with deployment or scaling events.\", \" - This pattern captures all Amazon EKS \\\"Describe\\\" API operations logged in CloudTrail, which occur when cluster metadata, node group configurations, or add-on details are queried. It helps SREs monitor how often EKS cluster information is accessed, providing visibility into potential reconnaissance or troubleshooting activities. A sudden spike in Describe calls\\u2014such as exceeding 100 requests within 5 minutes\\u2014may indicate unusual or automated querying that could precede configuration changes or security incidents, warranting an alert. Conversely, consistently low or zero Describe activity might suggest lack of monitoring or insufficient operational visibility. For example, an alert rule could trigger when Describe API calls surpass 100 in a 5-minute window, and a dashboard widget might display a time series graph of Describe call counts to track trends and detect anomalies in cluster information access patterns.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": true,
                        "score": 0.8053452275429859,
                        "reason": "The Retrieval Context clearly addresses the Input question by describing auto-scaling events triggered to adjust service capacity based on demand, including scale-up and scale-down operations. It explains what is measured (number of scaling actions), units (discrete events per service), and the context (resource allocation efficiency and cost optimization). The description is concise and understandable, enabling a user to effectively determine if scale events indicate capacity issues. However, it lacks explicit mention of alert thresholds or direct implications of high demand triggering scale events, which would improve coverage and utility.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Compare the Input (monitoring question) with the Retrieval Context (metric description) to assess if the description clearly addresses the question asked.\",\n    \"Evaluate the clarity of the Retrieval Context by checking if it is understandable and concise in relation to the Input provided.\",\n    \"Assess coverage by verifying that the Retrieval Context explains what is measured, units, context, and implications relevant to the Input question.\",\n    \"Determine utility by judging whether the Retrieval Context enables a user to effectively answer the Input question based on the information given.\"\n] \n \nRubric:\nNone \n \nScore: 0.8053452275429859"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Compare the Input (monitoring question) with the Retrieval Context (metric description) to assess if the description clearly addresses the question asked.",
                            "Evaluate the clarity of the Retrieval Context by checking if it is understandable and concise in relation to the Input provided.",
                            "Assess coverage by verifying that the Retrieval Context explains what is measured, units, context, and implications relevant to the Input question.",
                            "Determine utility by judging whether the Retrieval Context enables a user to effectively answer the Input question based on the information given."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventName\\\": \\\"Describe*\\\"}\", \"hyperparameters\": null, \"input\": \"Does the Describe* EventName metric exceed its normal threshold, indicating an unusual level of operations on cloud resources?\", \"retrieval_context\": [\" - EKS List* events in CloudTrail capture API calls that enumerate EKS resources such as clusters, node groups, add-ons, and other related components. These operations are primarily read-only and used for infrastructure discovery, capacity planning, and operational visibility. Monitoring the frequency of List* calls helps detect unusual activity patterns: a sudden spike may indicate automated scanning, reconnaissance, or potential misuse, while an abnormally low rate could suggest monitoring gaps or service disruptions. A practical alert threshold might be set at a rate exceeding the baseline average by 3x within a 5-minute window. For example, a dashboard widget could track the count of eks.amazonaws.com List* events per minute, with an alert rule triggering when this count surpasses the defined threshold, enabling timely investigation of unexpected enumeration activity.\", \" - Operations that retrieve detailed information about cloud resources across all services. This includes inspecting configurations, discovering resources, and providing operational visibility. It measures the number of API calls made to describe or list resource details. The unit of measurement is the count of these describe or list requests.\", \" - S3 List operations (EventName starting with \\\"List\\\") in CloudTrail capture requests to enumerate buckets, list objects, or browse directories within S3. These events help track data discovery activities, such as inventory management or security reconnaissance attempts by identifying who is accessing or exploring bucket contents.  \\n\\n**Purpose:**  \\n- Monitor access patterns to detect unusual or excessive listing activity that may indicate unauthorized data exploration or reconnaissance.  \\n- Support auditing and compliance by providing visibility into how and when bucket contents are being queried.\\n\\n**Alert Threshold Guidance:**  \\n- Trigger alerts when the number of List operations exceeds a baseline threshold (e.g., a sudden spike above normal daily averages or a sustained high rate over a short period).  \\n- Thresholds should be customized per environment but a common starting point is alerting on a 3x increase over the average hourly count or more than 100 List requests per minute from a single principal or IP.\\n\\n**Impact of Values:**  \\n- **High values:** May indicate automated scanning, data scraping, or reconnaissance by malicious actors, potentially preceding data exfiltration attempts. Could also reflect legitimate bulk inventory or analytics jobs\\u2014context matters.  \\n- **Low values:** Normal or expected in environments with limited or infrequent bucket browsing; very low values typically pose no risk.\\n\\n**Example Usage:**  \\n- **Dashboard:** Visualize the count of List* events over time, segmented by user or source IP, to identify unusual spikes or patterns.  \\n- **Alert Rule (pseudo-code):**  \\n  ```  \\n  IF count(EventName LIKE \\\"List*\\\") BY user OVER 15 minutes > 3x baseline THEN alert(\\\"Unusual S3 List activity detected for user\\\")  \\n  ```  \\nThis enables proactive detection of suspicious enumeration behavior while minimizing false positives from routine operations.\", \" - This pattern captures CloudWatch API operations that list resources, such as metrics, log groups, and alarms, as recorded in CloudTrail under EventSource \\\"cloudwatch.amazonaws.com\\\" with EventNames starting with \\\"List\\\". It helps SREs monitor enumeration activity on CloudWatch resources, which can indicate normal operational queries or potential reconnaissance by unauthorized users.\\n\\n**Purpose:**  \\nTo track and analyze the frequency of CloudWatch resource listing actions, enabling detection of unusual spikes that may signal automated scanning, misconfigurations, or security incidents.\\n\\n**Threshold Guidance:**  \\nSet alert thresholds based on baseline activity for your environment. For example, trigger an alert if the number of List* events exceeds 3 standard deviations above the daily average or if more than 100 list operations occur within a 5-minute window, indicating abnormal enumeration.\\n\\n**Impact of Values:**  \\n- **High values:** May indicate excessive or automated querying of CloudWatch resources, potentially revealing reconnaissance attempts or inefficient scripts causing performance overhead.  \\n- **Low values:** Typically normal, but a sudden drop could suggest issues with monitoring tools or API access problems.\\n\\n**Example Alert Rule:**  \\nTrigger an alert when the count of CloudWatch List* events in CloudTrail exceeds 100 within 5 minutes, signaling potential unauthorized or excessive enumeration activity.\\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of CloudWatch List* events per 5-minute interval, overlaid with the alert threshold line, to visualize normal versus anomalous listing activity.\", \" - This pattern captures all Amazon EKS \\\"Describe\\\" API operations logged in CloudTrail, which occur when cluster metadata, node group configurations, or add-on details are queried. It helps SREs monitor how often EKS cluster information is accessed, providing visibility into potential reconnaissance or troubleshooting activities. A sudden spike in Describe calls\\u2014such as exceeding 100 requests within 5 minutes\\u2014may indicate unusual or automated querying that could precede configuration changes or security incidents, warranting an alert. Conversely, consistently low or zero Describe activity might suggest lack of monitoring or insufficient operational visibility. For example, an alert rule could trigger when Describe API calls surpass 100 in a 5-minute window, and a dashboard widget might display a time series graph of Describe call counts to track trends and detect anomalies in cluster information access patterns.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": false,
                        "score": 0.7697269425765951,
                        "reason": "The description is clear and free of jargon, directly addressing the monitoring of 'Describe' EventName metrics in CloudTrail for Amazon EKS. It explains what is measured (API call counts), the units (number of requests), and the context (monitoring cluster metadata queries). The description includes actionable thresholds (e.g., exceeding 100 requests in 5 minutes) and implications of spikes or low activity, aligning well with the monitoring question. However, it could improve by explicitly defining the normal threshold range and providing more detailed guidance on interpreting borderline values to enhance utility.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Evaluate the clarity of the metric description by determining if it is easy to understand and free of unnecessary jargon, ensuring it directly relates to the input question.\",\n    \"Assess coverage by checking if the description fully explains what is measured, including units, context, and the implications relevant to the retrieval context and the monitoring question.\",\n    \"Judge utility by verifying whether the description provides enough actionable information to accurately answer the monitoring question given the retrieval context.\",\n    \"Compare the input metric description and retrieval context to ensure they are aligned and coherent, with the description adequately addressing the key aspects posed by the monitoring question.\"\n] \n \nRubric:\nNone \n \nScore: 0.7697269425765951"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Evaluate the clarity of the metric description by determining if it is easy to understand and free of unnecessary jargon, ensuring it directly relates to the input question.",
                            "Assess coverage by checking if the description fully explains what is measured, including units, context, and the implications relevant to the retrieval context and the monitoring question.",
                            "Judge utility by verifying whether the description provides enough actionable information to accurately answer the monitoring question given the retrieval context.",
                            "Compare the input metric description and retrieval context to ensure they are aligned and coherent, with the description adequately addressing the key aspects posed by the monitoring question."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventName\\\": \\\"Stop*\\\"}\", \"hyperparameters\": null, \"input\": \"Does the number of Stop* events exceed a 50% increase over the average daily stop events, indicating potential outages or unauthorized shutdowns?\", \"retrieval_context\": [\" - **{\\\"EventName\\\": \\\"Stop*\\\"}**  \\nThis event captures all resource stop operations across cloud services, such as stopping virtual machines, containers, or other compute resources. It signals intentional halting of resources for cost optimization, maintenance, or deactivation purposes.  \\n\\n**Purpose:**  \\nTo monitor when resources are stopped, enabling tracking of operational changes that affect availability and cost.  \\n\\n**Alert Threshold:**  \\nTrigger an alert if the number of Stop* events exceeds a defined baseline (e.g., a 50% increase over the average daily stop events) within a short time window (e.g., 15 minutes), which may indicate unexpected or mass shutdowns.  \\n\\n**Impact:**  \\n- **High values:** May indicate large-scale maintenance, potential outages, or unauthorized shutdowns impacting service availability and user experience.  \\n- **Low values:** Normal or no stop activity, indicating stable resource operation or potential lack of expected maintenance.  \\n\\n**Example Usage:**  \\nIn a dashboard, plot the count of Stop* events over time to visualize stop operation trends. An alert rule could be:  \\n`WHEN count(Stop* events) > baseline * 1.5 FOR 15 minutes THEN trigger alert`  \\nThis helps SREs quickly detect abnormal stop activity and respond accordingly.\", \" - This pattern captures AWS CloudTrail events where Amazon RDS instances are stopped (EventSource: \\\"rds.amazonaws.com\\\", EventName starting with \\\"Stop\\\"). It helps SREs monitor when RDS databases are intentionally or unintentionally stopped, which can impact application availability and indicate maintenance or cost-saving actions.\\n\\n**Purpose:**  \\n- Detect RDS stop operations to quickly identify potential service disruptions or planned maintenance.  \\n- Provide visibility into operational changes affecting database availability.\\n\\n**Alert Threshold Guidance:**  \\n- Trigger an alert if the number of RDS stop events exceeds a defined threshold within a short time window (e.g., more than 1 stop event per hour per critical environment), as multiple stops may indicate automation issues or unexpected failures.  \\n- For low-frequency environments, even a single unexpected stop event should trigger an alert.\\n\\n**Impact of Values:**  \\n- **High frequency of stop events:** May indicate instability, automation misconfiguration, or repeated manual interventions, potentially causing downtime or degraded service.  \\n- **Low or zero stop events:** Normal operation, assuming no planned maintenance is ongoing.\\n\\n**Example Alert Rule:**  \\n- Alert when count of events matching {\\\"EventSource\\\": \\\"rds.amazonaws.com\\\", \\\"EventName\\\": \\\"Stop*\\\"} exceeds 1 within 60 minutes for production accounts.  \\n- Dashboard widget can display a time series graph of RDS stop events over the past 24 hours, segmented by environment or instance ID, to correlate stops with incidents or maintenance windows.\", \" - This pattern captures SNS unsubscription events recorded in CloudTrail, indicating when endpoints or subscribers are removed from SNS topics. For an SRE, monitoring these events helps track changes in notification delivery and detect potential disruptions or configuration changes.\\n\\n**Purpose:**  \\n- Identify when subscribers unsubscribe from SNS topics, which may reflect endpoint decommissioning, application changes, or user-initiated opt-outs.  \\n- Detect unusual spikes that could indicate mass unsubscriptions due to misconfigurations, security incidents, or service issues.\\n\\n**Alert Threshold:**  \\n- Trigger an alert if the number of Unsubscribe events exceeds a baseline threshold (e.g., more than 5 unsubscriptions within 5 minutes) or shows a sudden increase compared to historical averages. Thresholds should be tuned based on normal subscription churn rates.\\n\\n**Impact:**  \\n- **High values:** May signal widespread endpoint removals causing notification delivery failures, potential service degradation, or security concerns (e.g., unauthorized unsubscriptions). Immediate investigation is warranted.  \\n- **Low or zero values:** Typically expected during stable operations; a sudden drop to zero after a period of regular unsubscriptions might indicate logging issues or CloudTrail misconfigurations.\\n\\n**Example Usage:**  \\n- **Dashboard:** Display a time series graph of Unsubscribe event counts per minute to visualize trends and detect anomalies.  \\n- **Alert Rule (pseudo-code):**  \\n  ```\\n  WHEN count(Events where EventSource=\\\"sns.amazonaws.com\\\" AND EventName LIKE \\\"Unsubscribe%\\\") \\n  OVER last 5 minutes > 5 \\n  THEN trigger alert \\\"High SNS Unsubscription Rate\\\"\\n  ```\", \" - This pattern captures all AWS Security Token Service (STS) \\\"Get\\\" operations, such as `GetSessionToken`, `GetCallerIdentity`, and similar API calls that issue or validate temporary security credentials. In CloudTrail, these events indicate when users or services request short-lived credentials to access AWS resources.\\n\\n**Purpose:**  \\nMonitor STS Get* events to detect unusual or excessive requests for temporary credentials, which can signal automation activity, credential misuse, or potential security incidents like privilege escalation or compromised identities.\\n\\n**Alert Threshold:**  \\nTrigger an alert when the count of STS Get* events exceeds a baseline threshold established from normal activity patterns\\u2014commonly, a sudden spike above 3-5 times the average hourly rate or an absolute count exceeding 100 requests per hour, depending on your environment size and usage.\\n\\n**Impact of Values:**  \\n- **High values:** May indicate automated processes requesting many temporary credentials, potential credential abuse, or an attacker attempting to escalate privileges or move laterally. Prompt investigation is warranted.  \\n- **Low or expected values:** Reflect normal operation with routine credential issuance and validation.\\n\\n**Example Usage:**  \\nIn a monitoring dashboard, plot the count of `sts.amazonaws.com` events with `EventName` matching `Get*` over time. Set an alert rule such as:  \\n`WHEN count(events where EventSource=\\\"sts.amazonaws.com\\\" AND EventName LIKE \\\"Get*\\\") > 100 within 1 hour THEN alert \\\"High STS Get* activity detected\\\"`  \\nThis helps SREs quickly identify abnormal credential request patterns and respond accordingly.\", \" - This pattern captures all Route 53 \\\"Get\\\" API operations logged in CloudTrail, such as retrieving hosted zone details, record sets, and health check statuses. It helps SREs monitor read access to DNS configurations and health data, which can indicate normal operational queries or potential reconnaissance activity. A sudden spike in these \\\"Get\\\" requests\\u2014exceeding a baseline threshold (e.g., 3 standard deviations above the average hourly rate)\\u2014may signal unusual interest in DNS infrastructure, warranting investigation. Conversely, a significant drop could indicate issues with monitoring or automation systems relying on these queries. For example, an alert rule could trigger when the count of **{\\\"EventSource\\\": \\\"route53.amazonaws.com\\\", \\\"EventName\\\": \\\"Get*\\\"}** events exceeds 100 requests per hour, and a dashboard widget might display a time series graph of these events to track trends and detect anomalies in DNS query activity.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": true,
                        "score": 0.9222700143984234,
                        "reason": "The description clearly addresses the question by explaining what Stop* events measure, including the context of resource stop operations and their implications for outages or unauthorized shutdowns. It provides clear alert thresholds (e.g., a 50% increase over average daily stops), impact explanations, and example usage, making it understandable and actionable. Minor deduction is due to slight complexity in the retrieval context that could be more concise, but overall it offers comprehensive coverage and utility for answering the monitoring question.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Compare the Input (metric description) and Retrieval Context (monitoring question) to determine if the description clearly addresses the question's focus.\",\n    \"Evaluate clarity by checking if the description is understandable, concise, and free of ambiguity when considered alongside the question.\",\n    \"Assess coverage by verifying if the description explains what is measured, units, context, and implications relevant to the question.\",\n    \"Determine utility by examining if the description provides sufficient information to directly answer or support answering the monitoring question.\"\n] \n \nRubric:\nNone \n \nScore: 0.9222700143984234"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Compare the Input (metric description) and Retrieval Context (monitoring question) to determine if the description clearly addresses the question's focus.",
                            "Evaluate clarity by checking if the description is understandable, concise, and free of ambiguity when considered alongside the question.",
                            "Assess coverage by verifying if the description explains what is measured, units, context, and implications relevant to the question.",
                            "Determine utility by examining if the description provides sufficient information to directly answer or support answering the monitoring question."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventName\\\": \\\"List*\\\"}\", \"hyperparameters\": null, \"input\": \"Does the rate of List* events exceed three times the baseline, indicating possible automated scanning or misconfigured scripts?\", \"retrieval_context\": [\" - EKS List* events in CloudTrail capture API calls that enumerate EKS resources such as clusters, node groups, add-ons, and other related components. These operations are primarily read-only and used for infrastructure discovery, capacity planning, and operational visibility. Monitoring the frequency of List* calls helps detect unusual activity patterns: a sudden spike may indicate automated scanning, reconnaissance, or potential misuse, while an abnormally low rate could suggest monitoring gaps or service disruptions. A practical alert threshold might be set at a rate exceeding the baseline average by 3x within a 5-minute window. For example, a dashboard widget could track the count of eks.amazonaws.com List* events per minute, with an alert rule triggering when this count surpasses the defined threshold, enabling timely investigation of unexpected enumeration activity.\", \" - Resource listing operations (events with names starting with \\\"List\\\") in CloudTrail capture API calls that enumerate or retrieve metadata about cloud resources across services (e.g., ListBuckets, ListInstances). These events help SREs monitor inventory changes, detect unusual enumeration activity, and maintain infrastructure visibility. \\n\\n**Purpose:** Track and audit resource discovery actions to identify potential reconnaissance or automation behaviors.\\n\\n**Alert Threshold:** Trigger alerts when the rate of List* events exceeds a baseline by 3x within a 5-minute window, indicating possible automated scanning or misconfigured scripts.\\n\\n**Impact:**  \\n- **High values:** May signal excessive resource enumeration, potentially due to unauthorized scanning, automation loops, or misconfigured monitoring tools, increasing API costs and risk exposure.  \\n- **Low values:** Could indicate loss of visibility or failures in inventory processes, risking outdated infrastructure awareness.\\n\\n**Example Alert Rule:**  \\n`IF count(List*) > 300 events in 5 minutes THEN alert \\\"High resource enumeration activity detected\\\"`  \\n\\n**Dashboard Use:** Visualize List* event counts over time alongside other API calls to correlate spikes with deployments or incidents, aiding in capacity planning and anomaly detection.\", \" - S3 List operations (EventName starting with \\\"List\\\") in CloudTrail capture requests to enumerate buckets, list objects, or browse directories within S3. These events help track data discovery activities, such as inventory management or security reconnaissance attempts by identifying who is accessing or exploring bucket contents.  \\n\\n**Purpose:**  \\n- Monitor access patterns to detect unusual or excessive listing activity that may indicate unauthorized data exploration or reconnaissance.  \\n- Support auditing and compliance by providing visibility into how and when bucket contents are being queried.\\n\\n**Alert Threshold Guidance:**  \\n- Trigger alerts when the number of List operations exceeds a baseline threshold (e.g., a sudden spike above normal daily averages or a sustained high rate over a short period).  \\n- Thresholds should be customized per environment but a common starting point is alerting on a 3x increase over the average hourly count or more than 100 List requests per minute from a single principal or IP.\\n\\n**Impact of Values:**  \\n- **High values:** May indicate automated scanning, data scraping, or reconnaissance by malicious actors, potentially preceding data exfiltration attempts. Could also reflect legitimate bulk inventory or analytics jobs\\u2014context matters.  \\n- **Low values:** Normal or expected in environments with limited or infrequent bucket browsing; very low values typically pose no risk.\\n\\n**Example Usage:**  \\n- **Dashboard:** Visualize the count of List* events over time, segmented by user or source IP, to identify unusual spikes or patterns.  \\n- **Alert Rule (pseudo-code):**  \\n  ```  \\n  IF count(EventName LIKE \\\"List*\\\") BY user OVER 15 minutes > 3x baseline THEN alert(\\\"Unusual S3 List activity detected for user\\\")  \\n  ```  \\nThis enables proactive detection of suspicious enumeration behavior while minimizing false positives from routine operations.\", \" - This pattern captures AWS KMS Decrypt API calls recorded in CloudTrail, indicating when encrypted data is accessed and decrypted using KMS keys. It helps SREs monitor data access events for security auditing and anomaly detection. A sudden spike in Decrypt events may signal unusual or unauthorized data access, while consistently low or expected volumes suggest normal operation. As a threshold, alerting on a sustained increase exceeding 3 standard deviations above the historical average or a sudden burst of Decrypt calls within a short time window (e.g., 5 minutes) is recommended. For example, an alert rule could trigger when the count of Decrypt events exceeds 100 in 5 minutes, indicating potential data exfiltration or misuse. In dashboards, tracking the rate of Decrypt events over time alongside user identities and key IDs can help quickly identify suspicious patterns or compromised credentials.\", \" - This pattern captures CloudWatch API operations that list resources, such as metrics, log groups, and alarms, as recorded in CloudTrail under EventSource \\\"cloudwatch.amazonaws.com\\\" with EventNames starting with \\\"List\\\". It helps SREs monitor enumeration activity on CloudWatch resources, which can indicate normal operational queries or potential reconnaissance by unauthorized users.\\n\\n**Purpose:**  \\nTo track and analyze the frequency of CloudWatch resource listing actions, enabling detection of unusual spikes that may signal automated scanning, misconfigurations, or security incidents.\\n\\n**Threshold Guidance:**  \\nSet alert thresholds based on baseline activity for your environment. For example, trigger an alert if the number of List* events exceeds 3 standard deviations above the daily average or if more than 100 list operations occur within a 5-minute window, indicating abnormal enumeration.\\n\\n**Impact of Values:**  \\n- **High values:** May indicate excessive or automated querying of CloudWatch resources, potentially revealing reconnaissance attempts or inefficient scripts causing performance overhead.  \\n- **Low values:** Typically normal, but a sudden drop could suggest issues with monitoring tools or API access problems.\\n\\n**Example Alert Rule:**  \\nTrigger an alert when the count of CloudWatch List* events in CloudTrail exceeds 100 within 5 minutes, signaling potential unauthorized or excessive enumeration activity.\\n\\n**Example Dashboard Widget:**  \\nA time-series graph showing the count of CloudWatch List* events per 5-minute interval, overlaid with the alert threshold line, to visualize normal versus anomalous listing activity.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": true,
                        "score": 0.9,
                        "reason": "The retrieval context clearly and comprehensively addresses the input question by explaining what List* events are, their purpose, and how they relate to detecting automated scanning or misconfigured scripts. It provides specific alert thresholds (3x baseline within 5 minutes), impact of high and low values, and example alert rules and dashboard uses, enabling confident monitoring and interpretation. The description is clear, detailed, and unambiguous, covering units, context, and implications relevant to the monitoring question. Minor deduction is due to the context being somewhat lengthy and segmented by service, which could slightly affect immediate clarity.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Assess the Input (monitoring question) and Retrieval Context (metric description) together to confirm the description clearly addresses the question's intent.\",\n    \"Evaluate Clarity by checking if the Retrieval Context is understandable and concise in relation to the Input, ensuring no ambiguity in terms/data used.\",\n    \"Check Coverage by verifying the description fully explains what is measured, including units, context, and implications relevant to the monitoring question.\",\n    \"Determine Utility by confirming that the description enables a user to confidently answer the monitoring question using the provided metric details.\"\n] \n \nRubric:\nNone \n \nScore: 0.9"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Assess the Input (monitoring question) and Retrieval Context (metric description) together to confirm the description clearly addresses the question's intent.",
                            "Evaluate Clarity by checking if the Retrieval Context is understandable and concise in relation to the Input, ensuring no ambiguity in terms/data used.",
                            "Check Coverage by verifying the description fully explains what is measured, including units, context, and implications relevant to the monitoring question.",
                            "Determine Utility by confirming that the description enables a user to confidently answer the monitoring question using the provided metric details."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        },
        "{\"actual_output\": \"\", \"context\": null, \"expected_output\": \"{\\\"EventName\\\": \\\"Start*\\\"}\", \"hyperparameters\": null, \"input\": \"Does the number of Start* events exceed ten, indicating a potential automated scaling event, misconfiguration, or security incident?\", \"retrieval_context\": [\" - **{\\\"EventName\\\": \\\"Start*\\\"}** events in CloudTrail indicate the initiation of resource start operations across various AWS services, such as starting EC2 instances, RDS databases, or other managed resources. These events help SREs track when resources transition from a stopped or inactive state to an active state, which is critical for service availability, cost management, and operational recovery.\\n\\n**Purpose:**  \\nTo monitor and audit the activation of cloud resources, ensuring that start operations align with expected usage patterns and do not indicate unauthorized or unexpected activity.\\n\\n**Alert Thresholds:**  \\n- Trigger an alert if the number of **Start*** events exceeds a predefined threshold within a short time window (e.g., more than 10 start operations within 5 minutes), which may indicate an automated scaling event, a potential misconfiguration, or a security incident.  \\n- Conversely, alert if expected start operations do not occur during scheduled maintenance windows, indicating possible failures in recovery or deployment processes.\\n\\n**Impact of Values:**  \\n- **High volume of Start* events:** Could lead to increased costs due to resource activation, potential service disruptions if resources are started unexpectedly, or indicate automated scaling or recovery actions.  \\n- **Low or zero Start* events during expected periods:** May signal failed recovery attempts, stalled deployments, or issues in operational workflows, potentially impacting service availability.\\n\\n**Example Usage:**  \\nIn a CloudWatch dashboard, plot the count of **Start*** events over time to visualize spikes or drops. An alert rule can be configured as:  \\n```\\nIF count(Start* events) > 10 within 5 minutes THEN trigger alert \\\"Unusual spike in resource start operations\\\"\\n```\\nThis enables proactive investigation into unexpected resource activations or failures to start critical services.\", \" - Auto-scaling events triggered to adjust service capacity based on demand. Measures the number of scaling actions performed, including scale-up and scale-down operations. Units are counted as discrete scaling events per service. This metric helps monitor resource allocation efficiency and cost optimization.\", \" - This pattern captures all modification events related to Elastic Load Balancing (ELB) resources in AWS, such as changes to load balancer configurations, target groups, and listeners. In CloudTrail, these events indicate when an ELB\\u2019s setup is altered, which can affect traffic routing, availability, and security posture.\\n\\n**Purpose:**  \\nTo monitor and audit any configuration changes to ELB components that could impact application availability or security.\\n\\n**Alert Threshold:**  \\nTrigger an alert if the number of ELB modification events exceeds a defined threshold within a short time window (e.g., more than 3 Modify* events within 10 minutes), as this may indicate unintended or unauthorized changes.\\n\\n**Impact of Values:**  \\n- **High frequency of Modify* events:** Could signal potential misconfigurations, automated deployment issues, or malicious activity altering load balancer behavior, risking downtime or security breaches.  \\n- **Low or no Modify* events:** Typically expected during stable operation; absence of changes suggests configuration stability.\\n\\n**Example Usage:**  \\nIn a monitoring dashboard or alert rule, track the count of **{\\\"EventSource\\\": \\\"elasticloadbalancing.amazonaws.com\\\", \\\"EventName\\\": \\\"Modify*\\\"}** events over rolling 10-minute intervals. Configure alerts to notify the SRE team when this count spikes above the threshold, enabling prompt investigation and rollback if necessary.\", \" - This pattern detects CloudTrail events where CloudWatch resources are created, such as alarms, dashboards, and log groups. Its purpose is to monitor the provisioning of new CloudWatch components, which can indicate changes in monitoring coverage or potential configuration drift. An alert should be triggered when the number of creation events exceeds a defined threshold within a short time window (e.g., more than 5 Create* events in 10 minutes), as a sudden spike may signal automated deployments, misconfigurations, or unauthorized activity. Conversely, a prolonged absence of creation events might suggest stagnation in monitoring updates or missed deployments. For example, in a monitoring dashboard, you can visualize the count of CloudWatch Create* events over time and set an alert rule to notify the SRE team if the event count surpasses the threshold, enabling timely investigation and response to unexpected changes in monitoring infrastructure.\", \" - This pattern detects SNS topic creation events recorded in CloudTrail, specifically any API calls starting with \\\"Create\\\" from the SNS service (e.g., CreateTopic). It helps SREs monitor when new SNS topics are provisioned, which can indicate changes in messaging architecture or potential unauthorized resource creation. An alert threshold could be set on the number of Create* events within a given time window (e.g., more than 5 topic creations in 10 minutes), as a sudden spike may signal automation errors or security issues. Low or expected values typically indicate normal operations, while high values may impact system stability by increasing resource usage or indicate potential misuse. For example, an alert rule could trigger if the count of {\\\"EventSource\\\": \\\"sns.amazonaws.com\\\", \\\"EventName\\\": \\\"Create*\\\"} events exceeds 5 in 10 minutes, and a dashboard widget could display a time series graph of topic creation events to track trends and detect anomalies.\"]}": {
            "cached_metrics_data": [
                {
                    "metric_data": {
                        "name": "Metric Description Quality [GEval]",
                        "threshold": 0.8,
                        "success": true,
                        "score": 0.9,
                        "reason": "The Retrieval Context directly addresses the Input question by explaining what Start* events represent, their significance, and the implications of exceeding ten events, including potential automated scaling, misconfiguration, or security incidents. It provides clear alert thresholds, impact of values, and example usage, enabling confident interpretation of the monitoring question. The description is detailed yet concise and focused, covering measurement, units, context, and consequences, though it could be slightly more explicit about the exact unit of measurement (e.g., count within a time window) for perfect clarity.",
                        "strictMode": false,
                        "evaluationModel": "gpt-4.1-mini",
                        "evaluationCost": 0,
                        "verboseLogs": "Criteria:\n\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n \n \nEvaluation Steps:\n[\n    \"Compare the Input (monitoring question) with the Retrieval Context (metric description) to ensure the description clearly addresses the question.\",\n    \"Evaluate the clarity of the Retrieval Context by checking if it is concise and easily understandable in relation to the user's monitoring question.\",\n    \"Assess the coverage of the Retrieval Context by verifying that it explains what is measured, unit definitions, relevant context, and implications tied to the Input.\",\n    \"Determine the utility by judging if the description enables the user to confidently answer the monitoring question based on the information provided.\"\n] \n \nRubric:\nNone \n \nScore: 0.9"
                    },
                    "metric_configuration": {
                        "threshold": 0.8,
                        "evaluation_model": "gpt-4.1-mini",
                        "strict_mode": false,
                        "criteria": "\nYou are an expert in cloud telemetry and documentation.\nGiven a metric description and a related monitoring question, evaluate the quality of the description on a scale from 1 (poor) to 10 (excellent) based on:\n- Clarity: Is the description understandable and concise?\n- Coverage: Does it explain what is measured, units, context, and implications?\n- Utility: Can this description help a user answer the provided question?\nIf the score is less than 8, provide a concrete suggestion for improvement.\n\nIMPORTANT RULES:\n- Respond ONLY with a JSON object.\n- Do NOT include any text before or after the JSON.\n- If unsure, output a JSON with {\"score\":1,\"reason\":\"Invalid description\",\"suggestion\":\"Review input\"}.\n\nIMPORTANT: Your entire response MUST be valid JSON, and nothing else. Do not include code blocks, explanations, or any extra text. Only output this object:\n{\n  \"score\": <integer from 1 to 10>,\n  \"reason\": \"<brief rationale>\",\n  \"suggestion\": \"<concrete suggestion, or null if score >= 8>\"\n}\n\nDescription:\n{context}\nQuestion:\n{input}\n",
                        "include_reason": false,
                        "evaluation_steps": [
                            "Compare the Input (monitoring question) with the Retrieval Context (metric description) to ensure the description clearly addresses the question.",
                            "Evaluate the clarity of the Retrieval Context by checking if it is concise and easily understandable in relation to the user's monitoring question.",
                            "Assess the coverage of the Retrieval Context by verifying that it explains what is measured, unit definitions, relevant context, and implications tied to the Input.",
                            "Determine the utility by judging if the description enables the user to confidently answer the monitoring question based on the information provided."
                        ],
                        "evaluation_params": [
                            "input",
                            "retrieval_context"
                        ]
                    }
                }
            ]
        }
    }
}
